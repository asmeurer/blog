<!DOCTYPE html>
<html prefix="
        og: http://ogp.me/ns#
        article: http://ogp.me/ns/article#
    " lang="en">
    <head>
    <meta charset="utf-8">
    <meta name="description" content="My blog">
    <meta name="viewport" content="width=device-width">
    <title>Aaron Meurer's Blog (old posts, page 3) | Aaron Meurer's Blog</title>

    
            <link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">

    
            <link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">

      <link rel="canonical" href="http://asmeurer.github.io/index-3.html">



    
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
   tex2jax: {
       inlineMath: [ ['$','$'], ["\\(","\\)"], ['$ latex','$'], ['$latex','$'] ],
       displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
   },
   displayAlign: 'left', // Change this to 'center' to center equations.
   "HTML-CSS": {
       styles: {'.MathJax_Display': {"margin": 0}}
   }
});
</script>

        <!--[if lt IE 9]><script src="/assets/js/html5.js"></script><![endif]-->

    
<link rel="stylesheet" type="text/css" href="assets/css/tipuesearch.css">
</head>
<body>
<div id="tipue_search_content" style="margin-left: auto; margin-right: auto; padding: 20px;"></div>







<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container-fluid">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://asmeurer.github.io/">Aaron Meurer's Blog</a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                
                <li>
<a href="archive.html">Archives</a>
                </li>
<li>
<a href="categories/index.html">Tags</a>
                </li>
<li>
<a href="rss.xml">RSS</a>

            </li>
</ul>
                
<span class="navbar-form pull-left">
<input type="text" id="tipue_search_input">
</span>

            <ul class="nav navbar-nav navbar-right">
                
                
                    
            </ul>
        </div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container-fluid -->
</nav>

<!-- End of Menubar -->

<div class="container">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
<div class="postindex">
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/06/04/pudb-a-better-python-debugger/" class="u-url">PuDB, a better Python debugger</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/06/04/pudb-a-better-python-debugger/" rel="bookmark"><time class="published dt-published" datetime="2010-06-04T20:59:17-05:00" itemprop="datePublished" title="Publication date">2010-06-04 20:59</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/06/04/pudb-a-better-python-debugger/#disqus_thread" data-disqus-identifier="cache/posts/2010/06/04/pudb-a-better-python-debugger.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>So  <a href="http://haz-tech.blogspot.com/">Chris­tian Muise</a>  un­wit­ting­ly just re­mind­ed me on IRC that I for­got to men­tion the main method that I used to learn how the heurisch func­tion works in my last blog post.  I usu­al­ly on­ly use a de­bug­ger when I have a re­al­ly hard bug I need to fig­ure out, when the print state­ments aren't enough.  The rea­son for this is that the de­bug­ger that I had been us­ing, win­pdb, is, well, a pain to use.  There are so many lit­tle bugs, at least in Mac OS X, that it is al­most not worth while to use it un­less I need to.  For ex­am­ple, restart­ing a script from the de­bug­ger does­n't work.  If I pass a point that I want­ed to see, I have to com­plete­ly close the win­pdb win­dow and restart it from the com­mand line, which takes about half a minute.  Al­so, win­pdb us­es it's own vari­ant of pdb, which seems to cause more prob­lems than it cre­ates (like bug­ging me about sympy im­port­ing pdb some­where  <em>ev­ery time</em>  I start de­bug­ging.)</p> 
 <p>But I re­al­ly want­ed to be able to step through the heurisch code to see ex­act­ly how it work­s, be­cause many of the im­ple­men­ta­tion de­tail­s, such as gath­er­ing the com­po­nents of an ex­pres­sion, will be sim­i­lar if not ex­act­ly the same in the full al­go­rith­m.  So I start­ed my quest for a bet­ter de­bug­ger.  For me, the ide­al de­bug­ger is the C de­bug­ger in XCode.  That de­bug­ger has saved me in most of my pro­gram­ming as­sign­ments in C.  But it is on­ly for C based lan­guages (C, Ob­jec­tive-C, prob­a­bly C++, …), not Python.  So I did a Google search, and it turns out that there is a list of Python de­bug­gers  <a href="http://wiki.python.org/moin/PythonDebuggers">here</a>.  So I went through them, and I did­n't have to go far.  The very first one,  <a href="http://pypi.python.org/pypi/pudb">pudb</a>, turns out to be awe­some!</p> 
 <p>You can watch this  <a href="http://vimeo.com/5255125">screen­cast</a>  to get a bet­ter idea of the fea­tures, or even bet­ter in­stall it and check them out.  The de­bug­ger runs in the con­sole, not in some half-hacked GUI (half-hacked is what any non-­Co­coa GUI looks like in Mac OS X).  The on­ly down side to this is that you have to use the key­board to do ev­ery­thing, but it ends up not be­ing too bad.  And you can press '?' at any time to see the pos­si­ble com­mand­s.   </p> 
 <p>To in­stall it, just do  <code>easy_in­stall pudb</code>.  To run it, just cre­ate a script of what you want to de­bug, and do  <code>python -m pud­b.run my-scrip­t.py  </code>  and it just work­s! I have a line that says  <code>alias pud­b='python -m pud­b.run'</code>  in my  <code>.pro­file</code>, which makes it even eas­i­er to run.  If you want to set a break point in the code, you can ei­ther nav­i­gate there from with­in pudb by press­ing 'm', or you add a line that says  <code>from pudb im­port set_­trace; set_­trace()</code>  to the code (if you add the line to your code, you don't even need to cre­ate a scrip­t.  Just ex­e­cute the code in IPython and when it hits that line, it will load the de­bug­ger).   </p> 
 <p>Some cool fea­tures:</p> 
 <ul>
<li> 
 <p>IPython con­­sole.  Just press '!' to go to a con­­sole, where you can ma­nip­u­late var­i­ables from the ex­e­­cut­ed names­­pace, and you can choose an IPython con­­sole.    </p>  
  </li> 
 <li> 
 <p>Very easy to nav­i­­gate.  You just need to know the keys 's', 'n', and 't'.    </p>  
  </li> 
 <li> 
 <p>View the code from else­where than what is be­ing run.  Press­ing 'm' lets you view all im­­port­ed mod­­ules.  You can eas­i­­ly view points on the stack by choos­ing them.    </p>  
  </li> 
 <li> 
 <p>If an ex­­cep­­tion is thrown, it   <em>catch­es it</em>!  This may sound ob­vi­ous for a de­bug­ger, but it is one of things that did­n't work very well in win­pdb.  You can view the trace­back of the ex­­cep­­tion, and choose to restart   <em>with­­out hav­ing to close and re­open the de­bug­ger</em>.  Ac­­tu­al­­ly, it asks you if you want to restart ev­ery time the script fin­ish­es too, which is al­­so a great im­prove­­ment over win­pdb.    </p>  
  </li> 
 </ul>
<p>This is what it looks like.  Click for a big­ger pic­ture:</p> 
 <p><a href="2010/06/pudb.png"><img src="2010/06/pudb.png" alt="" title="PuDB" width="450" height="298" class="size-full wp-image-401"></a></p> 
 <p>Some an­noy­ances (in case An­dreas Kloeck­n­er reads this):</p> 
 <ul>
<li> 
 <p>The de­­fault dis­­­play for var­i­ables is type, which is com­­plete­­ly use­­less. I have to man­u­al­­ly go through and change each to str so I can see what the var­i­able is.  Is there a way to change this de­­fault?</p>  
  </li> 
 <li> 
 <p>It asks me ev­ery time if I want to use IPython.  I al­ways want to use IPython.</p>  
  </li> 
 <li> 
 <p>This is might be a Mac OS X Ter­mi­­nal bug, but when I ex­e­­cute a state­­ment that takes a while to run, it does­n't re­­draw the pudb win­­dow un­til it fin­ish­es.  This means that step­ping through a pro­­gram "flash­es" black from what is above pudb in the win­­dow, and if I run a state­­ment that takes forever, I loose the abil­i­­ty to see where it is un­­less I key­board in­­ter­rup­t. For­­tu­­nate­­ly, it catch­es key­board in­­ter­rup­t­s, so I can still see the trace­back.</p>  
  </li> 
 <li> 
 <p>There is no way to re­­size the var­i­ables win­­dow, or to scroll side­ways in it.  If I want to see what a long var­i­able ex­pres­­sion is, I have to go to the IPython con­­sole and type it there.   </p>  
  </li> 
 </ul>
<p>Some of these might be fix­able and I just don't know it yet.  But even with them, this is still an or­der of mag­ni­tude im­prove­ment over win­pdb.  Now I can ac­tu­al­ly use the de­bug­ger all the time in my cod­ing, in­stead of just when I have a re­al­ly tough bug and no oth­er choice.   </p> 
 <p>UP­DATE:</p> 
 <p>The first two were triv­ial to fix in a fork of the repos­i­to­ry (is­n't open source awe­some?).  So if those are both­er­ing you too, check out my branch­es at  <a href="http://github.com/asmeurer/PuDB">http://github.­com/as­meur­er/PuDB</a>.  Maybe if I have some time I will make them glob­al op­tions us­ing en­vi­ron­ment vari­ables or some­thing and  see if An­dreas wants to merge them back in­to the main re­po.   </p> 
 <p>As for the sec­ond one, I re­al­ized that it might be a good thing, be­cause you can see any­thing that is print­ed.  Stil­l, I would pre­fer see­ing both, if pos­si­ble (and the black flash­es are an­noy­ing).   </p> 
 <p>UP­DATE 2:</p> 
 <p>You can re­size the side view by push­ing +/-, though there does­n't seem to be a way to, say, make the vari­ables view big­ger and the break­points view small­er.  </p> 
 <p>UP­DATE 3:</p> 
 <p>A while back On­drej mod­i­fied the code to have a dif­fer­ent col­or the­me, and I fol­lowed suit.  See  <a href="https://github.com/certik/PuDB/commit/38fed5024d022c5d6d1961c917026e021a833a9e#comments">this con­ver­sa­tion at GitHub</a>.  So now, in­stead of look­ing like a DOS ter­mi­nal, in PuDB for me looks like this:</p> 
 <p><a href="2010/07/screen-shot-2010-07-28-at-12-51-36-pm.png"><img src="2010/07/screen-shot-2010-07-28-at-12-51-36-pm.png" alt="PuDB XCode Midnight Theme Colors" title="PuDB XCode Midnight Theme Colors" width="450" height="360" class="size-full wp-image-682"></a>   This is ex­act­ly the same col­ors as my code in XCode, the ed­i­tor I use, with the Mid­night Theme.  It's pret­ty easy to change the col­ors to what­ev­er you wan­t.  Right now, you have to ed­it the source, but On­drej or I might some­day make it so you can have themes.   </p> 
 <p>Al­so, hav­ing used this all sum­mer (and it was a life-saver hav­ing it in mul­ti­ple oc­ca­sion­s, and I am sure made my de­vel­op­ment speed at least twice as fast in oth­er­s), I have one ad­di­tion­al gripe.  It is too dif­fi­cult to ar­row up to the vari­able that you want to ac­cess in the vari­ables view.  It would be nice to have a page up­/­page down fea­ture there.   </p> 
 <p>UP­DATE 4: PuDB has since im­proved a lot, in­clude many fix­es by my­self. It now sup­ports themes, saved set­tings, vari­able name wrap­ping, and more. See  <a href="http://asmeurersympy.wordpress.com/2011/08/08/hacking-pudb-now-an-even-better-python-debugger/">this fol­lowup post</a>.  </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/06/04/update-for-this-week/" class="u-url">Update for this week</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/06/04/update-for-this-week/" rel="bookmark"><time class="published dt-published" datetime="2010-06-04T18:45:26-05:00" itemprop="datePublished" title="Publication date">2010-06-04 18:45</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/06/04/update-for-this-week/#disqus_thread" data-disqus-identifier="cache/posts/2010/06/04/update-for-this-week.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>So I start­ed writ­ing up a blog post on how ra­tio­nal func­tion in­te­gra­tion work­s, but On­drej  <a href="http://groups.google.com/group/sympy/browse_thread/thread/7d7dceb34db45302">wants a blog post</a>  ev­ery week by the end of I don't think I would do it jus­tice by rush­ing to fin­ish it now (read: I'm to lazy to do it).  So in­stead, I'll just give a short post (if that's pos­si­ble for me) on what I have been do­ing this week.   </p> 
 <p>I fin­ished up writ­ing doctests for the poly­no­mi­als mod­ule for now (see  <a href="http://code.google.com/p/sympy/issues/detail?id=1949">is­sue 1949</a>), so now this week I start­ed look­ing at the in­te­gra­tor.  In par­tic­u­lar, I went through each of the 40 is­sues with the  <a href="http://code.google.com/p/sympy/issues/list?q=label:Integration">In­te­gra­tion la­bel</a>  and added them to a test file that I can mon­i­tor through­out the sum­mer to see my progress.  It is the test_­fail­ing_in­te­gral­s.py file in my  <a href="http://github.com/asmeurer/sympy/tree/integration">In­te­gra­tion branch</a>, where all my work will be go­ing for the fore­see­able fu­ture.  So if you want to fol­low my work, fol­low that branch.  Here are some ob­ser­va­tions from those is­sues:</p> 
 <ul>
<li> 
 <p>in­­te­­grate() can't han­­dle al­­most all al­ge­bra­ic in­­te­­grals (func­­tions with square root­s, etc.).  It can han­­dle the de­riv­a­­tive of ar­c­sin and ar­c­s­inh be­­cause of spe­­cial code in heurisch.py, but that's about it.  Be­­fore I can do any work on the Al­ge­bra­ic Risch Al­­go­rith­m, I will need to im­­ple­­ment the tran­s­cen­­den­­tal al­­go­rith­m, so I think my tem­po­rary so­lu­­tion for this may be to add pat­tern match­ing heuris­tics for some of the more com­­mon al­ge­bra­ic in­­te­­grals (any­one know a good in­­te­­gral table?).    </p>  
  </li> 
 <li> 
 <p>I fig­ured out why in­­te­­grate hangs for­ev­er with some in­­te­­gral­s, such as the one in   <a href="http://code.google.com/p/sympy/issues/detail?id=1441">is­­sue 1441</a>.  Here is, in a nut­shel­l, how the Heuris­tic Risch al­­go­rithm work­s:  Take the in­­te­­grand and split it in­­­to com­po­­nents.  For ex­am­­ple, the com­po­­nents of x<em>cos(x)</em>sin(x)<strong>2 are [x, cos(x), sin(x)].  Re­­place each of these com­po­­nents with a dum­my var­i­able, so if x = x0, cos(x) = x1, and sin(x) = x2, then the in­­te­­grand is x0<em>x1</em>x2</strong>2.  Al­­so, com­­pute the de­riv­a­­tive of each com­po­­nent in terms of the dum­my var­i­ables.  So the de­riv­a­­tives of [x0, x1, x2] are [1, -x2, 2<em>x1</em>x2].  Then, us­ing the­se, per­­form some mag­ic to cre­ate some ra­­tio­­nal func­­tions out of the com­po­­nent dum­my var­i­ables.  Then, cre­ate a can­di­­date in­­te­­gral with a bunch of un­­knowns [A1, A2, …], which will be ra­­tio­­nal num­ber­s, and a mul­ti­­no­mi­al of the An's and the xn's that should equal 0 if the can­di­­date in­­te­­gral is cor­rec­t.  Then, be­­cause the xn's are not 0, and there is al­­so some al­ge­bra­ic in­­de­pen­­dence, you have the the An co­e­f­­fi­­cients of each term must equal 0.  So you get a sys­tem of lin­ear equa­­tions in the An's.  You then solve these equa­­tion­s, and plug the val­ues of the An's in­­­to the can­di­­date in­­te­­gral to give you the so­lu­­tion, or, if the sys­tem is in­­­con­­sis­ten­t, then if can­not find a so­lu­­tion, pos­si­bly be­­cause there is no el­e­­men­­tary one.    </p>  
  </li> 
 </ul>
<p>Well, that over sim­pli­fies a lot of things, but the point I want to make is that the in­te­gral from is­sue 1441 cre­ates a sys­tem of ~600 lin­ear equa­tions in ~450 vari­ables, and solv­ing that equa­tion is what caus­es the in­te­gra­tion to hang.  Al­so, as Ma­teusz, my men­tor and the one who wrote the cur­rent in­te­gra­tion im­ple­men­ta­tion, point­ed out, quite a bit of time is spent in the heurisch al­go­rithm do­ing ex­pan­sion on large Ba­sic poly­no­mi­al­s.  When I say Ba­sic poly­no­mi­al­s, I mean that they are SymPy ex­pres­sion­s, in­stead of Poly in­stances.  Us­ing Poly should speed things up quite a bit, so my next move will be to con­vert heurisch() in­to us­ing Poly wher­ev­er ap­pli­ca­ble.   </p> 
 <ul>
<li> 
 <p>There were a few bugs in the ra­­tio­­nal in­­te­­gra­­tion, which I fixed in my branch.  The prob­lem was in ra­­tio­­nal in­­te­­grals with sym­bol­ic co­e­f­­fi­­cients.  Be­­cause the new polys are able to cre­ate poly­no­mi­als us­ing any ex­pres­­sion as a gen­er­a­­tor, not just sym­bol­s, things like Poly(s­in(y)<em>x, x) cre­ates Poly(s­in(y)</em>x, x, do­­main='Z­Z[s­in(y)]').  But us­ing the poly­no­mi­al ring or frac­­tion field cre­ates prob­lems with some things like di­vi­­sion, where­as we re­al­­ly on­­ly want the do­­main to be EX (ex­pres­­sion do­­main) in this case.  So this was not too dif­­fi­cult to fix, and you can see the fix in my in­­te­­gra­­tion branch.    </p>  
  </li> 
 <li> 
 <p>Some in­­te­­grals will re­quire some good im­­ple­­men­­ta­­tion of spe­­cial func­­tions such as the hy­per­ge­o­met­ric func­­tion to work.  Some­­times, you don't want to know what the non-ele­­men­­tary in­­te­­gral looks like, but you just want to cal­cu­late a de­f­i­nite in­­te­­gral.  The so­lu­­tion here is to use Mei­­jer-G func­­tion­s, which are on the list of things to pos­si­bly do at the end of the sum­mer if I have time.</p>  
  </li> 
 <li> 
 <p>An­oth­er bug that I plan on fix­ing (I haven't done it yet, but I know how to do it and it will be triv­ial), is this (<a href="http://code.google.com/p/sympy/issues/detail?id=1888">is­­sue 1888</a>):</p>  
  </li> 
 </ul>
<p>In [18]: print in­te­grate(f(x).d­if­f(x)**2, x)</p> 
 <p>2<em>D(f(x), x)</em>f(x)/3 - 2<em>x</em>D(f(x), x, x)<em>f(x)/3 + x</em>D(f(x), x)**2/3</p> 
 <p>The prob­lem is in the step where it com­putes the de­riv­a­tive of the com­po­nents, it tries to com­pute the de­riv­a­tive of f(x).d­if­f(x) in terms of a dum­my vari­able, but it re­duces to 0 be­cause dif­f(x2, x) == 0.  Thus, it treats f(x).d­if­f(x) like some­thing that has a 0 third deriva­tive, i.e., x**2.   </p> 
 <p>Well that's it.  I knew I could­n't make a short blog post :).  If you want to help, I have three branch­es that need re­view (<a href="http://code.google.com/p/sympy/issues/detail?id=1883">1</a>,  <a href="http://code.google.com/p/sympy/issues/detail?id=1949">2</a>,  <a href="http://code.google.com/p/sympy/issues/detail?id=1843">3</a>), and ex­cept for the last one, my work is based on top of the oth­er two, so none of my in­te­gra­tion work can be pushed in un­til those two re­viewed pos­i­tive­ly.   </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/05/26/more-information-on-my-google-summer-of-code-project-this-year/" class="u-url">More information on my Google Summer of Code project this year</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/05/26/more-information-on-my-google-summer-of-code-project-this-year/" rel="bookmark"><time class="published dt-published" datetime="2010-05-26T17:33:38-05:00" itemprop="datePublished" title="Publication date">2010-05-26 17:33</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/05/26/more-information-on-my-google-summer-of-code-project-this-year/#disqus_thread" data-disqus-identifier="cache/posts/2010/05/26/more-information-on-my-google-summer-of-code-project-this-year.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>So, as I not­ed  <a href="http://asmeurersympy.wordpress.com/2010/04/26/gsoc-2010/trackback/">here</a>, I have been ac­cept­ed in­to the Google Sum­mer of Code pro­gram again this year.  I men­tioned that my project in­volved im­prov­ing the in­te­gra­tor, but I did­n't say much oth­er than that.  So here I plan on say­ing a bit more.  If you want more de­tail­s, you can read my ap­pli­ca­tion  <a href="http://wiki.sympy.org/wiki/User:Asmeurer/GSoC2010_Application">on the SymPy wi­ki</a>.   </p> 
 <p>My goal is to im­prove the in­te­gra­tor in SymPy, in oth­er word­s, the back end to the  <code>in­te­grate()</code>  func­tion.  This is no easy task.  Cur­rent­ly, SymPy has a pret­ty dec­net in­te­gra­tion en­gine.  It is even able to solve some in­te­grals that no oth­er sys­tem is known to be able to solve (the sec­ond in­te­gral  <a href="http://en.wikipedia.org/wiki/Risch_algorithm#Implementation">here</a>). But, as I dis­cov­ered of­ten many times through­out my work on ODEs last year, the in­te­gra­tor can of­ten leave some­thing to be de­sired.  There are two prob­lems that I hope to ad­dress.   </p> 
 <p>First, the in­te­gra­tor of­ten fails on el­e­men­tary in­te­gral­s.  This is be­cause all of the in­te­gra­tion in SymPy is based on a heuris­tic called the Risch-Nor­man al­go­rith­m.  Sym­bol­ic in­te­gra­tion has been com­plete­ly solved in the form of the Risch al­go­rith­m, mean­ing that there ex­ists an al­go­rithm to de­ter­mine if an el­e­men­tary func­tion has an el­e­men­tary anti­deriv­a­tive or not, and to find it if it does.  This al­go­rith­m, called the Risch al­go­rith­m, is ex­treme­ly com­pli­cat­ed, to the ex­tent that no com­put­er al­ge­bra sys­tem has ev­er com­plete­ly im­ple­ment­ed all the parts of it.  My plan is to be­gin im­ple­ment­ing the full al­go­rithm in SymPy.  I don't ex­pect to fin­ish the whole thing -- as I said no one ev­er has.  Rather, I hope to make a good head­way in­to what is known as the tran­scen­den­tal part.  The Risch al­go­rithm is bro­ken up in­to four part­s: ra­tio­nal part, the tran­scen­den­tal part, the al­ge­bra­ic part, and the mixed part.   </p> 
 <p>The ra­tio­nal part is in­volves in­te­grat­ing ra­tio­nal func­tions (func­tions of the form $la­tex \frac{a_nx^n + a_{n-1}x^{n-1} + \c­dots + a_2x^2 + a_1x + a_0}{b_nx^n + b_{n-1}x^{n-1} + \c­dots + b_2x^2 + a_1x + a_0}$).  The ra­tio­nal part is the eas­i­est part in the sense that the al­go­rithm is the sim­plest, and al­so that all ra­tio­nal func­tion in­te­grals are el­e­men­tary (a term that I will de­fine lat­er).  Ra­tio­nal func­tion in­te­gra­tion is al­ready im­ple­ment­ed in sympy in ful­l, though I may give a brief out­line of how it works in a lat­er post.   </p> 
 <p>The tran­scen­den­tal part is the part that I will be im­ple­ment­ing this sum­mer.  My guide will be  <a href="http://www.amazon.com/Symbolic-Integration-Transcendental-Computation-Mathematics/dp/3540214933/ref=sr_1_fkmr0_2?ie=UTF8&amp;qid=1274894380&amp;sr=8-2-fkmr0"><em>Sym­bol­ic In­te­gra­tion I: Tran­scen­den­tal Func­tions</em>  by Manuel Bron­stein</a>, which de­scribes and proves the tran­scen­den­tal part of the al­go­rithm in some 300+ pages.  I will try to ex­plain a lit­tle of how the al­go­rithm works in some blog post­s, but un­der­stand that it is very com­plex.  There­fore, I will prob­a­bly ex­plain it with­out prov­ing things.  If you are in­ter­est­ed in buy­ing the book and learn­ing the al­go­rithm rig­or­ous­ly, the on­ly pre­req­ui­sites that I can tell are cal­cu­lus (so you know what an in­te­gral and a de­riv­a­tive are), and a se­mes­ter of ab­stract al­ge­bra (y­ou need to know about rings, field­s, ide­al­s, ho­mo­mor­phism­s, etc., as well as the var­i­ous the­o­rems re­lat­ing them).   </p> 
 <p>In the book, I am still in the part that de­vel­ops the the­o­ry called dif­fer­en­tial al­ge­bra nec­es­sary to prove the in­te­gra­tion al­go­rithm cor­rec­t.  So to be­gin the GSoC pro­gram, I am work­ing on learn­ing the polys mod­ule in sympy.  My method of do­ing this is to write doctests for all the func­tions in the mod­ule.  It's a daunt­ing task, but it's been prob­a­bly the best way of learn­ing how a com­put­er mod­ule works that I have ev­er tried.  You re­al­ly have to un­der­stand all as­pects of a func­tion to write a doctest for it, the types of the pa­ram­e­ters and re­turn val­ue, as well as what the al­go­rithm is ac­tu­al­ly do­ing.  It's es­pe­cial­ly help­ful that the code for the func­tions is right be­low the doc­string for each func­tion, so I can see how it re­al­ly works on the in­sid­e, re­mov­ing the mys­tery of the mod­ule.  Fur­ther­more, it will serve as a ref­er­ence for me for the re­main­der of the sum­mer, as well for any­one else who wants to learn the polys mod­ule, or just needs to de­bug it.  I've al­so ran in­to sev­er­al bugs and in­ef­fi­cien­cies in the mod­ule that I have tak­en the lib­er­ty of fix­ing.   </p> 
 <p>Well that's it for this post.  If you want to fol­low my progress on the doctest­s, my branch is  <a href="http://github.com/asmeurer/sympy/tree/polydocs-polys9">http://github.­com/as­meur­er/sympy/tree/poly­doc­s-polys9</a>.  Note that the branch will be very un­sta­ble un­til I fin­ish at some point at the end of this week or the be­gin­ning of the nex­t.   </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/04/26/gsoc-2010/" class="u-url">GSoC 2010</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/04/26/gsoc-2010/" rel="bookmark"><time class="published dt-published" datetime="2010-04-26T22:05:39-05:00" itemprop="datePublished" title="Publication date">2010-04-26 22:05</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/04/26/gsoc-2010/#disqus_thread" data-disqus-identifier="cache/posts/2010/04/26/gsoc-2010.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>So I ap­plied for Google Sum­mer of Code again this year, and I got ac­cept­ed!  I will post more here lat­er, but you can read the pro­pos­al ab­stract  <a href="http://socghop.appspot.com/gsoc/student_project/show/google/gsoc2010/python/t127230762920">here</a>.  The project is to im­prove the in­te­gra­tor in SymPy, mak­ing it faster, and able to solve more in­te­gral­s.   </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/04/06/latest-sympy-makes-it-to-fink/" class="u-url">Latest SymPy makes it to Fink</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/04/06/latest-sympy-makes-it-to-fink/" rel="bookmark"><time class="published dt-published" datetime="2010-04-06T19:41:16-05:00" itemprop="datePublished" title="Publication date">2010-04-06 19:41</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/04/06/latest-sympy-makes-it-to-fink/#disqus_thread" data-disqus-identifier="cache/posts/2010/04/06/latest-sympy-makes-it-to-fink.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>Look at this screen­shot:
 <a href="2010/04/screen-shot-2010-04-06-at-1-25-10-pm.png"><img src="2010/04/screen-shot-2010-04-06-at-1-25-10-pm.png" alt="" title="SymPy makes it to Fink" width="450" height="112" class="alignnone size-full wp-image-364"></a></p> 
 <p>So the lat­est ver­sion of SymPy fi­nal­ly made it in­to  <a href="http://www.finkproject.org/">fink</a>.  Nor­mal­ly, this would­n't be that ex­cit­ing, but be­fore this, the most re­cent ver­sion in fink was 0.6.4, which was be­fore I ev­er joined the pro­jec­t, with the ex­cep­tion of two com­mit­s.  So this is the first ver­sion on fink to in­clude all of my con­tri­bu­tion­s, in­clud­ing my 2009 Google Sum­mer of Code work.   </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2009/12/29/automatically-remove-trailing-whitespace-in-xcode/" class="u-url">Automatically Remove Trailing Whitespace in XCode</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2009/12/29/automatically-remove-trailing-whitespace-in-xcode/" rel="bookmark"><time class="published dt-published" datetime="2009-12-29T23:56:46-06:00" itemprop="datePublished" title="Publication date">2009-12-29 23:56</time></a></p>
                <p class="commentline">
        
    <a href="posts/2009/12/29/automatically-remove-trailing-whitespace-in-xcode/#disqus_thread" data-disqus-identifier="cache/posts/2009/12/29/automatically-remove-trailing-whitespace-in-xcode.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>I like XCode, and I use it to ed­it all of my source for SymPy.   But, like many ed­i­tors, it likes to au­to-in­dent new lines to the lev­el of in­den­ta­tion of the pre­vi­ous line.  This is a use­ful fea­ture, but it makes for train­ing white­space out the wa­zoo, since blank lines will be in­dent­ed in.  I am con­stant­ly find­ing my­self us­ing SymPy's strip_whites­pace script to clean up my files.   </p> 
 <p>This bugged me enough that I Googled a so­lu­tion, and found  <a href="http://code.google.com/p/google-toolbox-for-mac/wiki/GTMXcodePlugin">this</a>.  It is a sim­ple XCode plug­in that, among oth­er things, adds an op­tion to strip trail­ing white­space on save.  Just in­stall in the Plug­Ins fold­er in the XCode pack­age and en­able the op­tion in the new Google pane of the XCode pref­er­ences.   </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2009/11/13/how-to-get-both-32-bit/" class="u-url">How to get both 32-bit and 64-bit Python in Snow Leopard</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2009/11/13/how-to-get-both-32-bit/" rel="bookmark"><time class="published dt-published" datetime="2009-11-13T01:16:42-06:00" itemprop="datePublished" title="Publication date">2009-11-13 01:16</time></a></p>
                <p class="commentline">
        
    <a href="posts/2009/11/13/how-to-get-both-32-bit/#disqus_thread" data-disqus-identifier="cache/posts/2009/11/13/how-to-get-both-32-bit.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>We had some dis­cus­sion on one of the Python is­sues about whether my Python in Snow Leop­ard should be 32-bit or 64-bit.  I orig­i­nal­ly thought that it was tied to what the ker­nel was, but I turned out to be wrong.  </p> 
 <p>From what I dis­cov­ered, the im­por­tant thing is what the Python was com­piled as.  You can tell what your Python has been com­piled as by run­ning:</p> 
 <p><code></code></p> 
 <p>&gt;&gt;&gt; im­port sys</p> 
 <p>&gt;&gt;&gt; from math im­port log</p> 
 <p>&gt;&gt;&gt; log(sys.­max­size, 2)</p> 
 <p></p> 
 <p>If this is just un­der 31, then it is 32 bit.  If it re­turns 63, then it is 64.  An eas­i­er way to tell it to run:</p> 
 <p><code></code></p> 
 <p>&gt;&gt;&gt; 2**40</p> 
 <p></p> 
 <p>If you get 1099511627776L, then you have 32-bit Python, if you get 1099511627776, you have 64-bit Python (no­tice that the num­ber is long in 32-bit Python, be­cause it is larg­er than max­in­t).   </p> 
 <p>This test won't work in Python 3 be­cause all in­te­gers are "long" by de­fault, but the first part will still work.   </p> 
 <p>So why does this mat­ter, you ask?  Well, aside from the fact that much longer num­bers are not long (any­thing less than 2**63 - 1 = 9223372036854775807), there is the is­sue of hash­ing.  </p> 
 <p>In 64-bit Python:</p> 
 <p><code></code></p> 
 <p>&gt;&gt;&gt; hash('a')</p> 
 <p>12416037344</p> 
 <p></p> 
 <p>but in 32-bit Python</p> 
 <p><code></code></p> 
 <p>&gt;&gt;&gt; hash('a')</p> 
 <p>-468864544</p> 
 <p></p> 
 <p>SymPy us­es hash val­ues to or­der ar­gu­ments, so of­ten it hap­pens that be­hav­ior in one ar­chi­tec­ture will not show up in the oth­er.  These prob­lems are of­ten hard to track and fix, but the worst is when things work fine on the ma­chine you are work­ing on.  This ac­tu­al­ly hap­pened to me with my GSoC projec­t.  I was renum­ber­ing the ar­bi­trary con­stants in the print­ing or­der in an ex­pres­sion, but it turned out that the print­ing or­der of an ex­pres­sion can be de­pen­dent on .args or­der, so I had to mod­i­fy the tests to can­on­ize the num­ber­ing first.</p> 
 <p>So here comes the crux of the post.  It turns out that on Mac OS X, if you in­stall the bi­na­ry from python.org (Mac In­stall­er Disk Im­age), this in­stalls a 32-bit Python (for com­pat­i­bil­i­ty rea­son­s) in /Li­brary/Frame­work­s/Python.frame­work/Ver­sion­s/2.6/bin/python2.6</p> 
 <p>.  How­ev­er, if you in­stall Python us­ing 64-bit fink in Snow Leop­ard, it will com­pile it from source in­to 64-bit, and in­stall it in­to /sw/bin/python2.6.   </p> 
 <p>So now I have an easy way to test both ar­chi­tec­tures with­out hav­ing to ssh in­to some oth­er ma­chine, which was what I was do­ing be­fore.   </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2009/09/07/google-summer-of-code-2009-wrap-up/" class="u-url">Google Summer of Code 2009 Wrap Up</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2009/09/07/google-summer-of-code-2009-wrap-up/" rel="bookmark"><time class="published dt-published" datetime="2009-09-07T06:49:12-05:00" itemprop="datePublished" title="Publication date">2009-09-07 06:49</time></a></p>
                <p class="commentline">
        
    <a href="posts/2009/09/07/google-summer-of-code-2009-wrap-up/#disqus_thread" data-disqus-identifier="cache/posts/2009/09/07/google-summer-of-code-2009-wrap-up.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>Sor­ry about the ex­treme de­lay with this.  I of course have been busy with class­es.</p> 
 <p>Note that this will just be a sum­ma­ry of the sum­mer, with my com­ments look­ing back on it.  If you want more de­tails on each in­di­vid­u­al thing that I im­ple­ment­ed, look back on my pre­vi­ous blog post­s.</p> 
 <p>Let me start from the be­gin­ning.  Around late Feb­ru­ary to ear­ly March of this year, I dis­cov­ered the ex­is­tence of Google Sum­mer of Code.  I knew that I want­ed to do some kind of work this sum­mer, prefer­ably an in­tern­ship, so it piqued my in­ter­est.  At that time, the men­tor­ing or­ga­ni­za­tions were still ap­ply­ing for GSoC 2009, so I could on­ly look at the ones from 2008.  Most of them were ei­ther Lin­ux things or Web things, nei­ther of which I had any ex­pe­ri­ence in or am I much in­ter­est­ed in.  I took a free course in Python at my Uni­ver­si­ty the pre­vi­ous semester, and it was the pro­gram­ming lan­guage that I knew best at the time.  I had learned some Ja­va in my first se­mes­ter CS class (did I men­tion that this was my first year at col­lege?), and I hat­ed it, and I was still learn­ing C for my sec­ond se­mes­ter CS class.  So I looked at what the Python Foun­da­tion had to of­fer.  I am a dou­ble ma­jor in math and com­put­er sci­ence, so I looked un­der the math­/­science head­ing.  That's when I saw SymPy.</p> 
 <p>I should not that I have been ahead in Math.  It was my sec­ond semester, and I was tak­ing Dis­crete Math­e­mat­ic­s, Or­di­nary Dif­fer­en­tial Equa­tion­s, Ba­sic Con­cepts of Math, and Vec­tor Anal­y­sis.  So I looked for project ideas on the SymPy page that re­lat­ed to what I knew.  The on­ly one that I saw, oth­er than core im­prove­ments, was to im­prove the ODE solv­ing ca­pa­bil­i­ties.  I got in­to con­tact with the com­mu­ni­ty and looked at the source, find­ing that it was on­ly ca­pa­ble of solv­ing 1st or­der lin­ear equa­tions and some spe­cial cas­es of 2nd or­der lin­ear ho­mo­ge­neous equa­tions with con­stant co­ef­fi­cients.  I al­ready at that point knew sev­er­al meth­ods from my ODE course, and I knew much of what I would learn.   </p> 
 <p><strong>Ap­pli­ca­tion Pe­ri­od</strong></p> 
 <p>The most dif­fi­cult part of the Google Sum­mer of Code, in my opin­ion, is the ap­pli­ca­tion pe­ri­od.  For starter­s, you have to do it while you are still in class­es, so you pret­ty much have to do it in your free time.  Al­so, if you have nev­er ap­plied for Google Sum­mer of Code be­fore, you do not re­al­ly know what a good ap­pli­ca­tion should look like.  I have long had my ap­pli­ca­tion avail­able on the  <a href="http://wiki.sympy.org/wiki/User:Asmeurer/GSoC2009_Application">SymPy Wi­ki</a>, and I will ref­er­ence it here a few times.  First of­f, it was rec­om­mend­ed to me by some of the SymPy de­vel­op­ers that I put as many po­ten­tial things that I could do in the sum­mer in my ap­pli­ca­tion as I though I could do.  I was still on­ly about half way through my ODEs course when I wrote the ap­pli­ca­tion, but I had the syl­labus so I knew the meth­ods I would be learn­ing at least by name.  So that is ex­act­ly what I did:  I packed my ap­pli­ca­tion with ev­ery pos­si­ble thing that I knew we would be learn­ing about in ODEs.   </p> 
 <p>Af­ter I felt that I had a strong ap­pli­ca­tion, and On­drej had proof­read it for me, I sub­mit­ted it.  There were ac­tu­al­ly two iden­ti­cal ap­pli­ca­tion­s, one for the Python Soft­ware Foun­da­tion, and one for Port­land State Uni­ver­si­ty.  This is be­cause SymPy was not ac­cept­ed as a men­tor­ing or­ga­ni­za­tion di­rect­ly, so they had to use those two foun­da­tions as prox­ies.  A re­quire­ment of ac­cep­tance is to sub­mit a patch that pass­es re­view.  I de­cid­ed to add a Bernoul­li solver, be­cause Bernoul­li can be solved in the gen­er­al case much like the 1st or­der lin­ear ODE, which was al­ready im­ple­ment­ed.   </p> 
 <p>Af­ter I ap­plied, there was an ac­cep­tance pe­ri­od.  I used that pe­ri­od to be­come aquat­int­ed with the SymPy com­mu­ni­ty and code base.  A good way to do this is to try to fix  <a href="http://code.google.com/p/sympy/issues/list?q=label:EasyToFix">EasyToFix is­sues</a>.  I found  <a href="http://code.google.com/p/sympy/issues/detail?id=694">is­sue 694</a>, which is to im­ple­ment a bunch of tests from a pa­per by Michael West­er for test­ing com­put­er al­ge­bra sys­tem­s.  The tests cov­er ev­ery pos­si­ble thing that a full fea­tured CAS could do, so it was a great way to learn SymPy.  The is­sue is still un­fin­ished, so work­ing on it is still a good way to learn how to use SymPy.   </p> 
 <p>Al­so, it was im­por­tant to learn git, SymPy's ver­sion con­trol sys­tem.  The learn­ing curve it pret­ty steep if you have nev­er used ver­sion con­trol sys­tem be­fore, but once you can use it, it be­comes a great tool at your dis­pos­al.   </p> 
 <p><strong>Ac­cep­tance</strong></p> 
 <p>Af­ter be­ing ac­cept­ed, I toned down my work with SymPy to work on fin­ish­ing up my class­es.  My class­es fin­ished a few weeks be­fore the of­fi­cial start, so I used that pe­ri­od to get a jump start on my projec­t.</p> 
 <p><strong>The GSoC Pe­ri­od</strong></p> 
 <p>For the start of the pe­ri­od, I fol­lowed my time­line.  I im­ple­ment­ed 1st or­der ODEs with ho­mo­ge­neous co­ef­fi­cients and 1st or­der ex­act ODEs.  These were both pret­ty sim­ple to do, as I ex­pect­ed.   </p> 
 <p>The next thing I want­ed to do was sep­a­ra­ble.  My goal at this point was to get ev­ery rel­e­vant ex­er­cise from my text­book to work with my solver­s.  One of the ex­er­cis­es from my  <a href="http://books.google.com.np/books?id=29utVed7QMIC&amp;lpg=PA24&amp;ots=uxLSUKt_3P&amp;hl=en&amp;pg=PA56#v=onepage&amp;q=&amp;f=false">book</a>  (Pg. 56, No. 21) was $la­tex dy=e^{x + y}dx$.  I soon dis­cov­ered that it was im­pos­si­ble for SymPy to sep­a­rate $la­tex e^{x + y} \rightar­row e^{x}e^{y}$, be­cause the sec­ond would be au­to­mat­i­cal­ly com­bined in the core.  I al­so dis­cov­ered that  <code>ex­pand()</code>, which should have been the func­tion to split that, ex­pand­ed us­ing all pos­si­ble meth­ods in­dis­crim­i­nate­ly.  Part of my  <code>sep­a­rat­e­vars()</code>  func­tion that I was writ­ing to sep­a­rate vari­ables in ex­pres­sions would be to split things like $la­tex x + yx \rightar­row x(1 + y)$ and $la­tex 2 x y + x^{2} + y^{2} \rightar­row (x + y)^{2}$, but  <code>ex­pand()</code></p> 
 <p>as it was cur­rent­ly writ­ten would ex­pand those.   </p> 
 <p>So I spent a few weeks hack­ing on the core to make it not au­to-­com­bine ex­po­nents.  I came up with a rule that ex­po­nents would on­ly au­to-­com­bine if they had the same term mi­nus the co­ef­fi­cien­t, the same rule that  <code>Add</code>  us­es to de­ter­mine what terms should au­to com­bined by ad­di­tion.  So it would com­bine $la­tex e^{x}e^{x} \rightar­row e^{2x}$, but $la­tex e^{x}e^{y}$ would be left alone.  It turns out that some of our al­go­rithm­s, name­ly the Gruntz lim­it al­go­rith­m, re­lies on au­to-­com­bin­ing.  We al­ready had a func­tion that could com­bine ex­po­nents,  <code>powsim­p()</code>, but it al­so com­bined bases, as in $la­tex x^zy^z \rightar­row (xy)^z$, so I had to split the be­hav­ior so that it could act on­ly as au­to-­com­bin­ing once did (by the way, use  <code>powsim­p(­ex­pr, com­bine='­ex­p', deep­=True)</code>  to do this).  Then, af­ter some help from On­drej on pin­point­ing the ex­act lo­ca­tion of the bugs, I just ap­plied the func­tion there.  The last thing I did here was to split the be­hav­ior of ex­pand, so that you could do  <code>ex­pand(x<em>(y + 1), mul=­False)</em></code>  and it would leave it alone, but  <code>ex­pand(­ex­p(x + y), mul=­False)</code>  would re­turn  <code>ex­p(x)­ex­p(y)</code>.  This split be­hav­ior turned out to be use­ful in more than one place in my code.   </p> 
 <p>This was the first non bug fix patch of mine that was pushed in to SymPy, and at the time of this writ­ing, it is the last ma­jor one in the lat­est sta­ble ver­sion.  It took some ma­jor re­bas­ing to get my con­vo­lut­ed com­mit his­to­ry ready for sub­mis­sion, and it was dur­ing this phase that I git fi­nal­ly clicked for me, es­pe­cial the  <code>git re­base</code>  com­mand.  This work took a few weeks from my ODEs time, and it be­came clear that I would not be do­ing ev­ery pos­si­ble thing from my ap­pli­ca­tion.  The rea­son that I in­clud­ed so much in my ap­pli­ca­tion was that my project was non-atom­ic.  I could im­ple­ment a lit­tle or a lot and still have a work­ing  use­ful mod­ule.   </p> 
 <p>If you look at my time­line on my ap­pli­ca­tion, you can see that the first half is sym­bol­ic meth­od­s, and the sec­ond half is oth­er meth­od­s, things like se­ries.  It turns out that we did­n't re­al­ly learn much about sys­tems of ODEs in my course and we learned very lit­tle about nu­mer­i­cal meth­ods (and it would take much more to know how to im­ple­ment them).  We did learn se­ries meth­od­s, but they were so an­noy­ing to do that I came to hate them with a pas­sion.  So I de­cid­ed to just fo­cus on sym­bol­ic meth­od­s, which were my fa­vorite any­way.  My goal was to im­ple­ment as many as I could.   </p> 
 <p>Af­ter I fin­ished up sep­a­ra­ble equa­tion­s, I came up with an idea that I did not have dur­ing the ap­pli­ca­tion pe­ri­od.  <code>dsolve()</code>  was be­com­ing clut­tered fast with all of my so­lu­tion meth­od­s.  The way that it worked was that it took an ODE and it tried to match meth­ods one by one un­til it found one that worked, which it then used.   This had some draw­back­s.  First, as I men­tioned, the code was very clut­tered.  Sec­ond, the ODEs meth­ods would have to be ap­plied in a pre­de­ter­mined or­der.  There are sev­er­al ODEs that match more than one method.  For ex­am­ple, $la­tex 2xy + (x^2 + y^2)\frac{dy}{dx}=0$ has co­ef­fi­cients that are both ho­mo­ge­neous of or­der 2, and is al­so ex­ac­t, so it can be solved by ei­ther method.  The two solvers re­turn dif­fer­ent­ly for­mat­ted so­lu­tions for each one.  A sim­pler ex­am­ple is that 1st or­der ODEs with ho­mo­ge­neous co­ef­fi­cients can be solved in two dif­fer­ent ways.  My work­ing so­lu­tion was to try them both and then ap­ply some heuris­tics to re­turn the sim­plest one.  But some­times, one way would cre­ate an im­pos­si­ble in­te­gral that would hand the in­te­gra­tion en­gine.  And it made de­bug­ging the two solvers more dif­fi­cult be­cause I had to over­ride my heuris­tic.  This al­so touch­es on the third point.  Some­times the so­lu­tion to an ODE can on­ly be rep­re­sent­ed in the form of an un­eval­u­at­able in­te­gral. SymPy's  <code>in­te­grate()</code>  func­tion is sup­posed to re­turn an un­eval­u­at­ed  <code>In­te­gral</code>  class if it can­not do it, but all too of­ten it will just hang for­ev­er.   </p> 
 <p>The so­lu­tion I came up with was to re­write dsolve us­ing a hints method.  I would cre­ate a new func­tion called  <code>clas­si­fy_ode()</code>  that would do all of the ODE clas­si­fi­ca­tion, re­mov­ing it from the solv­ing code.  By de­fault, dsolve would still use a pre­de­ter­mined or­der of match­ing meth­od­s.  But you could over­ride it by pass­ing a "hin­t" to  <code>dsolve</code>  for any match­ing method, and it would ap­ply that method.  There would al­so be op­tions to on­ly re­turn un­eval­u­at­ed in­te­grals when ap­pli­ca­ble.   </p> 
 <p>I end­ed up do­ing this and more (see the doc­strings for  <code>clas­si­fy_ode()</code>  and  <code>dsolve()</code>  in the cur­rent git mas­ter branch), but be­fore I could I need­ed to clean up some things.  I need­ed to re­write all of  <code>dsolve()</code>  and re­lat­ed func­tion­s.  Be­fore I start­ed the pro­gram, there were some spe­cial cas­es in dsolve for sec­ond or­der lin­ear ho­mo­ge­neous ODEs with con­stant co­ef­fi­cients and one very spe­cial case ODE for the ex­pand­ed form of $la­tex \frac{d^2}{dx^2}(x­e^{-y}) = 0$.   </p> 
 <p>So the first thing I did was im­ple­ment a solver for the gen­er­al ho­mo­ge­neous lin­ear with con­stant co­ef­fi­cients case.  These are rather sim­ple to do: you just find the roots of the char­ac­ter­is­tic poly­no­mi­al built off of the co­ef­fi­cients, and then put the re­al parts of the roots in front of the ar­gu­ment of an ex­po­nen­tial and the imag­i­nary parts in front of the ar­gu­ments of a sine and co­sine (for ex­am­ple, $la­tex 3 \pm 2i$ would give $la­tex C1e^{3x}\s­in{2x} + C2e^{3x}\­cos{2x}$.  The thing was, that if the imag­i­nary part is 0, then you on­ly have 1 ar­bi­trary con­stant on the ex­po­nen­tial, but if it is non-ze­ro, you get 2, one for each trig func­tion.  The rest falls out nice­ly if you plug 0 in for $la­tex b$ in­to $e^{ax}(C1\s­in{bx} + C2\­cos{box})$ be­cause the sine goes to 0 and the co­sine be­comes 1.  But you would end up with $la­tex C1 + C2$ in­stead of just $la­tex C1$ in that case.  I had al­ready planned on do­ing ar­bi­trary con­stant sim­pli­fi­ca­tion as part of my pro­jec­t, so I fig­ured I would put this on hold and do that first.  Then, once that was done, the ho­mo­ge­neous case would be re­duced to 1 case in­stead of the usu­al 2 or 3.   </p> 
 <p>My orig­i­nal plan was to make an ar­bi­trary con­stant type that au­to­mat­i­cal­ly sim­pli­fied it­self.  So, for ex­am­ple, if you en­tered  <code>C1 + 2 + x</code>  with  <code>C1</code>  an ar­bi­trary con­stan­t, it would re­duce to just  <code>C1 + x</code>.  I worked with On­drej, in­clud­ing vis­it­ing him in Los Alam­os, and we build up a class that worked.  The prob­lem was that, in or­der to have au­to-sim­pli­fi­ca­tion, I had to write the sim­pli­fi­ca­tion di­rect­ly in­to the core.  Nei­ther of us liked this, so we worked a lit­tle bit on a ba­sic core that would al­low au­to-sim­pli­fi­ca­tion to be writ­ten di­rect­ly in the class­es in­stead of in the  <code>Mul.flat­ten()</code>  and  <code>Ad­d.flat­ten()</code>  meth­od­s.  It turns out that my con­stant class is­n't the on­ly thing that would ben­e­fit from this.  Things like the or­der class (O(x)) and the in­fin­i­ty class (oo) are au­to-sim­pli­fied in the core, and things could be much clean­er if they hap­pened in the class­es them­selves.  Un­for­tu­nate­ly, mod­i­fy­ing the core like this is not some­thing that can hap­pen overnight or even in a few week­s.  For one thing, it need­ed to wait un­til we had the new as­sump­tions sys­tem, which was an­oth­er Google Sum­mer of Code project run­ning par­al­lel to my own.  So we de­cid­ed to shelf the idea.</p> 
 <p>I still want­ed con­stant sim­pli­fi­ca­tion, so I set­tled with writ­ing a func­tion that could do it in­stead.  There were some down­sides to this.  Mak­ing the func­tion as gen­er­al as the class­es might have been would have been far too much work, so I set­tled on mak­ing it an in­ter­nal-on­ly  func­tion that on­ly worked on sym­bols named  <code>C1</code>,  <code>C2</code>, etc.  Al­so, un­like writ­ing the sim­pli­fi­ca­tion straight in­to  <code>Mul.flat­ten()</code>  which was as sim­ple as re­mov­ing any terms that were not de­pen­dent on x, writ­ing a func­tion that parsed an ex­pres­sion and sim­pli­fied it was con­sid­er­ably hard­er to write.  I man­aged to churn out some­thing that worked, and so I was ready to fin­ish up the solver I had start­ed a few para­graphs ago.   </p> 
 <p>Af­ter I fin­ished that, I still need­ed to main­tain the abil­i­ty to solve that spe­cial case ODE.  Ap­par­ent­ly, it is an ODE that you would get some­where in de­riv­ing some­thing about rel­a­tiv­i­ty, be­cause it was in the rel­a­tiv­i­ty.py ex­am­ple file.  I used Maple's ex­cel­lent  <code>ode­anal­y­ser()</code>  func­tion (this is where I go the idea for my  <code>clas­si­fy_ode()</code>)to find a sim­ple gen­er­al case ODE that it fit (Liou­ville ODE).  Af­ter I fin­ished this, I was ready to start work­ing on the hints en­gine.   </p> 
 <p>It took me about a week to move all clas­si­fi­ca­tion code in­to  <code>clas­si­fy_ode()</code>, move all solvers in­to in­di­vid­u­al func­tion­s, sep­a­rate sim­pli­fi­ca­tion code in­to yet oth­er func­tion­s, and tie it all to­geth­er in  <code>dsolve()</code>.  In the end, the mod­el worked very well.  The mod­u­lar­iza­tion al­lowed me to do some oth­er things that I had not con­sid­ered, such as cre­at­ing a spe­cial "best" hint that used some heuris­tics that I orig­i­nal­ly de­vel­oped for first or­der ho­mo­ge­neous which al­ways has two pos­si­ble so­lu­tions to try to give the best for­mat­ted so­lu­tion for any ODE that has more than one pos­si­ble so­lu­tion method.  It al­so made de­bug­ging in­di­vid­u­al meth­ods much eas­ier, be­cause I could just use the built in hint calls in  <code>dsolve()</code>  in­stead of com­ment­ing out lines of code in the source.   </p> 
 <p>This was good, be­cause there was one more method that I want­ed to im­ple­men­t.  I want­ed to be able to solve the in­ho­mo­ge­neous case of a nth or­der lin­ear ode with con­stant co­ef­fi­cients.  This can be done in the gen­er­al case us­ing the method of vari­a­tion of pa­ram­e­ter­s.  It was quite sim­ple to set up vari­a­tion of pa­ram­e­ters up in the code.  You on­ly have to set up a sys­tem of in­te­grals us­ing the Wron­skian of the gen­er­al so­lu­tion­s.  It would usu­al­ly be a very poor choice of a method if you were try­ing to solve an ODE by hand be­cause tak­ing the Wron­skian and com­put­ing n in­te­grals is a lot of work.  But for a CAS, the work is al­ready there.  I just have to set up the in­te­gral­s.   </p> 
 <p>It soon be­came clear that even though, in the­o­ry, the method of vari­a­tion of pa­ram­e­ters can solve any ODE of this type, in prac­tice, it does not al­ways work so well in SymPy.  This is be­cause SymPy have very poor sim­pli­fi­ca­tion, es­pe­cial­ly trigono­met­ric sim­pli­fi­ca­tion, so some­times there would be a trigono­met­ric Wron­skian that would be iden­ti­cal­ly equal to some con­stan­t, but it could on­ly sim­pli­fy it to some very large ra­tio­nal func­tion of sines and cosines.  When these were passed to the in­te­gral en­gine, it would cause it to fail, be­cause it could not find the in­te­gral for such a seem­ing­ly com­plex ex­pres­sion.   </p> 
 <p>In ad­di­tion, tak­ing Wron­skian­s, sim­pli­fy­ing them, and then tak­ing n in­te­grals is a lot of work as I said, and even when SymPy could do it, it took a long time.  There is an­oth­er method for solv­ing these types of equa­tions called un­de­ter­mined co­ef­fi­cients that does not re­quire in­te­gra­tion.  It on­ly works on a class of ODEs where the right hand side of the ODE is a sim­ple com­bi­na­tion of sines, cosi­nes, ex­po­nen­tial­s, and poly­no­mi­als in x.  It turns out that these kinds of func­tions are com­mon any­way, so most ODEs of this type that you would en­counter could be solved with this method.  Un­like vari­a­tion of pa­ram­e­ter­s, un­de­ter­mined co­ef­fi­cients re­quires con­sid­er­able se­tup, in­clud­ing check­ing for dif­fer­ent cas­es.  This would be the method that you would want to use if you had to solve the ODE by hand be­cause, even with all the se­tup, it on­ly re­quires solv­ing a sys­tem of lin­ear equa­tions vs. solv­ing n in­te­grals with vari­a­tion of pa­ram­e­ter­s, but for a CAS, it is the set­up that mat­ter­s, so this was a dif­fi­cult prospec­t.</p> 
 <p>I spent the last cou­ple of weeks writ­ing up the nec­es­sary al­go­rithms to set­up the re­quired sys­tem of lin­ear equa­tions and han­dling the dif­fer­ent cas­es.  Af­ter I fi­nal­ly worked out all of the bugs, I ran some pro­fil­ing against my vari­a­tion of pa­ram­e­ters solver.  It turned out that for ODEs that had trigono­met­ric so­lu­tions (which take longer to sim­pli­fy), my un­de­ter­mined co­ef­fi­cients solver was an or­der of mag­ni­tude faster than the vari­a­tion of pa­ram­e­ters solver (and that is just for the ODEs that the vari­a­tion of pa­ram­e­ters en­gine could even solve at al­l).  For ODEs that on­ly had ex­po­nen­tial­s, it was still 2-4 times faster.   </p> 
 <p>I fin­ished off the sum­mer by writ­ing ex­ten­sive doc­u­men­ta­tion for all of my solvers and func­tion­s.  Hope­ful­ly some­one who us­es SymPy to solve ODEs can learn some­thing about ODE solv­ing meth­ods as well as how to use the func­tion I wrote when they read my doc­u­men­ta­tion.  </p> 
 <p><strong>  Post-G­SoC</strong></p> 
 <p>I plan on con­tin­u­ing de­vel­op­ment with SymPy now that the Google Sum­mer of Code pe­ri­od is over.  SymPy is an amaz­ing pro­jec­t, mix­ing Python and Com­put­er Al­ge­bra, and I want to help it grow.  I may even ap­ply again in a fu­ture year to im­ple­ment some oth­er thing in SymPy, or maybe ap­ply as a men­tor for SymPy to help some­one else im­prove it.   </p> 
 <p><strong>Ad­vice</strong></p> 
 <p>What fol­lows is some gen­er­al ad­vice for some­one who wants to ap­ply for Google Sum­mer of Code.  Some of the ad­vice per­tains specif­i­cal­ly to SymPy, and some of it is gen­er­al ad­vice that I think would ap­ply to any projec­t.</p> 
 <ul>
<li> 
 <p>Get in­­­volved ear­­ly.  As soon as you de­­cide that you want to par­tic­i­­pate in Google Sum­mer of Code, start get­t­ing in­­­volved in the pro­jec­t.  Get in­­­to con­­tact with them and dis­­­cuss pos­si­ble pro­jec­t­s.  If you are look­ing be­­fore the par­tic­i­­pat­ing or­­ga­ni­za­­­tions are an­­nounced, look at the or­­ga­ni­za­­­tions from pre­vi­ous years. For some or­­ga­ni­za­­­tion­s, it will vary; for oth­­ers (like Python), it is al­­most giv­en that they will be ac­­cep­t­ed ev­ery year.     </p>  
  </li> 
 <li> 
 <p>Some projects (in­­clud­ing SymPy) re­quire you to send in a patch that pass­es re­view to be ac­­cep­t­ed.  This will give you a change to start fa­mil­iar­iz­ing your­­self with the code base.  If you are ap­­ply­ing to SymPy, the West­­er ex­am­­ple I men­­tioned above is a re­al­­ly good way to learn what SymPy can do and how it work­s.    </p>  
  </li> 
 <li> 
 <p>Sub­­scribe to the mail­ing list, and once you are com­­fort­able with it, par­tic­i­­pate.  Al­­so, it is a good idea to idle in IRC (SymPy is on freen­ode at #sympy).  This will help you get to know the main con­trib­u­­tors for the pro­jec­t.     </p>  
  </li> 
 <li> 
 <p>For you ap­­pli­­ca­­tion, see if the peo­­ple in the project you are ap­­ply­ing for will re­view it. If they like your project idea, they will try to help you write a good ap­­pli­­ca­­tion so you can be ac­­cep­t­ed and you can im­­ple­­ment it.  If they don't like your idea, then they will tell you and you should change it, oth­­er­­wise you will not be ac­­cep­t­ed, no mat­ter how well writ­ten your pro­­pos­al is.  I have my pro­­pos­al on the wi­­ki (see link above).  I am not say­ing that it is nec­es­sar­i­­ly a very good pro­­pos­al, but it did get ac­­cep­t­ed.  If you are ap­­ply­ing to SymPy, On­­drej will proof­read your ap­­pli­­ca­­tions for you.</p>  
  </li> 
 <li> 
 <p>If you are an IRC fan, there is al­­so #g­­soc on freen­ode, where you can ask all your GSoC re­lat­ed ques­­tion­s.  Be warned that it does get pret­­ty noisy in the ap­­pli­­ca­­tion pe­ri­od, es­­pe­­cial­­ly right be­­fore the ap­­pli­­ca­­tions are due and right be­­fore pro­­pos­als are ac­­cep­t­ed.    </p>  
  </li> 
 <li> 
 <p>I can­not stress this one enough.  If you have nev­er worked with a ver­­sion con­trol sys­tem be­­fore, it is per­haps more im­­por­­tant to spend your time learn­ing it than it is to learn the code base for your pro­jec­t.  These things have a steep learn­ing curve if you have nev­er used them be­­fore.  Once you mas­ter them though, they can make your life much eas­i­er.  Al­­so, the soon­er you learn to use them well, the eas­i­er your life will be lat­er on down the road.  I spent a good part of the last week of GSoC clean­ing up my com­mit his­­to­ry from the first half of the sum­mer when I bad very poor com­mit­t­ing/log habit­s.  If your project us­es git, such as SymPy does, you might look at   <a href="http://www-cs-students.stanford.edu/~blynn//gitmagic/">this</a>   tu­­to­ri­al.  If it us­es some­thing else, good luck.  Se­ri­ous­­ly, git is the on­­ly good ver­­sion con­trol sys­tem.  See   <a href="http://www.youtube.com/watch?v=4XpnKHJAok8">this video</a>.</p>  
  </li> 
 <li> 
 <p>Ex­pect to spend on­­ly about half of the sum­mer ac­­tu­al­­ly im­­ple­­men­t­ing stuff.  You may think that you are a good pro­­gram­mer and that your code will not be so bug­­gy that you will need to spend that much time fix­ing bugs, and you may be right.  But the fact is, you will be work­ing on code bases writ­ten by may pro­­gram­mers that are not so good.  You will need to fix sev­er­al al­ready ex­ist­ing bugs to make your code work, which means that you will need to learn the code base well, learn how to read oth­­er peo­­ple's code, and how to fix bugs that you had no part in cre­at­ing.  You will be glad if a bug is in your code be­­cause you will usu­al­­ly know im­me­di­ate­­ly what caus­es it and how to fix it.  But if a bug is some­where else, you will need to find it, fig­ure out why it hap­pen­s, what is sup­­posed to hap­pen, and how to fix it with­­out break­ing any­thing else.  This is al­­so why it is im­­por­­tant to be ac­­tive in the de­vel­op­er com­­mu­ni­­ty.    </p>  
  </li> 
 <li> 
 <p>Good luck.</p>  
  </li> 
 </ul>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2009/08/17/undetermined-coefficients/" class="u-url">Undetermined Coefficients</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2009/08/17/undetermined-coefficients/" rel="bookmark"><time class="published dt-published" datetime="2009-08-17T22:33:00-05:00" itemprop="datePublished" title="Publication date">2009-08-17 22:33</time></a></p>
                <p class="commentline">
        
    <a href="posts/2009/08/17/undetermined-coefficients/#disqus_thread" data-disqus-identifier="cache/posts/2009/08/17/undetermined-coefficients.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<em>[Sorry for the delay in this post.  I was having some difficulties coming up with some of the rationales below. Also, classes have started, which has made me very busy.]</em>
<p>If there was one ODE solv­ing method that I did not want to im­ple­ment this sum­mer, it was un­de­ter­mined co­ef­fi­cients.  I did­n't re­al­ly like the method too much when we did it my my ODE class (though it was not as un­en­joy­able as se­ries meth­od­s).  The thing that I nev­er re­al­ly un­der­stood very well is to what ex­tent you have to mul­ti­ply terms in the tri­al func­tion by pow­ers of x to make them lin­ear­ly in­de­pen­dent of the so­lu­tion to the gen­er­al equa­tion.  We did our ODEs home­work in Maple, so I would usu­al­ly just keep try­ing high­er pow­ers of x un­til I got a so­lu­tion.  But to im­ple­ment it in SymPy, I had to have a much bet­ter un­der­stand­ing of the ex­act rules for it.</p> 
 <p>From a user's point of view, the method of un­de­ter­mined co­ef­fi­cients is much bet­ter than the method of vari­a­tion of pa­ram­e­ter­s.  While it is true that vari­a­tion of pa­ram­e­ters is a gen­er­al method and un­de­ter­mined co­ef­fi­cients on­ly works on a spe­cial class of func­tion­s, un­de­ter­mined co­ef­fi­cients re­quires no in­te­gra­tion or ad­vanced sim­pli­fi­ca­tion, so it is fast (very fast, as well shall see be­low).  All that the CAS has to do is fig­ure out what a tri­al func­tion looks like, plug it in­to the ODE, and solve for the co­ef­fi­cients, which is a sys­tem of lin­ear equa­tion­s.   </p> 
 <p>On the oth­er hand, from the pro­gram­mer's point of view,  <a href="http://asmeurersympy.wordpress.com/2009/08/01/variation-of-parameters-and-more/">vari­a­tion of pa­ram­e­ters</a>  is much bet­ter.  All you have to do is take the Wron­skian of the gen­er­al so­lu­tion set and use it to set up some in­te­gral­s.  But the Wron­skian has to be sim­pli­fied, and if the gen­er­al so­lu­tion con­tains sin's and cos's, this re­quires trigono­met­ric sim­pli­fi­ca­tion not cur­rent­ly avail­able in SymPy (although it looks like the  <a href="http://code.google.com/p/sympy/issues/detail?id=1598">new Polys mod­ule</a>  will be mak­ing a big leap for­ward in this area).  Al­so, in­te­gra­tion is slow, and in SymPy, it of­ten fails (hangs forever).   </p> 
 <p>Fig­ur­ing out what the tri­al func­tion should be for un­de­ter­mined co­ef­fi­cients is way more dif­fi­cult to pro­gram, but hav­ing finnal­ly fin­ished it, I can say that it is def­i­nite­ly worth hav­ing in the mod­ule.  Prob­lems that it can solve can run or­ders of mag­ni­tude faster than the vari­a­tion of pa­ram­e­ter­s, and of­ten vari­a­tion of pa­ram­e­ters can't do the in­te­gral or re­turns a less sim­pli­fied re­sult.   </p> 
 <p>So what is this un­de­ter­mined co­ef­fi­cients?  Well, the idea is this:  if you knew what each lin­ear­ly in­de­pen­dent term of the par­tic­u­lar so­lu­tion was, mi­nus the co­ef­fi­cients, then you could just set each co­ef­fi­cient as an un­known, plug it in­to the ODE, and solve for them.  It turns out that re­sult­ing sys­tem of equa­tions is lin­ear, so if you do the first part right, you can al­ways get a so­lu­tion.   </p> 
 <p>The key thing here is that you know what form the par­tic­u­lar so­lu­tion will take.  How­ev­er, you don't re­al­ly know this ahead of time.  All you have is the lin­ear ode $la­tex a_ny^{(n)}(x) + \dots + a_1y'(x) + a_0y(x) = F(x)$ (as far as I can tel­l, this on­ly works in the case where the co­ef­fi­cients $la­tex a_i$ are con­stant with re­spect to x.  I'd be in­ter­est­ed to learn that it works for oth­er lin­ear ODEs.  At any rate, that is the on­ly one that works in my branch right now.).  The so­lu­tion to the ode is $la­tex y(x) = y_g(x) + y_p(x)$, where $la­tex y_g(x)$ is the so­lu­tion to the ho­mo­ge­neous equa­tion $la­tex f(x) \e­quiv 0$, and $la­tex y_p(x)$ is the par­tic­u­lar so­lu­tion that pro­duces the $la­tex F(x)$ term on the right hand side.  The key here is just that.  If you plug $la­tex y_p(x)$ in­to the left hand side of the ode, you get $la­tex F(x)$.   </p> 
 <p>It turns out that this method on­ly works if the func­tion $la­tex F(x)$ on­ly has a fi­nite num­ber of lin­ear­ly in­de­pen­dent de­riv­a­tives (I am un­sure, but this might be able to work in oth­er cas­es, but it would in­volve much more ad­vanced math­e­mat­ic­s).  So what kind of func­tions have a fi­nite num­ber of lin­ear­ly in­de­pen­dent so­lu­tion­s?  Ob­vi­ous­ly, poly­no­mi­als do.  So does $la­tex e^x$, $la­tex \cos{x}$, and $la­tex \s­in{x}$.  Al­so, if we mul­ti­ply two or more of these types to­geth­er, then we will get a fi­nite num­ber of lin­ear­ly in­de­pen­dent so­lu­tions af­ter ap­ply­ing the prod­uct rule.  But is that al­l?  Well, if we take the def­i­ni­tion of lin­ear in­de­pen­dence from lin­ear al­ge­bra, we know that a set of n vec­tors $la­tex {\boldsym­bol­{v_1}, \boldsym­bol­{v_2}, \boldsym­bol­{v_3}, \dot­s, \boldsym­bol­{v_n}}$, not all ze­ro, are lin­ear­ly in­de­pen­dent on­ly if $la­tex a_1\boldsym­bol­{v_1} + a_2\boldsym­bol­{v_2} + a_3\boldsym­bol­{v_3} + \dots + a_n\boldsym­bol­{v_n}=0$ holds on­ly when $la­tex a_1 \e­quiv 0, a_2 \e­quiv 0, a_3 \e­quiv 0, \dot­s, a_n \e­quiv 0$, that is, the on­ly so­lu­tion is the triv­ial one (re­mem­ber, this is the  <em>def­i­ni­tion</em>  of lin­ear in­de­pen­dence).  They are lin­ear­ly de­pen­dent if there ex­ist weights $la­tex a_1, a_2, a_3, \dot­s, a_n$, not all 0, such that the equa­tion $la­tex a_1\boldsym­bol­{v_1} + a_2\boldsym­bol­{v_2} + a_3\boldsym­bol­{v_3} + \dots + a_n\boldsym­bol­{v_n}=0$ is sat­is­fied.  Us­ing this def­i­ni­tion, we can see that a func­tion $la­tex f(x)$ will have a fi­nite num­ber of lin­ear­ly in­de­pen­dent de­riv­a­tives if it sat­is­fies $la­tex a_n­f^{(n)}(x) + a_{n - 1}f^{(n - 1)}(x) + \dots + a_1f'(x) + a_0f(x) = 0$ for some $la­tex n$ and with $la­tex a_i\neq 0$ for some $la­tex i$.  But this is just a  <a href="http://asmeurersympy.wordpress.com/2009/08/01/variation-of-parameters-and-more/">ho­mo­ge­neous lin­ear ODE with con­stant co­ef­fi­cients</a>, which we know how to solve.    The so­lu­tions are all of the form $la­tex ax^ne^{b x}\­cos{cx}$ or $la­tex ax^ne^{b x}\s­in{cx}$, where a, b, and c are re­al num­bers and n is a non-neg­a­tive in­te­ger.  We can set the var­i­ous con­stants to 0 to get the type we wan­t.  For ex­am­ple, for a poly­no­mi­al ter­m, b will be 0 and c will be 0 (use the cos ter­m).</p> 
 <p>So this gives us the ex­act form of func­tions that we need to look for to ap­ply un­de­ter­mined co­ef­fi­cients, based on the as­sump­tion that it on­ly works on func­tions with a fi­nite num­ber of lin­ear­ly in­de­pen­dent de­riv­a­tives.   </p> 
 <p>Well, im­ple­ment­ing it was quite dif­fi­cult.  For ev­ery ODE, the first step in im­ple­men­ta­tion is match­ing the ODE, so the solver can know what meth­ods it can ap­ply to a giv­en ODE.  To match in this case, I had to write a func­tion that de­ter­mined if the func­tion matched the form giv­en above, which was not too dif­fi­cult, though not as triv­ial as just grab­bing the right hand side in vari­a­tion of pa­ram­e­ter­s.  The next step is to use the match­ing to for­mat the ODE for the solver.  In this case, it means find­ing all of the fi­nite lin­ear­ly in­de­pen­dent de­riv­a­tives of the ODE, so that the solver can just cre­ate a lin­ear com­bi­na­tion of them solve for the co­ef­fi­cients.  This was a lit­tle more dif­fi­cult, and it took some lat­er­al think­ing.   </p> 
 <p>At this point, there is one more thing that needs to be not­ed. Since the tri­al func­tion­s, that is, the lin­ear­ly in­de­pen­dent de­riv­a­tive terms of the right hand side of the ODE, are of the same form as the so­lu­tions to the ho­mo­ge­neous equa­tion, it is pos­si­ble that one of the tri­al func­tion terms will be a so­lu­tion to the ho­mo­ge­neous equa­tion.  If this hap­pen­s, plug­ging it in­to the ODE will cause it to go to ze­ro, which means that we will not be able to solve for a co­ef­fi­cient for that ter­m.  In­deed, that term will be of the form $la­tex C1*\­tex­tr­m{ter­m}$ in the fi­nal so­lu­tion, so even if we had a co­ef­fi­cient for it, it would be ab­sorbed in­to this term from the so­lu­tion to the ho­mo­ge­neous equa­tion.  For ex­am­ple, vari­a­tion of pa­ram­e­ters will give a co­ef­fi­cient for such terms, even though it is un­nec­es­sary.  This is a clue that Maple us­es vari­a­tion of pa­ram­e­ters for all lin­ear con­stant co­ef­fi­cient ODE solv­ing, be­cause it gives the un­nec­es­sary terms with the co­ef­fi­cients that would be giv­en by vari­a­tion of pa­ram­e­ter­s, in­stead of ab­sorb­ing them in­to the ar­bi­trary con­stants.   </p> 
 <p>We can safe­ly ig­nore these terms for un­de­ter­mined co­ef­fi­cients, be­cause their co­ef­fi­cients will not even ap­pear in the sys­tem of lin­ear equa­tions of the co­ef­fi­cients any­way.  But, with­out these co­ef­fi­cients, we will run in­to trou­ble.  It turns out that if a term $la­tex x^ne^{ax}\s­in{bx}$ or $la­tex x^ne^{ax}\­cos{bx}$ is re­peat­ed so­lu­tion to the ho­mo­ge­neous equa­tion, and $la­tex x^{n + 1}e^{ax}\s­in{bx}$ or $la­tex x^{n + 1}e^{ax}\­cos{bx}$ is not, so that $la­tex n$ is the high­est $la­tex x$ pow­er that makes it a so­lu­tion to the ho­mo­ge­neous equa­tion, and if the tri­al so­lu­tion has $la­tex x^me^{ax}\s­in{bx}$ or $la­tex x^me^{ax}\­cos{bx}$ terms, but not $la­tex x^{m + 1}e^{ax}\s­in{bx}$ or $la­tex x^{m + 1}e^{ax}\­cos{bx}$ terms, so that $la­tex m$ is the high­est pow­er of $la­tex x$ in the the tri­al func­tion terms, then we need to mul­ti­ply these tri­al func­tion terms by $la­tex x^{n + m}$ to make them lin­ear­ly in­de­pen­dent with the so­lu­tions of the ho­mo­ge­neous equa­tion.   </p> 
 <p>Most  <a href="http://en.wikipedia.org/wiki/Method_of_undetermined_coefficients">ref­er­ences</a>  sim­ply say that you need to mul­ti­ply the tri­al func­tion terms by "suf­fi­cient pow­ers of x" to make them lin­ear­ly in­de­pen­dent with the ho­mo­ge­neous so­lu­tion.  Well, this is just fine if you are do­ing it by hand or you are cre­at­ing the tri­al func­tion man­u­al­ly in Maple and plug­ging it in and solv­ing for the co­ef­fi­cients.  You can just keep up­ping the pow­ers of x un­til you get a so­lu­tion for the co­ef­fi­cients.  Cre­at­ing those tri­al func­tions in Maple, plug­ging them in­to the ODE, and solv­ing for the co­ef­fi­cients is ex­act­ly what I had to do for my home­work when I took ODEs last spring, and this "up­ping pow­er­s" tri­al and er­ror method is ex­act­ly the method I used.  But when you are do­ing it in SymPy, you need to know ex­act­ly what pow­er to mul­ti­ply it by.  If it is too low, you will not get so­lu­tion to the co­ef­fi­cients.  If it is too high, you can ac­tu­al­ly end up with too many terms in the fi­nal so­lu­tion, giv­ing a wrong an­swer.   </p> 
 <p>For­tu­nate­ly, my ex­cel­lent  <a href="http://books.google.com.np/books?id=29utVed7QMIC&amp;lpg=PA24&amp;ots=uxLSUKt_3P&amp;dq=testing%20implicit%20solutions%20to%20ode&amp;hl=en&amp;pg=PA61#v=onepage&amp;q=&amp;f=false">ODEs text­book</a>  gives the ex­act cas­es to fol­low, and so I was able to im­ple­ment it cor­rect­ly.  The text­book al­so gives a whole slew of ex­er­cis­es, all for which the so­lu­tions are giv­en.  As usu­al, this helped me to find the bugs in my very com­plex and dif­fi­cult to write rou­tine.  It al­so helped me to find a  <a href="http://code.google.com/p/sympy/issues/detail?id=1601">match bug</a>  that would have pre­vent­ed  <code>dsolve()</code>  from be­ing able to match cer­tain types of ODEs.  The bug turned out to be fun­da­men­tal to the way  <code>match()</code>  is writ­ten, so I had to write my own cus­tom match­ing func­tion for lin­ear ODEs.   </p> 
 <p>The fi­nal step in solv­ing the un­de­ter­mined co­ef­fi­cients is of course just cre­at­ing a lin­ear com­bi­na­tion of the tri­al func­tion terms, plug­ging it in­to the orig­i­nal ODE, and set­ting the co­ef­fi­cients of each term on each side equal to each oth­er, which gives a lin­ear sys­tem. SymPy can solve these eas­i­ly, and once you have the val­ues of the co­ef­fi­cients, you can use them to build your par­tic­u­lar so­lu­tion, at which point, you are done.   </p> 
 <p>The re­sults were as­tound­ing.  Vari­a­tion of pa­ram­e­ters would hang on many sim­ple in­ho­mo­ge­neous ODEs be­cause of poor trig sim­pli­fi­ca­tion of the Wron­sikan, but my un­de­ter­mined co­ef­fi­cients method han­dles them per­fect­ly.  Al­so, there is no need to wor­ry about ab­sorb­ing su­per­flu­ous terms in­to the ar­bi­trary con­stants as with vari­a­tion of pa­ram­e­ter­s, be­cause they are re­moved from with­in the un­de­ter­mined co­ef­fi­cients al­go­rith­m.</p> 
 <p>But the big­gest thing was speed.  Here are some bench­marks on some ran­dom ODEs from the test suit­e. Word­Press code blocks are im­per­vi­ous to whites­pace, as I have men­tioned be­fore, so no pret­ty print­ing here.  Al­so, it trun­cates the hints.  The hints used are  <code>'n­th_­lin­ear_­con­stan­t_­co­ef­f_un­de­ter­mined_­co­ef­fi­cients'</code>  and  <code>'n­th_­lin­ear_­con­stan­t_­co­ef­f_­vari­a­tion_of_­pa­ram­e­ter­s'</code>:</p> 
 <p><code></code></p> 
 <blockquote>

In [1]: time dsolve(f(x).diff(x, 2) - 3*f(x).diff(x) - 2*exp(2*x)*sin(x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.07 s, sys: 0.00 s, total: 0.08 s

Wall time: 0.08 s

Out[2]: 

f(x) == C1 + (-3*sin(x)/5 - cos(x)/5)*exp(2*x) + C2*exp(3*x)



In [3]: time dsolve(f(x).diff(x, 2) - 3*f(x).diff(x) - 2*exp(2*x)*sin(x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')

CPU times: user 0.92 s, sys: 0.01 s, total: 0.93 s

Wall time: 0.94 s

Out[4]: 

f(x) == C1 + (-3*sin(x)/5 - cos(x)/5)*exp(2*x) + C2*exp(3*x)



In [5]: time dsolve(f(x).diff(x, 4) - 2*f(x).diff(x, 2) + f(x) - x + sin(x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.06 s, sys: 0.00 s, total: 0.06 s

Wall time: 0.06 s

Out[6]: 

f(x) == x - sin(x)/4 + (C1 + C2*x)*exp(x) + (C3 + C4*x)*exp(-x)



In [7]: time dsolve(f(x).diff(x, 4) - 2*f(x).diff(x, 2) + f(x) - x + sin(x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')

CPU times: user 5.43 s, sys: 0.03 s, total: 5.46 s

Wall time: 5.52 s

Out[8]: 

f(x) == x - sin(x)/4 + (C1 + C2*x)*exp(x) + (C3 + C4*x)*exp(-x)



In [9]: time dsolve(f(x).diff(x, 5) + 2*f(x).diff(x, 3) + f(x).diff(x) - 2*x - sin(x) - cos(x), f(x), 'nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.10 s, sys: 0.00 s, total: 0.10 s

Wall time: 0.11 s

Out[10]: 

f(x) == C1 + (C2 + C3*x - x**2/8)*sin(x) + (C4 + C5*x + x**2/8)*cos(x) + x**2



In [11]: time dsolve(f(x).diff(x, 5) + 2*f(x).diff(x, 3) + f(x).diff(x) - 2*x - sin(x) - cos(x), f(x), 'nth_linear_constant_coeff_variation_of_parameters')



</blockquote>

<p></p> 
 <p>The last one in­volves a par­tic­u­lar­ly dif­fi­cult Wron­skian for SymPy (run it with hin­t='n­th_­lin­ear_­con­stan­t_­co­ef­f_­vari­a­tion_of_­pa­ram­e­ter­s_In­te­gral', sim­pli­fy=­False).</p> 
 <p>Wall time com­par­isons re­veal amaz­ing speed dif­fer­ences.  We're talk­ing or­ders of mag­ni­tude.</p> 
 <p><code></code></p> 
 <blockquote>

In [13]: 0.94/0.08

Out[13]: 11.75



In [14]: 5.52/0.06

Out[14]: 92.0



In [15]: oo/0.11

Out[15]: +inf

</blockquote>

<p></p> 
 <p>Of course, vari­a­tion of pa­ram­e­ters has the most dif­fi­cult time when there are sin and cos terms in­volved, be­cause of the poor trig sim­pli­fi­ca­tion in SymPy.  So let's see what hap­pens with an ODE that just has ex­po­nen­tials and poly­no­mi­al terms in­volved.</p> 
 <p><code></code></p> 
 <blockquote>

In [16]: time dsolve(f(x).diff(x, 2) + f(x).diff(x) - x**2 - 2*x, f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.10 s, sys: 0.00 s, total: 0.10 s

Wall time: 0.10 s

Out[17]: 

f(x) == C1 + x**3/3 + C2*exp(-x)



In [18]: time dsolve(f(x).diff(x, 2) + f(x).diff(x) - x**2 - 2*x, f(x), hint='nth_linear_constant_coeff_variation_of_parameters')

CPU times: user 0.19 s, sys: 0.00 s, total: 0.19 s

Wall time: 0.20 s

Out[19]: 

f(x) == C1 + x**3/3 + C2*exp(-x)



In [20]: time dsolve(f(x).diff(x, 3) + 3*f(x).diff(x, 2) + 3*f(x).diff(x) + f(x) - 2*exp(-x) + x**2*exp(-x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.09 s, sys: 0.00 s, total: 0.09 s

Wall time: 0.09 s

Out[21]: 

f(x) == (C1 + C2*x + C3*x**2 + x**3/3 - x**5/60)*exp(-x)



In [22]: time dsolve(f(x).diff(x, 3) + 3*f(x).diff(x, 2) + 3*f(x).diff(x) + f(x) - 2*exp(-x) + x**2*exp(-x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')

CPU times: user 0.29 s, sys: 0.00 s, total: 0.29 s

Wall time: 0.29 s

Out[23]: 

f(x) == (C1 + C2*x + C3*x**2 + x**3/3 - x**5/60)*exp(-x)



</blockquote>

<p></p> 
 <p>The wall time com­par­isons here are:</p> 
 <p><code></code></p> 
 <blockquote>

In [24]: 0.20/0.10

Out[24]: 2.0



In [25]: 0.29/0.09

Out[25]: 3.22222222222

</blockquote>

<p></p> 
 <p>So we don't have or­ders of mag­ni­tude any­more, but it is still 2 to 3 times faster.  Of course, most ODEs of this form  <em>will</em>  have sin or cos terms in them, so the or­der of mag­ni­tude im­prove­ment over vari­a­tion of pa­ram­e­ters can prob­a­bly be at­trib­uted to un­de­ter­mined co­ef­fi­cients in gen­er­al.   </p> 
 <p>Of course, we know that vari­a­tion of pa­ram­e­ters will still be use­ful, be­cause func­tions like $la­tex \l­n{x}$, $la­tex \sec{x}$ and $la­tex \frac{1}{x}$ do not have a fi­nite num­ber of lin­ear­ly in­de­pen­dent deriva­tives, and so you can­not ap­ply the method of un­de­ter­mined co­ef­fi­cients to them.   </p> 
 <p>There is one last thing I want to men­tion.  You can in­deed mul­ti­ply any poly­no­mi­al, ex­po­nen­tial, sin, or cos func­tions to­geth­er and still get a func­tion that has a fi­nite num­ber of lin­ear­ly in­de­pen­dent so­lu­tion­s, but if you mul­ti­ply two or more of the trig func­tion­s, you have to ap­ply the  <a href="http://en.wikipedia.org/wiki/Trig_identities#Power-reduction_formulas">pow­er re­duc­tion rules</a>  to the re­sult­ing func­tion to get it in terms of sin and cos alone.  Un­for­tu­nate­ly, SymPy does not yet have a  <a href="http://code.google.com/p/sympy/issues/detail?id=1590">func­tion</a>  that can do this, so to solve such a dif­fer­en­tial equa­tion with un­de­ter­mined co­ef­fi­cients (rec­om­mend­ed, see above), you will have to ap­ply them man­u­al­ly your­self.  Al­so, just for the record, it does­n't play well with ex­po­nen­tials in the form of sin's and cos's or the oth­er way around (com­plex co­ef­fi­cients on the ar­gu­ments), so you should back con­vert those first too.   </p> 
 <p>Well, this con­cludes the first of two blog posts that I promised.  I al­so promised that I would write about my sum­mer of code ex­pe­ri­ences.  Not on­ly is this im­por­tant to me, but it is a  <a href="http://code.google.com/p/sympy/wiki/GSoC2009">re­quire­ment</a>.  I re­al­ly  <em>hope</em>  to get this done soon, but with class­es, who knows.   </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2009/08/17/los-alamos-sprint/" class="u-url">Los Alamos "Sprint"</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2009/08/17/los-alamos-sprint/" rel="bookmark"><time class="published dt-published" datetime="2009-08-17T18:42:57-05:00" itemprop="datePublished" title="Publication date">2009-08-17 18:42</time></a></p>
                <p class="commentline">
        
    <a href="posts/2009/08/17/los-alamos-sprint/#disqus_thread" data-disqus-identifier="cache/posts/2009/08/17/los-alamos-sprint.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>Last week­end, Luke came to vis­it On­drej in Los Alam­os, so I de­cid­ed to drive him up from Al­bu­querque and vis­it him again.  It was nice meet­ing Luke and see­ing On­drej again.   </p> 
 <p>Aside from cod­ing (the main thing that I did was fix an ug­ly match bug that was pre­vent­ing dsolve() from rec­og­niz­ing cer­tain ODEs), we vis­it­ed the atom­ic mu­se­um in Los Alam­os, the  <a href="http://en.wikipedia.org/wiki/Valles_Caldera">Valles Caldera</a>, and some of the sur­round­ing hot springs.   </p> 
 <p>Here are some pic­tures that Luke took with his iPhone.  Stupid Word­Press seems to in­sist on flip­ping some of them (I can't fix it):</p> 
 <p>[gallery]</p> 
 <p>This is one of three posts that I plan on do­ing this week.  I just fin­ished my GSoC project to­day/last night, so I will be blog­ging about that.  I plan on do­ing a post on the method of Un­de­ter­mined Co­ef­fi­cients, as well as some oth­er things that I man­aged to do.  The oth­er post will be my gen­er­al mus­ings/ad­vice for GSoC. That will prob­a­bly be my last post here in a while.  I plan on con­tin­u­ing work with SymPy, but I get very busy with class­es, so I most like­ly won't be do­ing much un­til next sum­mer.</p>
</div>
    </div>
    </article>
</div>

        <nav class="postindexpager">
        <ul class="pager">
            <li class="previous">
                <a href="index-4.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-2.html" rel="next">Older posts</a>
            </li>
        </ul>
        </nav>


        
       <script>var disqus_shortname="asmeurer";(function(){var a=document.createElement("script");a.async=true;a.src="//"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>



        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});</script>
        <script src="assets/js/mathjax.js"></script>


        </div>
        <!--End of body content-->

        <footer>
            Contents © 2014         <a href="mailto:asmeurer@gmail.com">Aaron Meurer</a> - Powered by         <a href="http://getnikola.com" rel="nofollow">Nikola</a>         
<p xmlns:dct="http://purl.org/dc/terms/" xmlns:vcard="http://www.w3.org/2001/vcard-rdf/3.0#">
  <a rel="license" href="http://creativecommons.org/publicdomain/zero/1.0/">
    <img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" style="border-style: none;" alt="CC0">
  </a>

        </p></footer>
    </div>
</div>


            <script src="assets/js/all-nocdn.js"></script>
    
<!-- Social buttons -->
<div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style">
<a class="addthis_button_more">Share</a>
<ul>
<li>
<a class="addthis_button_facebook"></a>
</li>
<li>
<a class="addthis_button_google_plusone_share"></a>
</li>
<li>
<a class="addthis_button_linkedin"></a>
</li>
<li>
<a class="addthis_button_twitter"></a>
</li>
</ul>
</div>
<script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"></script>
<!-- End of social buttons -->


    <script>jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script>
    

<script type="text/javascript" src="assets/js/tipuesearch_set.js"></script>
<script type="text/javascript" src="assets/js/tipuesearch.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    $('#tipue_search_input').tipuesearch({
        'mode': 'json',
        'contentLocation': '/assets/js/tipuesearch_content.json',
        'showUrl': false
    });
});
</script>


</body>
</html>
