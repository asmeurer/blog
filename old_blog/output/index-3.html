<!DOCTYPE html><html lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="My blog on my work on SymPy and other fun stuff.">
    <meta name="author" content="Joe Example">
    <title>Aaron Meurer's SymPy Blog (old posts, page 3) | Aaron Meurer's SymPy Blog</title>
    
            <link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
    <link rel="canonical" href="http://asmeurersympy.wordpress.com/index-3.html">
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js" type="text/javascript"></script>
    <![endif]-->
            <link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">

    
    
    
</head>
<body>
<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="http://asmeurersympy.wordpress.com/">Aaron Meurer's SymPy Blog</a>
    </div>
    <div class="collapse navbar-collapse navbar-ex1-collapse">
        <ul class="nav navbar-nav">
            
                <li><a href="archive.html">Archives</a>
                </li><li><a href="categories/index.html">Tags</a>
                </li><li><a href="rss.xml">RSS</a>

        </li></ul>

        <ul class="nav navbar-nav navbar-right">
            
            
        </ul>
    </div><!-- /.navbar-collapse -->
</nav>

<!-- End of Menubar -->

<div class="container">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2010/06/04/pudb-a-better-python-debugger.html" class="u-url">PuDB, a better Python debugger</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2010-06-04T20:59:17+00:00">2010-06-04 20:59</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>So <a href="http://haz-tech.blogspot.com/">Christian Muise</a> unwittingly just reminded me on IRC that I forgot to mention the main method that I used to learn how the heurisch function works in my last blog post.  I usually only use a debugger when I have a really hard bug I need to figure out, when the print statements aren't enough.  The reason for this is that the debugger that I had been using, winpdb, is, well, a pain to use.  There are so many little bugs, at least in Mac OS X, that it is almost not worth while to use it unless I need to.  For example, restarting a script from the debugger doesn't work.  If I pass a point that I wanted to see, I have to completely close the winpdb window and restart it from the command line, which takes about half a minute.  Also, winpdb uses it's own variant of pdb, which seems to cause more problems than it creates (like bugging me about sympy importing pdb somewhere <em>every time</em> I start debugging.)</p>
<p>But I really wanted to be able to step through the heurisch code to see exactly how it works, because many of the implementation details, such as gathering the components of an expression, will be similar if not exactly the same in the full algorithm.  So I started my quest for a better debugger.  For me, the ideal debugger is the C debugger in XCode.  That debugger has saved me in most of my programming assignments in C.  But it is only for C based languages (C, Objective-C, probably C++, …), not Python.  So I did a Google search, and it turns out that there is a list of Python debuggers <a href="http://wiki.python.org/moin/PythonDebuggers">here</a>.  So I went through them, and I didn't have to go far.  The very first one, <a href="http://pypi.python.org/pypi/pudb">pudb</a>, turns out to be awesome!</p>
<p>You can watch this <a href="http://vimeo.com/5255125">screencast</a> to get a better idea of the features, or even better install it and check them out.  The debugger runs in the console, not in some half-hacked GUI (half-hacked is what any non-Cocoa GUI looks like in Mac OS X).  The only down side to this is that you have to use the keyboard to do everything, but it ends up not being too bad.  And you can press '?' at any time to see the possible commands.  </p>
<p>To install it, just do <code>easy_install pudb</code>.  To run it, just create a script of what you want to debug, and do <code>python -m pudb.run my-script.py </code> and it just works! I have a line that says <code>alias pudb='python -m pudb.run'</code> in my <code>.profile</code>, which makes it even easier to run.  If you want to set a break point in the code, you can either navigate there from within pudb by pressing 'm', or you add a line that says <code>from pudb import set_trace; set_trace()</code> to the code (if you add the line to your code, you don't even need to create a script.  Just execute the code in IPython and when it hits that line, it will load the debugger).  </p>
<p>Some cool features:</p>
<ul>
<li>
<p>IPython console.  Just press '!' to go to a console, where you can manipulate variables from the executed namespace, and you can choose an IPython console.  </p>
</li>
<li>
<p>Very easy to navigate.  You just need to know the keys 's', 'n', and 't'.  </p>
</li>
<li>
<p>View the code from elsewhere than what is being run.  Pressing 'm' lets you view all imported modules.  You can easily view points on the stack by choosing them.  </p>
</li>
<li>
<p>If an exception is thrown, it <em>catches it</em>!  This may sound obvious for a debugger, but it is one of things that didn't work very well in winpdb.  You can view the traceback of the exception, and choose to restart <em>without having to close and reopen the debugger</em>.  Actually, it asks you if you want to restart every time the script finishes too, which is also a great improvement over winpdb.  </p>
</li>
</ul>
<p>This is what it looks like.  Click for a bigger picture:</p>
<p><a href="2010/06/pudb.png"><img src="2010/06/pudb.png" alt="" title="PuDB" width="450" height="298" class="size-full wp-image-401"></a></p>
<p>Some annoyances (in case Andreas Kloeckner reads this):</p>
<ul>
<li>
<p>The default display for variables is type, which is completely useless. I have to manually go through and change each to str so I can see what the variable is.  Is there a way to change this default?</p>
</li>
<li>
<p>It asks me every time if I want to use IPython.  I always want to use IPython.</p>
</li>
<li>
<p>This is might be a Mac OS X Terminal bug, but when I execute a statement that takes a while to run, it doesn't redraw the pudb window until it finishes.  This means that stepping through a program "flashes" black from what is above pudb in the window, and if I run a statement that takes forever, I loose the ability to see where it is unless I keyboard interrupt. Fortunately, it catches keyboard interrupts, so I can still see the traceback.</p>
</li>
<li>
<p>There is no way to resize the variables window, or to scroll sideways in it.  If I want to see what a long variable expression is, I have to go to the IPython console and type it there. </p>
</li>
</ul>
<p>Some of these might be fixable and I just don't know it yet.  But even with them, this is still an order of magnitude improvement over winpdb.  Now I can actually use the debugger all the time in my coding, instead of just when I have a really tough bug and no other choice.  </p>
<p>UPDATE:</p>
<p>The first two were trivial to fix in a fork of the repository (isn't open source awesome?).  So if those are bothering you too, check out my branches at <a href="http://github.com/asmeurer/PuDB">http://github.com/asmeurer/PuDB</a>.  Maybe if I have some time I will make them global options using environment variables or something and  see if Andreas wants to merge them back into the main repo.  </p>
<p>As for the second one, I realized that it might be a good thing, because you can see anything that is printed.  Still, I would prefer seeing both, if possible (and the black flashes are annoying).  </p>
<p>UPDATE 2:</p>
<p>You can resize the side view by pushing +/-, though there doesn't seem to be a way to, say, make the variables view bigger and the breakpoints view smaller. </p>
<p>UPDATE 3:</p>
<p>A while back Ondrej modified the code to have a different color theme, and I followed suit.  See <a href="https://github.com/certik/PuDB/commit/38fed5024d022c5d6d1961c917026e021a833a9e#comments">this conversation at GitHub</a>.  So now, instead of looking like a DOS terminal, in PuDB for me looks like this:</p>
<p><a href="2010/07/screen-shot-2010-07-28-at-12-51-36-pm.png"><img src="2010/07/screen-shot-2010-07-28-at-12-51-36-pm.png" alt="PuDB XCode Midnight Theme Colors" title="PuDB XCode Midnight Theme Colors" width="450" height="360" class="size-full wp-image-682"></a>  This is exactly the same colors as my code in XCode, the editor I use, with the Midnight Theme.  It's pretty easy to change the colors to whatever you want.  Right now, you have to edit the source, but Ondrej or I might someday make it so you can have themes.  </p>
<p>Also, having used this all summer (and it was a life-saver having it in multiple occasions, and I am sure made my development speed at least twice as fast in others), I have one additional gripe.  It is too difficult to arrow up to the variable that you want to access in the variables view.  It would be nice to have a page up/page down feature there.  </p>
<p>UPDATE 4: PuDB has since improved a lot, include many fixes by myself. It now supports themes, saved settings, variable name wrapping, and more. See <a href="http://asmeurersympy.wordpress.com/2011/08/08/hacking-pudb-now-an-even-better-python-debugger/">this followup post</a>. </p></div>
        </div>
            
        
    <p>
        <a href="posts/2010/06/04/pudb-a-better-python-debugger.html#disqus_thread" data-disqus-identifier="cache/posts/2010/06/04/pudb-a-better-python-debugger.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2010/06/04/update-for-this-week.html" class="u-url">Update for this week</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2010-06-04T18:45:26+00:00">2010-06-04 18:45</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>So I started writing up a blog post on how rational function integration works, but Ondrej <a href="http://groups.google.com/group/sympy/browse_thread/thread/7d7dceb34db45302">wants a blog post</a> every week by the end of I don't think I would do it justice by rushing to finish it now (read: I'm to lazy to do it).  So instead, I'll just give a short post (if that's possible for me) on what I have been doing this week.  </p>
<p>I finished up writing doctests for the polynomials module for now (see <a href="http://code.google.com/p/sympy/issues/detail?id=1949">issue 1949</a>), so now this week I started looking at the integrator.  In particular, I went through each of the 40 issues with the <a href="http://code.google.com/p/sympy/issues/list?q=label:Integration">Integration label</a> and added them to a test file that I can monitor throughout the summer to see my progress.  It is the test_failing_integrals.py file in my <a href="http://github.com/asmeurer/sympy/tree/integration">Integration branch</a>, where all my work will be going for the foreseeable future.  So if you want to follow my work, follow that branch.  Here are some observations from those issues:</p>
<ul>
<li>
<p>integrate() can't handle almost all algebraic integrals (functions with square roots, etc.).  It can handle the derivative of arcsin and arcsinh because of special code in heurisch.py, but that's about it.  Before I can do any work on the Algebraic Risch Algorithm, I will need to implement the transcendental algorithm, so I think my temporary solution for this may be to add pattern matching heuristics for some of the more common algebraic integrals (anyone know a good integral table?).  </p>
</li>
<li>
<p>I figured out why integrate hangs forever with some integrals, such as the one in <a href="http://code.google.com/p/sympy/issues/detail?id=1441">issue 1441</a>.  Here is, in a nutshell, how the Heuristic Risch algorithm works:  Take the integrand and split it into components.  For example, the components of x<em>cos(x)</em>sin(x)<strong>2 are [x, cos(x), sin(x)].  Replace each of these components with a dummy variable, so if x = x0, cos(x) = x1, and sin(x) = x2, then the integrand is x0<em>x1</em>x2</strong>2.  Also, compute the derivative of each component in terms of the dummy variables.  So the derivatives of [x0, x1, x2] are [1, -x2, 2<em>x1</em>x2].  Then, using these, perform some magic to create some rational functions out of the component dummy variables.  Then, create a candidate integral with a bunch of unknowns [A1, A2, …], which will be rational numbers, and a multinomial of the An's and the xn's that should equal 0 if the candidate integral is correct.  Then, because the xn's are not 0, and there is also some algebraic independence, you have the the An coefficients of each term must equal 0.  So you get a system of linear equations in the An's.  You then solve these equations, and plug the values of the An's into the candidate integral to give you the solution, or, if the system is inconsistent, then if cannot find a solution, possibly because there is no elementary one.  </p>
</li>
</ul>
<p>Well, that over simplifies a lot of things, but the point I want to make is that the integral from issue 1441 creates a system of ~600 linear equations in ~450 variables, and solving that equation is what causes the integration to hang.  Also, as Mateusz, my mentor and the one who wrote the current integration implementation, pointed out, quite a bit of time is spent in the heurisch algorithm doing expansion on large Basic polynomials.  When I say Basic polynomials, I mean that they are SymPy expressions, instead of Poly instances.  Using Poly should speed things up quite a bit, so my next move will be to convert heurisch() into using Poly wherever applicable.  </p>
<ul>
<li>
<p>There were a few bugs in the rational integration, which I fixed in my branch.  The problem was in rational integrals with symbolic coefficients.  Because the new polys are able to create polynomials using any expression as a generator, not just symbols, things like Poly(sin(y)<em>x, x) creates Poly(sin(y)</em>x, x, domain='ZZ[sin(y)]').  But using the polynomial ring or fraction field creates problems with some things like division, whereas we really only want the domain to be EX (expression domain) in this case.  So this was not too difficult to fix, and you can see the fix in my integration branch.  </p>
</li>
<li>
<p>Some integrals will require some good implementation of special functions such as the hypergeometric function to work.  Sometimes, you don't want to know what the non-elementary integral looks like, but you just want to calculate a definite integral.  The solution here is to use Meijer-G functions, which are on the list of things to possibly do at the end of the summer if I have time.</p>
</li>
<li>
<p>Another bug that I plan on fixing (I haven't done it yet, but I know how to do it and it will be trivial), is this (<a href="http://code.google.com/p/sympy/issues/detail?id=1888">issue 1888</a>):</p>
</li>
</ul>
<p>In [18]: print integrate(f(x).diff(x)**2, x)</p>
<p>2<em>D(f(x), x)</em>f(x)/3 - 2<em>x</em>D(f(x), x, x)<em>f(x)/3 + x</em>D(f(x), x)**2/3</p>
<p>The problem is in the step where it computes the derivative of the components, it tries to compute the derivative of f(x).diff(x) in terms of a dummy variable, but it reduces to 0 because diff(x2, x) == 0.  Thus, it treats f(x).diff(x) like something that has a 0 third derivative, i.e., x**2.  </p>
<p>Well that's it.  I knew I couldn't make a short blog post :).  If you want to help, I have three branches that need review (<a href="http://code.google.com/p/sympy/issues/detail?id=1883">1</a>, <a href="http://code.google.com/p/sympy/issues/detail?id=1949">2</a>, <a href="http://code.google.com/p/sympy/issues/detail?id=1843">3</a>), and except for the last one, my work is based on top of the other two, so none of my integration work can be pushed in until those two reviewed positively.  </p></div>
        </div>
            
        
    <p>
        <a href="posts/2010/06/04/update-for-this-week.html#disqus_thread" data-disqus-identifier="cache/posts/2010/06/04/update-for-this-week.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2010/05/26/more-information-on-my-google-summer-of-code-project-this-year.html" class="u-url">More information on my Google Summer of Code project this year</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2010-05-26T17:33:38+00:00">2010-05-26 17:33</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>So, as I noted <a href="http://asmeurersympy.wordpress.com/2010/04/26/gsoc-2010/trackback/">here</a>, I have been accepted into the Google Summer of Code program again this year.  I mentioned that my project involved improving the integrator, but I didn't say much other than that.  So here I plan on saying a bit more.  If you want more details, you can read my application <a href="http://wiki.sympy.org/wiki/User:Asmeurer/GSoC2010_Application">on the SymPy wiki</a>.  </p>
<p>My goal is to improve the integrator in SymPy, in other words, the back end to the <code>integrate()</code> function.  This is no easy task.  Currently, SymPy has a pretty decnet integration engine.  It is even able to solve some integrals that no other system is known to be able to solve (the second integral <a href="http://en.wikipedia.org/wiki/Risch_algorithm#Implementation">here</a>). But, as I discovered often many times throughout my work on ODEs last year, the integrator can often leave something to be desired.  There are two problems that I hope to address.  </p>
<p>First, the integrator often fails on elementary integrals.  This is because all of the integration in SymPy is based on a heuristic called the Risch-Norman algorithm.  Symbolic integration has been completely solved in the form of the Risch algorithm, meaning that there exists an algorithm to determine if an elementary function has an elementary antiderivative or not, and to find it if it does.  This algorithm, called the Risch algorithm, is extremely complicated, to the extent that no computer algebra system has ever completely implemented all the parts of it.  My plan is to begin implementing the full algorithm in SymPy.  I don't expect to finish the whole thing -- as I said no one ever has.  Rather, I hope to make a good headway into what is known as the transcendental part.  The Risch algorithm is broken up into four parts: rational part, the transcendental part, the algebraic part, and the mixed part.  </p>
<p>The rational part is involves integrating rational functions (functions of the form $latex \frac{a_nx^n + a_{n-1}x^{n-1} + \cdots + a_2x^2 + a_1x + a_0}{b_nx^n + b_{n-1}x^{n-1} + \cdots + b_2x^2 + a_1x + a_0}$).  The rational part is the easiest part in the sense that the algorithm is the simplest, and also that all rational function integrals are elementary (a term that I will define later).  Rational function integration is already implemented in sympy in full, though I may give a brief outline of how it works in a later post.  </p>
<p>The transcendental part is the part that I will be implementing this summer.  My guide will be <a href="http://www.amazon.com/Symbolic-Integration-Transcendental-Computation-Mathematics/dp/3540214933/ref=sr_1_fkmr0_2?ie=UTF8&amp;qid=1274894380&amp;sr=8-2-fkmr0"><em>Symbolic Integration I: Transcendental Functions</em> by Manuel Bronstein</a>, which describes and proves the transcendental part of the algorithm in some 300+ pages.  I will try to explain a little of how the algorithm works in some blog posts, but understand that it is very complex.  Therefore, I will probably explain it without proving things.  If you are interested in buying the book and learning the algorithm rigorously, the only prerequisites that I can tell are calculus (so you know what an integral and a derivative are), and a semester of abstract algebra (you need to know about rings, fields, ideals, homomorphisms, etc., as well as the various theorems relating them).  </p>
<p>In the book, I am still in the part that develops the theory called differential algebra necessary to prove the integration algorithm correct.  So to begin the GSoC program, I am working on learning the polys module in sympy.  My method of doing this is to write doctests for all the functions in the module.  It's a daunting task, but it's been probably the best way of learning how a computer module works that I have ever tried.  You really have to understand all aspects of a function to write a doctest for it, the types of the parameters and return value, as well as what the algorithm is actually doing.  It's especially helpful that the code for the functions is right below the docstring for each function, so I can see how it really works on the inside, removing the mystery of the module.  Furthermore, it will serve as a reference for me for the remainder of the summer, as well for anyone else who wants to learn the polys module, or just needs to debug it.  I've also ran into several bugs and inefficiencies in the module that I have taken the liberty of fixing.  </p>
<p>Well that's it for this post.  If you want to follow my progress on the doctests, my branch is <a href="http://github.com/asmeurer/sympy/tree/polydocs-polys9">http://github.com/asmeurer/sympy/tree/polydocs-polys9</a>.  Note that the branch will be very unstable until I finish at some point at the end of this week or the beginning of the next.  </p></div>
        </div>
            
        
    <p>
        <a href="posts/2010/05/26/more-information-on-my-google-summer-of-code-project-this-year.html#disqus_thread" data-disqus-identifier="cache/posts/2010/05/26/more-information-on-my-google-summer-of-code-project-this-year.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2010/04/26/gsoc-2010.html" class="u-url">GSoC 2010</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2010-04-26T22:05:39+00:00">2010-04-26 22:05</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>So I applied for Google Summer of Code again this year, and I got accepted!  I will post more here later, but you can read the proposal abstract <a href="http://socghop.appspot.com/gsoc/student_project/show/google/gsoc2010/python/t127230762920">here</a>.  The project is to improve the integrator in SymPy, making it faster, and able to solve more integrals.  </p></div>
        </div>
            
        
    <p>
        <a href="posts/2010/04/26/gsoc-2010.html#disqus_thread" data-disqus-identifier="cache/posts/2010/04/26/gsoc-2010.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2010/04/06/latest-sympy-makes-it-to-fink.html" class="u-url">Latest SymPy makes it to Fink</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2010-04-06T19:41:16+00:00">2010-04-06 19:41</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>Look at this screenshot:
<a href="2010/04/screen-shot-2010-04-06-at-1-25-10-pm.png"><img src="2010/04/screen-shot-2010-04-06-at-1-25-10-pm.png" alt="" title="SymPy makes it to Fink" width="450" height="112" class="alignnone size-full wp-image-364"></a></p>
<p>So the latest version of SymPy finally made it into <a href="http://www.finkproject.org/">fink</a>.  Normally, this wouldn't be that exciting, but before this, the most recent version in fink was 0.6.4, which was before I ever joined the project, with the exception of two commits.  So this is the first version on fink to include all of my contributions, including my 2009 Google Summer of Code work.  </p></div>
        </div>
            
        
    <p>
        <a href="posts/2010/04/06/latest-sympy-makes-it-to-fink.html#disqus_thread" data-disqus-identifier="cache/posts/2010/04/06/latest-sympy-makes-it-to-fink.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2009/12/29/automatically-remove-trailing-whitespace-in-xcode.html" class="u-url">Automatically Remove Trailing Whitespace in XCode</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2009-12-29T23:56:46+00:00">2009-12-29 23:56</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>I like XCode, and I use it to edit all of my source for SymPy.   But, like many editors, it likes to auto-indent new lines to the level of indentation of the previous line.  This is a useful feature, but it makes for training whitespace out the wazoo, since blank lines will be indented in.  I am constantly finding myself using SymPy's strip_whitespace script to clean up my files.  </p>
<p>This bugged me enough that I Googled a solution, and found <a href="http://code.google.com/p/google-toolbox-for-mac/wiki/GTMXcodePlugin">this</a>.  It is a simple XCode plugin that, among other things, adds an option to strip trailing whitespace on save.  Just install in the PlugIns folder in the XCode package and enable the option in the new Google pane of the XCode preferences.  </p></div>
        </div>
            
        
    <p>
        <a href="posts/2009/12/29/automatically-remove-trailing-whitespace-in-xcode.html#disqus_thread" data-disqus-identifier="cache/posts/2009/12/29/automatically-remove-trailing-whitespace-in-xcode.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2009/11/13/how-to-get-both-32-bit.html" class="u-url">How to get both 32-bit and 64-bit Python in Snow Leopard</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2009-11-13T01:16:42+00:00">2009-11-13 01:16</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>We had some discussion on one of the Python issues about whether my Python in Snow Leopard should be 32-bit or 64-bit.  I originally thought that it was tied to what the kernel was, but I turned out to be wrong. </p>
<p>From what I discovered, the important thing is what the Python was compiled as.  You can tell what your Python has been compiled as by running:</p>
<p><code></code></p>
<p>&gt;&gt;&gt; import sys</p>
<p>&gt;&gt;&gt; from math import log</p>
<p>&gt;&gt;&gt; log(sys.maxsize, 2)</p>
<p></p>
<p>If this is just under 31, then it is 32 bit.  If it returns 63, then it is 64.  An easier way to tell it to run:</p>
<p><code></code></p>
<p>&gt;&gt;&gt; 2**40</p>
<p></p>
<p>If you get 1099511627776L, then you have 32-bit Python, if you get 1099511627776, you have 64-bit Python (notice that the number is long in 32-bit Python, because it is larger than maxint).  </p>
<p>This test won't work in Python 3 because all integers are "long" by default, but the first part will still work.  </p>
<p>So why does this matter, you ask?  Well, aside from the fact that much longer numbers are not long (anything less than 2**63 - 1 = 9223372036854775807), there is the issue of hashing. </p>
<p>In 64-bit Python:</p>
<p><code></code></p>
<p>&gt;&gt;&gt; hash('a')</p>
<p>12416037344</p>
<p></p>
<p>but in 32-bit Python</p>
<p><code></code></p>
<p>&gt;&gt;&gt; hash('a')</p>
<p>-468864544</p>
<p></p>
<p>SymPy uses hash values to order arguments, so often it happens that behavior in one architecture will not show up in the other.  These problems are often hard to track and fix, but the worst is when things work fine on the machine you are working on.  This actually happened to me with my GSoC project.  I was renumbering the arbitrary constants in the printing order in an expression, but it turned out that the printing order of an expression can be dependent on .args order, so I had to modify the tests to canonize the numbering first.</p>
<p>So here comes the crux of the post.  It turns out that on Mac OS X, if you install the binary from python.org (Mac Installer Disk Image), this installs a 32-bit Python (for compatibility reasons) in /Library/Frameworks/Python.framework/Versions/2.6/bin/python2.6</p>
<p>.  However, if you install Python using 64-bit fink in Snow Leopard, it will compile it from source into 64-bit, and install it into /sw/bin/python2.6.  </p>
<p>So now I have an easy way to test both architectures without having to ssh into some other machine, which was what I was doing before.  </p></div>
        </div>
            
        
    <p>
        <a href="posts/2009/11/13/how-to-get-both-32-bit.html#disqus_thread" data-disqus-identifier="cache/posts/2009/11/13/how-to-get-both-32-bit.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2009/09/07/google-summer-of-code-2009-wrap-up.html" class="u-url">Google Summer of Code 2009 Wrap Up</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2009-09-07T06:49:12+00:00">2009-09-07 06:49</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>Sorry about the extreme delay with this.  I of course have been busy with classes.</p>
<p>Note that this will just be a summary of the summer, with my comments looking back on it.  If you want more details on each individual thing that I implemented, look back on my previous blog posts.</p>
<p>Let me start from the beginning.  Around late February to early March of this year, I discovered the existence of Google Summer of Code.  I knew that I wanted to do some kind of work this summer, preferably an internship, so it piqued my interest.  At that time, the mentoring organizations were still applying for GSoC 2009, so I could only look at the ones from 2008.  Most of them were either Linux things or Web things, neither of which I had any experience in or am I much interested in.  I took a free course in Python at my University the previous semester, and it was the programming language that I knew best at the time.  I had learned some Java in my first semester CS class (did I mention that this was my first year at college?), and I hated it, and I was still learning C for my second semester CS class.  So I looked at what the Python Foundation had to offer.  I am a double major in math and computer science, so I looked under the math/science heading.  That's when I saw SymPy.</p>
<p>I should not that I have been ahead in Math.  It was my second semester, and I was taking Discrete Mathematics, Ordinary Differential Equations, Basic Concepts of Math, and Vector Analysis.  So I looked for project ideas on the SymPy page that related to what I knew.  The only one that I saw, other than core improvements, was to improve the ODE solving capabilities.  I got into contact with the community and looked at the source, finding that it was only capable of solving 1st order linear equations and some special cases of 2nd order linear homogeneous equations with constant coefficients.  I already at that point knew several methods from my ODE course, and I knew much of what I would learn.  </p>
<p><strong>Application Period</strong></p>
<p>The most difficult part of the Google Summer of Code, in my opinion, is the application period.  For starters, you have to do it while you are still in classes, so you pretty much have to do it in your free time.  Also, if you have never applied for Google Summer of Code before, you do not really know what a good application should look like.  I have long had my application available on the <a href="http://wiki.sympy.org/wiki/User:Asmeurer/GSoC2009_Application">SymPy Wiki</a>, and I will reference it here a few times.  First off, it was recommended to me by some of the SymPy developers that I put as many potential things that I could do in the summer in my application as I though I could do.  I was still only about half way through my ODEs course when I wrote the application, but I had the syllabus so I knew the methods I would be learning at least by name.  So that is exactly what I did:  I packed my application with every possible thing that I knew we would be learning about in ODEs.  </p>
<p>After I felt that I had a strong application, and Ondrej had proofread it for me, I submitted it.  There were actually two identical applications, one for the Python Software Foundation, and one for Portland State University.  This is because SymPy was not accepted as a mentoring organization directly, so they had to use those two foundations as proxies.  A requirement of acceptance is to submit a patch that passes review.  I decided to add a Bernoulli solver, because Bernoulli can be solved in the general case much like the 1st order linear ODE, which was already implemented.  </p>
<p>After I applied, there was an acceptance period.  I used that period to become aquatinted with the SymPy community and code base.  A good way to do this is to try to fix <a href="http://code.google.com/p/sympy/issues/list?q=label:EasyToFix">EasyToFix issues</a>.  I found <a href="http://code.google.com/p/sympy/issues/detail?id=694">issue 694</a>, which is to implement a bunch of tests from a paper by Michael Wester for testing computer algebra systems.  The tests cover every possible thing that a full featured CAS could do, so it was a great way to learn SymPy.  The issue is still unfinished, so working on it is still a good way to learn how to use SymPy.  </p>
<p>Also, it was important to learn git, SymPy's version control system.  The learning curve it pretty steep if you have never used version control system before, but once you can use it, it becomes a great tool at your disposal.  </p>
<p><strong>Acceptance</strong></p>
<p>After being accepted, I toned down my work with SymPy to work on finishing up my classes.  My classes finished a few weeks before the official start, so I used that period to get a jump start on my project.</p>
<p><strong>The GSoC Period</strong></p>
<p>For the start of the period, I followed my timeline.  I implemented 1st order ODEs with homogeneous coefficients and 1st order exact ODEs.  These were both pretty simple to do, as I expected.  </p>
<p>The next thing I wanted to do was separable.  My goal at this point was to get every relevant exercise from my textbook to work with my solvers.  One of the exercises from my <a href="http://books.google.com.np/books?id=29utVed7QMIC&amp;lpg=PA24&amp;ots=uxLSUKt_3P&amp;hl=en&amp;pg=PA56#v=onepage&amp;q=&amp;f=false">book</a> (Pg. 56, No. 21) was $latex dy=e^{x + y}dx$.  I soon discovered that it was impossible for SymPy to separate $latex e^{x + y} \rightarrow e^{x}e^{y}$, because the second would be automatically combined in the core.  I also discovered that <code>expand()</code>, which should have been the function to split that, expanded using all possible methods indiscriminately.  Part of my <code>separatevars()</code> function that I was writing to separate variables in expressions would be to split things like $latex x + yx \rightarrow x(1 + y)$ and $latex 2 x y + x^{2} + y^{2} \rightarrow (x + y)^{2}$, but <code>expand()</code></p>
<p>as it was currently written would expand those.  </p>
<p>So I spent a few weeks hacking on the core to make it not auto-combine exponents.  I came up with a rule that exponents would only auto-combine if they had the same term minus the coefficient, the same rule that <code>Add</code> uses to determine what terms should auto combined by addition.  So it would combine $latex e^{x}e^{x} \rightarrow e^{2x}$, but $latex e^{x}e^{y}$ would be left alone.  It turns out that some of our algorithms, namely the Gruntz limit algorithm, relies on auto-combining.  We already had a function that could combine exponents, <code>powsimp()</code>, but it also combined bases, as in $latex x^zy^z \rightarrow (xy)^z$, so I had to split the behavior so that it could act only as auto-combining once did (by the way, use <code>powsimp(expr, combine='exp', deep=True)</code> to do this).  Then, after some help from Ondrej on pinpointing the exact location of the bugs, I just applied the function there.  The last thing I did here was to split the behavior of expand, so that you could do <code>expand(x<em>(y + 1), mul=False)</em></code> and it would leave it alone, but <code>expand(exp(x + y), mul=False)</code> would return <code>exp(x)exp(y)</code>.  This split behavior turned out to be useful in more than one place in my code.  </p>
<p>This was the first non bug fix patch of mine that was pushed in to SymPy, and at the time of this writing, it is the last major one in the latest stable version.  It took some major rebasing to get my convoluted commit history ready for submission, and it was during this phase that I git finally clicked for me, especial the <code>git rebase</code> command.  This work took a few weeks from my ODEs time, and it became clear that I would not be doing every possible thing from my application.  The reason that I included so much in my application was that my project was non-atomic.  I could implement a little or a lot and still have a working  useful module.  </p>
<p>If you look at my timeline on my application, you can see that the first half is symbolic methods, and the second half is other methods, things like series.  It turns out that we didn't really learn much about systems of ODEs in my course and we learned very little about numerical methods (and it would take much more to know how to implement them).  We did learn series methods, but they were so annoying to do that I came to hate them with a passion.  So I decided to just focus on symbolic methods, which were my favorite anyway.  My goal was to implement as many as I could.  </p>
<p>After I finished up separable equations, I came up with an idea that I did not have during the application period. <code>dsolve()</code> was becoming cluttered fast with all of my solution methods.  The way that it worked was that it took an ODE and it tried to match methods one by one until it found one that worked, which it then used.   This had some drawbacks.  First, as I mentioned, the code was very cluttered.  Second, the ODEs methods would have to be applied in a predetermined order.  There are several ODEs that match more than one method.  For example, $latex 2xy + (x^2 + y^2)\frac{dy}{dx}=0$ has coefficients that are both homogeneous of order 2, and is also exact, so it can be solved by either method.  The two solvers return differently formatted solutions for each one.  A simpler example is that 1st order ODEs with homogeneous coefficients can be solved in two different ways.  My working solution was to try them both and then apply some heuristics to return the simplest one.  But sometimes, one way would create an impossible integral that would hand the integration engine.  And it made debugging the two solvers more difficult because I had to override my heuristic.  This also touches on the third point.  Sometimes the solution to an ODE can only be represented in the form of an unevaluatable integral. SymPy's <code>integrate()</code> function is supposed to return an unevaluated <code>Integral</code> class if it cannot do it, but all too often it will just hang forever.  </p>
<p>The solution I came up with was to rewrite dsolve using a hints method.  I would create a new function called <code>classify_ode()</code> that would do all of the ODE classification, removing it from the solving code.  By default, dsolve would still use a predetermined order of matching methods.  But you could override it by passing a "hint" to <code>dsolve</code> for any matching method, and it would apply that method.  There would also be options to only return unevaluated integrals when applicable.  </p>
<p>I ended up doing this and more (see the docstrings for <code>classify_ode()</code> and <code>dsolve()</code> in the current git master branch), but before I could I needed to clean up some things.  I needed to rewrite all of <code>dsolve()</code> and related functions.  Before I started the program, there were some special cases in dsolve for second order linear homogeneous ODEs with constant coefficients and one very special case ODE for the expanded form of $latex \frac{d^2}{dx^2}(xe^{-y}) = 0$.  </p>
<p>So the first thing I did was implement a solver for the general homogeneous linear with constant coefficients case.  These are rather simple to do: you just find the roots of the characteristic polynomial built off of the coefficients, and then put the real parts of the roots in front of the argument of an exponential and the imaginary parts in front of the arguments of a sine and cosine (for example, $latex 3 \pm 2i$ would give $latex C1e^{3x}\sin{2x} + C2e^{3x}\cos{2x}$.  The thing was, that if the imaginary part is 0, then you only have 1 arbitrary constant on the exponential, but if it is non-zero, you get 2, one for each trig function.  The rest falls out nicely if you plug 0 in for $latex b$ into $e^{ax}(C1\sin{bx} + C2\cos{box})$ because the sine goes to 0 and the cosine becomes 1.  But you would end up with $latex C1 + C2$ instead of just $latex C1$ in that case.  I had already planned on doing arbitrary constant simplification as part of my project, so I figured I would put this on hold and do that first.  Then, once that was done, the homogeneous case would be reduced to 1 case instead of the usual 2 or 3.  </p>
<p>My original plan was to make an arbitrary constant type that automatically simplified itself.  So, for example, if you entered <code>C1 + 2 + x</code> with <code>C1</code> an arbitrary constant, it would reduce to just <code>C1 + x</code>.  I worked with Ondrej, including visiting him in Los Alamos, and we build up a class that worked.  The problem was that, in order to have auto-simplification, I had to write the simplification directly into the core.  Neither of us liked this, so we worked a little bit on a basic core that would allow auto-simplification to be written directly in the classes instead of in the <code>Mul.flatten()</code> and <code>Add.flatten()</code> methods.  It turns out that my constant class isn't the only thing that would benefit from this.  Things like the order class (O(x)) and the infinity class (oo) are auto-simplified in the core, and things could be much cleaner if they happened in the classes themselves.  Unfortunately, modifying the core like this is not something that can happen overnight or even in a few weeks.  For one thing, it needed to wait until we had the new assumptions system, which was another Google Summer of Code project running parallel to my own.  So we decided to shelf the idea.</p>
<p>I still wanted constant simplification, so I settled with writing a function that could do it instead.  There were some downsides to this.  Making the function as general as the classes might have been would have been far too much work, so I settled on making it an internal-only  function that only worked on symbols named <code>C1</code>, <code>C2</code>, etc.  Also, unlike writing the simplification straight into <code>Mul.flatten()</code> which was as simple as removing any terms that were not dependent on x, writing a function that parsed an expression and simplified it was considerably harder to write.  I managed to churn out something that worked, and so I was ready to finish up the solver I had started a few paragraphs ago.  </p>
<p>After I finished that, I still needed to maintain the ability to solve that special case ODE.  Apparently, it is an ODE that you would get somewhere in deriving something about relativity, because it was in the relativity.py example file.  I used Maple's excellent <code>odeanalyser()</code> function (this is where I go the idea for my <code>classify_ode()</code>)to find a simple general case ODE that it fit (Liouville ODE).  After I finished this, I was ready to start working on the hints engine.  </p>
<p>It took me about a week to move all classification code into <code>classify_ode()</code>, move all solvers into individual functions, separate simplification code into yet other functions, and tie it all together in <code>dsolve()</code>.  In the end, the model worked very well.  The modularization allowed me to do some other things that I had not considered, such as creating a special "best" hint that used some heuristics that I originally developed for first order homogeneous which always has two possible solutions to try to give the best formatted solution for any ODE that has more than one possible solution method.  It also made debugging individual methods much easier, because I could just use the built in hint calls in <code>dsolve()</code> instead of commenting out lines of code in the source.  </p>
<p>This was good, because there was one more method that I wanted to implement.  I wanted to be able to solve the inhomogeneous case of a nth order linear ode with constant coefficients.  This can be done in the general case using the method of variation of parameters.  It was quite simple to set up variation of parameters up in the code.  You only have to set up a system of integrals using the Wronskian of the general solutions.  It would usually be a very poor choice of a method if you were trying to solve an ODE by hand because taking the Wronskian and computing n integrals is a lot of work.  But for a CAS, the work is already there.  I just have to set up the integrals.  </p>
<p>It soon became clear that even though, in theory, the method of variation of parameters can solve any ODE of this type, in practice, it does not always work so well in SymPy.  This is because SymPy have very poor simplification, especially trigonometric simplification, so sometimes there would be a trigonometric Wronskian that would be identically equal to some constant, but it could only simplify it to some very large rational function of sines and cosines.  When these were passed to the integral engine, it would cause it to fail, because it could not find the integral for such a seemingly complex expression.  </p>
<p>In addition, taking Wronskians, simplifying them, and then taking n integrals is a lot of work as I said, and even when SymPy could do it, it took a long time.  There is another method for solving these types of equations called undetermined coefficients that does not require integration.  It only works on a class of ODEs where the right hand side of the ODE is a simple combination of sines, cosines, exponentials, and polynomials in x.  It turns out that these kinds of functions are common anyway, so most ODEs of this type that you would encounter could be solved with this method.  Unlike variation of parameters, undetermined coefficients requires considerable setup, including checking for different cases.  This would be the method that you would want to use if you had to solve the ODE by hand because, even with all the setup, it only requires solving a system of linear equations vs. solving n integrals with variation of parameters, but for a CAS, it is the setup that matters, so this was a difficult prospect.</p>
<p>I spent the last couple of weeks writing up the necessary algorithms to setup the required system of linear equations and handling the different cases.  After I finally worked out all of the bugs, I ran some profiling against my variation of parameters solver.  It turned out that for ODEs that had trigonometric solutions (which take longer to simplify), my undetermined coefficients solver was an order of magnitude faster than the variation of parameters solver (and that is just for the ODEs that the variation of parameters engine could even solve at all).  For ODEs that only had exponentials, it was still 2-4 times faster.  </p>
<p>I finished off the summer by writing extensive documentation for all of my solvers and functions.  Hopefully someone who uses SymPy to solve ODEs can learn something about ODE solving methods as well as how to use the function I wrote when they read my documentation. </p>
<p><strong> Post-GSoC</strong></p>
<p>I plan on continuing development with SymPy now that the Google Summer of Code period is over.  SymPy is an amazing project, mixing Python and Computer Algebra, and I want to help it grow.  I may even apply again in a future year to implement some other thing in SymPy, or maybe apply as a mentor for SymPy to help someone else improve it.  </p>
<p><strong>Advice</strong></p>
<p>What follows is some general advice for someone who wants to apply for Google Summer of Code.  Some of the advice pertains specifically to SymPy, and some of it is general advice that I think would apply to any project.</p>
<ul>
<li>
<p>Get involved early.  As soon as you decide that you want to participate in Google Summer of Code, start getting involved in the project.  Get into contact with them and discuss possible projects.  If you are looking before the participating organizations are announced, look at the organizations from previous years. For some organizations, it will vary; for others (like Python), it is almost given that they will be accepted every year.   </p>
</li>
<li>
<p>Some projects (including SymPy) require you to send in a patch that passes review to be accepted.  This will give you a change to start familiarizing yourself with the code base.  If you are applying to SymPy, the Wester example I mentioned above is a really good way to learn what SymPy can do and how it works.  </p>
</li>
<li>
<p>Subscribe to the mailing list, and once you are comfortable with it, participate.  Also, it is a good idea to idle in IRC (SymPy is on freenode at #sympy).  This will help you get to know the main contributors for the project.   </p>
</li>
<li>
<p>For you application, see if the people in the project you are applying for will review it. If they like your project idea, they will try to help you write a good application so you can be accepted and you can implement it.  If they don't like your idea, then they will tell you and you should change it, otherwise you will not be accepted, no matter how well written your proposal is.  I have my proposal on the wiki (see link above).  I am not saying that it is necessarily a very good proposal, but it did get accepted.  If you are applying to SymPy, Ondrej will proofread your applications for you.</p>
</li>
<li>
<p>If you are an IRC fan, there is also #gsoc on freenode, where you can ask all your GSoC related questions.  Be warned that it does get pretty noisy in the application period, especially right before the applications are due and right before proposals are accepted.  </p>
</li>
<li>
<p>I cannot stress this one enough.  If you have never worked with a version control system before, it is perhaps more important to spend your time learning it than it is to learn the code base for your project.  These things have a steep learning curve if you have never used them before.  Once you master them though, they can make your life much easier.  Also, the sooner you learn to use them well, the easier your life will be later on down the road.  I spent a good part of the last week of GSoC cleaning up my commit history from the first half of the summer when I bad very poor committing/log habits.  If your project uses git, such as SymPy does, you might look at <a href="http://www-cs-students.stanford.edu/~blynn//gitmagic/">this</a> tutorial.  If it uses something else, good luck.  Seriously, git is the only good version control system.  See <a href="http://www.youtube.com/watch?v=4XpnKHJAok8">this video</a>.</p>
</li>
<li>
<p>Expect to spend only about half of the summer actually implementing stuff.  You may think that you are a good programmer and that your code will not be so buggy that you will need to spend that much time fixing bugs, and you may be right.  But the fact is, you will be working on code bases written by may programmers that are not so good.  You will need to fix several already existing bugs to make your code work, which means that you will need to learn the code base well, learn how to read other people's code, and how to fix bugs that you had no part in creating.  You will be glad if a bug is in your code because you will usually know immediately what causes it and how to fix it.  But if a bug is somewhere else, you will need to find it, figure out why it happens, what is supposed to happen, and how to fix it without breaking anything else.  This is also why it is important to be active in the developer community.  </p>
</li>
<li>
<p>Good luck.</p>
</li>
</ul></div>
        </div>
            
        
    <p>
        <a href="posts/2009/09/07/google-summer-of-code-2009-wrap-up.html#disqus_thread" data-disqus-identifier="cache/posts/2009/09/07/google-summer-of-code-2009-wrap-up.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2009/08/17/undetermined-coefficients.html" class="u-url">Undetermined Coefficients</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2009-08-17T22:33:00+00:00">2009-08-17 22:33</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><em>[Sorry for the delay in this post.  I was having some difficulties coming up with some of the rationales below. Also, classes have started, which has made me very busy.]</em>
<p>If there was one ODE solving method that I did not want to implement this summer, it was undetermined coefficients.  I didn't really like the method too much when we did it my my ODE class (though it was not as unenjoyable as series methods).  The thing that I never really understood very well is to what extent you have to multiply terms in the trial function by powers of x to make them linearly independent of the solution to the general equation.  We did our ODEs homework in Maple, so I would usually just keep trying higher powers of x until I got a solution.  But to implement it in SymPy, I had to have a much better understanding of the exact rules for it.</p>
<p>From a user's point of view, the method of undetermined coefficients is much better than the method of variation of parameters.  While it is true that variation of parameters is a general method and undetermined coefficients only works on a special class of functions, undetermined coefficients requires no integration or advanced simplification, so it is fast (very fast, as well shall see below).  All that the CAS has to do is figure out what a trial function looks like, plug it into the ODE, and solve for the coefficients, which is a system of linear equations.  </p>
<p>On the other hand, from the programmer's point of view, <a href="http://asmeurersympy.wordpress.com/2009/08/01/variation-of-parameters-and-more/">variation of parameters</a> is much better.  All you have to do is take the Wronskian of the general solution set and use it to set up some integrals.  But the Wronskian has to be simplified, and if the general solution contains sin's and cos's, this requires trigonometric simplification not currently available in SymPy (although it looks like the <a href="http://code.google.com/p/sympy/issues/detail?id=1598">new Polys module</a> will be making a big leap forward in this area).  Also, integration is slow, and in SymPy, it often fails (hangs forever).  </p>
<p>Figuring out what the trial function should be for undetermined coefficients is way more difficult to program, but having finnally finished it, I can say that it is definitely worth having in the module.  Problems that it can solve can run orders of magnitude faster than the variation of parameters, and often variation of parameters can't do the integral or returns a less simplified result.  </p>
<p>So what is this undetermined coefficients?  Well, the idea is this:  if you knew what each linearly independent term of the particular solution was, minus the coefficients, then you could just set each coefficient as an unknown, plug it into the ODE, and solve for them.  It turns out that resulting system of equations is linear, so if you do the first part right, you can always get a solution.  </p>
<p>The key thing here is that you know what form the particular solution will take.  However, you don't really know this ahead of time.  All you have is the linear ode $latex a_ny^{(n)}(x) + \dots + a_1y'(x) + a_0y(x) = F(x)$ (as far as I can tell, this only works in the case where the coefficients $latex a_i$ are constant with respect to x.  I'd be interested to learn that it works for other linear ODEs.  At any rate, that is the only one that works in my branch right now.).  The solution to the ode is $latex y(x) = y_g(x) + y_p(x)$, where $latex y_g(x)$ is the solution to the homogeneous equation $latex f(x) \equiv 0$, and $latex y_p(x)$ is the particular solution that produces the $latex F(x)$ term on the right hand side.  The key here is just that.  If you plug $latex y_p(x)$ into the left hand side of the ode, you get $latex F(x)$.  </p>
<p>It turns out that this method only works if the function $latex F(x)$ only has a finite number of linearly independent derivatives (I am unsure, but this might be able to work in other cases, but it would involve much more advanced mathematics).  So what kind of functions have a finite number of linearly independent solutions?  Obviously, polynomials do.  So does $latex e^x$, $latex \cos{x}$, and $latex \sin{x}$.  Also, if we multiply two or more of these types together, then we will get a finite number of linearly independent solutions after applying the product rule.  But is that all?  Well, if we take the definition of linear independence from linear algebra, we know that a set of n vectors $latex {\boldsymbol{v_1}, \boldsymbol{v_2}, \boldsymbol{v_3}, \dots, \boldsymbol{v_n}}$, not all zero, are linearly independent only if $latex a_1\boldsymbol{v_1} + a_2\boldsymbol{v_2} + a_3\boldsymbol{v_3} + \dots + a_n\boldsymbol{v_n}=0$ holds only when $latex a_1 \equiv 0, a_2 \equiv 0, a_3 \equiv 0, \dots, a_n \equiv 0$, that is, the only solution is the trivial one (remember, this is the <em>definition</em> of linear independence).  They are linearly dependent if there exist weights $latex a_1, a_2, a_3, \dots, a_n$, not all 0, such that the equation $latex a_1\boldsymbol{v_1} + a_2\boldsymbol{v_2} + a_3\boldsymbol{v_3} + \dots + a_n\boldsymbol{v_n}=0$ is satisfied.  Using this definition, we can see that a function $latex f(x)$ will have a finite number of linearly independent derivatives if it satisfies $latex a_nf^{(n)}(x) + a_{n - 1}f^{(n - 1)}(x) + \dots + a_1f'(x) + a_0f(x) = 0$ for some $latex n$ and with $latex a_i\neq 0$ for some $latex i$.  But this is just a <a href="http://asmeurersympy.wordpress.com/2009/08/01/variation-of-parameters-and-more/">homogeneous linear ODE with constant coefficients</a>, which we know how to solve.    The solutions are all of the form $latex ax^ne^{b x}\cos{cx}$ or $latex ax^ne^{b x}\sin{cx}$, where a, b, and c are real numbers and n is a non-negative integer.  We can set the various constants to 0 to get the type we want.  For example, for a polynomial term, b will be 0 and c will be 0 (use the cos term).</p>
<p>So this gives us the exact form of functions that we need to look for to apply undetermined coefficients, based on the assumption that it only works on functions with a finite number of linearly independent derivatives.  </p>
<p>Well, implementing it was quite difficult.  For every ODE, the first step in implementation is matching the ODE, so the solver can know what methods it can apply to a given ODE.  To match in this case, I had to write a function that determined if the function matched the form given above, which was not too difficult, though not as trivial as just grabbing the right hand side in variation of parameters.  The next step is to use the matching to format the ODE for the solver.  In this case, it means finding all of the finite linearly independent derivatives of the ODE, so that the solver can just create a linear combination of them solve for the coefficients.  This was a little more difficult, and it took some lateral thinking.  </p>
<p>At this point, there is one more thing that needs to be noted. Since the trial functions, that is, the linearly independent derivative terms of the right hand side of the ODE, are of the same form as the solutions to the homogeneous equation, it is possible that one of the trial function terms will be a solution to the homogeneous equation.  If this happens, plugging it into the ODE will cause it to go to zero, which means that we will not be able to solve for a coefficient for that term.  Indeed, that term will be of the form $latex C1*\textrm{term}$ in the final solution, so even if we had a coefficient for it, it would be absorbed into this term from the solution to the homogeneous equation.  For example, variation of parameters will give a coefficient for such terms, even though it is unnecessary.  This is a clue that Maple uses variation of parameters for all linear constant coefficient ODE solving, because it gives the unnecessary terms with the coefficients that would be given by variation of parameters, instead of absorbing them into the arbitrary constants.  </p>
<p>We can safely ignore these terms for undetermined coefficients, because their coefficients will not even appear in the system of linear equations of the coefficients anyway.  But, without these coefficients, we will run into trouble.  It turns out that if a term $latex x^ne^{ax}\sin{bx}$ or $latex x^ne^{ax}\cos{bx}$ is repeated solution to the homogeneous equation, and $latex x^{n + 1}e^{ax}\sin{bx}$ or $latex x^{n + 1}e^{ax}\cos{bx}$ is not, so that $latex n$ is the highest $latex x$ power that makes it a solution to the homogeneous equation, and if the trial solution has $latex x^me^{ax}\sin{bx}$ or $latex x^me^{ax}\cos{bx}$ terms, but not $latex x^{m + 1}e^{ax}\sin{bx}$ or $latex x^{m + 1}e^{ax}\cos{bx}$ terms, so that $latex m$ is the highest power of $latex x$ in the the trial function terms, then we need to multiply these trial function terms by $latex x^{n + m}$ to make them linearly independent with the solutions of the homogeneous equation.  </p>
<p>Most <a href="http://en.wikipedia.org/wiki/Method_of_undetermined_coefficients">references</a> simply say that you need to multiply the trial function terms by "sufficient powers of x" to make them linearly independent with the homogeneous solution.  Well, this is just fine if you are doing it by hand or you are creating the trial function manually in Maple and plugging it in and solving for the coefficients.  You can just keep upping the powers of x until you get a solution for the coefficients.  Creating those trial functions in Maple, plugging them into the ODE, and solving for the coefficients is exactly what I had to do for my homework when I took ODEs last spring, and this "upping powers" trial and error method is exactly the method I used.  But when you are doing it in SymPy, you need to know exactly what power to multiply it by.  If it is too low, you will not get solution to the coefficients.  If it is too high, you can actually end up with too many terms in the final solution, giving a wrong answer.  </p>
<p>Fortunately, my excellent <a href="http://books.google.com.np/books?id=29utVed7QMIC&amp;lpg=PA24&amp;ots=uxLSUKt_3P&amp;dq=testing%20implicit%20solutions%20to%20ode&amp;hl=en&amp;pg=PA61#v=onepage&amp;q=&amp;f=false">ODEs textbook</a> gives the exact cases to follow, and so I was able to implement it correctly.  The textbook also gives a whole slew of exercises, all for which the solutions are given.  As usual, this helped me to find the bugs in my very complex and difficult to write routine.  It also helped me to find a <a href="http://code.google.com/p/sympy/issues/detail?id=1601">match bug</a> that would have prevented <code>dsolve()</code> from being able to match certain types of ODEs.  The bug turned out to be fundamental to the way <code>match()</code> is written, so I had to write my own custom matching function for linear ODEs.  </p>
<p>The final step in solving the undetermined coefficients is of course just creating a linear combination of the trial function terms, plugging it into the original ODE, and setting the coefficients of each term on each side equal to each other, which gives a linear system. SymPy can solve these easily, and once you have the values of the coefficients, you can use them to build your particular solution, at which point, you are done.  </p>
<p>The results were astounding.  Variation of parameters would hang on many simple inhomogeneous ODEs because of poor trig simplification of the Wronsikan, but my undetermined coefficients method handles them perfectly.  Also, there is no need to worry about absorbing superfluous terms into the arbitrary constants as with variation of parameters, because they are removed from within the undetermined coefficients algorithm.</p>
<p>But the biggest thing was speed.  Here are some benchmarks on some random ODEs from the test suite. WordPress code blocks are impervious to whitespace, as I have mentioned before, so no pretty printing here.  Also, it truncates the hints.  The hints used are <code>'nth_linear_constant_coeff_undetermined_coefficients'</code> and <code>'nth_linear_constant_coeff_variation_of_parameters'</code>:</p>
<p><code></code></p>
<blockquote>

In [1]: time dsolve(f(x).diff(x, 2) - 3*f(x).diff(x) - 2*exp(2*x)*sin(x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.07 s, sys: 0.00 s, total: 0.08 s

Wall time: 0.08 s

Out[2]: 

f(x) == C1 + (-3*sin(x)/5 - cos(x)/5)*exp(2*x) + C2*exp(3*x)



In [3]: time dsolve(f(x).diff(x, 2) - 3*f(x).diff(x) - 2*exp(2*x)*sin(x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')

CPU times: user 0.92 s, sys: 0.01 s, total: 0.93 s

Wall time: 0.94 s

Out[4]: 

f(x) == C1 + (-3*sin(x)/5 - cos(x)/5)*exp(2*x) + C2*exp(3*x)



In [5]: time dsolve(f(x).diff(x, 4) - 2*f(x).diff(x, 2) + f(x) - x + sin(x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.06 s, sys: 0.00 s, total: 0.06 s

Wall time: 0.06 s

Out[6]: 

f(x) == x - sin(x)/4 + (C1 + C2*x)*exp(x) + (C3 + C4*x)*exp(-x)



In [7]: time dsolve(f(x).diff(x, 4) - 2*f(x).diff(x, 2) + f(x) - x + sin(x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')

CPU times: user 5.43 s, sys: 0.03 s, total: 5.46 s

Wall time: 5.52 s

Out[8]: 

f(x) == x - sin(x)/4 + (C1 + C2*x)*exp(x) + (C3 + C4*x)*exp(-x)



In [9]: time dsolve(f(x).diff(x, 5) + 2*f(x).diff(x, 3) + f(x).diff(x) - 2*x - sin(x) - cos(x), f(x), 'nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.10 s, sys: 0.00 s, total: 0.10 s

Wall time: 0.11 s

Out[10]: 

f(x) == C1 + (C2 + C3*x - x**2/8)*sin(x) + (C4 + C5*x + x**2/8)*cos(x) + x**2



In [11]: time dsolve(f(x).diff(x, 5) + 2*f(x).diff(x, 3) + f(x).diff(x) - 2*x - sin(x) - cos(x), f(x), 'nth_linear_constant_coeff_variation_of_parameters')



</blockquote>

<p></p>
<p>The last one involves a particularly difficult Wronskian for SymPy (run it with hint='nth_linear_constant_coeff_variation_of_parameters_Integral', simplify=False).</p>
<p>Wall time comparisons reveal amazing speed differences.  We're talking orders of magnitude.</p>
<p><code></code></p>
<blockquote>

In [13]: 0.94/0.08

Out[13]: 11.75



In [14]: 5.52/0.06

Out[14]: 92.0



In [15]: oo/0.11

Out[15]: +inf

</blockquote>

<p></p>
<p>Of course, variation of parameters has the most difficult time when there are sin and cos terms involved, because of the poor trig simplification in SymPy.  So let's see what happens with an ODE that just has exponentials and polynomial terms involved.</p>
<p><code></code></p>
<blockquote>

In [16]: time dsolve(f(x).diff(x, 2) + f(x).diff(x) - x**2 - 2*x, f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.10 s, sys: 0.00 s, total: 0.10 s

Wall time: 0.10 s

Out[17]: 

f(x) == C1 + x**3/3 + C2*exp(-x)



In [18]: time dsolve(f(x).diff(x, 2) + f(x).diff(x) - x**2 - 2*x, f(x), hint='nth_linear_constant_coeff_variation_of_parameters')

CPU times: user 0.19 s, sys: 0.00 s, total: 0.19 s

Wall time: 0.20 s

Out[19]: 

f(x) == C1 + x**3/3 + C2*exp(-x)



In [20]: time dsolve(f(x).diff(x, 3) + 3*f(x).diff(x, 2) + 3*f(x).diff(x) + f(x) - 2*exp(-x) + x**2*exp(-x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')

CPU times: user 0.09 s, sys: 0.00 s, total: 0.09 s

Wall time: 0.09 s

Out[21]: 

f(x) == (C1 + C2*x + C3*x**2 + x**3/3 - x**5/60)*exp(-x)



In [22]: time dsolve(f(x).diff(x, 3) + 3*f(x).diff(x, 2) + 3*f(x).diff(x) + f(x) - 2*exp(-x) + x**2*exp(-x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')

CPU times: user 0.29 s, sys: 0.00 s, total: 0.29 s

Wall time: 0.29 s

Out[23]: 

f(x) == (C1 + C2*x + C3*x**2 + x**3/3 - x**5/60)*exp(-x)



</blockquote>

<p></p>
<p>The wall time comparisons here are:</p>
<p><code></code></p>
<blockquote>

In [24]: 0.20/0.10

Out[24]: 2.0



In [25]: 0.29/0.09

Out[25]: 3.22222222222

</blockquote>

<p></p>
<p>So we don't have orders of magnitude anymore, but it is still 2 to 3 times faster.  Of course, most ODEs of this form <em>will</em> have sin or cos terms in them, so the order of magnitude improvement over variation of parameters can probably be attributed to undetermined coefficients in general.  </p>
<p>Of course, we know that variation of parameters will still be useful, because functions like $latex \ln{x}$, $latex \sec{x}$ and $latex \frac{1}{x}$ do not have a finite number of linearly independent derivatives, and so you cannot apply the method of undetermined coefficients to them.  </p>
<p>There is one last thing I want to mention.  You can indeed multiply any polynomial, exponential, sin, or cos functions together and still get a function that has a finite number of linearly independent solutions, but if you multiply two or more of the trig functions, you have to apply the <a href="http://en.wikipedia.org/wiki/Trig_identities#Power-reduction_formulas">power reduction rules</a> to the resulting function to get it in terms of sin and cos alone.  Unfortunately, SymPy does not yet have a <a href="http://code.google.com/p/sympy/issues/detail?id=1590">function</a> that can do this, so to solve such a differential equation with undetermined coefficients (recommended, see above), you will have to apply them manually yourself.  Also, just for the record, it doesn't play well with exponentials in the form of sin's and cos's or the other way around (complex coefficients on the arguments), so you should back convert those first too.  </p>
<p>Well, this concludes the first of two blog posts that I promised.  I also promised that I would write about my summer of code experiences.  Not only is this important to me, but it is a <a href="http://code.google.com/p/sympy/wiki/GSoC2009">requirement</a>.  I really <em>hope</em> to get this done soon, but with classes, who knows.  </p></div>
        </div>
            
        
    <p>
        <a href="posts/2009/08/17/undetermined-coefficients.html#disqus_thread" data-disqus-identifier="cache/posts/2009/08/17/undetermined-coefficients.html">Comments</a>


        </p></article>
        <article class="postbox h-entry post-text">
        <h1 class="p-name"><a href="posts/2009/08/17/los-alamos-sprint.html" class="u-url">Los Alamos "Sprint"</a>
        <small>  
             Posted: <time class="published dt-published" datetime="2009-08-17T18:42:57+00:00">2009-08-17 18:42</time>
        </small></h1>
        <hr>
        <div class="e-content">
        <div><p></p><p>Last weekend, Luke came to visit Ondrej in Los Alamos, so I decided to drive him up from Albuquerque and visit him again.  It was nice meeting Luke and seeing Ondrej again.  </p>
<p>Aside from coding (the main thing that I did was fix an ugly match bug that was preventing dsolve() from recognizing certain ODEs), we visited the atomic museum in Los Alamos, the <a href="http://en.wikipedia.org/wiki/Valles_Caldera">Valles Caldera</a>, and some of the surrounding hot springs.  </p>
<p>Here are some pictures that Luke took with his iPhone.  Stupid WordPress seems to insist on flipping some of them (I can't fix it):</p>
<p>[gallery]</p>
<p>This is one of three posts that I plan on doing this week.  I just finished my GSoC project today/last night, so I will be blogging about that.  I plan on doing a post on the method of Undetermined Coefficients, as well as some other things that I managed to do.  The other post will be my general musings/advice for GSoC. That will probably be my last post here in a while.  I plan on continuing work with SymPy, but I get very busy with classes, so I most likely won't be doing much until next summer.</p></div>
        </div>
            
        
    <p>
        <a href="posts/2009/08/17/los-alamos-sprint.html#disqus_thread" data-disqus-identifier="cache/posts/2009/08/17/los-alamos-sprint.html">Comments</a>


        </p></article>
    
        <div>
        <ul class="pager">
            <li class="previous">
                <a href="index-4.html" rel="prev">← Newer posts</a>
            </li>
            <li class="next">
                <a href="index-2.html" rel="next">Older posts →</a>
            </li>
        </ul>
        </div>

    
        
       <script>var disqus_shortname="nikolademo";(function(){var a=document.createElement("script");a.async=true;a.src="//"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>


	
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}
        });
        </script>
        <script src="assets/js/mathjax.js"></script>


        </div>
        <!--End of body content-->

        <footer>
            Contents © 2014         <a href="mailto:joe@example.com">Joe Example</a> - Powered by         <a href="http://getnikola.com" rel="nofollow">Nikola</a>         
        </footer>
    </div>
</div>


            <script src="assets/js/all-nocdn.js" type="text/javascript"></script>


    
<!-- Social buttons -->
<div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style">
<a class="addthis_button_more">Share</a>
<ul><li><a class="addthis_button_facebook"></a>
</li><li><a class="addthis_button_google_plusone_share"></a>
</li><li><a class="addthis_button_linkedin"></a>
</li><li><a class="addthis_button_twitter"></a>
</li></ul>
</div>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"></script>
<!-- End of social buttons -->


    <script type="text/javascript">jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script>
    

</body>
</html>