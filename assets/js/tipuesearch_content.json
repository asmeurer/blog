{
  "pages": [
    {
      "title": "Moving to GitHub pages with Nikola", 
      "tags": "", 
      "text": "So I've fi\u00adnal\u00adly de\u00adcid\u00aded to move my blog from Word\u00adpress to GitHub pages.  I\nhigh\u00adly rec\u00adom\u00admend it if you are tech\u00adni\u00adcal\u00adly skilled enough to do it. I was\nget\u00adting pret\u00adty an\u00adnoyed at Word\u00adpress. It forces you to write your posts in\u00ad\nhtml (or else us\u00ading their WYSI\u00adWYG ed\u00adi\u00adtor), the word\u00adpress.\u00adcom is locked down,\n\u00adso you can't add any Javascrip\u00adt, their math is stuck in the past ren\u00adder\u00ading png\nin\u00adstead of us\u00ading Math\u00adJax. The list goes on. \n With GitHub pages, I can write my posts in Mark\u00addown, and I have full con\u00adtrol\nover ev\u00adery\u00adthing. And there is no lock in. If I de\u00adcide I don't like the\n\u00adsoft\u00adware that is gen\u00ader\u00adat\u00ading the post\u00ads, I can eas\u00adi\u00adly move to some\u00adthing else,\ns\u00adince the post con\u00adtent it\u00adself is all Mark\u00addown (or the oc\u00adca\u00adsion\u00adal rst or\nIPython note\u00adbook if I want to do some\u00adthing that Mark\u00addown does\u00adn't sup\u00adport\u00ad). \n Here's the guide on how to do it. First, you need to set up GitHub pages. This\nis a bit con\u00adfus\u00ading, be\u00adcause there are ac\u00adtu\u00adal\u00adly two kinds of GitHub pages, user\n\u00adpages and project pages. Us\u00ader pages are if you have a re\u00adpo named\n user\u00adname.github.io  (or  .com). The pages are served from the  mas\u00adter \nbranch. \n For project pages, you add a  gh-\u00adpages  branch to any one of your pro\u00adject\u00ads,\nand GitHub hosts the con\u00adtent au\u00adto\u00admat\u00adi\u00adcal\u00adly at\n user\u00adname.github.io/pro\u00adject\u00adname. I orig\u00adi\u00adnal\u00adly had my blog con\u00adtent at\n as\u00admeur\u00ader.github.io, but I did\u00adn't like that I had to do ev\u00adery\u00adthing in mas\u00adter,\nboth the gen\u00ader\u00adat\u00aded and orig\u00adi\u00adnal con\u00adtent. So in\u00adstead I cre\u00adat\u00aded a re\u00adpo called\n blog. I have my con\u00adtent in the  mas\u00adter  branch and the gen\u00ader\u00adat\u00aded pages in\u00ad\nthe  gh-\u00adpages  branch (more on this lat\u00ader). At my\n as\u00admeur\u00ader.github.\u00adcom  re\u00adpo,\nI just have for now a ba\u00adsic re\u00addi\u00adrect to the blog. In the fu\u00adture, I may want to\nput ad\u00addi\u00adtion\u00adal, non-blog con\u00adtent on the web\u00adsite, and it would go there (or in\u00ad\na sep\u00ada\u00adrate project re\u00adpo with its own  gh-\u00adpages  branch). \n Nikola\nI had ini\u00adtial\u00adly planned on us\u00ading\n Pel\u00adi\u00adcan. How\u00adev\u00ader, I got stalled on the\n\u00adWord\u00adpress im\u00adport. I like that Pel\u00adi\u00adcan is writ\u00adten in Python, but I was not too\n\u00adkeen on their abra\u00adsive\n li\u00adcense. Frankly,\nI should\u00adn't say too many bad things about Pel\u00adi\u00adcan be\u00adcause I nev\u00ader re\u00adal\u00adly tried\nthat hard with it. \n I have de\u00adcid\u00aded to try  Niko\u00adla  in\u00adstead. It's al\u00adso\nwrit\u00adten in Python. It has a very nice\n li\u00adcense. I like\nthe phi\u00adlos\u00ado\u00adphy of the  man\u00adu\u00adal: \n \nDON'T READ THIS MAN\u00adU\u00adAL. IF YOU NEED TO READ IT I FAILED, JUST USE THE THING. \n \nI've al\u00adso dis\u00adcov\u00adered that the\n Niko\u00adla com\u00admu\u00adni\u00adty  is\n very  nice. And of course, even if Niko\u00adla ends up not be\u00ading for me, it will\nbe easy to switch, be\u00adcause my ac\u00adtu\u00adal con\u00adtent is just some Mark\u00addown files that\nI own. \n Getting started\nGet\u00adting start\u00aded with Niko\u00adla is pret\u00adty easy. First, you need to in\u00adstall it. It\nhas a  ton  of de\u00adpen\u00adden\u00adcies (for\u00adtu\u00adnate\u00adly all Python, so it won't be that\nhard). In ad\u00addi\u00adtion to the ones in the re\u00adquire\u00adments.tx\u00adt, you should al\u00adso\nin\u00adstall  mark\u00addown  and  we\u00adbas\u00adsets. While us\u00ading  niko\u00adla, it will tell you if\ny\u00adou don't have some\u00adthing in\u00adstalled that you should, so if you see that, just\nin\u00adstall what it tells you to.  If you use  con\u00adda  and Mac OS X, I have\nu\u00adpload\u00aded all the de\u00adpen\u00adden\u00adcies to my  Bin\u00adstar,\n\u00adso you can just  con\u00adda in\u00adstall -c as\u00admeur\u00ader niko\u00adla. \n Then you just run the com\u00admands from\nhttp://get\u00adniko\u00adla.\u00adcom/hand\u00adbook.htm\u00adl#al\u00adl-y\u00adou-need-\u00adto-\u00adknow. \n One thing that does\u00adn't tell you is that af\u00adter you init the site, you should\nwalk through  con\u00adf.py  and change the set\u00adtings to your lik\u00ading. \n An\u00adoth\u00ader trick not there is that you can add \n eval \"`nikola tabcompletion`\"\n\n\n\nto your Bash pro\u00adfile to get tab com\u00adple\u00adtion. \n Wordpress import\nIm\u00adport\u00ading from Word\u00adpress is pret\u00adty easy ac\u00adtu\u00adal\u00adly. First you need to go to the\n\u00adWord\u00adpress site dash\u00adboard and go to \"Ex\u00adport\" from the \"Tool\u00ads\" menu. From here\ny\u00adou can down\u00adload an XML file with all your con\u00adtent. Then just do \n nikola import_wordpress export_file.xml\n\n\n\nNote that the cur\u00adrent ver\u00adsion of Niko\u00adla as of this writ\u00ading (6.3.0) does\u00adn't do\nthis right, so you'll need to use the\n git mas\u00adter. There are some is\u00adsues with\u00ad\nthe im\u00adport, since Word\u00adpress has its own markup that it does\u00adn't know ev\u00adery\u00adthing\nabout, so you may need to go in and fix things. Or re\u00adport them as bugs to\nNiko\u00adla and reim\u00adport when they are fixed. \n For com\u00adments, you first need to cre\u00adate a Dis\u00adqus ac\u00adcoun\u00adt, and en\u00adable it in your\n\u00adcon\u00adf.py. You should then up\u00adload the xml file that you ex\u00adport\u00aded from Word\u00adpress\n\u00adto Dis\u00adqus. At this point, the com\u00adments should just work, be\u00adcause Niko\u00adla set\u00ads\nthe Dis\u00adqus url for the im\u00adport\u00aded com\u00adments to the old Word\u00adpress url (look at the\nDis\u00adqus sec\u00adtion of one of the built pages). \n If there's a mis\u00admatch, or if you need to make the urls match your new site for\n\u00adsome rea\u00adson, you can use a url map csv. Niko\u00adla gen\u00ader\u00adates one au\u00adto\u00admat\u00adi\u00adcal\u00adly,\nbut you should make sure that it's cor\u00adrec\u00adt. \n The Dis\u00adqus im\u00adport can take a while to reg\u00adis\u00adter (ac\u00adcord\u00ading to Dis\u00adqus, it can\n\u00adtake up to 24 hours).", 
      "loc": "/posts/moving-to-github-pages-with-nikola/"
    }, 
    {
      "title": "Python 3: Single codebase vs. 2to3", 
      "tags": "", 
      "text": "In my  pre\u00advi\u00adous post  about switch\u00ading to Python 3 as my de\u00adfault Python, I praised the use of a sin\u00adgle code\u00adbase for sup\u00adport\u00ading both Python 2 and Python 3. I even chas\u00adtised the Python core de\u00advel\u00adop\u00aders for cre\u00adat\u00ading 2to3, writ\u00ading, \"I think that the core Python folks made a mis\u00adtake by pre\u00adsent\u00ading Python 3 as a new lan\u00adguage. It has made peo\u00adple an\u00adtag\u00ado\u00adnis\u00adtic against Python 3 (well, that and the print func\u00adtion, which was an\u00adoth\u00ader stupid mis\u00adtake, be\u00adcause even if it was a good idea, it alone has kept too many peo\u00adple from switch\u00ading). 2to3 was a mis\u00adtake too, be\u00adcause it per\u00adpet\u00adu\u00adat\u00aded this idea.\" \n Well, this is\u00adn't en\u00adtire\u00adly fair, be\u00adcause I my\u00adself used to be one of the big\u00adgest ad\u00advo\u00adcates of us\u00ading 2to3 over a sin\u00adgle code\u00adbase. Take this  GitHub com\u00adment  from when the IPython guys were con\u00adsid\u00ader\u00ading this is\u00adsue, where I wrote, \"main\u00adtain\u00ading a com\u00admon code base is go\u00ading to be a bit an\u00adnoy\u00ading from the de\u00advel\u00adop\u00ader side.\u2026The main ben\u00ade\u00adfit of us\u00ading 2to3 is that 99% of the time, you can just write your code as you would for Python 2, and when it gets to Python 3, it just works (maybe that per\u00adcent is a bit small\u00ader if you use strings a lot, but it's still quite high\u00ad). To write for Python 2 and 3 at the same time, you have to re\u00admem\u00adber a lot of lit\u00adtle rules, which no one will re\u00admem\u00adber (and new con\u00adtrib\u00adu\u00adtors will not even know about). And giv\u00aden that IPython's test cov\u00ader\u00adage is still poor (un\u00adless I am mis\u00adtak\u00aden, in which case, please cor\u00adrect me), lit\u00adtle mis\u00adtakes will slip through, and no one will no\u00adtice un\u00adtil they try the cer\u00adtain be\u00adhav\u00adior in Python 3.\" \n So I just want to clar\u00adi\u00adfy a few things. \n \n    I was wrong.   When I chas\u00adtised the Python core de\u00advel\u00adop\u00aders for mak\u00ading peo\u00adple be\u00adlieve that Python 3 is a dif\u00adfer\u00adent lan\u00adguage from Python 2,  I too  fell in\u00adto that trap. It took a month of me work\u00ading on a code\u00adbase that had to be di\u00adrect\u00adly Python 3 com\u00adpat\u00adi\u00adble to see the fal\u00adla\u00adcy of this.  And see\u00ading just how small the SymPy  com\u00adpat\u00adi\u00adbil\u00adi\u00adty  file is sealed the deal. I now be\u00adlieve that I was com\u00adplete\u00adly wrong in say\u00ading that main\u00adtain\u00ading a com\u00admon code\u00adbase is an\u00adnoy\u00ading. As I wrote in the pre\u00advi\u00adous post, it is no dif\u00adfer\u00adent from sup\u00adport\u00ading 2.4-2.7, for in\u00adstance (ac\u00adtu\u00adal\u00adly, by my mem\u00ado\u00adry, sup\u00adport\u00ading 2.4-2.7 was much worse than sup\u00adport\u00ading 2.6-3.3, be\u00adcause  so  many lan\u00adguage fea\u00adtures were in\u00adtro\u00adduced in Python 2.5) \n     If you have to sup\u00adport 2.5 or ear\u00adli\u00ader and Python 3, then 2to3 might ac\u00adtu\u00adal\u00adly be bet\u00adter.  The rea\u00adson is sim\u00adple: Python 2.6 was the first ver\u00adsion of Python to \"know\" about Python 3. So, for in\u00adstance,  from  fu\u00adture  im\u00adport print\u00ad_\u00adfunc\u00adtion  was in\u00adtro\u00adduced in Python 2.6. This means that to sup\u00adport a sin\u00adgle code\u00adbase for 2.5-3.x you have to write  print\u00ad('\\n')  to print an emp\u00adty line and to print some\u00adthing with\u00adout a new\u00adline at the end, you have to use  sys.std\u00adout.write. Al\u00adso,  ex\u00adcept Ex\u00adcep\u00adtion as e, us\u00ading the  as  key\u00adword, which is the on\u00adly syn\u00adtax al\u00adlowed in Python 3, was in\u00adtro\u00adduced in Python 2.6, so if you want to catch an ex\u00adcep\u00adtion you have to use  sys.ex\u00adc_in\u00adfo()[1]. Now that re\u00adal\u00adly  is  an\u00adnoy\u00ading. But in Python 2.6, most dif\u00adfer\u00adences can be fixed with sim\u00adple def\u00adi\u00adni\u00adtion\u00ads, most of which boil down to try, ex\u00adcept Im\u00adportEr\u00adror, im\u00adport x as y type work\u00adarounds. The worst are the print func\u00adtion, which can be im\u00adport\u00aded from  fu\u00adture, di\u00advi\u00adsion, which can al\u00adso be im\u00adport\u00aded from  fu\u00adture  (or worked around), and uni\u00adcode lit\u00ader\u00adals (if it's a big deal, drop sup\u00adport for Python 3.2). Most oth\u00ader things are just sim\u00adple re\u00adnames, like xrange -> range, or mak\u00ading sure that you wrap func\u00adtions that are it\u00ader\u00ada\u00adtors in Python 3 in  list  if you want to ac\u00adcess items from them. \n     I was right about test cov\u00ader\u00adage.  Sup\u00adport\u00ading Python 2 and Python 3 in a sin\u00adgle code\u00adbase if you have bad test cov\u00ader\u00adage is not go\u00ading to work. You can get around the worst things by mak\u00ading sure that  fu\u00adture  im\u00adports are at the top of each file, but you are bound to miss things, be\u00adcause, as I said, you will for\u00adget that  map(f, s)[0]  does\u00adn't work in Python 3 or that the  Strin\u00adgIO  mod\u00adule has been re\u00adnamed to  io, or that you can't pass around da\u00adta as strings\u2014they have to be bytes.\n Of course, you al\u00ad\u00adso need good test cov\u00ad\u00ader\u00adage to sup\u00ad\u00adport Python 3 well us\u00ading 2to3, but you can get away with more be\u00ad\u00adcause 2to3 will take care of things like the above for you.  Per\u00adhaps in\u00ad\u00adstead of 2to3 what re\u00adal\u00ad\u00adly should have been made is a pyflakes-\u00ad\u00adlike tool that us\u00ades the same knowl\u00ad\u00adedge as 2to3 to check for cross-\u00ad\u00adcom\u00ad\u00adpat\u00adi\u00ad\u00adbil\u00adi\u00ad\u00adty for Python 2 and Python 3. \n     In the end, you have to be ac\u00adtu\u00adal\u00adly us\u00ading Python 3.  I feel like peo\u00adple haven't been, even to\u00adday, tak\u00ading Python 3 se\u00adri\u00adous\u00adly. They aren't ac\u00adtu\u00adal\u00adly us\u00ading it. There's a feel\u00ading that some\u00adday in the fu\u00adture they will, but for now, Python 2 is the way to go. 2to3 ex\u00adac\u00ader\u00adbates this feel\u00ading, be\u00adcause to use it, you have to de\u00advel\u00adop in Python 2. You should\u00adn't touch the code gen\u00ader\u00adat\u00aded by 2to3. As it is, then, if you de\u00advel\u00adop with 2to3, you on\u00adly ev\u00ader use Python 3 to test that things are work\u00ading in Python 3. You don't pro\u00adto\u00adtype your code in Python 3, be\u00adcause then you will write code that does\u00adn't work in Python 2. \n With the sin\u00ad\u00adgle code\u00adbase, your view should change. You should start pro\u00ad\u00adto\u00ad\u00adtyp\u00ading in Python 3. You should on\u00ad\u00adly use Python 2 to test that things work in Python 2 (and since you've been us\u00ading Python 2 for so long be\u00ad\u00adfore switch\u00ading to Python 3, or at least if you're like me you have, this is not that bad). Just yes\u00adter\u00ad\u00adday, I found a   bug   in SymPy in Python 3 that went un\u00adno\u00adticed. It re\u00adlates to what I said above about us\u00ading bytes in\u00ad\u00adstead of strings for da\u00ad\u00adta. I just checked, and 2to3 would\u00adn't have fixed it (and in\u00ad\u00addeed, the bug is present in SymPy 0.7.3, which used 2to3), be\u00ad\u00adcause there's no way for 2to3 to have known that the da\u00ad\u00adta was bytes and not a string.  The code was ob\u00advi\u00adous\u00ad\u00adly untest\u00aded, but it would have been ob\u00advi\u00adous that it did\u00adn't work if any\u00adone was us\u00ading Python 3 to use SymPy in\u00ad\u00adter\u00adac\u00ad\u00adtive\u00ad\u00adly.  As it turns out, some of our users are do\u00ading this, and they point\u00aded it out on the mail\u00ading list, but it re\u00ad\u00admained un\u00ad\u00adfixed un\u00adtil I found it my\u00ad\u00adself in\u00ad\u00adde\u00adpen\u00ad\u00adden\u00adt\u00ad\u00adly.      \n \n\nSo old mis\u00adtakes aside, the lessons to take away from this and the  pre\u00advi\u00adous blog post  are   \n \n    Use a sin\u00adgle code\u00adbase in\u00adstead of 2to3 to sup\u00adport both Python 2 and Python 3. \n     Use Python 3 as your de\u00adfault Python. \n     Keep Python 2 around, though, be\u00adcause not ev\u00adery\u00adthing sup\u00adports Python 3 yet. \n     Ex\u00adpect to find some bugs, be\u00adcause, un\u00adtil ev\u00adery\u00adone starts do\u00ading this, peo\u00adple aren't go\u00ading to test their soft\u00adware in Python 3.", 
      "loc": "/posts/2013/08/22/python-3-single-codebase-vs-2to3/"
    }, 
    {
      "title": "Using Python 3 as my default Python", 
      "tags": "", 
      "text": "So I just fin\u00adished my in\u00adtern\u00adship with  Con\u00adtin\u00adu\u00adum. For the in\u00adtern\u00adship, I pri\u00admar\u00adi\u00adly worked on  Ana\u00adcon\u00adda, their free Python dis\u00adtri\u00adbu\u00adtion, and  con\u00adda, its free (B\u00adSD open source) pack\u00adage man\u00adag\u00ader. I might write a blog post about con\u00adda lat\u00ader, but suf\u00adfice it to say that I'm con\u00advinced that it is do\u00ading pack\u00adage man\u00adage\u00adment the right way. One of the ma\u00adjor de\u00advel\u00adop\u00adments this sum\u00admer that I helped out with was the abil\u00adi\u00adty for  any\u00adbody to build a con\u00adda pack\u00adage, and a site called  Bin\u00adstar \u00a0where peo\u00adple can up\u00adload them (the be\u00adta code is \"bin\u00adstar in be\u00adta\" with no quotes).\u00a0 An\u00adoth\u00ader thing that hap\u00adpened over the sum\u00admer is that Al\u00admar Klein made con\u00adda Python 3 com\u00adpat\u00adi\u00adble, so that it can be used with the  Py\u00adzo \u00a0pro\u00adjec\u00adt, which is Python 3 on\u00adly.\u00a0\u00a0 \u00a0The way this was done was by us\u00ading a sin\u00adgle code base for Python 2 and Python 3. Thus, this be\u00adcame the first time I have done any heavy de\u00advel\u00adop\u00adment on Python source that had to be Python 3 com\u00adpat\u00adi\u00adble from a sin\u00adgle code\u00adbase (as op\u00adposed to us\u00ading the 2to3 tool).\u00a0 An\u00adoth\u00ader de\u00advel\u00adop\u00adment this sum\u00admer was that SymPy was re\u00adleased (0.7.3). This marked the last re\u00adlease to sup\u00adport Python 2.5. Around the same time, we dis\u00adcussed our Python 3 sit\u00adu\u00ada\u00adtion, and how an\u00adnoy\u00ading it is to run use2\u00adto3 all the time. The re\u00adsult was  this pull re\u00adquest, which made SymPy use a sin\u00adgle code base for Python 2 and Python 3. Now, that pull re\u00adquest is hard to mull through, but the im\u00adpor\u00adtant part to look at is the  com\u00adpat\u00adi\u00adbil\u00adi\u00adty  file. Ev\u00adery\u00adthing in that file has to be im\u00adport\u00aded and used, be\u00adcause it rep\u00adre\u00adsents things that are dif\u00adfer\u00adent be\u00adtween Python 2 and Python 3. Ond\u0159ej has writ\u00adten more about this on  his blog.\u00a0 In al\u00adl, I think that sup\u00adport\u00ading Python 2.6-3.3 (not in\u00adclud\u00ading 3.0 or 3.1) is not that bad. The com\u00adpat\u00adi\u00adbil\u00adi\u00adty file has a few things, but think\u00ading back, it was just that bad or worse sup\u00adport\u00ading Python 2.4-2.7 (heck, back then, we could\u00adn't even use the  all  func\u00adtion with\u00adout im\u00adport\u00ading it). The sit\u00adu\u00ada\u00adtion is much bet\u00adter to\u00adday now that we use Travis too, since any mis\u00adtake is caught be\u00adfore the pull re\u00adquest is merged. The worst of course is the  print  func\u00adtion, but since that can be im\u00adport\u00aded from  fu\u00adture, I will be warned about it pret\u00adty fast, since  print  as a state\u00adment is a Syn\u00adtax\u00adEr\u00adror in that case. It al\u00adso does\u00adn't take that long to get in\u00adto the habit of typ\u00ading  ()  af\u00adter  print.   \n Of course, there are a lot of nice Python 3 on\u00adly fea\u00adtures that we can\u00adnot use, but this was the case for sup\u00adport\u00ading Python 2.4-2.7 too (e.g., the with state\u00adment and the ternary state\u00adment were both in\u00adtro\u00adduced in Python 2.5).  \u00a0So this is re\u00adal\u00adly noth\u00ading new. There is al\u00adways a stick to drop the old\u00adest Python ver\u00adsion we sup\u00adport, and a lag on what fea\u00adtures we can use. Now that we have dropped Python 2.5 sup\u00adport in SymPy, we can fi\u00adnal\u00adly start us\u00ading new-style string for\u00admat\u00adting, ab\u00adstract base class\u00ades, rel\u00ada\u00adtive im\u00adport\u00ads, and key\u00adword ar\u00adgu\u00adments af\u00adter  *args. \n So as a re\u00adsult of this, I've come to the con\u00adclu\u00adsion that Python 3 is  not  an\u00adoth\u00ader lan\u00adguage. It's just an\u00adoth\u00ader ver\u00adsion of the same lan\u00adguage. Sup\u00adport\u00ading Python 2.6-3.3 is no dif\u00adfer\u00adent from sup\u00adport\u00ading Python 2.4-2.7. You have to have some com\u00adpat\u00adi\u00adbil\u00adi\u00adty im\u00adport\u00ads, you can't use new lan\u00adguage fea\u00adtures, and you have to have good test cov\u00ader\u00adage. I think that the core Python folks made a mis\u00adtake by pre\u00adsent\u00ading Python 3 as a new lan\u00adguage. It has made peo\u00adple an\u00adtag\u00ado\u00adnis\u00adtic against Python 3 (well, that and the  print  func\u00adtion, which was an\u00adoth\u00ader stupid mis\u00adtake, be\u00adcause even if it was a good idea, it alone has kept too many peo\u00adple from switch\u00ading). 2to3 was a mis\u00adtake too, be\u00adcause it per\u00adpet\u00adu\u00adat\u00aded this idea.   \n In the past, I have al\u00adways de\u00advel\u00adoped against the lat\u00adest ver\u00adsion of Python: 2.6 was the best when I learned Python, and then 2.7. Even though I have had to sup\u00adport back to 2.4, I on\u00adly used 2.4 ex\u00adplic\u00adit\u00adly when test\u00ading.   \n Well, giv\u00aden what I said above, the on\u00adly log\u00adi\u00adcal thing to do is to use Python 3.3 as my main de\u00advel\u00adop\u00adment Python. If you use Ana\u00adcon\u00adda, there are ba\u00adsi\u00adcal\u00adly two ways you can do this. The first is to just cre\u00adate a Python 3 en\u00advi\u00adron\u00adment (con\u00adda cre\u00adate -n python3 python=3), and put that first in your  PATH  (y\u00adou al\u00adso will need to add  source ac\u00adti\u00advate python3  to your bash pro\u00adfile if you go this route, so that  con\u00adda in\u00adstall  will in\u00adstall in\u00adto that en\u00advi\u00adron\u00adment by de\u00adfault\u00ad). For me, though, I plan to use a Python 3 ver\u00adsion of Ana\u00adcon\u00adda, which has Python 3 as the de\u00adfault. The main dif\u00adfer\u00adence here is that  con\u00adda  it\u00adself is writ\u00adten in Python 3. Aside from pu\u00adri\u00adty, and the fact that I plan to fix any oc\u00adca\u00adsion\u00adal con\u00adda bugs that I come across, the oth\u00ader dif\u00adfer\u00adence here is that con\u00adda it\u00adself will de\u00adfault to Python 3 in this case (i.e., when cre\u00adat\u00ading a new en\u00advi\u00adron\u00adment with Python like  con\u00adda cre\u00adate -n en\u00advname python, the Python will be Python 3, not Python 2, and al\u00adso it will build against Python 3 by de\u00adfault with  con\u00adda build). Con\u00adtin\u00adu\u00adum does not yet make Python 3 ver\u00adsions of Ana\u00adcon\u00adda, but there are Python 3 ver\u00adsions of  Mini\u00adcon\u00adda  (Mini\u00adcon\u00adda3), which is a stripped down ver\u00adsion of Ana\u00adcon\u00adda with just Python, the con\u00adda pack\u00adage man\u00adager, and its de\u00adpen\u00adden\u00adcies. You can eas\u00adi\u00adly in\u00adstall Ana\u00adcon\u00adda in\u00adto it though with  con\u00adda in\u00adstall ana\u00adcon\u00adda. I per\u00adson\u00adal\u00adly pre\u00adfer to in\u00adstall on\u00adly what I need to keep the disk us\u00adage low (on an SS\u00adD, disk space is sparse), so this is per\u00adfect for me any\u00adway. \n My rec\u00adom\u00admen\u00adda\u00adtion is to put a Python 2 in\u00adstal\u00adla\u00adtion sec\u00adond in your PATH, so that you can eas\u00adi\u00adly call  python2  if you want to use Python 2. The eas\u00adi\u00adest way to do this is to cre\u00adate a con\u00adda en\u00advi\u00adron\u00adment for it (con\u00adda cre\u00adate -n python2 python=2) and add  ~/ana\u00adcon\u00adda/en\u00advs/python2  to your PATH.   \n So far, I have run in\u00adto a few is\u00adsues: \n \n    Some pack\u00adages aren't build for Python 3 yet in Ana\u00adcon\u00adda, or they don't sup\u00adport it at al\u00adl.  The big\u00adgest block\u00ader in Ana\u00adcon\u00adda is Py\u00adSide (at least on Mac OS X), though it should be com\u00ading soon.   \n     Some pack\u00adages on\u00adly in\u00adstall en\u00adtry points with a \"3\" suf\u00adfix, which is an\u00adnoy\u00ading. The big\u00adgest of\u00adfend\u00ader here is IPython. I brought up this is\u00adsue on their  mail\u00ading list,  so hope\u00adful\u00adly they will see the light and fix this be\u00adfore the next re\u00adlease, but it has\u00adn't been im\u00adple\u00adment\u00aded yet. I al\u00adso plan to make sure that the Ana\u00adcon\u00adda pack\u00adage for IPython in\u00adstalls an  ipython  en\u00adtry point in\u00adto Python 3 en\u00advi\u00adron\u00adments. Even so, one has to re\u00admem\u00adber this when in\u00adstalling old ver\u00adsions of IPython in en\u00advi\u00adron\u00adments.   \n     There are some bugs in con\u00adda in Python 3. Ac\u00adtu\u00adal\u00adly, I sus\u00adpect that there are bugs in a lot of pack\u00adages in Python 3, be\u00adcause peo\u00adple don't de\u00advel\u00adop against it, un\u00adless they have ex\u00adcel\u00adlent test cov\u00ader\u00adage. Even SymPy missed a few print state\u00adments.   \n     You can't  set\u00adup.py de\u00advel\u00adop  against any\u00adthing that us\u00ades 2to3 (like IPython).   \n     It's a lit\u00adtle an\u00adnoy\u00ading work\u00ading against old ver\u00adsions of SymPy (e.g., when dig\u00adging through the git his\u00adto\u00adry to track some\u00adthing down), be\u00adcause I have to ex\u00adplic\u00adit\u00adly use Python 2. Con\u00adda makes this eas\u00adi\u00ader be\u00adcause I can just cre\u00adate a Python 2 en\u00advi\u00adron\u00adment and do  source ac\u00adti\u00advate python2  when I am us\u00ading Python 2. Or, for a one-of\u00adf, I can just use  python2, and keep a Python 2 en\u00advi\u00adron\u00adment sec\u00adond in my PATH. But this is\u00adsue is not re\u00adal\u00adly new. For ex\u00adam\u00adple, re\u00adal\u00adly old ver\u00adsions of SymPy on\u00adly work with Python 2.5, be\u00adcause they used  as  as a vari\u00adable name. \n     Ev\u00adery\u00adone else is\u00adn't us\u00ading Python 3 yet, so if I write a script that on\u00adly needs to sup\u00adport \"the lat\u00adest ver\u00adsion of Python,\" it prob\u00ada\u00adbly needs to sup\u00adport Python 2.7, or else I should ex\u00adplic\u00adit\u00adly put  /us\u00adr/bin/env python3  in the she\u00adbang line. But for SymPy, I have to be aware of how to sup\u00adport 2.6-3.3, so I have to know all the fea\u00adtures that are on\u00adly in some ver\u00adsions any\u00adway. On the oth\u00ader side of things, if I run some ran\u00addom Python script with a she\u00adbang line, it prob\u00ada\u00adbly is go\u00ading to ex\u00adpect Python 2 and not Python 3, so I ei\u00adther have to ex\u00adplic\u00adit\u00adly add  python2  to the com\u00admand or ac\u00adti\u00advate a Python 2 en\u00advi\u00adron\u00adment \n     Some pack\u00adages just don't sup\u00adport Python 3 yet. Fab\u00adric (and its main de\u00adpen\u00adden\u00adcy, Paramiko) is the one ex\u00adam\u00adple I have come across so far in my own work. So I have to fall back to Python 2 if I want to use them. The best thing to do here is to pitch in and help these li\u00adbraries port them\u00adselves. \n     Peo\u00adple al\u00adways give code ex\u00adam\u00adples with  print  as a state\u00adment in\u00adstead of a func\u00adtion, so I ei\u00adther have to fix it man\u00adu\u00adal\u00adly be\u00adfore past\u00ading it or use Python 2. I had tried at one point to make a  %print  mag\u00adic for IPython that would let print work like a state\u00adment in Python 3, but I nev\u00ader fin\u00adished it. I guess I should re\u00advis\u00adit it. \n \n\nI'll up\u00addate this list as I come across more is\u00adsues.   \n In al\u00adl, so far, it's noth\u00ading too bad. Con\u00adda makes switch\u00ading back to Python 2 easy enough, and deal\u00ading with these is\u00adsues are hard\u00adly the worst thing I have to deal with when de\u00advel\u00adop\u00ading with Python. And if any\u00adthing, see\u00ading Python 2-3 bugs and is\u00adsues makes me more aware of the dif\u00adfer\u00adences be\u00adtween the two ver\u00adsions of the lan\u00adguage, which is a good things since I have to de\u00advel\u00adop against code that has to sup\u00adport both.", 
      "loc": "/posts/2013/08/09/using-python-3-as-my-default-python/"
    }, 
    {
      "title": "Automating the SymPy release process", 
      "tags": "", 
      "text": "So I have just pub\u00adlished  SymPy 0.7.3.r\u00adc1. I'll write a blog post about the re\u00adlease it\u00adself when we re\u00adlease 0.7.3 fi\u00adnal, but for now, I want\u00aded to write about how we man\u00adaged to au\u00adto\u00admate our re\u00adlease process. \n Our sto\u00adry be\u00adgins back in Oc\u00adto\u00adber of 2012, when I wrote a long wind\u00aded  rant  to the mail\u00ading list about how long it was tak\u00ading to get the 0.7.2 re\u00adlease out (it took over a month from the time the re\u00adlease branch was cre\u00adat\u00aded).   \n The rant is fun, and I rec\u00adom\u00admend read\u00ading it. Here are some quotes \n The in\u00adtro: \n \nNow here's a time\u00adline: 0.7.1 was re\u00adleased Ju\u00adly 29, 2011, more than a year and two months ago.  0.7.0 was re\u00adleased just over a month be\u00adfore that, on June 28.  0.6.7 was re\u00adleased March 18, 2010, again over a year be\u00adfore 0.7.0.  In al\u00admost two year's time, we've had three re\u00adleas\u00ades, and are strug\u00adgling to get out a fourth.  And it's not like there were no changes; quite the op\u00adpo\u00adsite in fac\u00adt.  If you look at SymPy 0.6.6 com\u00adpared to the cur\u00adrent mas\u00adter, it's un\u00adbe\u00adliev\u00adable the amount of changes that have gone for\u00adward in that time.  We've had   \n since then the new polys, at least four com\u00adplete\u00adly new sub\u00admod\u00adules (com\u00adbi\u00adna\u00adtoric\u00ads, set\u00ads, dif\u00adfer\u00aden\u00adtial ge\u00adom\u00ade\u00adtry, and stat\u00ads), mas\u00adsive im\u00adprove\u00adments to in\u00adte\u00adgra\u00adtion and spe\u00adcial func\u00adtion\u00ads, a ton of new stuff in the physics mod\u00adule, lit\u00ader\u00adal\u00adly thou\u00adsands of bug fix\u00ades, and the list goes on.  Each of these changes on it's own was enough to war\u00adrant a re\u00adlease.   \n So in case I did\u00adn't make my point, le me state it ex\u00adplic\u00adit\u00adly: we need to re\u00adlease more of\u00adten.  We need to re\u00adlease  way  more of\u00adten.   \n \n\nMy views on some of the fun\u00adda\u00admen\u00adtal (non-tech\u00adni\u00adcal) is\u00adsues: \n \n\nI think that one other thing that has held back many releases is the feeling of \"wait, we should put this in the release\". The use of a release branch has helped keep master moving along independently, but there still seems to be the feeling with many branches of, \"this is a nice feature, it ought to go in the release.\"  My hope is that by making the release process smoother, we can release more often, and this feeling will go away, because it won't be a big deal if something waits until the next release.  As far as deprecations go, the real issue with them is time, not release numbers.  So if we deprecate a feature today vs. one month from today, it's not a big deal (as opposed to today vs. a year from today), regardless of how many versions are in between. \n\n\n\nI read about what GitHub does for their Windows product regarding releasing often on their blog: https://github.com/blog/1271-how-we-ship-github-for-windows (they actually have this philosophy for all their products).  One thing that they said is, \"And by shipping updates so often, there is less anxiety about getting a particular feature ready for a particular release. If your pull request isn\u2019t ready to be merged in time for today\u2019s release, relax. There will be another one soon, so make that code shine!\"  I think that is exactly the point here.  Another thing that they noted is that automation is the key to doing this, which is what I am aiming for with the above point. \n\n\n\nMy vi\u00adsion: \n \n\nOnce we start releasing very often (and believe me, this is way down the road, but I'm trying to be forward looking here), we can do away with release candidates.  A release candidate lives in the wild for a week before the full release.  But if we are capable of releasing literally every week, then having release candidates is pointless.  If a bug slips into a release, we just fix it and it will be in the next release. \n\n\n\n... \n \n\nWe should release *at least* once a month.  I think that if the process is automated enough, that this will be very possible (as opposed to the current situation, where the release branch lasts longer than a month).  In times of high activity, we can release more often than that (e.g., after a big pull request is merged, we can release). \n\n\n\nThat was Oc\u00adto\u00adber. To\u00adday is Ju\u00adly. Ba\u00adsi\u00adcal\u00adly, our re\u00adlease process was way too long. Half of it was test\u00ading stuff, half of it was te\u00addious re\u00adleas\u00ading stuff (like mak\u00ading tar\u00adballs and so on), and half of it was up\u00addat\u00ading web\u00adsites.   \n We have moved all our test\u00ading to Travis CI. So now ev\u00adery pull re\u00adquest is test\u00aded, and we can be pret\u00adty much as\u00adsured that mas\u00adter is al\u00adways pass\u00ading the test\u00ads.  There is still some work to do here (cur\u00adrent\u00adly Travis CI does\u00adn't test with ex\u00adter\u00adnal de\u00adpen\u00adden\u00adcies), but it's most\u00adly a solved prob\u00adlem. \n For up\u00addat\u00ading web\u00adsites, we con\u00adced\u00aded that we are not go\u00ading to up\u00addate any\u00adthing that we don't own. That means no at\u00adtempt\u00ading to make De\u00adbian or Sage pack\u00adages, or up\u00addat\u00ading Wikipedia or Fresh\u00admeat. Some\u00adone else will do that (and does any\u00adone even use Fresh\u00admeat any more?).   \n That leaves the re\u00adleas\u00ading it\u00adself. It's still a pain, be\u00adcause we have to make a source tar\u00adball, Win\u00addows in\u00adstaller, html doc\u00ads, and pdf doc\u00ads, and do them all for both Python 2 and Python 3.   \n So On\u00addrej sug\u00adgest\u00aded mov\u00ading to fab\u00adric/\u00adva\u00adgrant. At the SciPy 2013 sprints, he start\u00aded work\u00ading on a fab\u00adfile that au\u00adto\u00admates the whole process. Ba\u00adsi\u00adcal\u00adly va\u00adgrant is a pre\u00adde\u00adfined Lin\u00adux vir\u00adtu\u00adal ma\u00adchine that makes it easy to make ev\u00adery\u00adthing com\u00adplete\u00adly re\u00adpro\u00adducible. Fab\u00adric is a tool that makes it easy to write com\u00admands (in Python) that are run on that ma\u00adchine.   \n Build\u00ading the ba\u00adsic stuff was easy, but I want to au\u00adto\u00admate  ev\u00adery\u00adthing. So far, not ev\u00adery\u00adthing is done yet, but we're get\u00adting close. For ex\u00adam\u00adple, in ad\u00addi\u00adtion to build\u00ading the tar\u00adball\u00ads, the fab\u00adric script checks the con\u00adtents of the tar\u00adball against  git ls-\u00adfiles  to make sure that noth\u00ading is in\u00adclud\u00aded that should\u00adn't be or left out ac\u00adci\u00adden\u00adtal\u00adly (and, in\u00addeed, we caught some miss\u00ading files that weren't in\u00adclud\u00aded in the tar\u00adball, in\u00adclud\u00ading the READ\u00adME).   \n You can run all this your\u00adself. Check\u00adout the 0.7.3 branch from SymPy, then cd in\u00adto the re\u00adlease di\u00adrec\u00adto\u00adry, and read the README. Ba\u00adsi\u00adcal\u00adly, you just in\u00adstall Fab\u00adric and Va\u00adgrant if you don't have them al\u00adready, then run \n [code] \n va\u00adgrant up \n fab va\u00adgrant pre\u00adpare \n fab va\u00adgrant re\u00adlease \n [/\u00adcode] \n Note that this down\u00adloads a 280 MB vir\u00adtu\u00adal ma\u00adchine, so it will take some time to run for the first time. When you do this, the re\u00adleas\u00ades are in the  re\u00adlease  di\u00adrec\u00adto\u00adry.   \n Fi\u00adnal\u00adly, I up\u00adload\u00aded 0.7.3.r\u00adc1 to GitHub us\u00ading the new re\u00adleas\u00ades fea\u00adture. This is what the re\u00adlease looks like on GitHub, from the us\u00ader point of view \n  \n This is what it looks like to me \n  \n GitHub has (ob\u00advi\u00adous\u00adly) the best in\u00adter\u00adface I've ev\u00ader seen for this. Of course, even bet\u00adter would be if there were an API, so that I could au\u00adto\u00admate this too.  But since Google's  an\u00adnounce\u00adment  that they are dis\u00adcon\u00adtin\u00adu\u00ading down\u00adload\u00ads, we can no longer up\u00adload to Google Code. Our plan was to just use PyP\u00adI, but I am glad that we can have at least one oth\u00ader lo\u00adca\u00adtion, es\u00adpe\u00adcial\u00adly since PyPI is so bug\u00adgy and un\u00adre\u00adli\u00adable (I can't even log in, I get a 502). \n So please down\u00adload this re\u00adlease can\u00addi\u00addate and test it. We es\u00adpe\u00adical\u00adly need peo\u00adple to test the Win\u00addows in\u00adstaller, since we haven't au\u00adto\u00admat\u00aded that part yet (ac\u00adtu\u00adal\u00adly, we are con\u00adsid\u00ader\u00ading not mak\u00ading them any more, es\u00adpecail\u00adly giv\u00aden the ex\u00adis\u00adtence of peo\u00adple like Christoph Gohlke who  make them  for SymPy any\u00adway, but we'll see). The on\u00adly thing that re\u00admains to be done is to fin\u00adish writ\u00ading the  re\u00adlease notes. If you made any con\u00adtri\u00adbu\u00adtions to SymPy since the last re\u00adlease, please add them there. Or if you want to help out, you can go through our pull re\u00adquests and make sure that noth\u00ading is miss\u00ading.", 
      "loc": "/posts/2013/07/07/automating-the-sympy-release-process/"
    }, 
    {
      "title": "SciPy 2013", 
      "tags": "", 
      "text": "This past week was the 2013 SciPy con\u00adfer\u00adence. It was an ex\u00adcit\u00ading time, and a lot of in\u00adter\u00adest\u00ading things hap\u00adpened.\u00a0 First, a back\u00adground. This sum\u00admer, I have been do\u00ading an in\u00adtern\u00adship with  Con\u00adtin\u00adu\u00adum An\u00ada\u00adlyt\u00adics. There I have been work\u00ading main\u00adly on Ana\u00adcon\u00adda and con\u00adda. Ana\u00adcon\u00adda is Con\u00adtin\u00adu\u00adum's free (to ev\u00adery\u00adone) Python dis\u00adtri\u00adbu\u00adtion, which makes it re\u00adal\u00adly easy to get boot\u00adstrapped with all the sci\u00aden\u00adtif\u00adic soft\u00adware (in\u00adclud\u00ading SymPy). Con\u00adda is Ana\u00adcon\u00adda's pack\u00adage man\u00adager, which, I think, solves many if not all of the main is\u00adsues with the Python pack\u00adag\u00ading tools like pip, easy_in\u00adstal\u00adl, PyP\u00adI, and vir\u00adtualen\u00adv.\u00a0 I may write more about that lat\u00ader, but for now, I want to write about my ex\u00adpe\u00adri\u00adences at the con\u00adfer\u00adence. The main point there is that I have al\u00adready been in Austin for about a mon\u00adth, so get\u00adting to the con\u00adfer\u00adence this year was pret\u00adty easy.On the first day of the con\u00adfer\u00adence, on Mon\u00adday morn\u00ading, On\u00addrej Cer\u00adtik and I had our tu\u00adto\u00adri\u00adal for SymPy. For the past cou\u00adple of month\u00ads, I have been rewrit\u00ading the of\u00adfi\u00adcial SymPy tu\u00adto\u00adri\u00adal from scratch. The of\u00adfi\u00adcial tu\u00adto\u00adri\u00adal for SymPy was very old, and had many is\u00adsues. It on\u00adly went over fea\u00adtures that were good at the time of its writ\u00ading, so while noth\u00ading in the tu\u00adto\u00adri\u00adal was wrong, it did\u00adn't re\u00adal\u00adly rep\u00adre\u00adsent the lat\u00adest and great\u00adest of the li\u00adbrary. Al\u00adso, it was writ\u00adten just like a list of ex\u00adam\u00adples, which is not much more than the API doc\u00ads. In my new tu\u00adto\u00adri\u00adal, I aimed to give a nar\u00adra\u00adtive style doc\u00adu\u00admen\u00adta\u00adtion, which starts from the very be\u00adgin\u00adning of what sym\u00adbol\u00adics are and works its way up to the ba\u00adsic func\u00adtion\u00adal\u00adi\u00adty of things like solv\u00ading and sim\u00adpli\u00adfy\u00ading ex\u00adpres\u00adsion\u00ads. My goal was al\u00adso to lead by ex\u00adam\u00adple, and in par\u00adtic\u00adu\u00adlar, to avoid teach\u00ading things that I think ei\u00adther are an\u00adtipat\u00adtern\u00ads, or lead to an\u00adtipat\u00adtern\u00ads. In Python, there is one-- and prefer\u00adably on\u00adly one --way to do it. In SymPy, by the na\u00adture of the li\u00adbrary, there are about sev\u00aden dif\u00adfer\u00adent ways to cre\u00adate a Sym\u00adbol, for ex\u00adam\u00adple (see\u00a0http\u00ads://github.\u00adcom/sympy/sympy/wik\u00adi/Id\u00adiom\u00ads-and-An\u00adtipat\u00adtern\u00ads, the sec\u00adtion, \"Cre\u00adat\u00ading Sym\u00adbol\u00ads\"). But there is one  best  way to do it: by us\u00ading sym\u00adbol\u00ads(). So all through\u00adout the tu\u00adto\u00adri\u00adal, I just use sym\u00adbol\u00ads(), even if I am cre\u00adat\u00ading a sin\u00adgle Sym\u00adbol. I avoid messy things like var.\u00a0 The fi\u00adnal tu\u00adto\u00adri\u00adal is at\u00a0http://\u00addoc\u00ads.sympy.org/\u00adtu\u00adto\u00adri\u00adal/\u00adtu\u00adto\u00adri\u00adal/. This was the ba\u00adsis for the tu\u00adto\u00adri\u00adal that On\u00addrej and I gave at SciPy. The site for our tu\u00adto\u00adri\u00adal is at\u00a0http://cer\u00adtik.github.io/s\u00adcipy-2013-\u00adtu\u00adto\u00adri\u00adal/htm\u00adl/in\u00addex.htm\u00adl. There are links to videos, slides, and ex\u00ader\u00adcise note\u00adbooks there.\u00a0 I think our tu\u00adto\u00adri\u00adal was a great suc\u00adcess. Peo\u00adple liked (I think) the in\u00adtro\u00adduc\u00adtion from noth\u00ading to SymPy. For our ex\u00ader\u00adcis\u00ades, we used the  IPython Doctester. I think that peo\u00adple re\u00adal\u00adly liked this way of do\u00ading ex\u00ader\u00adcis\u00ades, but there were some is\u00adsues get\u00adting it to work on ev\u00adery\u00adone's ma\u00adchine.\u00a0 In ad\u00addi\u00adtion to my stuff, On\u00addrej pre\u00adsent\u00aded some note\u00adbooks of ex\u00adam\u00adples of work that he has used in his work at LAN\u00adL. I think this worked well. There were sev\u00ader\u00adal physi\u00adcists in the au\u00addi\u00adence, who un\u00adder\u00adstood most of the con\u00adtent, but even for those who weren't (in\u00adclud\u00ading me!), it re\u00adal\u00adly showed that SymPy is a use\u00adful tool. In a be\u00adgin\u00adner tu\u00adto\u00adri\u00adal, it is easy to get lost in the easy de\u00adtail\u00ads, and for\u00adget that in the end, you can ac\u00adtu\u00adal\u00adly use SymPy to com\u00adpute some pow\u00ader\u00adful things. \u00a0SymPy has in the past year or two re\u00adal\u00adly passed the bar\u00adri\u00ader of toy to tool.\u00a0 Af\u00adter our tu\u00adto\u00adri\u00adal, I at\u00adtend\u00aded the IPython tu\u00adto\u00adri\u00adal, and the two-\u00adpart Scik\u00adit-Learn tu\u00adto\u00adri\u00adal. The most awe\u00adsome part of this was just get\u00adting to meet peo\u00adple. Fer\u00adnan\u00addo Perez, Thomas Kluyver, and Bri\u00adan Granger of IPython were at the con\u00adfer\u00adence. Brain is al\u00adso a SymPy de\u00advel\u00adop\u00ader, who has spear\u00adhead\u00aded the quan\u00adtum mod\u00adule. From SymPy, in ad\u00addi\u00adtion to On\u00addrej (who cre\u00adat\u00aded SymPy), I met Matthew Rock\u00adlin, one of the top con\u00adtrib\u00adu\u00adtors, Ja\u00adson Moore, one of the de\u00advel\u00adop\u00aders of Py\u00adDy, which us\u00ades SymPy's me\u00adchan\u00adics mod\u00adule, and David Li, who works on SymPy Gam\u00adma and SymPy Live (more on these peo\u00adple lat\u00ader).\u00a0 Af\u00adter the tu\u00adto\u00adri\u00adal\u00ads, Wednes\u00adday and Thurs\u00adday were the talk\u00ads. There were a lot of good ones. Here are the ones that I re\u00admem\u00adber the mostFer\u00adnan\u00addo's key\u00adnote. If you've ev\u00ader seen one of Fer\u00adnan\u00addo's talk\u00ads, you know that he is a great speak\u00ader.\u00a0 Matthew's talk. His talk was about his work on us\u00ading SymPy's ma\u00adtrix ex\u00adpres\u00adsions to com\u00adpile ex\u00adpres\u00adsions for BLAS/LA\u00adPACK. This talk ex\u00adcit\u00aded many peo\u00adple in the au\u00addi\u00adence. I think this is great, be\u00adcause it shows peo\u00adple some of the re\u00adal pow\u00ader of things you can on\u00adly do with sym\u00adbol\u00adic\u00ads.Ja\u00adson Moore's talk about Py\u00adDy and the me\u00adchan\u00adics mod\u00adule. He ran out of time, but there is a nice ex\u00adam\u00adple of us\u00ading SymPy to gen\u00ader\u00adate a con\u00adtroller for an in\u00advert\u00aded triple pen\u00addu\u00adlum, which seems im\u00adpos\u00adsi\u00adble, but then he shows a video of an ac\u00adtu\u00adal thing that can do it.William Schroed\u00ader's key\u00adnote. The mes\u00adsage was that the aca\u00addem\u00adic mod\u00adel is bro\u00adken, and does\u00adn't lead to re\u00adpro\u00adducible re\u00adsearch. While they are fix\u00ading things, the mes\u00adsage is that we are the new pub\u00adlish\u00ader\u00ads. There was al\u00adso men\u00adtion at the end that we should stop us\u00ading non\u00adcom\u00admer\u00adcial li\u00adcens\u00ades, and stop us\u00ading vi\u00adral li\u00adcens\u00ades like the GPL and LGPL. I was a lit\u00adtle sur\u00adprised to hear such a con\u00adtro\u00adver\u00adsial state\u00admen\u00adt, but it's ac\u00adtu\u00adal\u00adly very true, and I agree with him that if peo\u00adple don't stop us\u00ading the GPL, then we will nev\u00ader achieve open\u00adness in sci\u00adence.\u00a0 David Li's talk. David Li is a high school stu\u00addent (s\u00adtart\u00ading his se\u00adnior year in the fal\u00adl), who start\u00aded with SymPy two years ago with Google Code-In. He has con\u00adtin\u00adued work\u00ading on  SymPy Live, and  SymPy Gam\u00adma  since. He is the rea\u00adson that we have  SymPy Live in our docs. His talk was al\u00adso well re\u00adceived.\u00a0\u00a0\u00adDavid is a good speak\u00ader, and SymPy Gam\u00adma and SymPy Live are pret\u00adty cool (for those of you who don't know, SymPy Live is an on\u00adline shell where you can run a Python ses\u00adsion with SymPy in the browser, and SymPy Gam\u00adma is the SymPy ver\u00adsion of Wol\u00adfra\u00admAl\u00adpha).Bri\u00adan Granger's talk. His talk is en\u00adti\u00adtled \"Why you should write bug\u00adgy soft\u00adware with as few fea\u00adtures as pos\u00adsi\u00adble\".  I think he had some good mes\u00adsages in there. You have to re\u00adduce the scope of your pro\u00adjec\u00adt, or it will get out of hand. As for bugs, get\u00adting bug re\u00adports is a good thing, be\u00adcause it shows that peo\u00adple are us\u00ading the soft\u00adware, and what parts of it they are us\u00ading.\u00a0 The light\u00adning talk\u00ads. Es\u00adpe\u00adcial\u00adly Matthew Rock\u00adlin's light\u00adning talk. His talk was about split\u00adting things up in\u00adto very small pack\u00adages, so that you don't have to get a huge pack\u00adage just for one func\u00adtion. He went a lit\u00adtle far with it, and I think his ideas aren't re\u00adal\u00adly us\u00adable in the cur\u00adrent Python pack\u00adag\u00ading ecosys\u00adtem, but, tak\u00aden in mod\u00ader\u00ada\u00adtion, I agree with him. At any rate, it was very en\u00adter\u00adtain\u00ading (I don't have any video links here be\u00adcause they aren't post\u00aded yet, but I en\u00adcour\u00adage you to watch the light\u00adning talks once they are post\u00aded).\u00a0 I heard the mat\u00adplotlib talk was good, but I haven't seen it be\u00adcause it was at the same time as Matthew's talk. I plan to watch it when the videos come out. If you saw it, I en\u00adcour\u00adage you to watch Matthew's talk, es\u00adpe\u00adcial\u00adly if you've ev\u00ader used BLAS/LA\u00adPACK.Top\u00adping off the week were the sprints on Fri\u00adday and Sat\u00adur\u00adday. My goal was to get out a re\u00adlease of SymPy. We did\u00adn't quite get that far, but we got close. We are on\u00adly block\u00ading on a few small things to get out a re\u00adlease can\u00addi\u00addate, so ex\u00adpect one be\u00adfore the end of the week. We did in\u00adtro\u00adduce a lot of peo\u00adple to SymPy at the sprints, though, and got some first time con\u00adtri\u00adbu\u00adtion\u00ads. Def\u00adi\u00adnite\u00adly I think we made a lot more peo\u00adple aware of SymPy at this con\u00adfer\u00adence than we ev\u00ader have be\u00adfore.\u00a0 An\u00adoth\u00ader in\u00adter\u00adest\u00ading thing at the sprints: be\u00adfore the con\u00adfer\u00adence, I was telling David Li that we should switch to Dill for SymPy Live (the way SymPy Live works on the App En\u00adgine, it has to pick\u00adle the ses\u00adsion be\u00adtween run\u00ads, be\u00adcause there is a 60 time lim\u00adit on each ex\u00ade\u00adcu\u00adtion). Dill is a li\u00adbrary that ex\u00adtends Python's pick\u00adle so that it can pick\u00adle just about any\u00adthing. At the end of David's talk, the guy who wrote Dil\u00adl, Mike McK\u00adern\u00ads\u00a0raised his hand and asked him about it! At the sprints, David and he worked to\u00adgeth\u00ader to get it work\u00ading in SymPy Live (and co\u00adin\u00adci\u00adden\u00adtal\u00adly, he al\u00adso us\u00ades SymPy in an\u00adoth\u00ader pack\u00adage, mys\u00adtic). There were some fix\u00ades need\u00aded for Dil\u00adl. He al\u00adso moved Dill out of a larg\u00ader project (in the spir\u00adit of Matthew's light\u00adning talk), and over to  GitHub. Now all they need is a lo\u00adgo (Paul Ivanov sug\u00adgest\u00aded a vari\u00ada\u00adtion on \"we can pick\u00adle that!\").\u00a0 In al\u00adl, it was a fun con\u00adfer\u00adence. The best part, as al\u00adways, was meet\u00ading peo\u00adple in per\u00adson, and talk\u00ading to them. To con\u00adclude, I want to men\u00adtion two oth\u00ader in\u00adter\u00adest\u00ading things that hap\u00adpened.The first is that Matthew and I talked se\u00adri\u00adous\u00adly about how to go about fix\u00ading the as\u00adsump\u00adtions in SymPy. I will write to the list about this soon, but the ba\u00adsic idea is to just get in there and hack things to\u00adgeth\u00ader, so that we can get some\u00adthing that work\u00ads. The work there is start\u00aded at\u00a0http\u00ads://github.\u00adcom/sympy/sympy/pul\u00adl/2210, where I am see\u00ading if we can merge the old and new as\u00adsump\u00adtion\u00ads, so that some\u00adthing as\u00adsumed in one can be asked in the old one.The sec\u00adond thing is that On\u00addrej got a new hat:", 
      "loc": "/posts/2013/07/02/scipy-2013/"
    }, 
    {
      "title": "How to make attributes un-inheritable in Python using descriptors", 
      "tags": "", 
      "text": "For http\u00ads://github.\u00adcom/sympy/sympy/pul\u00adl/1969, and pre\u00advi\u00adous work at http\u00ads://github.\u00adcom/sympy/sympy/pul\u00adl/1901, we added the abil\u00adi\u00adty for the SymPy doctester to run or not run doctests con\u00addi\u00adtion\u00adal\u00adly de\u00adpend\u00ading on whether or not re\u00adquired ex\u00adter\u00adnal de\u00adpen\u00adden\u00adcies are in\u00adstalled. This means that for ex\u00adam\u00adple we can doctest all the plot\u00adting ex\u00adam\u00adples with\u00adout them fail\u00ading when mat\u00adplotlib is not in\u00adstalled.   \n For func\u00adtion\u00ads, this is as easy as dec\u00ado\u00adrat\u00ading the func\u00adtion with  @doctest_de\u00adpends, which adds the at\u00adtribute  _doctest_de\u00adpend\u00ads_on  to the func\u00adtion with a list of what de\u00adpen\u00adden\u00adcies the doctest de\u00adpends on. The doctest will then not run the doctest un\u00adless those de\u00adpen\u00adden\u00adcies are in\u00adstalled. \n For class\u00ades, this is not so easy. Ide\u00adal\u00adly, one could just de\u00adfine  _doctest_de\u00adpend\u00ads_on  as an at\u00adtribute of the class. How\u00adev\u00ader, the is\u00adsue is that with class\u00ades, we have in\u00adher\u00adi\u00adtance. But if class  A  has a doc\u00adstring with a doctest that de\u00adpends on some mod\u00adules, it does\u00adn't mean that a sub\u00adclass  B  of  A  will have a doctest that does.    \n Re\u00adal\u00adly, what we need to do is to dec\u00ado\u00adrate the doc\u00adstring it\u00adself, not the class. Un\u00adfor\u00adtu\u00adnate\u00adly, Python does not al\u00adlow adding at\u00adtributes to strings \n [code lan\u00adguage=\"py\"] \n >>> a = \"\" \n >>> a.x = 1 \n Trace\u00adback (most re\u00adcent call last):\n  File \"<st\u00add\u00adin>\", line 1, in <mod\u00adule>\nAt\u00adtribu\u00adteEr\u00adror: 'str' ob\u00adject has no at\u00adtribute 'x' \n [/\u00adcode] \n So what we have to do is to cre\u00adate a at\u00adtribute that does\u00adn't in\u00adher\u00adit.    \n I had for some time want\u00aded to give  de\u00adscrip\u00adtors  in Python a try, since they are a cool fea\u00adture, but al\u00adso the sec\u00adond most com\u00adpli\u00adcat\u00aded fea\u00adture in Python (the first is meta\u00adclass\u00ades). If you don't know what a de\u00adscrip\u00adtor is, I rec\u00adom\u00admend read\u00ading  this blog post  by Gui\u00addo van Rossum, the cre\u00adator of Python. It's the best ex\u00adpla\u00adna\u00adtion of the fea\u00adture there is.    \n Ba\u00adsi\u00adcal\u00adly, Python lets at\u00adtributes de\u00adfine what hap\u00adpens when they are ac\u00adcessed (like  a.x).  You may al\u00adready know that ob\u00adjects can de\u00adfine how their at\u00adtributes are ac\u00adcessed via  getat\u00adtr. This is dif\u00adfer\u00aden\u00adt. With de\u00adscrip\u00adtors, the  at\u00adtributes them\u00adselves  de\u00adfine what hap\u00adpen\u00ads.  This may sound less use\u00adful, but in fac\u00adt, it's a very core fea\u00adture of the lan\u00adguage.   \n If you've ev\u00ader won\u00addered how  prop\u00ader\u00adty,  class\u00admethod, or  stat\u00adicmethod  work in Python, the an\u00adswer is de\u00adscrip\u00adtors. Ba\u00adsi\u00adcal\u00adly, if you have some\u00adthing like \n [code lan\u00adguage=\"py\"] \n class A(ob\u00adjec\u00adt):\n    def f(\u00adself):\n        re\u00adturn 1\n    f = prop\u00ader\u00adty(f)\n[/\u00adcode] \n Then  A().f  mag\u00adi\u00adcal\u00adly calls what would nor\u00admal\u00adly be  A().f(). The way it works is that  prop\u00ader\u00adty  de\u00adfines the  get  method, which re\u00adturns  f(ob\u00adj), where  obj  is the call\u00ading ob\u00adjec\u00adt, here  A()  (re\u00admem\u00adber in Python that the first ar\u00adgu\u00adment of a method, usu\u00adal\u00adly called  self  is the ob\u00adject that calls the method\u00ad).    \n De\u00adscrip\u00adtors can al\u00adlow method to de\u00adfine ar\u00adbi\u00adtrary be\u00adhav\u00adior when called, set, or delet\u00aded.  To make an at\u00adtribute in\u00adac\u00adces\u00adsi\u00adble to sub\u00adclass\u00ades, then, you just need to de\u00adfine a de\u00adscrip\u00adtor that pre\u00advents the at\u00adtribute from be\u00ading ac\u00adcessed if the class of the call\u00ading ob\u00adject is not the orig\u00adi\u00adnal class.  Here is some code: \n [code lan\u00adguage=\"py\"] \n class no\u00adsub\u00adclass\u00ades(ob\u00adjec\u00adt):\n    def  init(self, f, cls):\n        self\u00ad.f = f\n        self\u00ad.\u00adcls = cls\n    def  get(self, ob\u00adj, type\u00ad=None):\n        if type == self\u00ad.\u00adcls:\n            if hasat\u00adtr(\u00adself.f, 'get'):\n                re\u00adturn self\u00ad.f.get(ob\u00adj, type\u00ad)\n            re\u00adturn self\u00ad.f\n        raise At\u00adtribu\u00adteEr\u00adror\n[/\u00adcode] \n it works like this \n [code lan\u00adguage=\"py\"] \n In [2]: class My\u00adClass(ob\u00adjec\u00adt):\n   ...:     x = 1\n   ...: \n In [3]: My\u00adClass.x = no\u00adsub\u00adclass\u00ades(My\u00adClass.x, My\u00adClass) \n In [4]: class My\u00adSub\u00adclass(My\u00adClass):\n   ...:     pass\n   ...: \n In [5]: My\u00adClass.x \n Out\u00ad[5]: 1 \n In [6]: My\u00adClass().x \n Out\u00ad[6]: 1 \n In [80]: My\u00adSub\u00adclass.x \n \nAt\u00adtribu\u00adteEr\u00adror                            Trace\u00adback (most re\u00adcent call last) \n <ipython-in\u00adput-80-2b2f456d\u00add101> in <mod\u00adule>() \n ----> 1 My\u00adSub\u00adclass.x \n <ipython-in\u00adput-51-7fe1b5063367> in  get(self, ob\u00adj, type\u00ad)\n      8                 re\u00adturn self\u00ad.f.get(ob\u00adj, type\u00ad)\n      9             re\u00adturn self\u00ad.f\n---> 10         raise At\u00adtribu\u00adteEr\u00adror \n At\u00adtribu\u00adteEr\u00adror: \n In [81]: My\u00adSub\u00adclass().x \n \nAt\u00adtribu\u00adteEr\u00adror                            Trace\u00adback (most re\u00adcent call last) \n <ipython-in\u00adput-81-93764ee\u00adb9948> in <mod\u00adule>() \n ----> 1 My\u00adSub\u00adclass().x \n <ipython-in\u00adput-51-7fe1b5063367> in  get(self, ob\u00adj, type\u00ad)\n      8                 re\u00adturn self\u00ad.f.get(ob\u00adj, type\u00ad)\n      9             re\u00adturn self\u00ad.f\n---> 10         raise At\u00adtribu\u00adteEr\u00adror \n At\u00adtribu\u00adteEr\u00adror: \n [/\u00adcode] \n Note that by us\u00ading the third ar\u00adgu\u00adment to  get, this works re\u00adgard\u00adless if the at\u00adtribute is ac\u00adcessed from the class or the ob\u00adjec\u00adt. I have to call  get  on  self\u00ad.f  again if it has it to en\u00adsure that the right thing hap\u00adpens if the at\u00adtribute has oth\u00ader de\u00adscrip\u00adtor log\u00adic de\u00adfined (and note that reg\u00adu\u00adlar meth\u00adods have de\u00adscrip\u00adtor log\u00adic de\u00adfined---that's how they con\u00advert the first ar\u00adgu\u00adment  self  to im\u00adplic\u00adit\u00adly be the call\u00ading ob\u00adjec\u00adt). \n One could eas\u00adi\u00adly make class dec\u00ado\u00adra\u00adtor that au\u00adto\u00admat\u00adi\u00adcal\u00adly adds the at\u00adtribute to the class in a non-in\u00adher\u00adi\u00adta\u00adble way: \n [code lan\u00adguage=\"py\"] \n def no\u00adsub\u00adclass_x(args):\n    def _wrap\u00adper(\u00adcls):\n        cls.x = no\u00adsub\u00adclass\u00ades(args, cls)\n        re\u00adturn cls\n    re\u00adturn _wrap\u00adper\n[/\u00adcode] \n This au\u00adto\u00admat\u00adi\u00adcal\u00adly adds the prop\u00ader\u00adty  x  to the dec\u00ado\u00adrat\u00aded class with the val\u00adue giv\u00aden in the dec\u00ado\u00adra\u00adtor, and it won't be ac\u00adces\u00adsi\u00adble to sub\u00adclass\u00ades: \n [code lan\u00adguage=\"py\"] \n In [87]: @no\u00adsub\u00adclass_x(1)\n   ....: class My\u00adClass(ob\u00adjec\u00adt):\n   ....:     pass\n   ....: \n In [88]: My\u00adClass().x \n Out\u00ad[88]: 1 \n In [89]: My\u00adSub\u00adclass().x \n \nAt\u00adtribu\u00adteEr\u00adror                            Trace\u00adback (most re\u00adcent call last) \n <ipython-in\u00adput-89-93764ee\u00adb9948> in <mod\u00adule>() \n ----> 1 My\u00adSub\u00adclass().x \n <ipython-in\u00adput-51-7fe1b5063367> in  get(self, ob\u00adj, type\u00ad)\n      8                 re\u00adturn self\u00ad.f.get(ob\u00adj, type\u00ad)\n      9             re\u00adturn self\u00ad.f\n---> 10         raise At\u00adtribu\u00adteEr\u00adror \n At\u00adtribu\u00adteEr\u00adror: \n [/\u00adcode] \n For SymPy, we can't use class dec\u00ado\u00adra\u00adtors be\u00adcause we still sup\u00adport Python 2.5, and they were in\u00adtro\u00adduced in Python 2.6. The best work around is to just call  Class.at\u00adtribute = no\u00adsub\u00adclass\u00ades(\u00adClass.at\u00adtribute, Class)  af\u00adter the class def\u00adi\u00adni\u00adtion. Un\u00adfor\u00adtu\u00adnate\u00adly, you can't ac\u00adcess a class in\u00adside its def\u00adi\u00adni\u00adtion like you can with func\u00adtion\u00ads, so this has to go at the end.   \n Name Man\u00adgling \n Af\u00adter com\u00ading up with all this, I re\u00admem\u00adbered that Python al\u00adready has a pret\u00adty stan\u00addard way to de\u00adfine at\u00adtributes in such a way that sub\u00adclass\u00ades won't have ac\u00adcess to them. All you have to do is use two un\u00adder\u00adscores be\u00adfore the name, like  x, and it will be  name man\u00adgled. This means that the name will be re\u00adnamed to  _class\u00adnamex  out\u00adside the class def\u00adi\u00adni\u00adtion. The name will not be in\u00adher\u00adit\u00aded by sub\u00adclass\u00ades.  There are some sub\u00adtleties with this, par\u00adtic\u00adu\u00adlar\u00adly for strange class names (names that are too long, or names that be\u00adgin with an un\u00adder\u00adscore). I  asked about this on Stack\u00adOver\u00adflow. The best an\u00adswer is that there was a func\u00adtion in the stan\u00addard li\u00adbrary, but it was re\u00admoved in Python 3. My tests re\u00adveal that the be\u00adhav\u00adior is dif\u00adfer\u00adent in CPYthon than in PyPy, so get\u00adting it right for ev\u00adery pos\u00adsi\u00adble class is non\u00adtriv\u00adial. The de\u00adscrip\u00adtor thing should work ev\u00adery\u00adwhere, though.  On the oth\u00ader hand,  getat\u00adtr(ob\u00adj, '_' + ob\u00adj.class.name  + at\u00adtribute\u00adname)  will work 99% of the time, and is much eas\u00adi\u00ader both to write and to un\u00adder\u00adstand than the de\u00adscrip\u00adtor.", 
      "loc": "/posts/2013/04/06/how-to-make-attributes-un-inheritable-in-python-using-descriptors/"
    }, 
    {
      "title": "When does x^log(y) = y^log(x)?", 
      "tags": "mathjax", 
      "text": "In this blog post, when I write $latex \\log(x)$, I mean the natural logarithm, or log base $latex e$, i.e., $latex \\ln(x)$.\nA dis\u00adcus\u00adsion on a\u00a0 pull re\u00adquest \u00a0got me think\u00ading about this ques\u00adtion: what are the so\u00adlu\u00adtions to the com\u00adplex equa\u00adtion $la\u00adtex x{\\log{(y)}} = y{\\log(x)}$? \u00a0At the out\u00adset, they look like dif\u00adfer\u00adent ex\u00adpres\u00adsion\u00ads. \u00a0But clear\u00adly there some so\u00adlu\u00adtion\u00ads. For ex\u00adam\u00adple, if $la\u00adtex x = y$, then ob\u00advi\u00adous\u00adly the two ex\u00adpres\u00adsions will be the same. \u00a0We prob\u00ada\u00adbly should ex\u00adclude $la\u00adtex x = y = 0$, though note that even if $la\u00adtex 0{\\log(0)}$ is well-de\u00adfined (prob\u00ada\u00adbly if it is it is ei\u00adther 0 or com\u00adplex $la\u00adtex \\in\u00adfty$), it will be the same well-de\u00adfined val\u00adue. But for the re\u00admain\u00adder of this blog post, I'll as\u00adsume that $la\u00adtex x$ and $la\u00adtex y$ are nonze\u00adro. \n Now, ob\u00adserve that if we ap\u00adply $la\u00adtex \\log$ to both sides of the equa\u00adtion, we get $la\u00adtex \\log{\\left\u00ad(x{\\log(y)}\\right )} = \\log {\\left (y{\\log(x)}\\right )}$. \u00a0Now, sup\u00adpos\u00ading that we can ap\u00adply the fa\u00admous log\u00ada\u00adrithm ex\u00adpo\u00adnent rule, we would get $la\u00adtex \\log(x)\\log(y) = \\log(y)\\log(x)$, which means that if ad\u00addi\u00adtion\u00adal\u00adly $la\u00adtex \\log$ is one-\u00adto-one, we would have that the orig\u00adi\u00adnal ex\u00adpres\u00adsions must be equal. \n The sec\u00adond ques\u00adtion, that of  in\u00adjec\u00adtiv\u00adi\u00adty, is eas\u00adi\u00ader to an\u00adswer than the first, so I'll ad\u00address it first. \u00a0Note that the com\u00adplex ex\u00adpo\u00adnen\u00adtial is not one-\u00adto-one, be\u00adcause for ex\u00adam\u00adple $la\u00adtex e0 = e{2\\pi i} = 1$. \u00a0But we still de\u00adfine the com\u00adplex log\u00ada\u00adrithm as the \"in\u00adverse\" of the com\u00adplex ex\u00adpo\u00adnen\u00adtial. \u00a0What this re\u00adal\u00adly means is that the com\u00adplex log\u00ada\u00adrithm is strict\u00adly speak\u00ading not a func\u00adtion, be\u00adcause it is not well-de\u00adfined. Re\u00adcall that the def\u00adi\u00adni\u00adtion of one-\u00adto-one means that $la\u00adtex f(x) = f(y)$ im\u00adplies $la\u00adtex x = y$, and that the def\u00adi\u00adni\u00adtion of well-de\u00adfined is that $la\u00adtex x = y$ im\u00adplies $la\u00adtex f(x) = f(y)$. \u00a0It is clear to see here that $la\u00adtex f$ be\u00ading one-\u00adto-one is the same as $la\u00adtex f{-1}$ be\u00ading well-de\u00adfined and visa-ver\u00adsa ($la\u00adtex f{-1}$ here is the same loose def\u00adi\u00adni\u00adtion of an in\u00adverse as say\u00ading that the com\u00adplex log\u00ada\u00adrithm is the in\u00adverse of the com\u00adplex ex\u00adpo\u00adnen\u00adtial). \n So note that the com\u00adplex log\u00ada\u00adrithm is not well-de\u00adfined ex\u00adact\u00adly be\u00adcause the com\u00adplex ex\u00adpo\u00adnen\u00adtial is not one-\u00adto-one. \u00a0We of course fix this prob\u00adlem by mak\u00ading it well-de\u00adfined, i.e., it nor\u00admal\u00adly is mul\u00adti\u00adval\u00adued, but we pick a sin\u00adgle val\u00adue con\u00adsis\u00adtent\u00adly (i.e., we pick a  branch), so that it is well-de\u00adfined. \u00a0For the re\u00admain\u00adder of this blog post, I will as\u00adsume the stan\u00addard choice of branch cut for the com\u00adplex log\u00ada\u00adrith\u00adm, i.e., the branch cut is along the neg\u00ada\u00adtive ax\u00adis, and we choose the branch where, for $la\u00adtex x > 0$, $la\u00adtex \\log(x)$ is re\u00adal and $la\u00adtex \\log(-x) = \\log(x) + i\\pi$. \n My point here is that we au\u00adto\u00admat\u00adi\u00adcal\u00adly know that the com\u00adplex log\u00ada\u00adrithm is one-\u00adto-one be\u00adcause we know that the com\u00adplex ex\u00adpo\u00adnen\u00adtial is well-de\u00adfined. \n So our ques\u00adtion boils down to, when does the iden\u00adti\u00adty $la\u00adtex \\log{\\left (za\\right)} = a \\log(z)$ hold? \u00a0In SymPy, this iden\u00adti\u00adty is on\u00adly ap\u00adplied by  ex\u00adpand_log()  or  log\u00adcom\u00adbine()  when $la\u00adtex a$ is re\u00adal and $la\u00adtex z$ is pos\u00adi\u00adtive, so let us as\u00adsume that we know that it holds un\u00adder those con\u00addi\u00adtion\u00ads. Note that it al\u00adso holds for some oth\u00ader val\u00adues too. \u00a0For ex\u00adam\u00adple, by our def\u00adi\u00adni\u00adtion $la\u00adtex \\log{\\left (e{i\\pi}\\right)} = \\log(-1) = \\log(1) + i\\pi = i\\pi = i\\pi\\log(e)$. \u00a0For our ex\u00adam\u00adple, this means that $la\u00adtex x = e$, $la\u00adtex y = -1$ is a non-triv\u00adial so\u00adlu\u00adtion (non-triv\u00adial mean\u00ading $la\u00adtex x \\neq y$). \u00a0 Ac\u00adtu\u00adal\u00adly, the way that the com\u00adplex log\u00ada\u00adrithm be\u00ading the \"in\u00adverse\" of the com\u00adplex ex\u00adpo\u00adnen\u00adtial works is that $la\u00adtex e{\\log(x)} = x$ for all $la\u00adtex x$ (on the oth\u00ader hand $la\u00adtex \\log{\\left\u00ad(ex\\right)} \\neq x$ in gen\u00ader\u00adal), so that if $la\u00adtex x = e$, then $la\u00adtex x{\\log(y)} = e{\\log(y)} = y$ and $la\u00adtex y{\\log(x)} = y{\\log(e)} = y1 = y$. \u00a0In oth\u00ader word\u00ads, $la\u00adtex x = e$ is al\u00adways a so\u00adlu\u00adtion, for any $la\u00adtex y\\, (\\neq 0)$ (and sim\u00adi\u00adlar\u00adly $la\u00adtex y = e$ for all $la\u00adtex x$). \u00a0In terms of our ques\u00adtion of when $la\u00adtex \\log{\\left\u00ad(za\\right)} = a\\log(z)$, this just says that this al\u00adways true for $la\u00adtex a = \\log(e) = 1$, re\u00adgard\u00adless of $la\u00adtex z$, which is ob\u00advi\u00adous. \u00a0We can al\u00adso no\u00adtice that this iden\u00adti\u00adty al\u00adways holds for $la\u00adtex a = 0$, re\u00adgard\u00adless of $la\u00adtex z$. In terms of our orig\u00adi\u00adnal equa\u00adtion, this means that $la\u00adtex x = e0 = 1$ is a so\u00adlu\u00adtion for all $la\u00adtex y$ (and as be\u00adfore, $la\u00adtex y = 1$ for all $la\u00adtex x$). \n Note that $la\u00adtex z > 0$ and $la\u00adtex a$ re\u00adal cor\u00adre\u00adsponds to $la\u00adtex x, y > 0$ and $la\u00adtex \\log(x), \\log(y)$ re\u00adal, re\u00adspec\u00adtive\u00adly, (which are the same con\u00addi\u00adtion). \u00a0So we have so far that the fol\u00adlow\u00ading are so\u00adlu\u00adtions to $la\u00adtex x{\\log(y)} = y{\\log(x)}$: \n \n    $la\u00ad\u00adtex x, y > 0$ \n     $la\u00adtex x = y$ \n     $la\u00adtex x = e$, $la\u00adtex y$ ar\u00adbi\u00adtrary \n     $la\u00adtex y = e$, $la\u00adtex x$ ar\u00adbi\u00adtrary \n     $la\u00adtex x = 1$, $la\u00adtex y$ ar\u00adbi\u00adtrary \n     $la\u00adtex y = 1$, $la\u00adtex x$ ar\u00adbi\u00adtrary \n \n\nNow let's look at some cas\u00ades where $la\u00adtex \\log{\\left (za\\right)} \\neq a\\log(z)$. \u00a0If $la\u00adtex z < 0$ and $la\u00adtex a$ is a nonze\u00adro even in\u00adte\u00adger, then $la\u00adtex za > 0$ so $la\u00adtex \\log{\\left (za \\right)}) = \\log{\\left (\\left (-z\\right )a \\right )} = a\\log(-z)$, where\u00adas $la\u00adtex a\\log(z) = a(\\log(-z) + i\\pi)$, which are dif\u00adfer\u00adent by our as\u00adsump\u00adtion that $la\u00adtex a \\neq 0$. \u00a0If $la\u00adtex a$ is an odd in\u00adte\u00adger not equal to 1, then $la\u00adtex za < 0$, so\u00a0$la\u00adtex \\log{\\left (za \\right)} = \\log{\\left (-za \\right )} + i\\pi$ = $la\u00adtex\u00a0\\log{\\left (\\left\u00ad(- z\\right){a} \\right )} + i\\pi$  Word\u00adpress is re\u00adfus\u00ading to ren\u00adder this. It should be  log((-z)a) + i\u03c0 = $la\u00adtex a\\log(-z) + i\\pi$, where\u00adas $la\u00adtex a\\log(z) = a(\\log(-z) + i\\pi)$ again, which is not the same be\u00adcause $la\u00adtex a \\neq 1$. This means that if we let $la\u00adtex x < 0$ and $la\u00adtex y = ea$, where $la\u00adtex a \\neq 0, 1$, we get a non-\u00adso\u00adlu\u00adtion (and the same if we swap $la\u00adtex x$ and $la\u00adtex y$).    \n This is as far as I got tonight. Word\u00adpress is ar\u00adbi\u00adtrar\u00adi\u00adly not ren\u00adder\u00ading that La\u00adTeX for no good rea\u00adson.  That and the very ug\u00adly La\u00adTeX im\u00adages is piss\u00ading me off (why word\u00adpress.\u00adcom has\u00adn't switched to Math\u00adJaX yet is be\u00adyond me).  The next time I get some free time, I am go\u00ading to se\u00adri\u00adous\u00adly con\u00adsid\u00ader switch\u00ading my blog to some\u00adthing host\u00aded on GitHub, prob\u00ada\u00adbly us\u00ading the IPython note\u00adbook.  I wel\u00adcome any hints peo\u00adple can give me on that, es\u00adpe\u00adcial\u00adly con\u00adcern\u00ading mi\u00adgrat\u00ading pages from this blog. \n Here is some work on find\u00ading the rest of the so\u00adlu\u00adtion\u00ads: the gen\u00ader\u00adal def\u00adi\u00adni\u00adtion of $la\u00adtex \\log(x)$ is $la\u00adtex \\log(|x|) + i\\arg(x)$, where $la\u00adtex \\arg(x)$ is cho\u00adsen in $la\u00adtex (-\\pi, \\pi]$.  There\u00adfore, if $la\u00adtex \\log{\\left\u00ad(za\\right )} = a\\log(z)$, we must have $la\u00adtex \\arg(za) = a\\arg(z)$.  I be\u00adlieve a de\u00adscrip\u00adtion of all such com\u00adplex $la\u00adtex z$ and $la\u00adtex a$ will give all so\u00adlu\u00adtions $la\u00adtex x = z$, $la\u00adtex y = ea$ (and $la\u00adtex y = z$, $la\u00adtex x = ea$) to $la\u00adtex x{\\log(y)} = y{\\log(x)}$.  I need to ver\u00adi\u00adfy that, though, and I al\u00adso need to think about how to de\u00adscribe such $la\u00adtex z$ and $la\u00adtex a$. I will (hope\u00adful\u00adly) con\u00adtin\u00adue this post lat\u00ader, ei\u00adther by edit\u00ading this one or writ\u00ading a new one (de\u00adpend\u00ading on how much more I come up with\u00ad).    \n Any com\u00adments to this post are wel\u00adcome.  I know you can't pre\u00adview com\u00adments, but if you want to use math, just write it as  $la\u00adtex math$  (like  $la\u00adtex \\log(x)$  for $la\u00adtex \\log(x)$). If you mess some\u00adthing up, I'll ed\u00adit your com\u00adment and fix it.", 
      "loc": "/posts/2013/03/03/when-does-xlogy-ylogx/"
    }, 
    {
      "title": "Tip for debugging SymPy with PuDB", 
      "tags": "", 
      "text": "Usu\u00adal\u00adly, when I de\u00adbug SymPy code with  PuDB, I cre\u00adate a script that calls the code, then I put a   \n [code lan\u00adguage=\"py\"] \n im\u00adport pud\u00adb; pud\u00adb.set_\u00adtrace() \n [/\u00adcode] \n in the SymPy li\u00adbrary code where I want to start de\u00adbug\u00adging. But this is an\u00adnoy\u00ading, first be\u00adcause I have to cre\u00adate the scrip\u00adt, and sec\u00adond, be\u00adcause I have to mod\u00adi\u00adfy the li\u00adbrary code, and there's al\u00adways the risk of ac\u00adci\u00adden\u00adtal\u00adly com\u00admit\u00ading that.  Al\u00adso, if I want to start de\u00adbug\u00adging some\u00adwhere else, I have to ed\u00adit the files and change it. \n Well, I just fig\u00adured out a bet\u00adter way.   First, if you haven't al\u00adready, add an alias like this in your bash con\u00adfig file (~/.pro\u00adfile  or  ~/.bashrc):alias pud\u00adb='python -m pud\u00adb.run.   As of  this pull re\u00adquest, this is no longer nec\u00ades\u00adsary.  A  pudb  script is in\u00adstalled au\u00adto\u00admat\u00adi\u00adcal\u00adly with PuD\u00adB. \n This will let you run  pudb scrip\u00adt.py  to de\u00adbug  scrip\u00adt.py.   Nex\u00adt, start PuD\u00adB. It does\u00adn't mat\u00adter with what. You can just run  touch test.py, and then  pudb test.py.    It oc\u00adcured to me that you can just set the break\u00adpoint when start\u00ading isympy with PuD\u00adB. \n Now, press  m, and nav\u00adi\u00adgate to where in the li\u00adbrary code you want to start de\u00adbug\u00adging.  It al\u00adso helps to use  /  to search the cur\u00adrent file and  L  to jump to a spe\u00adcif\u00adic line.  When you get to the line where you want to start de\u00adbug\u00adging, press  b  to set a break\u00adpoint. You can do this in mul\u00adti\u00adple places if you wan\u00adt. \n Now, you just have to start  isympy  from with\u00adin PuD\u00adB.  Just run  pudb bin/isympy, and im\u00adme\u00addi\u00adate\u00adly press  c  to jump to the in\u00adter\u00adac\u00adtive promp\u00adt.  Now, run what\u00adev\u00ader code you want to de\u00adbug.  When it gets to the break\u00adpoint, PuDB will open, and you can start de\u00adbug\u00adging.  If you type  c  to con\u00adtin\u00adue, it will go back to isympy. But the next time you run some\u00adthing that hits the break\u00adpoint, it will open PuDB again.   \n This trick works be\u00adcause break\u00adpoints are saved to file (at  ~/.\u00adcon\u00adfig/pud\u00adb/saved-break\u00adpoints). In fac\u00adt, if you wan\u00adt, you can just mod\u00adi\u00adfy that file in the first step.  You can ed\u00adit your saved break\u00adpoints in the bot\u00adtom right pane of PuD\u00adB.   \n When you are done and you type  Ctr\u00adl-D  PuDB will pop-up again, ask\u00ading if you want to quit.  That's be\u00adcause it was run\u00adning the whole time, un\u00adder\u00adneath isympy.  Just press  q.  Note that you should avoid press\u00ading  q  while de\u00adbug\u00adging, or else PuDB will quit, and you will be left with just nor\u00admal isympy (it won't break at your break\u00adpoints any more).  Ac\u00adtu\u00adal\u00adly, if you do this, but do\u00ading  Ctr\u00adl-D  still opens the PuDB promp\u00adt, you can just press \"Restart\", and it should start work\u00ading again.  Note that \"Restart\" will not ac\u00adtu\u00adal\u00adly re\u00adset isympy:  all your saved vari\u00adables will still be the same, and any changes to the li\u00adbrary code will not be reload\u00aded.  To do that, you have to com\u00adplete\u00adly ex\u00adit and start over again. \n Of course, there is noth\u00ading SymPy spe\u00adcif\u00adic about this trick. As long as you have a script that acts as an en\u00adtry point to an in\u00adter\u00adac\u00adtive con\u00adsole for your ap\u00adpli\u00adca\u00adtion, you can use it.  If you just use IPython, you can use some\u00adthing like  pudb /bin/ipython  (re\u00adplace  /bin/ipython  with the out\u00adput of  which ipython).", 
      "loc": "/posts/2013/01/28/tip-for-debugging-sympy-with-pudb/"
    }, 
    {
      "title": "Emacs: One year later", 
      "tags": "", 
      "text": "As read\u00aders of this blog may re\u00admem\u00adber, back in 2011, I de\u00adcid\u00aded to move to a com\u00admand-\u00adline based ed\u00adi\u00adtor. For rough\u00adly two weeks in De\u00adcem\u00adber, 2011, I ex\u00adclu\u00adsive\u00adly used Vim, and for the same amount of time in Jan\u00aduary, 2012, I used ex\u00adclu\u00adsive\u00adly Emac\u00ads. I had used a lit\u00adtle of each ed\u00adi\u00adtor in the past, but this was my first time us\u00ading them to do true edit\u00ading work. My ex\u00adpe\u00adri\u00adences are chron\u00adi\u00adcled in my blog posts (parts  1,  2,  3, and  7 months lat\u00ader fol\u00adlow up).    \n To sum\u00adma\u00adrize, I de\u00adcid\u00aded to use Emac\u00ads, as I found it to be much more in\u00adtu\u00aditive, and much more user-friend\u00adly.  To\u00adday, Jan\u00adu\u00adary 1, marks the one-year point of my us\u00ading Emacs as my sole text ed\u00adi\u00adtor, with some ex\u00adcep\u00adtions (no\u00adtably, I'm cur\u00adrent\u00adly writ\u00ading this blog post in the browser).  So I'd like to make some ob\u00adser\u00adva\u00adtion\u00ads: \n </p><li>Either one of these editors (Vim or Emacs) is going to really suck unless you are willing to make a serious investment in customizing them and installing nice addons. For the second point, Emacs has an advantage, because the philosophy of Vim is to be barebones whereas the philosophy of Emacs is to be featureful, so that in particular many things that were once addons of Emacs are now included in the standard installation.  For customization, on the one hand, Emacs is easier, because it has a nice interface (<code>M-x customize</code>), but on the other hand, Vim's scripting language is much easier to hack on than Emacs lisp (I still can't code in Lisp to save my life; it's a very challenging programming language).<br><br>But my point here is that neither has really great defaults. For example, in Emacs, <code>M-space</code> is bound to <code>just-one-space</code>, which is great for programming.  What it does is remove all spaces around the cursor, except for one.  But to be really useful, it also should include newlines.  It doesn't do this by default.  Rather, you have to call it with a negative argument.  So to be really useful, you have to add\n\n\n\n[source\u00adcode] \n (de\u00adfun just-one-s\u00adpace-with\u00ad-new\u00adline ()\n  \"Call just-one-s\u00adpace with a neg\u00ada\u00adtive ar\u00adgu\u00admen\u00adt\"\n  (in\u00adter\u00adac\u00adtive)\n  (just-one-s\u00adpace -1)) \n (glob\u00adal-set-key (kbd \"M-SPC\") 'just-one-s\u00adpace-with\u00ad-new\u00adline) \n ~~~~~~~~~~~~ \n to your  .emacs  file. \n <li>Emacs has great features, but I always have to look them up.  Or rather, I have to look up the keyboard shortcuts for them.  I only have the keyboard shortcuts memorized for the things I do every day.  I even ended up forgetting really important ones, like <code>M-w</code> (Emacs version of copy).  And if a feature involves several keystrokes to access, forget about it (for example, rectangular selection, or any features of special modes).  If I use a new mode, e.g., for some file type that I rarely edit (like HTML), I might as well not have any of the features, other than the syntax highlighting, because I either don't know what they are, or even if I know that they should exist (like automatic tag completion for html), I have no idea how to access them. <br><br>\n\n\n\nThere's re\u00adal\u00adly some\u00adthing to be said about GUI ed\u00adi\u00adtors, which give these things to users in a way that they don't have to mem\u00ado\u00adrize any\u00adthing.  Per\u00adhaps I should try to use the menu more.  Or maybe au\u00adthors of ad\u00addons should aim to make fea\u00adtures re\u00adquire as lit\u00adtle cog\u00adni\u00adtive us\u00ader in\u00adter\u00adac\u00adtion as pos\u00adsi\u00adble (such as the ex\u00adcel\u00adlent  au\u00adto-\u00adcom\u00adplete-\u00admode  I men\u00adtioned in  part 3). \n   I men\u00adtion this be\u00adcause it is one of the things I com\u00adplained about with Vim, that the key\u00adbind\u00adings were too hard to mem\u00ado\u00adrize.  Of course, the dif\u00adfer\u00adence with Vim is that one has to mem\u00ado\u00adrize key\u00adbind\u00adings to do even the most ba\u00adsic of edit\u00ading tasks, where\u00adas with Emacs one can al\u00adways fall back to more nat\u00adu\u00adral things like  Shift-Ar\u00adrow Key  to se\u00adlect text or  Delete  to delete the char\u00adac\u00adter un\u00adder the cur\u00adsor (and yes, I know you can re\u00adbind this stuff in Vim; I re\u00adfer you to the pre\u00advi\u00adous bul\u00adlet point).   \n <li>I mentioned at the end of part 3 that Vim might still be useful to learn, as vi is available literally anywhere that you have POSIX.  I honestly don't think I would be able to use vi or vim if I had to, customization or no, unless I had my keyboard cheat sheet and a decent amount of time.  If I'm stuck on a barebones system and I can't do anything about it, I'll use nano/pico before I use vi.  It's not that I hate vi. I just can't do anything with it. It is the same to me now as it was before I used it in-depth.  I have forgotten all the keyboard shortcuts, except for <code>ESC</code> and <code>i</code>.</li>\n\n<li>I don't use <code>emacsclient</code> any more.  Ever since I got my new retina MacBook Pro, I don't need it any more, because with the solid state drive starting Emacs from scratch is instantaneous.  I'm glad to get rid of it, because it had some seriously annoying glitches.</li>\n\n<li>Add <code>alias e=emacs</code> to your Bash config file (<code>.profile</code> or <code>.bashrc</code>). It makes life much easier. \"emacs\" is not an easy word to type, at least on QWERTY keyboards.</li>\n\n<li>I still feel like I am not nearly as efficient in Emacs as I could be. On the one hand, I know there are built-in features (like rectangular selection) that I do not take advantage of enough.  I have been a bit lazy with customization: there are a handful of things that I do often that require several keystrokes, but I still haven't created custom keyboard shortcuts for (off the top of my head: copying and pasting to/from the Mac OS X clipboard and rigidly indenting/dedenting a block of text (<code>C-u 4 C-x TAB</code>, actually <code>C-c u 4 C-x TAB</code>, since I did the sensible thing and rebound <code>C-u</code> to clear to the previous newline, and bound <code>universal-argument</code> to <code>C-c u</code>) come to mind). <br><br>I feel as if I were to watch someone who has used Emacs for a long time that I would learn a lot of tricks.</li>\n\n<li>I really should learn Emacs lisp. There are a lot of little customizations that I would like to make, but they are really niche, and can only be done programmatically.  But who has the time to learn a completely new programming language (plus a whole library, as just knowing Lisp is useless if you don't know the proper Emacs funtions and variables and coding styles)?</li>\n\n\n\n<li>I've still not found a good visual browser for jumping to function definitions in a file (mostly Python function definitions, but also other kinds of headers for other kinds of files).  The best I've found is <code>imenu</code>. If you know of anything, please let me know.  One thing I really liked about Vim was the <a href=\"http://www.vim.org/scripts/script.php?script_id=273\">tag list</a> extension, which did this perfectly (thanks to commenter <a href=\"http://asmeurersympy.wordpress.com/2011/12/20/vim-vs-emacs-part-1/#comment-424\">Scott</a> for pointing it out to me).  I've been told that Cedet has something like this, but every time I try to install it, I run into some issues that just seem like way too much work (I don't remember what they are, it won't compile or something, or maybe it just wants to do just way too much and I can't figure out how to disable everything except for the parts I want).  </li>\n\n<li>If you ever code in C, add the following to your Makefile\n\n\n\n[code] \n check\u00ad-syn\u00adtax:\n    $(C\u00adC) -o nul $(FLAGS) -S $(CHK_\u00adSOURCES)\n[/\u00adcode] \n (and if you don't use a Make\u00adfile, start us\u00ading one now).  This is as\u00adsum\u00ading you have  CC  and  FLAGS  de\u00adfined at the top (gen\u00ader\u00adal\u00adly to some\u00adthing like  cc  and  -Wall, re\u00adspec\u00adtive\u00adly). Al\u00adso, add the fol\u00adlow\u00ading to your  .emacs \n [code] \n ;; ===== Turn on fly\u00admake-\u00admode ==== \n (ad\u00add-hook 'c-\u00admod\u00ade-\u00adcom\u00admon-hook 'turn-on-fly\u00admake) \n (de\u00adfun turn-on-fly\u00admake ()\n  \"Force fly\u00admake-\u00admode on. For use in hook\u00ads.\"\n  (in\u00adter\u00adac\u00adtive)\n  (fly\u00admake-\u00admode 1)) \n (ad\u00add-hook 'c-\u00admod\u00ade-\u00adcom\u00admon-hook 'fly\u00admake-key\u00adboard\u00ad-short\u00adcut\u00ads) \n (de\u00adfun fly\u00admake-key\u00adboard\u00ad-short\u00adcuts ()\n  \"Add key\u00adboard short\u00adcuts for fly\u00admake go\u00adto nex\u00adt/prev er\u00adror.\"\n  (in\u00adter\u00adac\u00adtive)\n  (lo\u00adcal-set-key \"\\M-n\" 'fly\u00admake-\u00adgo\u00adto-nex\u00adt-er\u00adror)\n  (lo\u00adcal-set-key \"\\M-p\" 'fly\u00admake-\u00adgo\u00adto-pre\u00adv-er\u00adror))\n[/\u00adcode] \n The last part adds the use\u00adful key\u00adboard short\u00adcuts  M-n  and  M-p  to move be\u00adtween er\u00adrors.  Now, er\u00adrors in your C code will show up au\u00adto\u00admat\u00adi\u00adcal\u00adly as you type.  If you use the com\u00admand line ver\u00adsion of emacs like I do, and not the GUI ver\u00adsion, you'll al\u00adso need to in\u00adstall the  fly\u00admake-cur\u00adsor  mod\u00adule, which makes the er\u00adrors show up in the mode line, since oth\u00ader\u00adwise it tries to use mouse pop\u00adup\u00ads.  You can change the col\u00adors us\u00ading  M-x cus\u00adtomize-\u00adface  (search for \"fly\u00admake\").   \n <li>I never got flymake to work with LaTeX.  Does anyone know how to do it? It seems it is hardcoded to use MikTeX, the Windows version of LaTeX. I found some stuff, but none of it worked.  <br><br>\n\n\n\nAc\u00adtu\u00adal\u00adly, what I re\u00adal\u00adly would like is not syn\u00adtax check\u00ading (I rarely make syn\u00adtax mis\u00adtakes in La\u00adTeX any more), but rather some\u00adthing that au\u00adto\u00admat\u00adi\u00adcal\u00adly builds the PDF con\u00adstant\u00adly as I type.  That way, I can just look over at the PDF as I am writ\u00ading (I use an ex\u00adter\u00adnal mon\u00adi\u00adtor for this. I high\u00adly rec\u00adom\u00admend it if you use La\u00adTeX, es\u00adpe\u00adcial\u00adly one of those mon\u00adi\u00adtors that swivels to por\u00adtrait mod\u00ade).    \n <li>If you use Mac OS X, you can use the very excellent <a href=\"http://pqrs.org/macosx/keyremap4macbook/\">KeyRemap4MacBook</a> program to make regular Mac OS X programs act more like Emacs.  Mac OS X already has many Emacs shortcuts built in (like <code>C-a</code>, <code>C-e</code>, etc.), but that only works in Cocoa apps, and it doesn't include any meta key shortcuts.  This lets you use additional shortcuts literally everywhere (don't worry, it automatically doesn't use them in the Terminal), including an emulator for <code>C-space</code> and some <code>C-x</code> commands (like <code>C-x C-s</code> to <code>Command-s</code>).  It doesn't work on context sensitive shortcuts, unfortunately, unless the operating system already supports it with another keyboard shortcut (e.g., it can map <code>M-f</code> to <code>Option-right arrow</code>).  For example, it can't enable moving between paragraphs with <code>C-S-{</code> and <code>C-S-}</code>.  If anyone knows how to do that, let me know. </li>\n\n<li>For about a month this summer, I had to use a Linux laptop, because my Mac broke and my new Mac took a month to arrive (the downside to ordering a new computer immediately after it is announced by Apple).  At this point, my saving of all my customizations to <a href=\"http://pqrs.org/macosx/keyremap4macbook/\">GitHub</a> really helped a lot.  I created a new branch for the Linux computer (because several things in my customizations were Mac specific), and just symlinked the files I wanted.  A hint I can give to people using Linux is to use Konsole.  The Gnome terminal sucks.  One thing I never figured out is how to make Konsole (or any other Terminal for that matter) to send Control-Shift shortcuts to Emacs (see http://superuser.com/q/439961/39697).   I don't use Linux any more at the moment, but if anyone knows what was going on there, add an answer to that question. </li>\n\n<li>In <a href=\"http://asmeurersympy.wordpress.com/2012/01/13/vim-vs-emacs-part-3/\">part 3</a> mentioned that <a href=\"http://www.dr-qubit.org/predictive/predictive-user-manual/html/index.php\">predictive mode</a> was cool, but not very useful.  What it does is basically add tab completion for every word in the English language.  Actually, I've found using auto-complete-mode even when editing text (or LaTeX) to be very useful.  Unlike predictive mode, it only guesses words that you've already typed  (it turns out that you tend to type the same words over and over, and doubly so if those words are LaTeX math commands).  Also, predictive mode has a set order of words, which supposedly helps to use it with muscle memory, whereas auto-complete-mode tries to learn what words you are more likely to use based on some basic statistical machine-learning.  Also, auto-complete-mode has a much better visual UI and smarter defaults than predictive mode. The result is that it's actually quite useful and makes typing plain text, as well as LaTeX (actually, pretty much anything, as long as you tend to use the same words repeatedly) much faster.  I recommend enabling auto-complete-mode almost everywhere using hooks, like\n\n\n\n[code] \n (ad\u00add-hook 'la\u00adtex-\u00admod\u00ade-hook 'au\u00adto-\u00adcom\u00adplete-\u00admod\u00ade) \n (ad\u00add-hook 'La\u00adTeX-\u00admod\u00ade-hook 'au\u00adto-\u00adcom\u00adplete-\u00admod\u00ade) \n (ad\u00add-hook 'prog-\u00admod\u00ade-hook 'au\u00adto-\u00adcom\u00adplete-\u00admod\u00ade) \n ;; etc. \n [/\u00adcode] \n\n\n <li>At the end of the day, I'm pretty happy with Emacs.  I've managed to fix most of the things that make it annoying, and it is orders of magnitude more powerful than any GUI editor or IDE I've ever seen, especially at just basic text editing, which is the most important thing (I can always use another program for other things, like debugging or whatever).  The editor uses the basic shortcuts that I am used to, and is quite efficient to write in.  Extensions like auto-complete-mode make using it much faster, though I could use some more extensions to make it even better (namely, a better isearch and a better imenu). Regarding Vim vs. Emacs, I'd like to quote something I said back in my <a href=\"http://asmeurersympy.wordpress.com/2011/12/20/vim-vs-emacs-part-1\">first blog post</a> about Vim over a year ago:\n\n\n\nVim is great for text editing, but not so hot for text writing (unless you always write text perfectly, so that you never need to leave insert mode until you are done typing). Just the simple act of deleting a mistyped word (yes, word, that happens a lot when you are decently fast touch typist) takes several keystrokes, when it should in my opinion only take one (two if you count the meta-key).\n\nNeed\u00adless to say, I find Emacs to be great for both text edit\u00ading and text writ\u00ading.", 
      "loc": "/posts/2013/01/01/emacs-one-year-later/"
    }, 
    {
      "title": "2012 in review", 
      "tags": "", 
      "text": "The Word\u00adPress.\u00adcom stats helper mon\u00adkeys pre\u00adpared a 2012 an\u00adnu\u00adal re\u00adport for this blog. \n     \n    Here's an ex\u00adcerp\u00adt: \n <blockquote>4,329 films were submitted to the 2012 Cannes Film Festival. This blog had <strong>20,000</strong> views in 2012. If each view were a film, this blog would power 5 Film Festivals</blockquote>\n<p><a href=\"http://asmeurersympy.wordpress.com/2012/annual-report/\">Click here to see the complete report.</a></p>", 
      "loc": "/posts/2012/12/30/2012-in-review/"
    }, 
    {
      "title": "Infinitely nested lists in Python", 
      "tags": "", 
      "text": "Read\u00aders of this blog know that I some\u00adtimes like to write about some  strange,  un\u00adex\u00adpect\u00aded, and  un\u00adusu\u00adal  things in Python that I stum\u00adble across.  This post is an\u00adoth\u00ader one of those. \n First, look at this \n [code lan\u00adguage=\"py\"] \n >>> a = [] \n >>> a.ap\u00adpend(a) \n >>> a \n [[...]] \n [/\u00adcode] \n What am I do\u00ading here?  I'm cre\u00adat\u00ading a list,  a, and I'm adding it to it\u00adself.  What you end up with is an in\u00adfin\u00adite\u00adly nest\u00aded list.  The first in\u00adter\u00adest\u00ading thing about this is that Python is smart enough to not ex\u00adplode when print\u00ading this list.  The fol\u00adlow\u00ading should con\u00advince you that  a  does in\u00addeed con\u00adtain it\u00adself. \n [code lan\u00adguage=\"py\"] \n >>> a[0] is a \n True \n >>> a[0] == a \n True \n [/\u00adcode] \n Now, if you have pro\u00adgrammed in C, or a sim\u00adi\u00adlar lan\u00adguage that us\u00ades point\u00ader\u00ads, this should not come as a sur\u00adprise to you.  Lists in Python, like most things, do not ac\u00adtu\u00adal\u00adly con\u00adtain the items in\u00adside them.  Rather, they con\u00adtain ref\u00ader\u00adences (in C ter\u00admi\u00adnol\u00ado\u00adgy, \"point\u00ader\u00ads\") to the items in\u00adside them.  From this per\u00adspec\u00adtive, there is no is\u00adsue at all with  a  con\u00adtain\u00ading a point\u00ader to it\u00adself. \n The first thing I won\u00addered when I saw this was just how clever the print\u00ader was at notic\u00ading that the list was in\u00adfin\u00adite\u00adly nest\u00aded.  What if we make the cy\u00adcle a lit\u00adtle more com\u00adplex? \n [code lan\u00adguage=\"py\"] \n >>> a = [] \n >>> b = [] \n >>> a.ap\u00adpend(b) \n >>> b.ap\u00adpend(a) \n >>> a \n [[[...]]] \n >>> b \n [[[...]]] \n >>> a[0] is b \n True \n >>> b[0] is a \n True \n [/\u00adcode] \n So it still work\u00ads.  I had thought that maybe repr just catch\u00ades  Run\u00adtimeEr\u00adror  and falls back to print\u00ading  ...  when the list is nest\u00aded too deeply, but it turns out that is not true: \n [code lan\u00adguage=\"py\"] \n >>> a = [] \n >>> for i in range(10000): \n ...     a = [a] \n ...   \n >>> a \n Trace\u00adback (most re\u00adcent call last):\n  File \"<st\u00add\u00adin>\", line 1, in <mod\u00adule>\nRun\u00adtimeEr\u00adror: max\u00adi\u00admum re\u00adcur\u00adsion depth ex\u00adceed\u00aded while get\u00adting the repr of a list \n [/\u00adcode] \n And by the way, in case you were won\u00adder\u00ading, it is pos\u00adsi\u00adble to catch a  Run\u00adtimeEr\u00adror  (us\u00ading the same  a  as the pre\u00advi\u00adous code block) \n [code lan\u00adguage=\"py\"] \n >>> try: \n ...     print\u00ad(a) \n ... ex\u00adcept Run\u00adtimeEr\u00adror: \n ...     print\u00ad(\"no way\") \n ...   \n no way \n [/\u00adcode] \n (and you al\u00adso may no\u00adtice that this is Python 3. Things be\u00adhave the same way in Python 2) \n Back to in\u00adfin\u00adite\u00adly nest\u00aded list\u00ads, we saw that print\u00ading work\u00ads, but there are some things that don't work. \n [code lan\u00adguage=\"py\"] \n >>> a[0] == b \n True \n >>> a[0] == a \n Trace\u00adback (most re\u00adcent call last):\n  File \"<st\u00add\u00adin>\", line 1, in <mod\u00adule>\nRun\u00adtimeEr\u00adror: max\u00adi\u00admum re\u00adcur\u00adsion depth ex\u00adceed\u00aded in com\u00adpar\u00adi\u00adson \n [/\u00adcode] \n a[0] is b  holds (i.e., they are ex\u00adact\u00adly the same ob\u00adject in mem\u00ado\u00adry), so  ==  is able to short\u00ad-\u00adcir\u00adcuit on them.  But to test  a[0] == a  it has to re\u00adcur\u00adsive\u00adly com\u00adpare the el\u00ade\u00adments of  a  and  a[0].  Since it is in\u00adfin\u00adite\u00adly nest\u00aded, this leads to a re\u00adcur\u00adsion er\u00adror.  Now an in\u00adter\u00adest\u00ading ques\u00adtion: why does this hap\u00adpen?  Is it be\u00adcause  ==  on lists us\u00ades a depth first search?  If it were some\u00adhow pos\u00adsi\u00adble to com\u00adpare these two ob\u00adject\u00ads, would they be equal? \n One is re\u00admind\u00aded of  Rus\u00adsel's para\u00addox, and the rea\u00adson why in  ax\u00adiomat\u00adic set the\u00ado\u00adry, sets are not al\u00adlowed to con\u00adtain them\u00adselves.   \n Think\u00ading of this brought me to my fi\u00adnal ques\u00adtion.  Is it pos\u00adsi\u00adble to make a Python  set  that con\u00adtains it\u00adself?  The an\u00adswer is ob\u00advi\u00adous\u00adly no, be\u00adcause  set  ob\u00adjects can on\u00adly con\u00adtain hash\u00adable ob\u00adject\u00ads, and  set  is not hash\u00adable.  But  frozenset,  set's coun\u00adter\u00adpart, is hash\u00adable.  So can you cre\u00adate a  frozenset  that con\u00adtains it\u00adself?  The same for  tu\u00adple.  The method I used for  a  above won't work, be\u00adcause  a  must be mu\u00adta\u00adble to ap\u00adpend it to it\u00adself.", 
      "loc": "/posts/2012/09/19/infinitely-nested-lists-in-python/"
    }, 
    {
      "title": "isympy -I:  A saner interactive environment", 
      "tags": "", 
      "text": "As  promised, here is an\u00adoth\u00ader post de\u00adscrib\u00ading a new fea\u00adture in the up\u00adcom\u00ading  SymPy 0.7.2. \n Automatic Symbol Definition\nWhile not as ground break\u00ading as the fea\u00adture I de\u00adscribed in my  last post, this fea\u00adture is still quite use\u00adful. As you may know, SymPy is in\u00adher\u00adent\u00adly a Python li\u00adbrary, mean\u00ading that it lives by the rules of Python. If you want to use any name, whether it be a Sym\u00adbol or a func\u00adtion (like cos), you need to de\u00adfine it (in the case of Sym\u00adbol\u00ads), or im\u00adport it (in the case of func\u00adtions that come with SymPy). We pro\u00advide the script  isympy  with SymPy to as\u00adsist with this. This script au\u00adto\u00admat\u00adi\u00adcal\u00adly runs IPython (if it's in\u00adstalled), im\u00adports all names from sympy (from sympy im\u00adport *), and de\u00adfines com\u00admon sym\u00adbol names (like  x,  y, and  z). \n But if you want to use a Sym\u00adbol that is not one of the ones pre\u00adde\u00adfined by  isympy, you will get some\u00adthing like \n [code lan\u00adguage=\"py\"] \n In [1]: r*x \n \nNameEr\u00adror                                 Trace\u00adback (most re\u00adcent call last)\n in ()\n----> 1 r*x \n NameEr\u00adror: name 'r' is not de\u00adfined \n [/\u00adcode] \n The best so\u00adlu\u00adtion for this has been ei\u00adther to type  var('r'), which will cre\u00adate the Sym\u00adbol  r  and in\u00adject it in\u00adto the names\u00adpace, or to wrap your text in a string and pass it to  sympi\u00adfy(), like  sympi\u00adfy(\"r*x\"). Nei\u00adther of these are very friend\u00adly in in\u00adter\u00adac\u00adtive mod\u00ade. \n In SymPy 0.7.2,  isympy  has a new com\u00admand line op\u00adtion,  isympy -a, which will en\u00adable a mech\u00ada\u00adnism that will au\u00adto\u00admat\u00adi\u00adcal\u00adly de\u00adfine all un\u00adde\u00adfined names as Sym\u00adbols for you: \n [code lan\u00adguage=\"py\"] \n In [1]: r*x \n Out\u00ad[1]: r\u22c5x \n [/\u00adcode] \n There are some caveats to be aware of when us\u00ading this fea\u00adture: \n \n    Names must be un\u00adde\u00adfined for  isympy -a  to work. If you type some\u00adthing like  S*x, you'll get:[\u00adcode lan\u00adguage=\"py\"]\nIn [3]: S*x\n\n---------------------------------------------------------------------------\n\n\u00adType\u00adEr\u00adror                                 Trace\u00adback (most re\u00adcent call last)\n\n<ipython-in\u00adput-3-6656a97ea7b0> in <mod\u00adule>()\n\n----> 1 S*x\n\n\n\n\u00adType\u00adEr\u00adror: un\u00adsup\u00adport\u00aded op\u00ader\u00adand type\u00ad(s) for *: 'S\u00adin\u00adgle\u00adton\u00adReg\u00adistry' and 'Sym\u00adbol\u00ad'\n\n[/\u00adcode]\n\n\n\nThat's be\u00adcause  S  is al\u00adready de\u00adfined (it's the  Sin\u00adgle\u00adton\u00adReg\u00adistry, and al\u00adso a short\u00adcut to  sympi\u00adfy()). To use a name that's al\u00adready de\u00adfined, ei\u00adther cre\u00adate it man\u00adu\u00adal\u00adly with  var()  or delete it us\u00ading  del. \n     This on\u00adly works on the top lev\u00adel names\u00adpace. If you de\u00adfine a func\u00adtion with an un\u00adde\u00adfined name, it will not au\u00adto\u00admat\u00adi\u00adcal\u00adly de\u00adfine that sym\u00adbol when run. \n     This works by catch\u00ading NameEr\u00adror, defin\u00ading the name, and then re-run\u00adning the ex\u00adpres\u00adsion. If you have a mul\u00adti\u00adline state\u00admen\u00adt, any lines be\u00adfore the un\u00adde\u00adfined name will be run be\u00adfore the NameEr\u00adror will be caugh\u00adt. This usu\u00adal\u00adly won't hap\u00adpen, but it's a po\u00adten\u00adtial side-\u00adef\u00adfect to be aware of. We plan to re\u00adwrite it us\u00ading ei\u00adther ast or to\u00adk\u00adenize to avoid this is\u00adsue. \n     Ob\u00advi\u00adous\u00adly, this is in\u00adtend\u00aded for in\u00adter\u00adac\u00adtive use on\u00adly. If you copy code and put it in a scrip\u00adt, or in some oth\u00ader place where some\u00adone might be ex\u00adpect\u00aded to run it, but not nec\u00ades\u00adsar\u00adi\u00adly from  isympy -a, you should in\u00adclude sym\u00adbol def\u00adi\u00adni\u00adtion\u00ads. \n \n\nAutomatic int to Integer Conversion\n\nA sec\u00adond thing that is an\u00adnoy\u00ading with Python and SymPy is that some\u00adthing like  1/2  will be in\u00adter\u00adpret\u00aded com\u00adplete\u00adly by Python, with\u00adout any SymPy. This means that some\u00adthing like  1/2 + x  will give ei\u00adther  0 + x  or  0.5 + x, de\u00adpend\u00ading on whether or not  fu\u00adture.di\u00advi\u00adsion  has been im\u00adport\u00aded.  isympy  has al\u00adways ran  from  fu\u00adture  im\u00adport di\u00advi\u00adsion, so that you'll get the lat\u00adter, but we usu\u00adal\u00adly would pre\u00adfer to get  Ra\u00adtio\u00adnal(1, 2). Pre\u00advi\u00adous\u00adly, the best way to do this was again to ei\u00adther run it through  sympi\u00adfy()  as a string, or to sympi\u00adfy at least one of the num\u00adbers (here the  S()  short\u00adcut to  sympi\u00adfy()  is use\u00adful, be\u00adcause you can type just  S(1)/2). \n With SymPy 0.7.2, you can run  isympy -i, and it will au\u00adto\u00admat\u00adi\u00adcal\u00adly wrap all in\u00adte\u00adgers lit\u00ader\u00adals with  In\u00adte\u00adger(). The re\u00adsult is that  1/2  pro\u00adduces  Ra\u00adtio\u00adnal(1, 2): \n [code lan\u00adguage=\"py\"] \n In [1]: 1/2 + x \n Out\u00ad[1]: x + 1/2 \n [/\u00adcode] \n Again, there are a cou\u00adple of caveat\u00ads: \n \n    If you want to get Python style di\u00advi\u00adsion, you just need to wrap both ar\u00adgu\u00adments in  in\u00adt():[\u00adcode lan\u00adguage=\"py\"]\nIn [2]: in\u00adt(1)/in\u00adt(2)\n\nOut[2]: 0.5\n\n[/\u00adcode]\n\n\n\nOf course, if you just want a float\u00ading point num\u00adber, you can just use  N()  or  .e\u00advalf() \n     This works by pars\u00ading the text and wrap\u00adping all in\u00adte\u00adger lit\u00ader\u00adals with  In\u00adte\u00adger(). This means that if you have a vari\u00adable set to a Python in\u00adt, it will still act like a Python in\u00adt:[\u00adcode lan\u00adguage=\"py\"]\nIn [6]: a = in\u00adt(1)\n\n\n\nIn [7]: b = in\u00adt(2)\n\n\n\nIn [8]: a/b\n\nOut[8]: 0.5\n\n[/\u00adcode]\n\n\n\nNote that to even do that ex\u00adam\u00adple, I had to man\u00adu\u00adal\u00adly make  a  and  b  Python ints by wrap\u00adping them in  in\u00adt(). If I had just done  a = 1, it would have been parsed as  a = In\u00adte\u00adger(1), and I would have got\u00adten a SymPy In\u00adte\u00adger. But this can be an is\u00adsue if you use the re\u00adsult of some func\u00adtion that re\u00adturns an int (a\u00adgain, note that most func\u00adtions in SymPy that re\u00adturn in\u00adte\u00adgers re\u00adturn In\u00adte\u00adger, not in\u00adt). \n     The same as be\u00adfore: this will on\u00adly work in\u00adter\u00adac\u00adtive\u00adly. If you want to re\u00aduse your code out\u00adside of  isympy -i, you should take care of any in\u00adt/int by rewrit\u00ading it as S(in\u00adt)/in\u00adt. \n \n\nSince these are both use\u00adful fea\u00adtures, we've added a way that you can get them both at on\u00adce: by do\u00ading  isympy -I  (the \"I\" stands for \"In\u00adter\u00adac\u00adtive\"). If we add sim\u00adi\u00adlar fea\u00adtures in the fu\u00adture, we will al\u00adso add them to the  -I  short\u00adcut (for ex\u00adam\u00adple, we may add an op\u00adtion to al\u00adlow    to au\u00adto\u00admat\u00adi\u00adcal\u00adly be re\u00adplaced with  **).", 
      "loc": "/posts/2012/08/31/isympy-i-a-saner-interactive-environment/"
    }, 
    {
      "title": "SymPy Live Sphinx Extension", 
      "tags": "", 
      "text": "I did\u00adn't blog about SymPy all sum\u00admer, so I thought I would write a post about my fa\u00advorite fea\u00adture of the up\u00adcom\u00ading SymPy 0.7.2 re\u00adlease. \u00a0In fac\u00adt, this fea\u00adture has got me more ex\u00adcit\u00aded than any oth\u00ader fea\u00adture from any ver\u00adsion of SymPy. \u00a0Yeah, it's that good. \n The fea\u00adture is the SymPy Live Sphinx ex\u00adten\u00adsion. \u00a0To start, if you don't know about it, check out  SymPy Live. \u00a0This is a con\u00adsole that runs on the  App En\u00adgine. \u00a0We've ac\u00adtu\u00adal\u00adly had this for quite some time, but this win\u00adter, it got a huge up\u00adgrade thanks to the con\u00adtri\u00adbu\u00adtion of some  GCI  stu\u00addents. \u00a0Ba\u00adsi\u00adcal\u00adly, SymPy Live lets you try out SymPy in your brows\u00ader com\u00adplete\u00adly for free, be\u00adcause it runs all the code on the App En\u00adgine. \u00a0Ac\u00adtu\u00adal\u00adly, the con\u00adsole is a full Python con\u00adsole, so you can ac\u00adtu\u00adal\u00adly run any valid Python com\u00admand on it. \u00a0This past win\u00adter, GCI stu\u00addents up\u00adgrad\u00aded the look of the site, added a mo\u00adbile ver\u00adsion (vis\u00adit live.sympy.org on your phone), and added oth\u00ader neat fea\u00adtures like search his\u00adto\u00adry and au\u00adto\u00adcom\u00adple\u00adtion. \n Now,  Sphinx \u00a0is the doc\u00adu\u00admen\u00adta\u00adtion sys\u00adtem that we use to gen\u00ader\u00adate  SymPy's html doc\u00adu\u00admen\u00adta\u00adtion. Last year, when I was at the\u00a0 SciPy Con\u00adfer\u00adence, Ma\u00adteusz had an idea at the sprints to cre\u00adate an ex\u00adten\u00adsion link\u00ading SymPy Live and Sphinx, so that the ex\u00adam\u00adples in Sphinx could be eas\u00adi\u00adly run in SymPy Live. \u00a0He did\u00adn't fin\u00adish the ex\u00adten\u00adsion, but I'm hap\u00adpy to re\u00adport that thanks to David Li, who was al\u00adso one of the\u00a0afore\u00admen\u00adtioned\u00a0G\u00adCI stu\u00addents, the ex\u00adten\u00adsion is now com\u00adplete, and is run\u00adning live on our  de\u00advel\u00adop\u00adment docs. \u00a0When SymPy 0.7.2 is re\u00adleased (soon I promise), it will be part of the ofi\u00adcial doc\u00adu\u00admen\u00adta\u00adtion. \n The best way to see how awe\u00adsome this is is to vis\u00adit the web\u00adsite and check it out. \u00a0Y\u00adou will need a mod\u00adern brows\u00ader (the lat\u00adest ver\u00adsion of Fire\u00adfox, Sa\u00adfar\u00adi, or Chrome will work, IE might work too). \u00a0Go to a page in the de\u00advel\u00adop\u00adment docs with doc\u00adu\u00admen\u00adta\u00adtion ex\u00adam\u00adples, for ex\u00adam\u00adple,\u00a0 http://\u00addoc\u00ads.sympy.org/de\u00adv/\u00adtu\u00adto\u00adri\u00adal.htm\u00adl#al\u00adge\u00adbra, and click on one of the ex\u00adam\u00adples (or click on one of the green \"Run code block in SymPy Live\" but\u00adton\u00ads). You should see a con\u00adsole pop up from the bot\u00adtom-right of the screen, and run your code. \u00a0For ex\u00adam\u00adple: \n   Ex\u00adam\u00adple of the SymPy Live Sphinx ex\u00adten\u00adsion at  http://\u00addoc\u00ads.sympy.org/de\u00adv/\u00adtu\u00adto\u00adri\u00adal.htm\u00adl#al\u00adge\u00adbra. Click for larg\u00ader im\u00adage. \n You can ac\u00adcess or hide the con\u00adsole at any time by click\u00ading on the green box at the bot\u00adtom-right of the page. \u00a0If you click on \"Set\u00adtings\", you will see that you can change all the same set\u00adtings as the reg\u00adu\u00adlar SymPy Live con\u00adsole, such as the print\u00ader type, and the keys for ex\u00ade\u00adcu\u00adtion and au\u00adto\u00adcom\u00adple\u00adtion. \u00a0Ad\u00addi\u00adtion\u00adal\u00adly, there is a new set\u00adting, \"E\u00adval\u00adu\u00ada\u00adtion Mod\u00ade\", which changes how the Sphinx ex\u00adam\u00adples are eval\u00adu\u00adat\u00aded. \u00a0The de\u00adfault is \"E\u00adval\u00adu\u00adate\". \u00a0In this mod\u00ade, if you click on an ex\u00adam\u00adple, it is ex\u00ade\u00adcut\u00aded im\u00adme\u00addi\u00adate\u00adly. \u00a0The oth\u00ader op\u00adtion is \"Copy\u00ad\". \u00a0In this mod\u00ade, if you click an ex\u00adam\u00adple, it is copied to the con\u00adsole, but not ex\u00ade\u00adcut\u00aded right away. This way, you can ed\u00adit the code to try some\u00adthing dif\u00adfer\u00aden\u00adt. \u00a0Re\u00admem\u00adber, this is a full fledged Python con\u00adsole run\u00adning SymPy, so you can try lit\u00ader\u00adal\u00adly any\u00adthing \n So play with this and  let us know  what you think. \u00a0We would love to hear ways that we can im\u00adprove the ex\u00adpe\u00adri\u00adence even fur\u00adther. \u00a0In par\u00adtic\u00adu\u00adlar, I think we should think about ways to make the \"Copy\" mode more user-friend\u00adly. \u00a0Sug\u00adges\u00adtions wel\u00adcome! \u00a0Al\u00adso, please  re\u00adport any bugs. \n And one word of warn\u00ading: \u00a0even though these are the de\u00advel\u00adop\u00adment doc\u00ads, SymPy Live is still run\u00adning SymPy 0.7.1. \u00a0So some ex\u00adam\u00adples may not work un\u00adtil 0.7.2 is re\u00adleased, at which point we will up\u00addate SymPy Live. \n I be\u00adlieve that this ex\u00adten\u00adsion rep\u00adre\u00adsents the fu\u00adture of in\u00adter\u00adac\u00adtive doc\u00adu\u00admen\u00adta\u00adtion.\u00a0I hope you en\u00adjoy.", 
      "loc": "/posts/2012/08/21/sympy-live-sphinx-extension/"
    }, 
    {
      "title": "Emacs: 7 months later", 
      "tags": "", 
      "text": "In my  fi\u00adnal post  about my switch\u00ading to Emac\u00ads, a  com\u00admenter, Scot\u00adt, asked me, \"It has been a while since you start\u00aded us\u00ading Emac\u00ads. I\u2019m just cu\u00adri\u00adous. How is your ex\u00adpe\u00adri\u00adence so far now that you have more ex\u00adpe\u00adri\u00adence and a more com\u00adplete con\u00adfig\u00adu\u00adra\u00adtion?\"  My re\u00adply was get\u00adting quite long, so I fig\u00adured it would be best suit\u00aded as a new post. \n The short an\u00adswer is, most\u00adly the same since I wrote that  Vim vs. Emacs (part 3). Once you use some\u00adthing a lot, you no\u00adtice all kinds of things that could use im\u00adprove\u00adments. Some of them are just mi\u00adnor an\u00adnoy\u00adances. For ex\u00adam\u00adple, many in\u00adter\u00adac\u00adtive com\u00admands in Emacs (but not al\u00adl!) re\u00adquire you to type out \"yes\" in\u00adstead of just \"y\" as a con\u00adfir\u00adma\u00adtion. Oth\u00aders are more se\u00adri\u00adous, like the need for a re\u00adal re\u00adplace\u00adment of Su\u00adperTab from vim. \n I ac\u00adtu\u00adal\u00adly did\u00adn't have much free time to work on con\u00adfig\u00adur\u00ading Emacs dur\u00ading the school year, and once the sum\u00admer start\u00aded, my com\u00adput\u00ader died, and I've been work\u00ading of an old lap\u00adtop run\u00adning Lin\u00adux un\u00adtil I can get a new one. For\u00adtu\u00adnate\u00adly, I had the fore\u00adsight to put all my Emacs con\u00adfig\u00adu\u00adra\u00adtion  on\u00adline on GitHub, so it was easy to get my con\u00adfig\u00adu\u00adra\u00adtion again. I've no\u00adticed that in Lin\u00adux, the Alt key (i.e., Meta) is used for oth\u00ader things, so it does\u00adn't work so well in Emacs (e.g., press\u00ading Alt with\u00adout any oth\u00ader keys some\u00adtimes ac\u00adti\u00advates a menu that re\u00admoves the key\u00adboard fo\u00adcus, and al\u00adso C-M short\u00adcuts don't seem to work at al\u00adl). \n I've mem\u00ado\u00adrized very few key\u00adboard short\u00adcut\u00ads, even ones that might be use\u00adful to me (e.g., I don't re\u00admem\u00adber the short\u00adcut to jump to a match\u00ading paren\u00adthe\u00adsis). Usu\u00adal\u00adly, if I am us\u00ading some mode or some\u00adthing and I want to know how to do some\u00adthing, I just Google it, and gen\u00ader\u00adal\u00adly find the an\u00adswer with\u00adin a few sec\u00adond\u00ads. \n There are sev\u00ader\u00adal ma\u00adjor con\u00adfig\u00adu\u00adra\u00adtion is\u00adsues that I've yet to ad\u00address, ei\u00adther due to lack of time or be\u00adcause I could\u00adn't find a suit\u00adable so\u00adlu\u00adtion. A Su\u00adperTab re\u00adplace\u00adment is one.  This is ac\u00adtu\u00adal\u00adly a big one, be\u00adcause scrolling through a file just to see what's there is get\u00adting old\u00ader and old\u00ader, as is search\u00ading just to jump to a func\u00adtion def\u00adi\u00adni\u00adtion.  If any\u00adone knows of a good way to do this, please let me know.  I main\u00adly need it for Python files, but hav\u00ading it oth\u00ader modes as well would be nice.  Ba\u00adsi\u00adcal\u00adly, I just want some\u00adthing that shows me all the class and func\u00adtion def\u00adi\u00adni\u00adtions in the file, in or\u00adder, that I can eas\u00adi\u00adly se\u00adlect one and jump to it. \n Re\u00adlat\u00aded to search\u00ading, search\u00ading in Emacs suck\u00ads. I'm us\u00ading isearch+, which is an im\u00adprove\u00admen\u00adt, but it still bugs me that search does not wrap around by de\u00adfault. Al\u00adso, for some rea\u00adson, press\u00ading delete does\u00adn't delete the last char\u00adac\u00adter you type\u00add, but the last char\u00adac\u00adter that it matched. That may sound mi\u00adnor, but I use it a lot, so it's re\u00adal\u00adly got\u00adten on my nerves. \n Reg\u00adu\u00adlar ex\u00adpres\u00adsion search\u00ading in Emacs is use\u00adless.  I can nev\u00ader get it to work (usu\u00adal\u00adly be\u00adcause of dif\u00adfer\u00adences be\u00adtween () and ()).  What I re\u00adal\u00adly want is an in\u00adter\u00adac\u00adtive, us\u00ader friend\u00adly, reg\u00adu\u00adlar ex\u00adpres\u00adsion search/search and re\u00adplace tool.  There's reg\u00adex\u00adp-builder, but that's use\u00adless be\u00adcause once you build the reg\u00adu\u00adlar ex\u00adpres\u00adsion, you have to man\u00adu\u00adal\u00adly copy it and paste it in\u00adto the re\u00adal reg\u00adu\u00adlar ex\u00adpres\u00adsion search func\u00adtion to ac\u00adtu\u00adal\u00adly use it.  And it does\u00adn't work with search and re\u00adplace. \n This last se\u00admes\u00adter I had a se\u00admes\u00adter long project in C.  For that, fly\u00admake-\u00admode was a god\u00adsend.  It re\u00adquires a bit of man\u00adu\u00adal con\u00adfig\u00adu\u00adra\u00adtion (y\u00adou have to add some\u00adthing to your Make\u00adfile, and you have to add some stuff to .emacs as al\u00adways to en\u00adable it by de\u00adfault\u00ad), but once you do that, it just work\u00ads.  If you don't know what this is, ba\u00adsi\u00adcal\u00adly, it high\u00adlights the com\u00adpil\u00ader er\u00adrors in your source in re\u00adal time, as you type it.  So in\u00adstead of do\u00ading some\u00adthing stupid twen\u00adty times, and then com\u00adpil\u00ading and find\u00ading them al\u00adl, you do some\u00adthing stupid on\u00adce, see the er\u00adror, and don't do make the mis\u00adtake any more.  It's al\u00adso nice to close your ed\u00adi\u00adtor and know that your code will com\u00adpile. \n The Python mode I am mixed about.  On the one hand, it's re\u00adal\u00adly awe\u00adsome how smart it is about in\u00adden\u00adta\u00adtion.  On the oth\u00ader hand, the syn\u00adtax high\u00adlight\u00ading is just shy of what I want (grant\u00aded, it's pret\u00adty good, but I want bet\u00adter than that).  For ex\u00adam\u00adple, I want to be able to col\u00ador doc\u00adstrings, sin\u00adgle quot\u00aded strings, and dou\u00adble quot\u00aded strings dif\u00adfer\u00adent\u00adly.  It would al\u00adso be awe\u00adsome to get some col\u00ador\u00ading in doc\u00adstrings it\u00adself.  I'm think\u00ading mark\u00addown mode for any text that's in a doc\u00adstring, ex\u00adcept for doctest\u00ads, which are col\u00adored in Python mode (or some vari\u00adant). \n Some things I've not re\u00adal\u00adly cared much about yet be\u00adcause I haven't used that type of file yet.  For ex\u00adam\u00adple, I'm cur\u00adrent\u00adly writ\u00ading this post in Emac\u00ads, and just now notic\u00ading the de\u00adfi\u00adcien\u00adcies in htm\u00adl-\u00admode (e.g., I want an easy way to se\u00adlect text and turn it in\u00adto a link, just like in the Word\u00adPress ed\u00adi\u00adtor). \n Fi\u00adnal\u00adly, I've been try\u00ading to write my own theme.  That process has been slow and slight\u00adly painful.  Emacs is cur\u00adrent\u00adly in the process of mov\u00ading to themes, though, so this is to be ex\u00adpect\u00aded.  When Emacs 24 is ac\u00adtu\u00adal\u00adly re\u00adleased I think it will be fair to judge how well this fea\u00adture work\u00ads. \n That's my wish\u00adlist (or most of it any\u00adway).  But there are pos\u00adi\u00adtive things too. au\u00adto-\u00adcom\u00adplete-\u00admod\u00ade, which I men\u00adtioned at the top of my pre\u00advi\u00adous blog post, is ab\u00adso\u00adlute\u00adly awe\u00adsome.  I think this ex\u00adten\u00adsion alone has made me more pro\u00adduc\u00adtive. \n Some things I take for grant\u00aded, like au\u00adto\u00admat\u00adic spell check\u00ading of strings and com\u00adments in Python (not en\u00adabled by de\u00adfault, but not hard to con\u00adfig\u00adure ei\u00adther).  Thanks to some\u00adone on an Emacs mail\u00ading list, I have the per\u00adfect au\u00adto\u00admat\u00adic clear\u00ading of trail\u00ading whites\u00adpace, that au\u00adto\u00admat\u00adi\u00adcal\u00adly leaves your white\u00adspace be\u00adfore the cur\u00adsor in the buffer, but still writes the clear to the file (see my .emacs file from my dot\u00adfiles re\u00adpo linked to above for de\u00adtail\u00ads). \n I've been hop\u00ading to learn Emacs lisp, so that I could rem\u00ade\u00addy many of these prob\u00adlems on my own, but so far I haven't re\u00adal\u00adly had the free time.  Lisp is a very con\u00adfus\u00ading lan\u00adguage, so it's not easy to jump in\u00adto (com\u00adpared to the lan\u00adguage vim us\u00ades, which I found easy enough to hack on with\u00adout know\u00ading at al\u00adl). \n Ul\u00adti\u00admate\u00adly, I'm quite pleased with how us\u00ader friend\u00adly Emacs is, and with how easy it is to find out how to do al\u00admost any\u00adthing I want just by Googling it. Con\u00adfig\u00adu\u00adra\u00adtion is an up\u00adhill bat\u00adtle.  Emacs has a ton of great pack\u00adages, many of which are in\u00adclud\u00aded, but al\u00admost none are en\u00adabled by de\u00adfault.  Just to\u00adday I dis\u00adcov\u00adered Ido mod\u00ade, thanks to    David Li.  I feel that in the long ter\u00adm, as I learn Emacs Lisp, I can make it do what\u00adev\u00ader I wan\u00adt.  It pro\u00advides a good base\u00adline edit\u00ading ex\u00adpe\u00adri\u00adence, and a good frame\u00adwork for con\u00adfig\u00adur\u00ading it to do what\u00adev\u00ader you wan\u00adt, and al\u00adso enough peo\u00adple use it that 99% of the things you want are al\u00adready done by some\u00adbody.", 
      "loc": "/posts/2012/07/09/emacs-7-months-later/"
    }, 
    {
      "title": "How to install the development version of IPython Qtconsole and Notebook in Ubuntu", 
      "tags": "Standard", 
      "text": "Both the awe\u00adsome  IPython note\u00adbook  and  Qt\u00adcon\u00adsole  are in the Ubun\u00adtu repos\u00adi\u00adto\u00adries, so if you just want to use the sta\u00adble re\u00adleased ver\u00adsion\u00ads, you can just do \n [code lan\u00adguage=\"bash\"] \n su\u00addo ap\u00adt-get in\u00adstall ipython-note\u00adbook ipython-qt\u00adcon\u00adsole \n [/\u00adcode] \n and be on your way.  But the git de\u00advel\u00adop\u00adment ver\u00adsion has a lot of cool new fea\u00adtures, and you may not want to wait for 0.13 to be re\u00adleased and make its way to the Ubun\u00adtu re\u00adpos.  But you may be think\u00ading that to use those you will have to fig\u00adure out all the de\u00adpen\u00adden\u00adcies your\u00adself.  Ac\u00adtu\u00adal\u00adly, it's pret\u00adty easy: \n [code lan\u00adguage=\"bash\"] \n First install git, if you don't already have it\nsu\u00addo ap\u00adt-get in\u00adstall git \n Then, clone the IPython repo, if you haven't already.\ngit clone git://github.\u00adcom/ipython/ipython.git \n cd ipython \n Now just install IPython with apt, then uninstall it.  The dependencies will remain\nsu\u00addo ap\u00adt-get in\u00adstall ipython-note\u00adbook ipython-qt\u00adcon\u00adsole \n su\u00addo ap\u00adt-get re\u00admove ipython-note\u00adbook ipython -qt\u00adcon\u00adsole ipython \n Now install the IPython git version in such a way that will keep up to date when you pull\nsu\u00addo python set\u00adup.py de\u00advel\u00adop \n [/\u00adcode] \n To up\u00addate, just cd in\u00adto that ipython di\u00adrec\u00adto\u00adry and type  git pull.  That's it.  Now type  ipython note\u00adbook  or  ipython qt\u00adcon\u00adsole  to get the mag\u00adic. \n ED\u00adIT: Af\u00adter you do this,  ap\u00adt-get  will start bug\u00adging you ev\u00adery time that you use it that a bunch of pack\u00adages are no longer need\u00aded.  These are the ones that you do need for the qt\u00adcon\u00adsole and the note\u00adbook, so you should not au\u00adtore\u00admove them as it says.  Rather, set them as man\u00adu\u00adal\u00adly in\u00adstalled by copy\u00ading the list of pack\u00adages that it tells you about and  su\u00addo ap\u00adt-get in\u00adstalling them.", 
      "loc": "/posts/2012/06/14/how-to-install-the-development-version-of-ipython-qtconsole-and-notebook-in-ubuntu/"
    }, 
    {
      "title": "Vim vs. Emacs (Part 3)", 
      "tags": "", 
      "text": "See parts  1  and  2. \n Some more com\u00adments af\u00adter us\u00ading emacs for a while: \n </p><li>I finally found the perfect tab completion solution. It took way too much searching for how awesome it is.  It's called <a href=\"http://cx4a.org/software/auto-complete/manual.html\">auto-complete-mode</a>.  The best way to get an idea of what this is is to watch <a href=\"http://www.youtube.com/watch?v=rGVVnDxwJYE\">this screencast</a>.  Basically, it shows you a completion list automatically.  It uses the <em>TAB</em> key to do completion (to me, this is a no brainer, but for some reason, no other completion extension that I found did this, requiring you to do all kinds of nonsense in your .emacs file).  It's got cool features like simple fuzzy matching and intelligent matching (so the first completion is what you tend to use, instead of just the first one that matches).  To quote the author, \"a goal of auto-complete-mode is to provide a system that does what users want without any command.\" I couldn't agree with that goal more. If you install it, I recommend adding <code>(define-key ac-mode-map (kbd \"M-TAB\") 'auto-complete)</code> to your .emacs, so that you can use M-TAB to force the completion menu to come up.  This generally happens automatically, but I think this is the only way to get fuzzy matching, for example. Actually, you can also just use <code>(ac-set-trigger-key \"TAB\")</code>, which intelligently sets TAB to complete or indent, based on which one you more likely want.  This seems to work pretty well to me.</li>\n\n<li>Speaking of indenting, emacs has a pretty nice indentation feature for Python.  You just press <code>TAB</code> repeatedly, and it cycles through all the syntactically legal indentations.  I find this to be more useful than the usual <code>TAB</code> indents behavior of most editors. Note that by default, it won't automatically indent, even with trivial indentations (i.e., keeping the previous indentation).  This is easy to fix, though.  Just add <code>(define-key global-map (kbd \"RET\") 'newline-and-indent)</code> to your .emacs file.  This will make <code>RET</code> do the same thing as <code>C-j</code>, i.e., basically the equivalent of <code>RET TAB</code>.</li>\n\n<li>emacs comes with an extension that lets you work with version control systems, called VC.  I don't use it.  I don't like stuff messing with my git stuff behind my back (sounds like a good way to lose data to me), and I'm good enough with git commands straight that I don't need the help.\n\n\n\nBut un\u00adlike all the oth\u00ader hun\u00addreds of emacs fea\u00adtures that I don't use, this one was se\u00adri\u00adous\u00adly slow\u00ading down my work\u00adflow.  It adds three or four sec\u00adonds to the start\u00adup time of emacs when load\u00ading from with\u00adin a git repos\u00adi\u00adto\u00adry.  So I did some Googling and added this to my .emacs file: \n [code] \n ;; Dis\u00adable all the ver\u00adsion con\u00adtrol stuff           \n ;; Makes emacs load much faster in\u00adside git re\u00adpos   \n (setq vc-han\u00addled-back\u00adends nil) \n [/\u00adcode] \n (un\u00adre\u00adlat\u00aded: Why does\u00adn't Word\u00adPress sup\u00adport lisp as a lan\u00adguage for syn\u00adtax high\u00adlight\u00ading?) \n This dis\u00adables the ver\u00adsion con\u00adtrol stuff, mak\u00ading emacs load fast again (vir\u00adtu\u00adal\u00adly as fast as vim, ac\u00adtu\u00adal\u00adly). \n\n\n <li>Speaking of making emacs go faster, make sure you compile all your extensions into byte code.  For whatever reason, emacs doesn't do this automatically, even though compiled files run much faster, and it doesn't take very long.  The easiest way is to use <code>M-x byte-compile-file</code> from within emacs.  Just make sure that if you modify the .el file that you recompile the byte code, or it will continue to use the old version.</li>\n\n\n\n<li>I finally figured out how to enable mouse support.  For whatever reason, Googling got me nowhere with this, so I ended up asking on the <a href=\"https://lists.gnu.org/mailman/listinfo/help-gnu-emacs\">help-gnu-emacs</a> list, which was very helpful.  The solution is to put\n\n\n\n[code] \n ;; ===== En\u00adable mouse sup\u00adport ==== \n (re\u00adquire 'x\u00adt-\u00admouse)                     \n (x\u00adter\u00adm-\u00admouse-\u00admod\u00ade) \n [/\u00adcode] \n in your .emacs file.  And then it just work\u00ads.  It needs some tweak\u00ading (e.g., it does\u00adn't play so well with mo\u00admen\u00adtum scrolling), but at least it work\u00ads. I thought I was go\u00ading to hang my\u00adself with\u00adout mouse sup\u00adport. Be\u00adcause frankly, as good as the move\u00adment com\u00admands are, mov\u00ading with the mouse is so much eas\u00adi\u00ader some\u00adtimes (the same is true for vim too, btw). \n <li>I compiled the git version of emacs (it's not very hard btw).  I did this to see if the mouse suport \"bug\" was fixed there, but I've gone ahead and kept using it, as it's nicer.  But I didn't figure out how to configure it to not load in an X window. So for now, I've aliased <code>emacs</code> to <code>emacs -nw</code>. I'm sure I just need to add some flag to <code>configure</code>, but I haven't gotten around to looking it up yet.</li>\n\n<li>I found out how to allow editing in the Isearch mode (again, thanks to the help-gnu-emacs list).  You need to install the <a href=\"https://github.com/asmeurer/dotfiles/blob/master/.emacs.d/lisp/isearch%2B.el\">isearch+</a> extension, add the following to your .emacs,\n\n\n\n[code] \n ;; ===== isearch+ =====           \n (re\u00adquire 'isearch+) \n [/\u00adcode] \n and most im\u00adpor\u00adtant\u00adly, you need to ed\u00adit the file and un\u00adcom\u00adment all the com\u00adm\u00admands you want to al\u00adlow.  If you fol\u00adlow my link above, it goes to my per\u00adson\u00adal dot\u00adfiles re\u00adpo, where I've al\u00adready done that. \n <li>On a related note, this is the first of several emacs extensions I've installed that I've edited the extension file itself for.  The rest, I just had to add some code to .emacs.  In most cases, there was already a variable or suggested code snippet to add to .emacs to get what I wanted.\n\n\n\nOn the oth\u00ader hand, with vim, I had to ed\u00adit vir\u00adtu\u00adal\u00adly ev\u00adery ex\u00adten\u00adsion I in\u00adstalled to make it do what I wan\u00adt.  I'm not sure what this mean\u00ads, though.  It could be a state\u00adment about one of many things: how the emacs com\u00admu\u00adni\u00adty pro\u00advides nicer de\u00adfault\u00ads, how the vim lan\u00adguage is eas\u00adi\u00ader to use, and hence more invit\u00ading for me to ed\u00adit the files, or how I haven't got\u00adten around to mess\u00ading with cer\u00adtain things yet. \n <li>If you do a lot of work with LaTeX, check out <a href=\"http://www.gnu.org/software/auctex/\">AUCTeX</a>. I haven't used it enough yet to say much about it, but from what I've played around with, it's pretty awesome.  And if you use a windowed version of emacs, it's got a really awesome preview mode.</li>\n\n<li>If you're bored, check out the <a href=\"http://www.dr-qubit.org/predictive/predictive-user-manual/html/index.php\">predictive</a> extension.  It's actually not as helpful as you'd think (unlike the very similar auto-complete-mode module mentioned above).  But it's kind of cool to turn on and play around with when you're typing something.  Maybe you'll learn new words or something.</li>\n\n<li>I could go on and on.  I haven't mentioned the most basic customizations (like how to setup four-space tabs).  If you are starting to use emacs, I recommend going through <code>M-x customize</code>, and reading my <a href=\"https://github.com/asmeurer/dotfiles/blob/master/.emacs\"><code>.emacs</code></a> file.  And my best advice: if you want emacs to do something, first do <code>M-x customize</code> and search for what you want (EDIT: apparently searching customize requires emacs 24, i.e., the development version).  If you don't find what you want there (and you will surprisingly often), search Google.  There are so many emacs users, that the chances of someone else wanting what you want are very likely. I've found the results from the <a href=\"http://www.emacswiki.org/\">emacs wiki</a> to be particularly helpful. And one more thing: if you find an extension you like, double check first to see if it's not already included in emacs. Emacs seems to like including good extensions in future releases, so an older extension has a good chance of already being included.</li>\n\n\n\nSome emacs ques\u00adtion\u00ads: \n <li>I tried <code>(define-abbrev global-abbrev-table \"Ondrej\" \"Ond\u0159ej\")</code>, so that when I type Ondrej it give me Ond\u0159ej.  But it doesn't work.  Is this a bug or what? If I do <code>(define-abbrev global-abbrev-table \"foo\" \"bar\")</code> and type \"foo\", it turns into \"bar\", but the above leaves Ondrej alone. <em>EDIT: I guess this was an emacs bug.  It doesn't seem to be there any more (perhaps it was fixed with the git version or something).</em></li>\n\n<li>Is there a way to reload .emacs without closing emacs? I'm doing that a lot these days. <em>EDIT: I found it. Do <code>M-x load-file RET ~/.emacs</code></em></li>\n\n<li>Is there a good emacs equivalent of the vim <a href=\"http://www.vim.org/scripts/script.php?script_id=273\">tag list plugin</a>  (thanks for commenter Scott for pointing me to that in the first place)?  I just want something that lists all the class and function definitions in a Python file in order, so I can easily jump to the one I want, or just get an overview of the file.  </li>\n\n\n\nThis Tues\u00adday will mark the point where I will have spend as long us\u00ading emacs as I did us\u00ading vim. But al\u00adready, I feel more com\u00adpe\u00adtent with emac\u00ads.  I won't re\u00adpeat what I said in my last post, but I just want to say that the abil\u00adi\u00adty to ed\u00adit and write at the same time makes me way more pro\u00adduc\u00adtive.  The fact that it us\u00ades key\u00adboard short\u00adcuts that I'm al\u00adready used to prob\u00ada\u00adbly helps a lot too.  Even so, I've not used any kind of cheat sheet for emacs (s\u00adince I nev\u00ader re\u00adal\u00adly found any that were any good), and yet I feel like I've mem\u00ado\u00adrized more key com\u00admands now than I ev\u00ader did with vim, for which I did use a  cheat sheet.    \n So I re\u00adal\u00adly don't see my\u00adself go\u00ading back to vim at this point. \n I'm ac\u00adtu\u00adal\u00adly sur\u00adprised.  Vir\u00adtu\u00adal\u00adly ev\u00adery\u00adone I know who us\u00ades a com\u00admand line ed\u00adi\u00adtor us\u00ades vim.  It's def\u00adi\u00adnite\u00adly the more pop\u00adu\u00adlar of the two.  But hav\u00ading tried both, I can on\u00adly spec\u00adu\u00adlate as to why.  Vim has a much high\u00ader learn\u00ading curve than emac\u00ads.  Ev\u00adery\u00adbody grows up learn\u00ading how to write text in ed\u00adi\u00adtors like Mi\u00adcro\u00adsoft Word, TextE\u00add\u00adit, Notepad, etc., that all work fun\u00adda\u00admen\u00adtal\u00adly like emac\u00ads: if you type tex\u00adt, it en\u00adters the tex\u00adt.  If you want to do ad\u00advanced edit\u00ading with the key\u00adboard, you hold down some meta keys and type chord\u00aded key\u00adboard short\u00adcut\u00ads.  The vim modal edit\u00ading method\u00adol\u00ado\u00adgy is so dif\u00adfer\u00adent from this, that it sur\u00adpris\u00ades me that so many peo\u00adple go to the trou\u00adble of learn\u00ading it (I mean, to the point that they are more ef\u00adfi\u00adcient with it).  I can see the ben\u00ade\u00adfit over GUI ed\u00adi\u00adtors, which have noth\u00ading on ei\u00adther vim or emacs with re\u00adgards to cus\u00adtomiza\u00adtion, or just the plain edit\u00ading pow\u00ader that is re\u00adal\u00adly nec\u00ades\u00adsary for cod\u00ading. My guess\u00ades why peo\u00adple use vim: \n <li>They are shown vim first, so just use it.\n\n\n\n\n\n<li>They are turned off by the massiveness of emacs (it seems contradictory to me, since the whole point of using a command line editor is to get more power, but I could see it).\n\n\n\n\n\n<li>They are turned off by emacs lisp.\n\n\n\n\n\n<li>Some combination of those.</li>\n\n\n\nMaybe the vim users out there could com\u00adment why they use vim.  Am I miss\u00ading some\u00adthing?  Or are your heads just wired dif\u00adfer\u00adent\u00adly from mine? And if you use emacs (or any\u00adthing else), I'd love to hear from you too? \n At any rate, I rec\u00adom\u00admend that any\u00adone who wants to give com\u00admand line ed\u00adi\u00adtors a chance do what I did: learn both vim and emac\u00ads.  My blog posts should be enough to give you some good ad\u00advice.  I went cold-\u00adturkey, and I rec\u00adom\u00admend that you do too, but on\u00adly do it if you won't have any im\u00adpor\u00adtant edit\u00ading to do for a few week\u00ads, as your edit\u00ading rate will slow down a lot as you are learn\u00ading for both ed\u00adi\u00adtors.  And even though I think I am go\u00ading to stick with emac\u00ads, learn\u00ading vim was still valu\u00adable.  Un\u00adlike emac\u00ads, vi is part of the POSIX stan\u00addard, so it's in\u00adclud\u00aded in pret\u00adty much ev\u00adery UNIX dis\u00adtri\u00adbu\u00adtion.  I'll be glad when I find my\u00adself on a min\u00adi\u00admal com\u00admand line and know how to use a de\u00adcent text ed\u00adi\u00adtor.  And any\u00adway, you can't re\u00adal\u00adly know which one will be your way un\u00adtil you try them both.  I re\u00adal\u00adly thought I would end up us\u00ading vim, as it was so pop\u00adu\u00adlar among all the peo\u00adple I know who use com\u00admand line ed\u00adi\u00adtors. But I guess there is on\u00adly  One True Ed\u00adi\u00adtor. \n ED\u00adIT:  I found out how to make emacs re\u00adal\u00adly fast.  The key is to run one process of emacs in dae\u00admon mod\u00ade, and have the rest con\u00adnect to that.  Then you on\u00adly have to wait for the start\u00adup once (per com\u00adput\u00ader ses\u00adsion).  To do it, just set your  ED\u00adI\u00adTOR  to  'emac\u00adsclient -a \"\" -n\u00adw'  (and you might al\u00adso want to alias  emacs  to that as well).  What this does is con\u00adnect to the emacs dae\u00admon.  The  -a \"\"  starts one if it is\u00adn't al\u00adready start\u00aded (y\u00adou can al\u00adso do this your\u00adself with  emacs --\u00addae\u00admon.  If you on\u00adly want to use the dae\u00admon ver\u00adsion if you've specif\u00adi\u00adcal\u00adly start\u00aded it, re\u00adplace  \"\"  with  emacs.  This will con\u00adnect to the dae\u00admon if it's run\u00adning, and oth\u00ader\u00adwise just start a new emacs process.    \n The  -nw  keeps it from run\u00adning in win\u00addow mod\u00ade.  Re\u00admove this if you use the GUI ver\u00adsion of emac\u00ads.  This is nec\u00ades\u00adsary to make it work cor\u00adrect\u00adly with mul\u00adti\u00adple tab\u00ads.  This is so fast that you should nev\u00ader re\u00adal\u00adly even need to use  C-z  to quick\u00adly ex\u00adit emac\u00ads.   C-x C-c  is just fine, be\u00adcause re\u00adopen\u00ading will be in\u00adstan\u00adta\u00adneous.  I like this be\u00adcause I was start\u00ading to ac\u00adcu\u00admu\u00adlate back\u00adground emacs pro\u00adcess\u00ades that I for\u00adgot about. \n This prob\u00ada\u00adbly re\u00adquires a fair\u00adly new ver\u00adsion of emac\u00ads, pos\u00adsi\u00adbly even the de\u00advel\u00adop\u00adment ver\u00adsion.", 
      "loc": "/posts/2012/01/13/vim-vs-emacs-part-3/"
    }, 
    {
      "title": "Vim vs. Emacs (Part 2)", 
      "tags": "", 
      "text": "As I not\u00aded in  part 1, I have de\u00adcid\u00aded to switch to a com\u00admand line text ed\u00adi\u00adtor.  I de\u00adcid\u00aded that, to be fair, I would try both vim and emac\u00ads.  And to force my\u00adself to learn them, I de\u00adcid\u00aded to use them cold-\u00adturkey.    \n Since I'm go\u00ading cold-\u00adturkey, I am do\u00ading this over my break from class\u00ades, so that I can weed out any dif\u00adfi\u00adcul\u00adties dur\u00ading a pe\u00adri\u00adod when I can live with slow text edit\u00ading if nec\u00ades\u00adsary.  This is a one month break.  I have reached (rough\u00adly) the half way point.  For the first half, I used noth\u00ading but vim to ed\u00adit tex\u00adt.  Now, I will use noth\u00ading but emac\u00ads. \n Now that I've stopped us\u00ading vim (for now any\u00adway), my view of it is\u00adn't much dif\u00adfer\u00adent from what I wrote in the first part.  A lot of things there were ad\u00addressed by com\u00admenters (or rather com\u00admenter).  I still feel that it's not an a method of text edit\u00ading that fits my head.  My en\u00adtire life, I've used text ed\u00adi\u00adtors where typ\u00ading in\u00adserts tex\u00adt, and var\u00adi\u00adous con\u00adtrol char\u00adac\u00adters do things like move around faster.    \n En\u00adter emac\u00ads. It does ex\u00adact\u00adly this.  Al\u00adso a ton more. \n I've on\u00adly been us\u00ading emacs for two days, but here are my im\u00adpres\u00adsions so far: \n </p><li><strong>The tutorial is better.</strong>  When you start emacs, it tells you how to start the tutorial.  Just type <code>C-h t</code> (if you don't already know, in emacs <code>C-</code> means <code>CTRL-</code> and <code>M-</code> means <code>ALT-</code>).  Like I said last time, the very first thing you learn is how to scroll by more than one line at a time.  That turns out to be a very useful thing to do.  Also, the emacs tutorial did a better job of explaining how to use multiple files at once in emacs, which is something that I still don't really know how to do very well in vim.\n\n\n\nI have to give the vim tu\u00adto\u00adri\u00adal some cred\u00adit for one thing, though.  It has bet\u00adter in\u00adter\u00adac\u00adtive ex\u00adam\u00adples.  For ex\u00adam\u00adple, in the vim tu\u00adto\u00adri\u00adal, you have stuff like   \n [code]\n  1. Move the cur\u00adsor to the sec\u00adond line in the phrase be\u00adlow.\n  2. Type  dd  to delete the line.\n  3. Now move to the fourth line.\n  4. Type   2dd   to delete two lines. \n --->  1)  Ros\u00ades are red, \n --->  2)  Mud is fun, \n --->  3)  Vi\u00ado\u00adlets are blue, \n --->  4)  I have a car, \n --->  5)  Clocks tell time, \n --->  6)  Sug\u00adar is sweet \n --->  7)  And so are you. \n [/\u00adcode] \n where\u00adas in the emacs tu\u00adto\u00adri\u00adal, you just have \n [code] \n >> Kill a line, move around, kill an\u00adoth\u00ader line.\n   Then do C-y to get back the sec\u00adond killed line.\n   Then do M-y and it will be re\u00adplaced by the first killed line.\n   Do more M-y's and see what you get.  Keep do\u00ading them un\u00adtil\n   the sec\u00adond kill line comes back, and then a few more.\n   If you like, you can try giv\u00ading M-y pos\u00adi\u00adtive and neg\u00ada\u00adtive\n   ar\u00adgu\u00adments.\n[/\u00adcode] \n which is a lit\u00adtle more vague.  So I have to give vim cred\u00adit for that.    \n <li><strong>Everything's a buffer.</strong> This line from the emacs tutorial really stuck with me: \"ANY text you see in an Emacs window is always part of some buffer.\"  Emacs has really a awesome editing model, even simple things like <code>M-f</code> and <code>M-b</code> to move around words at a time, or <code>M-DEL</code> to delete whole words make things <strong>way</strong> faster.  Vim of course has all of these too, albiet in a different way, but they aren't everywhere.  In emacs, everything is a buffer, which just means that everything supports all the standard emacs commands.  So if you type <code>M-x</code> (roughly the equivalent of vim's <code>:</code>) and start typing a command, you can move around and edit your command with emacs commands.  One of the things that bothered me about vim was that when I was typing something with <code>:</code>, I couldn't use vim's text moving/modifying commands to manipulate the text.  Typing ESC just canceled the command.\n\n\n\nEx\u00adcep\u00adtion\u00ads: There are at least two ex\u00adcep\u00adtions I've found to this rule.  First, if you do a search with  C-s  or  C-r, no con\u00adtrol com\u00admands work.  If you type a search string, and then type  M-DEL  to try to delete the last word in your search string, you will in\u00adstead delete the word where the cur\u00adsor is!  The so\u00adlu\u00adtion I think is to use some\u00adthing like  M-x re-builder  in\u00adstead.  This was a lit\u00adtle slow in my test\u00ads. \n Sec\u00adond, the emacs man\u00adu\u00adal is pre\u00adsent\u00aded in the  in\u00adfo  pro\u00adgram, which us\u00ades com\u00adplete\u00adly dif\u00adfer\u00adent key com\u00admands from ev\u00adery oth\u00ader pro\u00adgram.  This irked me quite a bit, be\u00adcause as soon as I fin\u00adished the emacs tu\u00adto\u00adri\u00adal, it point\u00aded me to the man\u00adu\u00adal, which was in  in\u00adfo.  Then, the first thing in  in\u00adfo  is a tu\u00adto\u00adri\u00adal on how to use  in\u00adfo!  I opt\u00aded to skip this.  If I need any in\u00adfor\u00adma\u00adtion on emac\u00ads, I'll just do a Google search any\u00adway, so I found this to be a waste of time. \n <li><strong>It's a little slower.</strong> I do notice a speed difference between emacs and vim.  vim is much more lightweight, and it shows.  Starting up emacs takes a second or two.  Also, since a lot of the features are more interactive, they suffer from a speed delay.  It's not nearly slow enough to be a serious issue, though, and it's still way faster than the GUI program I was using before (start up time).\n\n\n\nThe emacs tu\u00adto\u00adri\u00adal sug\u00adgests us\u00ading  C-z  when\u00adev\u00ader you want to on\u00adly tem\u00adpo\u00adrar\u00adily close emac\u00ads.  This seems like a good idea, and has worked pret\u00adty well for me so far (though I still usu\u00adal\u00adly close the whole thing with  C-x C-c  out of habit). \n On a re\u00adlat\u00aded note, I no\u00adticed that do\u00ading type\u00ad-a\u00adhead while wait\u00ading for emacs to start up did\u00adn't al\u00adways work, where\u00adas it al\u00adways worked in vim (I do this, e.g., when wait\u00ading for the ed\u00adi\u00adtor to start up when writ\u00ading com\u00admit mes\u00adsages). \n <li><strong>It's way more user-friendly.</strong> Note that this is of course a relative term.  I mean more user-friendly than vim, and pretty user-friendly for a command line program.  Obviously, the most user-friendly text editors are the GUI ones used by the majority of the population (for that very reason).  Actually, both vim and emacs are user-unfriendly in that if you accidentally open them and don't know what they are or how to use them, you have no idea how to close them.  But even <code>less</code> (i.e., <code>man</code>) is technically like this.\n\n\n\nI'm not even re\u00adfer\u00adring to the dif\u00adfer\u00adent edit\u00ading \"mod\u00ades\" of the two ed\u00adi\u00adtors, though you could eas\u00adi\u00adly ar\u00adgue that emacs style edit\u00ading is more user-friend\u00adly than vim style edit\u00ading. What I mean here is that emacs in\u00adter\u00adac\u00adtion is nice. When you type  :  in vim, start typ\u00ading a com\u00admand, and type  TAB, it en\u00adters the first com\u00adple\u00adtion, re\u00adgard\u00adless if it's unique.  Press\u00ading  TAB  mul\u00adti\u00adple times give the rest.  In emac\u00ads, if you type  M-x  and start typ\u00ading a com\u00admand and type  TAB, it pops up a tem\u00adpo\u00adrary win\u00addow with the list of all com\u00adple\u00adtion\u00ads.  It even col\u00adors the next char\u00adac\u00adter, so you can eas\u00adi\u00adly see what to type next to get what you wan\u00adt.  As soon as you en\u00adter the com\u00admand, the win\u00addow dis\u00adap\u00adpears. (yes, I know about  CTR\u00adL-D  in vim, but to me tab com\u00adple\u00adtion should  al\u00adways  work like it does in bash: com\u00adplete char\u00adac\u00adters if and on\u00adly if they are unique in the list of com\u00adple\u00adtion\u00ads) \n By the way, when I said ev\u00adery\u00adthing's a buffer, I mean ev\u00adery\u00adthing.  If you wan\u00adt, you can ex\u00adit the  M-x  en\u00adtry (type  C-g), type  C-x C-b  to show the list of buffer\u00ads,  C-x o  to switch to it, scroll down to \"Com\u00adple\u00adtion\u00ads\", press En\u00adter, and ac\u00adtu\u00adal\u00adly get in the com\u00adple\u00adtion list, as a buf\u00adfer (there's prob\u00ada\u00adbly a less com\u00adpli\u00adcat\u00aded way to get to it, by the way).  You can then do what\u00adev\u00ader your heart fan\u00adcies with it (save it to a file, copy it, what\u00adev\u00ader). \n <li><strong>Customization is harder.</strong> This was expected, since I already knew that emacs used lisp.  vim uses a language that is really easy to understand.  I was able to modify all the vim plugins I installed very easily.  If you want to change a setting globally in vim, just Google it and add one line to your .vimrc.   In emacs, everything is in Emacs Lisp.  I suppose prior experience with Lisp would probably help here.\n\n\n\nIn the vim tu\u00adto\u00adri\u00adal, near the end, it told how to cre\u00adate a .vim\u00adrc file, and even gave a very use\u00adful sam\u00adple one as a starter.  In emac\u00ads, it took me a while to fig\u00adure out how to do the equiv\u00ada\u00adlent (it took me a few Google search\u00ades just to fig\u00adure out that the name of the con\u00adfig\u00adu\u00adra\u00adtion file in emacs is .emac\u00ads).    \n Ac\u00adtu\u00adal\u00adly, the emacs equiv\u00ada\u00adlent is way bet\u00adter than in vim, but it is\u00adn't re\u00adal\u00adly men\u00adtioned any\u00adwhere. It took me prob\u00ada\u00adbly a dozen Google search\u00ades be\u00adfore I learned about it (grant\u00aded, I was look\u00ading for things in the same way I did for vim, lines to add to .emac\u00ads). What you have to do is type  M-x con\u00adfig\u00adure.  This opens what is ba\u00adsi\u00adcal\u00adly a huge pref\u00ader\u00adences di\u00ada\u00adlog for emac\u00ads.  You can then go through and set just about ev\u00adery set\u00adtable emacs set\u00adting from there.  The in\u00adter\u00adface is very nice, as it's in\u00adter\u00adac\u00adtive and tells you all about each set\u00adting.  And you nev\u00ader have to touch Lisp.  I'm still go\u00ading through it, so I can't com\u00adment more on it yet.  But I rec\u00adom\u00admend do\u00ading  M-x con\u00adfig\u00adure  as soon as you have fin\u00adished the tu\u00adto\u00adri\u00adal and have got\u00adten used to edit\u00ading with emac\u00ads, as you are in\u00advari\u00adably go\u00ading to want to change some things (though I should note that emacs gen\u00ader\u00adal\u00adly has nicer de\u00adfaults than vim). \n <li><strong>Better text editing methodology?</strong> Like I've already mentioned a bunch of times, the emacs editing model seems to fit my head better than the vim model.  In emacs, you type text, and it inserts the text.  If you want to do some advanced modification or move around, you type a control sequence.  In vim, you type characters, and it does modifications or moves around.  If you want to type text, you type <code>i</code> (or one of a few other characters) and type it.  Then, if you want to move around or modify the text, you have to press <code>ESC</code>.  This so-called \"modular editing\" doesn't seem to work for me.  For one thing, I like to rapidly switch back and forth between these two \"modes\" (editing and inserting) when I write things.  I type too fast and write something wrong, and have to delete some stuff. The <code>M-DEL</code> emacs command is probably my most used (this also works in Mac OS X text dialogs, so I'm used to it already).  In vim, there is <code>CTRL-w</code> and a few others, but if I want to do something more advanced, like rearranging a sentence, then half of my key presses would be <code>ESC</code> or <code>i</code>, i.e., just moving between the modes.  In emacs, I can always have my pinky by Control and Alt (especially as soon as I remap CAPS-LOCK to Control).\n\n\n\nAl\u00adso, it re\u00adal\u00adly irks me how in vim, if you are at the end of a line and press  l  (or right-ar\u00adrow), in\u00adstead of mov\u00ading to the be\u00adgin\u00adning of the next line, it beep\u00ads!  In emac\u00ads, if you are at the end of a the line and type  C-f, it moves to the be\u00adgin\u00adning of the next line (ac\u00adtu\u00adal\u00adly, it tech\u00adni\u00adcal\u00adly moves just be\u00adyond the line, in case you want to ap\u00adpend, which is an\u00adoth\u00ader an\u00adnoy\u00ading thing about vim: you have to use  A, not  i,  to add text to the end of a line).   \n Well, that's it for now.  I will hold off on the ques\u00adtions un\u00adtil af\u00adter I go through all the cus\u00adtomiza\u00adtion\u00ads, as it seems that, un\u00adlike vim, emacs has many things al\u00adready built-in (but we al\u00adready knew that, did\u00adn't we :).  So I have just one ques\u00adtion for read\u00ader\u00ads: does any\u00adone know of a re\u00adal\u00adly good emacs cheat\u00adsheet?  The  one I used for vim  was re\u00adal\u00adly awe\u00adsome, but I haven't found any\u00adthing equal for emac\u00ads.  I find my\u00adself search\u00ading the tu\u00adto\u00adri\u00adal when\u00adev\u00ader I for\u00adget some\u00adthing, which is not very ef\u00adfi\u00adcien\u00adt, so I would ap\u00adpre\u00adci\u00adate some\u00adthing bet\u00adter. Oth\u00ader\u00adwise, I'll just find some\u00adthing de\u00adcent and print it out, as it would be bet\u00adter than noth\u00ading. \n And if any\u00adone cares, you can see what I've got for my .emacs file so far at  http\u00ads://github.\u00adcom/as\u00admeur\u00ader/\u00addot\u00adfiles/blob/\u00admas\u00adter/.emacs.", 
      "loc": "/posts/2012/01/03/vim-vs-emacs-part-2/"
    }, 
    {
      "title": "2011 in review", 
      "tags": "", 
      "text": "The Word\u00adPress.\u00adcom stats helper mon\u00adkeys pre\u00adpared a 2011 an\u00adnu\u00adal re\u00adport for this blog. \n     \n    Here's an ex\u00adcerp\u00adt: \n <blockquote>The concert hall at the Syndey Opera House holds 2,700 people.  This blog was viewed about <strong>11,000</strong> times in 2011.  If it were a concert at Sydney Opera House, it would take about 4 sold-out performances for that many people to see it.</blockquote>\n<p><a href=\"/2011/annual-report/\">Click here to see the complete report.</a></p>", 
      "loc": "/posts/2012/01/01/2011-in-review/"
    }, 
    {
      "title": "Vim vs. Emacs (Part 1)", 
      "tags": "", 
      "text": "So about a month or so ago, I de\u00adcid\u00aded that I need\u00aded to start learn\u00ading a com\u00admand line text ed\u00adi\u00adtor.  XCode, the ed\u00adi\u00adtor I had been us\u00ading for Python files, did\u00adn't work very well with the new ver\u00adsion (in par\u00adtic\u00adu\u00adlar, the  es\u00adsen\u00adtial plug\u00adin  that I'd been us\u00ading to clear trail\u00ading white\u00adspace on save does\u00adn't yet work in XCode 4).  I'd been us\u00ading Tex\u00adtWran\u00adgler for oth\u00ader things, and start\u00aded to switch to it for Python edit\u00ading too.  As far as free GUI text ed\u00adi\u00adtors on the Mac go, Tex\u00adtWran\u00adgler is the best.    \n But I'd seen some of the nice fea\u00adtures that vim has, like au\u00adto\u00admat\u00adi\u00adcal\u00adly keep\u00ading all lines un\u00adder 80 char\u00adac\u00adter\u00ads, on a friend's com\u00adput\u00ader, and I de\u00adcid\u00aded that I should try it. \n Now, I had had a lit\u00adtle pri\u00ador ex\u00adpe\u00adri\u00adence with both vim and emac\u00ads, but all that I re\u00admem\u00adbered was for vim that  i  in\u00adserts and  ZZ  quits (for when I ac\u00adci\u00adden\u00adtal\u00adly open it) and for emac\u00ads, that  M-X doc\u00adtor  starts the psy\u00adchi\u00ada\u00adtrist.   \n So I've de\u00adcid\u00aded to try them out, do\u00ading it cold tur\u00adkey.  To make sure that I choose the bet\u00adter one, I've de\u00adcid\u00aded to try both.  So, start\u00ading about a week ago, I've been us\u00ading noth\u00ading but vim for all my text edit\u00ading.  Start\u00ading in Jan\u00aduary, I will try us\u00ading emac\u00ads, and af\u00adter two week\u00ads, I will see what I like bet\u00adter. \n My opin\u00adions so far on vim: \n </p><li>The tutorials suck.  The best tutorial is <code>vimtutor</code> (type that in the command line), which I think comes with vim.  It's not bad, but it leaves out a few things that I would consider to be essential to a tutorial, for example, how to scroll (answer: use CTRL-D and CTRL-U).  I started the emacs tutorial a while back, and while I never finished it, from what I remember, it was much better (and I also remember that the first thing it talked about was how to scroll by more than one line at a time). It also left out the <code>.</code> command, which I think is rather useful.  I did print out <a href=\"http://www.viemu.com/a_vi_vim_graphical_cheat_sheet_tutorial.html\">this cheatsheet</a> and have it sitting next to me on my desk.  That has helped a lot.  I hope I can find something similar for emacs when I get to it.</li>\n<li>vim is too line oriented.  vi started out as an extension to ed, the line editor, so this is not surprising.  But I still can't understand why pressing <code>l</code> at the end of a line can't bring me to the beginning of the next line.  Maybe I'm just still doing it wrong (supposedly, you should rarely use <code>h</code> and <code>l</code> over more efficient moving commands).  </li>\n<li>Somewhat related to the last point, vim really likes to ring the terminal bell a lot. To quote <a href=\"http://en.wikipedia.org/wiki/Editor_war\">Wikipedia</a>, \"vi has two modes \u2013 'beep repeatedly' and 'break everything'\"</li>\n<li>I managed to customize it to the point of usability (there are still several things I need to go in and figure out how to fix).  See https://github.com/asmeurer/dotfiles for my .vimrc and .vim/ files.  I found a decent Python syntax file, but it's actually not that great.  I modified it to color single quoted strings different from double quoted strings (a feature I missed from Xcode). I still need to make a better color scheme (preferably the same as Xcode's midnight), but this is enough work that I've put it off.</li>\n<li>Pressing ESC all the time is really annoying.  Sometimes, I just arrow over, even though I know you're not \"supposed to\", just because my fingers don't want to reach over and press ESC.  I'm also really used to using control sequences to move around while typing, which of course doesn't work in vim.  In fact, so far, I'm suspecting that I'll like emacs better.  But I've vowed to give both a fair chance.  But so far, my impression is that vim is a great for text <em>editing</em>, but not so hot for text <em>writing</em> (unless you always write text perfectly, so that you never need to leave insert mode until you are done typing).  Just the simple act of deleting a mistyped word (yes, word, that happens a lot when you are decently fast touch typist) takes several keystrokes, when it should in my opinion only take one (two if you count the meta-key).</li>\n<li>The customizability is really nice.  So far, everything that I've thought of to change has been changeable.  Also, language is easy enough to understand that I was able to modify the Python syntax file without any difficulty.  </li>\n<li>I like how it syntax highlights virtually everything I throw at it. </li>\n\n\n\nIf there are any vim ex\u00adperts out there read\u00ading this, I have some ques\u00adtion\u00ads: \n <li>Is there an easy way to get a list of and jump to a function/class definition in a Python file?  In Xcode and TextWrangler, there was a nice popup at the top of the window that I could access these from.  In vim, so far the best I've found is searching for it, which isn't very efficient.</li>\n\n<li>I got TAB to indent 4 spaces in Python, but for some reason, when I create a new line after a <code>:</code>, it puts 8 extra spaces. I wouldn't be surprised if this is the result of some mismatch/error in <a href=\"https://github.com/asmeurer/dotfiles\">my .vimrc or .vim/ files</a>, but I don't know how to fix it</li>\n\n<li>Any useful tricks to share?  Especially for editing Python files.</li>\n<li>How long did it take you to become reasonably efficient with vim?</li>\n\n\n\nED\u00adIT: I thought of some more ques\u00adtion\u00ads: \n     Is there a way to make vim con\u00adsid\u00ader camel\u00adCase to be word bound\u00adaries? \n Fi\u00adnal\u00adly, if any\u00adone else is think\u00ading of start\u00ading vim, I have some use\u00adful things I've al\u00adready found in my .vim\u00adr\u00adc. So you might take a look at that, and add the ones that you like to your .vim\u00adr\u00adc.  Fi\u00adnal\u00adly, if you are on Mac OS X, you should use  iTer\u00adm2.  Ac\u00adtu\u00adal\u00adly, you should use this re\u00adgard\u00adless of what text ed\u00adi\u00adtor you use.  It's a very good Ter\u00admi\u00adnal.app re\u00adplace\u00adment that has vir\u00adtu\u00adal\u00adly all the fea\u00adtures (with a cou\u00adple of ex\u00adcep\u00adtion\u00ads) as Ter\u00admi\u00adnal.ap\u00adp, and a ton of ex\u00adtra ones.  The one I want to men\u00adtion here is mouse re\u00adport\u00ading sup\u00adport, so you can use your mouse to do things in vim.  This is very use\u00adful, as some\u00adtimes, e.g., when se\u00adlect\u00ading tex\u00adt, us\u00ading the mouse is just more ef\u00adfi\u00adcien\u00adt.  Al\u00adso, if you get frus\u00adtrat\u00aded try\u00ading to re\u00admem\u00adber the com\u00admands that will move around you faster than  h,  j,  k, and  l, you can just click on where you want to go. \n :wq", 
      "loc": "/posts/2011/12/20/vim-vs-emacs-part-1/"
    }, 
    {
      "title": "sqrt(x) now prints as \"sqrt(x)\"", 
      "tags": "mathjax", 
      "text": "Just a few mo\u00adments ago,  a branch  was pushed in that fixed one of my big\u00adgest griev\u00adances in SymPy, if not the big\u00adgest.  Pre\u00advi\u00adous\u00adly we had this be\u00adhav\u00adior: \n [code lan\u00adguage=\"py\"] \n In [1]: sqrt(x) \n Out\u00ad[1]: x**(1/2) \n In [2]: solve(x**2 - 2, x) \n Out\u00ad[2]: [-2(1/2), 2(1/2)] \n [/\u00adcode] \n Now sup\u00adpose you took the out\u00adput of those ex\u00adpres\u00adsions and past\u00aded them in\u00adto isympy: \n [code lan\u00adguage=\"py\"] \n In [3]: x**(1/2) \n Out\u00ad[3]: x**0.5 \n In [4]: [-2(1/2), 2(1/2)] \n Out\u00ad[4]: [-1.41421356237, 1.41421356237] \n [/\u00adcode] \n That's with  fu\u00adture.di\u00advi\u00adsion.  Here's what would hap\u00adpen with old di\u00advi\u00adsion: \n [code lan\u00adguage=\"py\"] \n In [2]: x**(1/2) \n Out\u00ad[2]: 1 \n In [3]: [-2(1/2), 2(1/2)] \n Out\u00ad[3]: [-1, 1] \n [/\u00adcode] \n This is be\u00adcause with old di\u00advi\u00adsion,  1/2  eval\u00adu\u00adates to  0. \n The prob\u00adlem is that Python eval\u00adu\u00adates  1/2  to  0.5  (or  0) be\u00adfore SymPy has a change to con\u00advert it to a Ra\u00adtio\u00adnal.  There were sev\u00ader\u00adal ways that peo\u00adple got around this.  If you copy an ex\u00adpres\u00adsion with num\u00adber di\u00advi\u00adsion in it and want to paste it in\u00adto a SymPy ses\u00adsion, the eas\u00adi\u00adest way to do this was to pass it as a string to  sympi\u00adfy(): \n [code lan\u00adguage=\"py\"] \n In [1]: sympi\u00adfy(\"x**(1/2)\") \n Out\u00ad[1]: x**(1/2) \n In [2]: sympi\u00adfy(\"[-2(1/2), 2(1/2)]\") \n Out\u00ad[2]: [-2(1/2), 2(1/2)] \n [/\u00adcode] \n If that was too much typ\u00ading for you, you could use the  S()  short\u00adcut to  sympi\u00adfy() \n [code lan\u00adguage=\"py\"] \n In [3]: S(\"x**(1/2)\") \n Out\u00ad[3]: x**(1/2) \n In [4]: S(\"[-2(1/2), 2(1/2)]\") \n Out\u00ad[4]: [-2(1/2), 2(1/2)] \n [/\u00adcode] \n This so\u00adlu\u00adtion is fine if you want to paste an ex\u00adpres\u00adsion in\u00adto a SymPy ses\u00adsion, but it's not a very clean one if you want to paste code in\u00adto a scrip\u00adt. For that, you need to mod\u00adi\u00adfy the code so that it no longer con\u00adtains Python in\u00adt/Python in\u00adt.  The eas\u00adi\u00adest way to do this is to sympi\u00adfy one of the ints.  So you would do some\u00adthing like \n [code lan\u00adguage=\"py\"] \n In [5]: x**(S(1)/2) \n Out\u00ad[5]: x**(1/2) \n In [6]: [-2(S(1)/2), 2(S(1)/2)] \n Out\u00ad[6]: [-2(1/2), 2(1/2)] \n [/\u00adcode] \n This was\u00adn't ter\u00adri\u00adbly read\u00adable, though.  The  best  way to fix the prob\u00adlem when you had a pow\u00ader of one half was to use  sqrt(), which is a short\u00adcut to  Pow(\u2026, Ra\u00adtio\u00adnal(1, 2)).    \n Well, this last item should make you think.  If  sqrt(x)  is more read\u00adable than  x(S(1)/2)  or even  x(1/2), why not print it like that in the first place.  Well, I thought so, so I changed the string print\u00ader, and now this is the way that SymPy work\u00ads.  So 90% of the time, you can just paste the re\u00adsult of  str()  or  print, and it will just work, be\u00adcause there won't be any  **(1/2), which was by far the most com\u00admon prob\u00adlem of \"Python eval\u00adu\u00adat\u00ading the ex\u00adpres\u00adsion to some\u00adthing be\u00adfore we can.\"  In the git mas\u00adter, SymPy now be\u00adhaves like \n [code lan\u00adguage=\"py\"] \n In [1]: sqrt(x) \n Out\u00ad[1]: sqrt(x) \n In [2]: solve(x**2 - 2, x) \n Out\u00ad[2]: [-sqrt(2), sqrt(2)] \n [/\u00adcode] \n You can ob\u00advi\u00adous\u00adly just copy and paste these re\u00adsult\u00ads, and you get the ex\u00adact same thing back.  Not on\u00adly does this make ex\u00adpres\u00adsions more copy\u00ad-and-\u00adpastable, but the out\u00adput is  much  nicer in terms of read\u00adabil\u00adi\u00adty.  Here are some be\u00adfore and af\u00adters that come from ac\u00adtu\u00adal SymPy doctests that I had to change af\u00adter fix\u00ading the print\u00ader: \n [code lan\u00adguage=\"py\"] \n Be\u00adfore: \n >>> e = ((2+2sqrt(2))x+(2+sqrt(8))*y)/(2+sqrt(2)) \n >>> rad\u00adsim\u00adp(e) \n 2(1/2)*x + 2(1/2)*y \n Af\u00adter: \n >>> rad\u00adsim\u00adp(e) \n sqrt(2)x + sqrt(2)y \n [/\u00adcode] \n [code lan\u00adguage=\"py\"] \n Be\u00adfore: \n >>> b = besselj(n, z) \n >>> b.rewrite(jn) \n 2(1/2)*z(1/2)jn(n - 1/2, z)/pi*(1/2) \n Af\u00adter: \n >>> b.rewrite(jn) \n sqrt(2)sqrt(z)jn(n - 1/2, z)/sqrt(pi) \n [/\u00adcode] \n [code lan\u00adguage=\"py\"] \n Be\u00adfore: \n >>> x = sympi\u00adfy('-1/(-3/2+(1/2)sqrt(5))sqrt(3/2-1/2*sqrt(5))') \n >>> x \n (3/2 - 5(1/2)/2)(-1/2) \n Af\u00adter \n >>> x \n 1/sqrt(3/2 - sqrt(5)/2) \n [/\u00adcode] \n And not on\u00adly is  sqrt(x)  eas\u00adi\u00ader to read than  x**(1/2)  but it's few\u00ader char\u00adac\u00adter\u00ads. \n In the course of chang\u00ading this, I went ahead and did some greps of the repos\u00adi\u00adto\u00adry to get rid of all  (S(1)/2),  Ra\u00adtio\u00adnal(1, 2)  and sim\u00adi\u00adlar through\u00adout the code base (not just in the out\u00adput of doctests where the change had to be made), re\u00adplac\u00ading them with just  sqrt.  Big thanks to Chris Smith for help\u00ading me catch all in\u00adstances of this.  Now the code should be a lit\u00adtle eas\u00adi\u00ader to read and main\u00adtain. \n Fu\u00adture Work \n This is a big change, and I be\u00adlieve it will fix the copy\u00ad-\u00adpaste prob\u00adlem for 90% of ex\u00adpres\u00adsion\u00ads. But it does not solve it com\u00adplete\u00adly.  It is still pos\u00adsi\u00adble to get in\u00adt/int in the string form of an ex\u00adpres\u00adsion.  On\u00adly pow\u00aders of 1/2 and -1/2 are con\u00advert\u00aded to sqrt, so any oth\u00ader ra\u00adtio\u00adnal pow\u00ader will still print as a/b, like \n [code lan\u00adguage=\"py\"] \n In [1]: x**Ra\u00adtional(3, 2) \n Out\u00ad[1]: x**(3/2) \n [/\u00adcode] \n Al\u00adso, as you may have no\u00adticed in the last ex\u00adam\u00adple above, a ra\u00adtio\u00adnal num\u00adber that sits by it\u00adself will still be print\u00aded as in\u00adt/in\u00adt, like \n [code lan\u00adguage=\"py\"] \n In [2]: (1 + x)/2 \n Out\u00ad[2]: x/2 + 1/2 \n [/\u00adcode] \n There\u00adfore, I'm leav\u00ading the  is\u00adsue for this  open to dis\u00adcuss po\u00adten\u00adtial fu\u00adture fix\u00ades to the string print\u00ader.  One idea is to cre\u00adate a  root  func\u00adtion that is a short\u00adcut to  root(x, a) == x**(1/a). This would work for ra\u00adtio\u00adnal pow\u00aders where the nu\u00admer\u00ada\u00adtor is 1.  For oth\u00ader ra\u00adtio\u00adnal pow\u00ader\u00ads, we could then den\u00adest these with an in\u00adte\u00adger pow\u00ader.  It's im\u00adpor\u00adtant to do this in the right or\u00adder, though, as they are not equiv\u00ada\u00adlen\u00adt.  You can see that SymPy au\u00adto-sim\u00adpli\u00adfies it when it is math\u00ade\u00admat\u00adi\u00adcal\u00adly cor\u00adrect in all cas\u00ades, and not when it is not: \n [code lan\u00adguage=\"py\"] \n In [3]: sqrt(x**3) \n Out\u00ad[3]: sqrt(x**3) \n In [4]: sqrt(x)**3 \n Out\u00ad[4]: x**(3/2) \n [/\u00adcode] \n Thus $la\u00adtex \\left\u00ad(\\sqrt{x}\\right)3 = x{\\frac{3}{2}}$ but $la\u00adtex \\sqrt{x3} \\neq x{\\frac{3}{2}}$ (to see this, re\u00adplace $la\u00adtex x$ with -1). \n So the idea would be to print  Pow(\u00adex\u00adpr, Ra\u00adtio\u00adnal(a, b))  as  root(\u00adex\u00adpr, b)**a.    \n The mer\u00adits of this are de\u00adbat\u00adable, but any\u00adway I think we should have this  root()  func\u00adtion in any case (see  is\u00adsue 2643). \n An\u00adoth\u00ader idea, which is prob\u00ada\u00adbly not a good one, is to al\u00adways print  in\u00adt/int  as  S(in\u00adt)/int.  So we would get \n [code lan\u00adguage=\"py\"] \n >>> Ra\u00adtio\u00adnal(1, 2) \n S(1)/2 \n >>> x**Ra\u00adtional(4, 5) \n x**(S(4)/5) \n [/\u00adcode] \n This is prob\u00ada\u00adbly a bad idea be\u00adcause even though ex\u00adpres\u00adsions would al\u00adways be copy\u00ad-\u00adpastable, they would be slight\u00adly less read\u00adable.    \n By the way, in case you did\u00adn't catch it, all of these changes on\u00adly af\u00adfect the string print\u00ader.  The pret\u00adty print\u00ader re\u00admained un\u00adaf\u00adfect\u00aded, and would un\u00adder any ad\u00addi\u00adtion\u00adal changes, as it is\u00adn't copy\u00ad-\u00adpastable any\u00adway, and al\u00adready does a su\u00adperb job of print\u00ading root\u00ads.", 
      "loc": "/posts/2011/08/18/sqrtx-now-prints-as-sqrtx/"
    }, 
    {
      "title": "Hacking PuDB: Now an even better Python debugger", 
      "tags": "", 
      "text": "Read\u00aders of this blog may re\u00admem\u00adber last year when I  wrote  about this awe\u00adsome vis\u00adual con\u00adsole Python de\u00adbug\u00adger called  PuDB.  I sug\u00adgest you read that post if you haven't. \n At the end of that post, I not\u00aded that Ond\u0159ej and I had hacked it to make the col\u00adors more liv\u00adable.  Well, a cou\u00adple of weeks ago, GitHub us\u00ader  jtri\u00adley  sent me an email ask\u00ading me to back port my changes. \n A lot has changed since I wrote my blog post last year.  PuDB now has an of\u00adfi\u00adcial  mail\u00ading list  and an of\u00adfi\u00adcial  GitHub re\u00adpo. \n So I delet\u00aded my  GitHub clone  and re\u00adforked from the of\u00adfi\u00adcial ver\u00adsion.    \n A lot has al\u00adso changed in the of\u00adfi\u00adcial code.  An\u00addreas had added con\u00adfig sup\u00adport, in\u00adclud\u00ading a built-in prefs di\u00ada\u00adlog that lets you set a few set\u00adtings:  the abil\u00adi\u00adty to turn on or off line num\u00adbers and the abil\u00adi\u00adty to change themes. \n So I took the new code and added my theme as an of\u00adfi\u00adcial theme.  This was pret\u00adty straight for\u00adward to do. \n But then, I got a lit\u00adtle car\u00adried away.    \n I no\u00adticed that it was dif\u00adfi\u00adcult to choose a theme with the built-in prefs win\u00addow be\u00adcause you had to close and re\u00adopen the win\u00addow each time you made a change.  So I added code to make it au\u00adto-up\u00addate your changes as you made them. \n Then I went back and looked at my orig\u00adi\u00adnal blog post and looked at the things that I did\u00adn't like.  There were two things.  First, the de\u00adfault stringi\u00adfi\u00ader for vari\u00adables is  type, which is com\u00adplete\u00adly use\u00adless.  This is be\u00adcause  type  is very fast and sta\u00adble to com\u00adpute.  I had pre\u00advi\u00adous\u00adly hacked this to be  str, but now that there was an of\u00adfi\u00adcial con\u00adfig file with a prefs di\u00adalog, I fig\u00adured it should go there.   \n So I added sup\u00adport to change this set\u00adting.  But this was\u00adn't enough for me.  I al\u00adso added the abil\u00adi\u00adty to de\u00adfine your own cus\u00adtom stringi\u00adfi\u00ader.  You just cre\u00adate a Python file that de\u00adfines a func\u00adtion called  pud\u00adb_stringi\u00adfier(ob\u00adj), which con\u00adverts  obj  in\u00adto the de\u00adsired string rep\u00adre\u00adsen\u00adta\u00adtion.  I in\u00adclud\u00aded an  ex\u00adam\u00adple file  that gives a fan\u00adcy ex\u00adam\u00adple that us\u00ades sig\u00adnals to com\u00adpute the string val\u00adue, but times out af\u00adter one sec\u00adond and falls back to the type.  This al\u00adle\u00advi\u00adates one of the prob\u00adlems of us\u00ading  str, which is that it can be slow for ob\u00adjects with large string ex\u00adpres\u00adsion\u00ads, es\u00adpe\u00adcial\u00adly SymPy ob\u00adject\u00ads, where some\u00adtimes the print\u00ader can be slow. \n The sec\u00adond thing I did\u00adn't like was that al\u00adthough you can change the width of the right-\u00adhand side bar, you could not change the rel\u00ada\u00adtive heights of the vari\u00adables, stack, and break\u00adpoints box\u00ades.  I nev\u00ader use break\u00adpoints, and rarely use the stack, so I would pre\u00adfer to have those small\u00ader and the vari\u00adables larg\u00ader.  So I im\u00adple\u00adment\u00aded it so that the  [  and  ]  keys make the se\u00adlect\u00aded view small\u00ader or larg\u00ader.  This in\u00adfor\u00adma\u00adtion is all saved in the con\u00adfig file, so it's re\u00admem\u00adbered when you close and re\u00adopen PuD\u00adB. \n There was one oth\u00ader thing that I did\u00adn't like, which a change since my last blog post that re\u00adversed the or\u00adder of the stack vari\u00adables from what it was.  It used to be most re\u00adcent at the bot\u00adtom, but it was changed to most re\u00adcent at the top.  This per\u00adhaps makes more sense, but the but\u00adtons to move around the stack,  u  and  d, were still the same:  u  moves down the stack (i.e., less re\u00adcen\u00adt), and  d  moves up.  These keys were al\u00adready well es\u00adtab\u00adlished\u2014in\u00addeed, these are the same keys used in Python's built-in de\u00adbug\u00adger pdb\u2014\u00adso I added a set\u00adting to change the stack or\u00adder.  This was an easy change to make at this point, as I was al\u00adready well aquat\u00adint\u00aded with the set\u00adtings code, and on\u00adly two lines of code need\u00aded to be changed when the set\u00adting changed.  Like all oth\u00ader set\u00adtings, this us\u00ades the cool mag\u00adic that changes the set\u00adting in re\u00adal time, so you can see the ef\u00adfect with\u00adout clos\u00ading the set\u00adtings win\u00addow. \n Then some\u00adone on the mail\u00ading list re\u00adquest\u00aded a fea\u00adture that I re\u00adal\u00adized I al\u00adso want\u00aded, the abil\u00adi\u00adty to wrap vari\u00adables.  Pre\u00advi\u00adous\u00adly, any vari\u00adable that was longer than the vari\u00adable view would just be cut of\u00adf.  You could make it wider, but that on\u00adly helped a lit\u00adtle bit.  Oth\u00ader\u00adwise, if you want\u00aded to see the whole vari\u00adable, you had to open IPython by press\u00ading  !  and view it there. \n So, I im\u00adple\u00adment\u00aded this.  This was def\u00adi\u00adnite\u00adly the hard\u00adest thing to im\u00adple\u00admen\u00adt.  I found out that it's iron\u00adi\u00adcal\u00adly very dif\u00adfi\u00adcult to de\u00adbug PuDB it\u00adself.  You can't run PuDB in\u00adside of PuDB if PuDB crash\u00ades, as both in\u00adstances will just crash.  Al\u00adso, PuDB eats any print state\u00adments.  The so\u00adlu\u00adtion, sug\u00adgest\u00aded by PuDB au\u00adthor An\u00addreas Kl\u00f6ck\u00adn\u00ader, was to get the ttys file of an\u00adoth\u00ader ter\u00admi\u00adnal (e.g.,  /de\u00adv/t\u00adtys012) and write the out\u00adput to that. \n I al\u00adso made it so that non-wrapped vari\u00adables show  ...  at the end, at An\u00addreas's sug\u00adges\u00adtion.  I want\u00aded to use the uni\u00adcode  \u2026, but this was not work\u00ading at al\u00adl.  I dis\u00adcov\u00adered how much uni\u00adcode re\u00adal\u00adly is a mess in Python 2.  The prob\u00adlem has some\u00adthing to do with \u2026 be\u00ading a three byte char\u00adac\u00adter, and I think it al\u00adso has to do with the col\u00ador codes that ur\u00adwid us\u00ades.  I'll try it again once PuDB is port\u00aded to Python 3, but for now,  we are go\u00ading to have to do with the three ascii dot\u00ads. \n The wrap\u00adping code is wait\u00ading for merge, but the rest are al\u00adready in.  Here is a screen shot demon\u00adstrat\u00ading some of the things I did: \n  \n Things that I im\u00adple\u00adment\u00aded to no\u00adtice here: \n \n \n The mid\u00adnight theme.  \n   \n  \n The stack and break\u00ad\u00adpoints views have been shrunk\u00ad\u00aden.  \n   \n  \n The var\u00adi\u00adables are wrapped.  \n   \n  \n Wrap\u00adping for the var\u00adi\u00adable   fourhun\u00ad\u00addred   has been turned off (y\u00adou can turn wrap\u00adping on or off on a per-\u00ad\u00advar\u00adi\u00adable ba\u00ad\u00adsis by se\u00adlec\u00adt\u00ading the var\u00adi\u00adable and press\u00ading   w).   No\u00adtice that there is an el\u00adlip\u00ad\u00adsis at the end to note it has been cut of\u00adf.  \n   \n  \n Nest\u00aded var\u00adi\u00adables now have   |   be\u00ad\u00adfore them, to dis\u00ad\u00adt\u00adin\u00adguish them from wrapped var\u00adi\u00adables, which are al\u00ad\u00adso in\u00ad\u00ad\u00adden\u00adt\u00aded.  This change may or may not be ac\u00ad\u00adcep\u00adt\u00aded by An\u00ad\u00addreas.  \n   \n \nHere's a screen shot show\u00ading the prefs win\u00addow.  I did not im\u00adple\u00adment this, but I did im\u00adple\u00adment all but the first two pref\u00ader\u00adences in the win\u00addow. I've made my win\u00addow tall so you can see all the op\u00adtion\u00ads.  You re\u00adal\u00adly have to get the code and try it to see the au\u00adto-up\u00addate awe\u00adsome\u00adness.  You can open the prefs win\u00addow by press\u00ading  Ctr\u00adl-p  (this was not at all ob\u00advi\u00adous to me the first time I used it, so I al\u00adso sub\u00admit\u00adted a patch that makes it open the first time you use PuD\u00adB). \n  \n So if you're not al\u00adready us\u00ading this awe\u00adsome Python de\u00adbug\u00adger, you should.  You can  pip in\u00adstall pudb, or  fork it  at GitHub. \n Run\u00adning it in your code is very easy.  Just add \n [code lang=\"py\"] \n im\u00adport pud\u00adb;pud\u00adb.set_\u00adtrace() \n [/\u00adcode] \n in your code wher\u00adev\u00ader you want to set a break point, or you can do  python -m pud\u00adb.run scrip\u00adt.py. \n This awe\u00adsome tool has in\u00adcreased my pro\u00adduc\u00adtiv\u00adi\u00adty ten\u00adfold since I dis\u00adcov\u00adered it, and has helped me track down bugs that would have oth\u00ader\u00adwise ex\u00adtreme\u00adly dif\u00adfi\u00adcult if not im\u00adpos\u00adsi\u00adble to find.  And now, it's just bet\u00adter. \n PuDB us\u00ades the  ur\u00adwid li\u00adbrary  to do all its con\u00adsole GUI mag\u00adic.  This li\u00adbrary makes it pret\u00adty easy to do a lot of stuff. For ex\u00adam\u00adple, it au\u00adto\u00admat\u00adi\u00adcal\u00adly does rel\u00ada\u00adtive siz\u00ading of wid\u00adget\u00ads, so, for ex\u00adam\u00adple, when you re\u00adsize the vari\u00adables, stack, or break\u00adpoints views, you are ac\u00adtu\u00adal\u00adly in\u00adcreas\u00ading the rel\u00ada\u00adtive size of each, not the size in char\u00adac\u00adter\u00ads.  This makes it por\u00adta\u00adble against any ter\u00admi\u00adnal size.  The li\u00adbrary al\u00adso made cod\u00ading the prefs win\u00addow autoup\u00addate mag\u00adic very easy. \n Al\u00adso, I just want to note that git and GitHub make col\u00adlab\u00ado\u00adra\u00adtion like this very easy.  I just forked his pro\u00adjec\u00adt, made some im\u00adprove\u00adments, and sub\u00admit\u00adted them as pull re\u00adquest\u00ads.  Then it was easy to dis\u00adcuss the changes.  If the code had not been on GitHub and es\u00adpe\u00adcial\u00adly if it had not been in git, I prob\u00ada\u00adbly would have nev\u00ader both\u00adered to sub\u00admit my con\u00adtri\u00adbu\u00adtions up\u00adstream.  I high\u00adly rec\u00adom\u00admend that ev\u00adery open source project use git and GitHub.", 
      "loc": "/posts/2011/08/08/hacking-pudb-now-an-even-better-python-debugger/"
    }, 
    {
      "title": "SymPy 0.7.1 Released", 
      "tags": "", 
      "text": "Cross posted on the official SymPy Blog\nSymPy 0.7.1 has been re\u00adleased on Ju\u00adly 29, 2011. It is avail\u00adable at \n http://sympy.org \n  \n The source dis\u00adtri\u00adbu\u00adtion can be down\u00adload\u00aded from: \n http://\u00adcode.\u00adgoogle.\u00adcom/p/sympy/\u00addown\u00adload\u00ads/de\u00adtail?\u00adname=sympy-0.7.1.\u00adtar.gz \n  \n You can get the Win\u00addows in\u00adstall\u00ader here: \n http://\u00adcode.\u00adgoogle.\u00adcom/p/sympy/\u00addown\u00adload\u00ads/de\u00adtail?\u00adname=sympy-0.7.1.win32.exe \n  \n And the html doc\u00adu\u00admen\u00adta\u00adtion here: \n http://\u00adcode.\u00adgoogle.\u00adcom/p/sympy/\u00addown\u00adload\u00ads/de\u00adtail?\u00adname=sympy-0.7.1-\u00addoc\u00ads-htm\u00adl.zip \n  \n About SymPy \n  \n SymPy is a Python li\u00adbrary for sym\u00adbol\u00adic math\u00ade\u00admat\u00adic\u00ads. It aims to be\u00adcome a ful\u00adl-fea\u00adtured com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtem (CAS) while keep\u00ading the code as sim\u00adple as pos\u00adsi\u00adble in or\u00adder to be com\u00adpre\u00adhen\u00adsi\u00adble and eas\u00adi\u00adly ex\u00adten\u00adsi\u00adble. SymPy is writ\u00adten en\u00adtire\u00adly in Python. \n Re\u00adlease notes \n  \n Ma\u00adjor changes \n \n \n Python 2.4 is no longer sup\u00ad\u00adport\u00aded.  SymPy will not work at all in\n  Python 2.4.  If you still need to use SymPy un\u00adder Python 2.4 for some\n  rea\u00ad\u00adson, you will need to use SymPy 0.7.0 or ear\u00adli\u00ader.  \n   \n  \n The Py\u00ad\u00adglet plot\u00adt\u00ading li\u00adbrary is now an (op\u00ad\u00adtion\u00adal) ex\u00adter\u00ad\u00adnal de\u00adpen\u00ad\u00adden\u00ad\u00adcy. \n  Pre\u00advi\u00adous\u00ad\u00adly, we shipped a ver\u00ad\u00adsion of Py\u00ad\u00adglet with SymPy, but this was\n  old and bug\u00ad\u00adgy.  The plan is to even\u00ad\u00adtu\u00adal\u00ad\u00adly make the plot\u00adt\u00ading in SymPy\n  much more mod\u00ad\u00adu\u00adlar, so that it sup\u00ad\u00adports many back\u00ad\u00adend\u00ads, but this has not\n  been done yet.  For now, still on\u00ad\u00adly Py\u00ad\u00adglet is di\u00adrec\u00adt\u00ad\u00adly sup\u00ad\u00adport\u00aded. \n  Note that Py\u00ad\u00adglet is on\u00ad\u00adly an op\u00ad\u00adtion\u00adal de\u00adpen\u00ad\u00adden\u00ad\u00adcy and is on\u00ad\u00adly need\u00aded for\n  plot\u00adt\u00ading. The rest of SymPy can still be used with\u00ad\u00adout any de\u00adpen\u00ad\u00adden\u00ad\u00adcies\n  (ex\u00ad\u00adcept for Python).  \n   \n  \n isympy now works with the new IPython 0.11.  \n   \n  \n mp\u00ad\u00admath has been up\u00ad\u00ad\u00addat\u00aded to 0.17.  See the cor\u00adre\u00adspond\u00ading mp\u00ad\u00admath re\u00adlease\n  notes at http://m\u00adp\u00ad\u00admath\u00ad\u00ad.\u00ad\u00adgoogle\u00ad\u00adcode.\u00ad\u00adcom/svn/trunk\u00ad\u00ad/CHANGES.  \n   \n  \n Added a Subs ob\u00ad\u00adject for rep\u00adre\u00adsen\u00adt\u00ading un\u00ade\u00adval\u00adu\u00adat\u00aded sub\u00ad\u00adsti\u00ad\u00adtu\u00ad\u00adtion\u00ads.  This\n  fi\u00ad\u00adnal\u00ad\u00adly lets us rep\u00adre\u00adsent de\u00adriv\u00ada\u00ad\u00adtives eval\u00adu\u00adat\u00aded at a point, i.e.,\n    dif\u00adf(f(x), x).\u00ad\u00adsub\u00ad\u00ads(x, 0)   re\u00ad\u00adturns   Sub\u00ad\u00ads(Deriva\u00ad\u00adtive(f(_x), _x), (_x,), (0,)).\n  This al\u00ad\u00adso means that SymPy can now cor\u00adrec\u00adt\u00ad\u00adly com\u00ad\u00adpute the chain rule\n  when this func\u00ad\u00adtion\u00adal\u00adi\u00ad\u00adty is re\u00adquired, such as with   f(g(x)).d\u00adif\u00adf(x).  \n   \n \nHy\u00adper\u00adge\u00ado\u00admet\u00adric func\u00ad\u00adtion\u00ads/Mei\u00ad\u00adjer G-\u00ad\u00adFunc\u00ad\u00adtions \n \n \n Added class\u00ades hy\u00adper\u00ad() and mei\u00ad\u00adjerg() to rep\u00adre\u00adsent Hy\u00adper\u00adge\u00ado\u00admet\u00adric and Mei\u00ad\u00adjer G-\u00ad\u00adfunc\u00ad\u00adtion\u00ads, re\u00adspec\u00ad\u00adtive\u00ad\u00adly. They sup\u00ad\u00adport nu\u00admer\u00adi\u00ad\u00adcal eval\u00adu\u00ada\u00ad\u00adtion (us\u00ading mp\u00ad\u00admath) and sym\u00adbol\u00adic dif\u00adfer\u00ad\u00aden\u00adti\u00ada\u00ad\u00adtion (not with re\u00adspect to the pa\u00adram\u00ade\u00adter\u00ads).  \n   \n  \n Added an al\u00ad\u00adgo\u00adrithm for rewrit\u00ading hy\u00adper\u00adge\u00ado\u00admet\u00adric and mei\u00ad\u00adjer g-\u00ad\u00adfunc\u00ad\u00adtions in terms of more fa\u00admil\u00adiar, named spe\u00ad\u00adcial func\u00ad\u00adtion\u00ads. It is ac\u00adces\u00adsi\u00adble via the func\u00ad\u00adtion hy\u00adper\u00adex\u00ad\u00adpand(), or al\u00ad\u00adso via ex\u00ad\u00adpand_\u00ad\u00adfunc(). This al\u00ad\u00adgo\u00adrithm recog\u00adnis\u00ades many el\u00ade\u00ad\u00admen\u00ad\u00adtary func\u00ad\u00adtion\u00ads, and al\u00ad\u00adso com\u00ad\u00adplete and in\u00ad\u00ad\u00adcom\u00ad\u00adplete gam\u00ad\u00adma func\u00ad\u00adtion\u00ads, bessel func\u00ad\u00adtion\u00ads, and er\u00adror func\u00ad\u00adtion\u00ads. It can eas\u00adi\u00ad\u00adly be ex\u00ad\u00adtend\u00aded to han\u00ad\u00addle more class\u00ades of spe\u00ad\u00adcial func\u00ad\u00adtion\u00ads.  \n   \n \nSets \n \n \n Added Finite\u00adSet class to mim\u00adic python set be\u00adhav\u00adior while al\u00ad\u00adso in\u00ad\u00adter\u00adac\u00adt\u00ading with ex\u00adist\u00ading In\u00ad\u00adter\u00ad\u00advals and Unions  \n   \n  \n Finite\u00adSets and In\u00ad\u00adter\u00ad\u00advals in\u00ad\u00adter\u00adact so that, for ex\u00adam\u00ad\u00adple   In\u00ad\u00adter\u00ad\u00adval(0, 10) - Finite\u00adSet(0, 5)   pro\u00ad\u00adduces   (0, 5) U (5, 10]  \n   \n  \n Finite\u00adSets al\u00ad\u00adso han\u00ad\u00addle non-nu\u00admer\u00adi\u00ad\u00adcal ob\u00ad\u00adjects so the fol\u00adlow\u00ading is pos\u00adsi\u00adble   {1, 2, 'one', 't\u00ad\u00adwo', {a, b}}  \n   \n  \n Added Prod\u00aduc\u00adt\u00adSet to han\u00ad\u00addle Carte\u00adsian prod\u00aducts of sets  \n   \n  \n Cre\u00adate us\u00ading the   *   op\u00ader\u00ada\u00ad\u00adtor, i.e.   twodice = Finite\u00adSet(1, 2, 3, 4, 5, 6) * Finite\u00adSet(1, 2, 3, 4, 5, 6) or square = In\u00ad\u00adter\u00ad\u00adval(0, 1) * In\u00ad\u00adter\u00ad\u00adval(0, 1)  \n   \n  \n pow op\u00ader\u00ada\u00ad\u00adtor al\u00ad\u00adso works as ex\u00adpec\u00adt\u00aded:   R3 = In\u00ad\u00adter\u00ad\u00adval(-oo, oo)**3 ; (3, -5, 0) in R3 == True  \n   \n  \n Sub\u00ad\u00ad\u00adtrac\u00ad\u00adtion, union, mea\u00ad\u00adsure\u00ad\u00adment all work tak\u00ading com\u00ad\u00adplex in\u00ad\u00adter\u00adsec\u00ad\u00adtions in\u00ad\u00ad\u00adto ac\u00ad\u00adcoun\u00adt.     \n   \n  \n Added as_re\u00adla\u00ad\u00adtion\u00adal method to set\u00ads, pro\u00ad\u00adduc\u00ading bool\u00adean state\u00ad\u00adments us\u00ading And, Or, Eq, Lt, Gt, etc...  \n   \n  \n Changed re\u00ad\u00adduce_poly_inequal\u00adi\u00adties to re\u00ad\u00adturn unions of sets rather than lists of sets  \n   \n \nIt\u00ader\u00adables \n \n \n Added gen\u00ader\u00adat\u00ading rou\u00adtines for in\u00ad\u00adte\u00adger par\u00adti\u00ad\u00adtions and bi\u00ad\u00adna\u00adry par\u00adti\u00ad\u00adtion\u00ads. The rou\u00ad\u00adtine for in\u00ad\u00adte\u00adger par\u00adti\u00ad\u00adtions takes 3 ar\u00adgu\u00ad\u00adments, the num\u00adber it\u00ad\u00adself, the max\u00adi\u00ad\u00admum pos\u00adsi\u00adble el\u00ade\u00ad\u00adment al\u00adlowed in the par\u00adti\u00ad\u00adtions gen\u00ader\u00adat\u00aded and the max\u00adi\u00ad\u00admum pos\u00adsi\u00adble num\u00adber of el\u00ade\u00ad\u00adments that will be in the par\u00adti\u00ad\u00adtion. Bi\u00ad\u00adna\u00adry par\u00adti\u00ad\u00adtions are char\u00adac\u00adter\u00adized by con\u00ad\u00adtain\u00ading on\u00ad\u00adly pow\u00aders of two.  \n   \n  \n Added gen\u00ader\u00adat\u00ading rou\u00ad\u00adtine for mul\u00adti\u00ad-set par\u00adti\u00ad\u00adtion\u00ads. Giv\u00aden a mul\u00adti\u00adset, the al\u00ad\u00adgo\u00adrithm im\u00ad\u00adple\u00ad\u00admen\u00adt\u00aded will gen\u00ader\u00adate all pos\u00adsi\u00adble par\u00adti\u00ad\u00adtions of that mul\u00adti\u00ad-set.  \n   \n  \n Added gen\u00ader\u00adat\u00ading rou\u00adtines for bell per\u00ad\u00admu\u00ad\u00adta\u00ad\u00adtion\u00ads, de\u00adrange\u00ad\u00adments, and in\u00ad\u00advo\u00adlu\u00ad\u00adtion\u00ads. A bell per\u00ad\u00admu\u00ad\u00adta\u00ad\u00adtion is one in which the cy\u00ad\u00adcles that com\u00ad\u00adpose it con\u00ad\u00adsist of in\u00ad\u00adte\u00adgers in a de\u00adcreas\u00ading or\u00adder. A de\u00adrange\u00ad\u00adment is a per\u00ad\u00admu\u00ad\u00adta\u00ad\u00adtion such that the ith el\u00ade\u00ad\u00adment is not at the ith po\u00adsi\u00ad\u00adtion. An in\u00ad\u00advo\u00adlu\u00ad\u00adtion is a per\u00ad\u00admu\u00ad\u00adta\u00ad\u00adtion that when mul\u00adti\u00ad\u00adplied by it\u00ad\u00adself gives the iden\u00adti\u00ad\u00adty per\u00ad\u00admu\u00ad\u00adta\u00ad\u00adtion.  \n   \n  \n Added gen\u00ader\u00adat\u00ading rou\u00ad\u00adtine for un\u00adre\u00adstric\u00adt\u00aded neck\u00ad\u00adlaces. An un\u00adre\u00adstric\u00adt\u00aded neck\u00ad\u00adlace is an a-ary string of n char\u00adac\u00adter\u00ads, each of a pos\u00adsi\u00adble type\u00ad\u00ads. These have been char\u00adac\u00adter\u00adized by the pa\u00adram\u00ade\u00adters n and k in the rou\u00ad\u00adtine.  \n   \n  \n Added gen\u00ader\u00adat\u00ading rou\u00ad\u00adtine for ori\u00aden\u00adt\u00aded forest\u00ads. This is an im\u00ad\u00adple\u00ad\u00admen\u00ad\u00adta\u00ad\u00adtion of al\u00ad\u00adgo\u00adrithm S in TAOCP Vol 4A.  \n   \n \nxyz Spin bases \n \n \n The rep\u00adre\u00adsen\u00adt, re\u00adwrite and In\u00ad\u00adn\u00ader\u00adProd\u00aduct log\u00adic has been im\u00adproved to work be\u00adtween any two spin bases. This was done by uti\u00adl\u00adiz\u00ading the Wign\u00ader-D ma\u00adtrix, im\u00ad\u00adple\u00ad\u00admen\u00adt\u00aded in the Wign\u00aderD class, in defin\u00ading the changes be\u00adtween the var\u00adi\u00adous bases. Rep\u00adre\u00adsen\u00adt\u00ading a state, i.e.   rep\u00adre\u00adsen\u00adt(JzKet(1,0), ba\u00ad\u00adsis=Jx), can be used to give the vec\u00ad\u00adtor rep\u00adre\u00adsen\u00ad\u00adta\u00ad\u00adtion of any get in any of the x/y/z bases for nu\u00admer\u00adi\u00ad\u00adcal val\u00adues of j and m in the spin eigen\u00ads\u00adtate. Sim\u00adi\u00adlar\u00ad\u00adly, rewrit\u00ading states in\u00ad\u00ad\u00adto dif\u00adfer\u00ad\u00adent bases, i.e.   JzKet(1,0).rewrite('Jx'), will write the states as a lin\u00adear com\u00adbi\u00ad\u00adna\u00ad\u00adtion of el\u00ade\u00ad\u00adments of the giv\u00aden ba\u00ad\u00adsis. Be\u00ad\u00adcause this re\u00adlies on the rep\u00adre\u00adsent func\u00ad\u00adtion, this on\u00ad\u00adly works for nu\u00admer\u00adi\u00ad\u00adcal j and m val\u00adues. The in\u00ad\u00adn\u00ader prod\u00aduct of two eigen\u00ads\u00adtates in dif\u00adfer\u00ad\u00adent bases can be eval\u00adu\u00adat\u00aded, i.e.   In\u00ad\u00adn\u00ader\u00adPro\u00ad\u00adduc\u00adt(JzKet(1,0),JxKet(1,1)). When two dif\u00adfer\u00ad\u00adent bases are used, one state is rewrit\u00adten in\u00ad\u00ad\u00adto the oth\u00ad\u00ader ba\u00ad\u00adsis, so this re\u00adquires nu\u00admer\u00adi\u00ad\u00adcal val\u00adues of j and m, but in\u00ad\u00adn\u00ader\u00adprod\u00aducts of states in the same ba\u00ad\u00adsis can still be done sym\u00adbol\u00adi\u00ad\u00adcal\u00ad\u00adly.  \n   \n  \n The   Ro\u00ad\u00adta\u00ad\u00adtion.D   and   Ro\u00ad\u00adta\u00ad\u00adtion.d   meth\u00adod\u00ads, rep\u00adre\u00adsen\u00adt\u00ading the Wign\u00ader-D func\u00ad\u00adtion and the Wign\u00ader smal\u00adl\u00ad-d func\u00ad\u00adtion, re\u00ad\u00adturn an in\u00ad\u00ads\u00adtance of the Wign\u00aderD class, which can be eval\u00adu\u00adat\u00aded with the   doit()   method to give the cor\u00adre\u00adspond\u00ading ma\u00adtrix el\u00ade\u00ad\u00adment of the Wign\u00ader-D ma\u00adtrix.  \n   \n \nOth\u00ad\u00ader changes \n \n \n We now use Math\u00ad\u00ad\u00adJax in our doc\u00ads. Math\u00ad\u00ad\u00adJax ren\u00adders La\u00ad\u00adTeX math en\u00adtier\u00ad\u00adly in\n  the brows\u00ader us\u00ading Javascrip\u00adt.  This means that the math is much more\n  read\u00ad\u00adable than the pre\u00advi\u00adous png math, which us\u00ades im\u00adages.  Math\u00ad\u00ad\u00adJax is\n  on\u00ad\u00adly sup\u00ad\u00adport\u00aded on mod\u00ad\u00adern browser\u00ads, so La\u00ad\u00adTeX math in the docs may not\n  work on old\u00ader browser\u00ads.  \n   \n  \n nroot\u00ads() now lets you set the pre\u00ad\u00adci\u00ad\u00adsion of com\u00adpu\u00ad\u00adta\u00ad\u00adtions  \n   \n  \n Added sup\u00ad\u00adport for gmpy and mp\u00ad\u00admath\u00ad\u00ad's types to sympi\u00ad\u00adfy()  \n   \n  \n Fix some bugs with lam\u00adb\u00add\u00adi\u00ad\u00adfy()  \n   \n  \n Fix a bug with as_in\u00adde\u00adpen\u00ad\u00addent and non-\u00ad\u00adcom\u00ad\u00admu\u00ad\u00adta\u00ad\u00adtive sym\u00adbol\u00ads.  \n   \n  \n Fix a bug with col\u00adlect (is\u00ad\u00adsue 2516)  \n   \n  \n Many fix\u00ades re\u00adlat\u00ading to port\u00ading SymPy to Python 3.  Thanks to our GSoC\n  stu\u00ad\u00addent Vladimir Per\u00adi\u0107, this task is al\u00ad\u00admost com\u00ad\u00adplet\u00aded.  \n   \n  \n Some peo\u00ad\u00adple were retroac\u00ad\u00adtive\u00ad\u00adly added to the AU\u00adTHORS file.  \n   \n  \n Added a solver for a spe\u00ad\u00adcial case of the Ric\u00ad\u00adcati equa\u00ad\u00adtion in the ODE\n  mod\u00ad\u00adule.  \n   \n  \n It\u00ader\u00adat\u00aded de\u00adriv\u00ada\u00ad\u00adtives are pret\u00ad\u00adty print\u00ad\u00aded in a con\u00ad\u00adcise way.  \n   \n  \n Fix a bug with in\u00ad\u00adte\u00ad\u00adgrat\u00ading func\u00ad\u00adtions with mul\u00adti\u00ad\u00adple DiracDeltas.  \n   \n  \n Add sup\u00ad\u00adport for Ma\u00adtrix.nor\u00adm() that works for Ma\u00adtri\u00adces (not just vec\u00ad\u00adtors).  \n   \n  \n Im\u00adprove\u00ad\u00adments to the Groe\u00adb\u00adn\u00ader bases al\u00ad\u00adgo\u00adrith\u00adm.  \n   \n  \n Plot.saveim\u00adage now sup\u00ad\u00adports a Strin\u00ad\u00adgIO out\u00ad\u00ad\u00adfile  \n   \n  \n Ex\u00adpr.as_ordered_terms now sup\u00ad\u00adports non lex or\u00adder\u00adings.  \n   \n  \n diff now canon\u00adi\u00ad\u00adcal\u00adizes the or\u00adder of dif\u00adfer\u00ad\u00aden\u00adti\u00ada\u00ad\u00adtion sym\u00adbol\u00ads.  This is\n  so it can sim\u00ad\u00adpli\u00ad\u00adfy ex\u00adpres\u00ad\u00adsions like   f(x, y).d\u00adif\u00adf(x, y) - f(x,\n  y).d\u00adif\u00adf(y, x).  If you want to cre\u00adate a De\u00adriv\u00ada\u00ad\u00adtive ob\u00ad\u00adject with\u00ad\u00adout\n  sort\u00ading the args, you should cre\u00adate it ex\u00ad\u00adplic\u00adit\u00ad\u00adly with   De\u00adriv\u00ada\u00ad\u00adtive,\n  so that you will get   Deriva\u00ad\u00adtive(f(x, y), x, y) != Deriva\u00ad\u00adtive(f(x, y), y, x).\n  Note that in\u00ad\u00adter\u00ad\u00adnal\u00ad\u00adly, de\u00adriv\u00ada\u00ad\u00adtives that can be com\u00adput\u00aded are al\u00adways\n  com\u00adput\u00aded in the or\u00adder that they are giv\u00aden in.  \n   \n  \n Added func\u00ad\u00adtions   is_se\u00adquence()   and   it\u00ader\u00adable()   for de\u00adter\u00admin\u00ading if\n  some\u00adthing is an or\u00addered it\u00ader\u00adable or nor\u00ad\u00admal it\u00ader\u00adable, re\u00adspec\u00ad\u00adtive\u00ad\u00adly.  \n   \n  \n En\u00adabled an op\u00ad\u00adtion in Sphinx that adds a   source   link next to each func\u00ad\u00adtion, which links to a copy of the source code for that func\u00ad\u00adtion.  \n   \n \nIn ad\u00addi\u00adtion to the more no\u00adtice\u00adable changes list\u00aded above, there have been nu\u00admer\u00adous oth\u00ader small\u00ader ad\u00addi\u00adtion\u00ads, im\u00adprove\u00adments and bug fix\u00ades in the ~300 com\u00admits in this re\u00adlease. See the git log for a full list of all changes.  The com\u00admand  git log sympy-0.7.0..sympy-0.7.1  will show all com\u00admits made be\u00adtween this re\u00adlease and the last. You can al\u00adso see the is\u00adsues closed since the last re\u00adlease  here. \n Au\u00adthors \n The fol\u00adlow\u00ading peo\u00adple con\u00adtrib\u00aduted at least one patch to this re\u00adlease (names are giv\u00aden in al\u00adpha\u00adbet\u00adi\u00adcal or\u00adder by last name).  A to\u00adtal of 26 peo\u00adple con\u00adtrib\u00aduted to this re\u00adlease.  Peo\u00adple with a * by their names con\u00adtrib\u00aduted a patch for the first time for this re\u00adlease.  Five peo\u00adple con\u00adtrib\u00aduted for the first time for this re\u00adlease.    \n Thanks to ev\u00adery\u00adone who con\u00adtrib\u00aduted to this re\u00adlease! \n \n \n Tom Bach\u00ad\u00admann  \n   \n  \n Ond\u0159ej \u010cert\u00edk  \n   \n  \n Re\u00ad\u00adna\u00ad\u00adto Coutin\u00adho  \n   \n  \n Bill Fly\u00ad\u00adnn  \n   \n  \n Bradley Froehle*  \n   \n  \n Gilbert Gede  \n   \n  \n Bri\u00adan Granger  \n   \n  \n Em\u00ad\u00adma Hogan*  \n   \n  \n Yuri Karadzhov  \n   \n  \n Ste\u00ad\u00adfan Kras\u00ad\u00adtanov*  \n   \n  \n Ro\u00ad\u00adnan Lamy  \n   \n  \n To\u00ad\u00admo La\u00ad\u00adzovich  \n   \n  \n Sam Magu\u00adra*  \n   \n  \n Sap\u00ad\u00adtarshi Man\u00ad\u00addal  \n   \n  \n Aaron Meur\u00ader  \n   \n  \n Sher\u00adjil Ozair  \n   \n  \n Ma\u00ad\u00adteusz Pa\u00adproc\u00ad\u00adki  \n   \n  \n Vladimir Per\u00adi\u0107  \n   \n  \n Mario Per\u00adni\u00ad\u00adci  \n   \n  \n Nico\u00adlas Pourcelot  \n   \n  \n Min Ra\u00ad\u00adgan-Kel\u00ad\u00adley*  \n   \n  \n Matthew Rock\u00ad\u00adlin  \n   \n  \n Chris Smith  \n   \n  \n Vinzent Stein\u00adberg  \n   \n  \n Sean Vig  \n   \n  \n Thomas Wiec\u00ad\u00adki", 
      "loc": "/posts/2011/07/30/sympy-0-7-1-released/"
    }, 
    {
      "title": "Merging integration3 with sympy-0.7.0 nightmare", 
      "tags": "mathjax", 
      "text": "For a long time, there have been sev\u00ader\u00adal prob\u00adlems in my  in\u00adte\u00adgra\u00adtion3  branch that were fixed in  mas\u00adter.  I de\u00adcid\u00aded that as an in\u00adcen\u00adtive to fin\u00adish the re\u00adlease, I would hold off on merg\u00ading  mas\u00adter  in\u00adto my branch un\u00adtil the 0.7.0 re\u00adlease was fin\u00adished.  Well, here's a lit\u00adtle time\u00adline: \n \n    June 28, 2011:  SymPy 0.7.0 fi\u00adnal is re\u00adleased. \n     June 29, 2011:  I type  git merge sympy-0.7.0  in my  in\u00adte\u00adgra\u00adtion3  branch. \n     Ju\u00adly 24, 2011 (to\u00adday; tech\u00adni\u00adcal\u00adly Ju\u00adly 25 be\u00adcause it's 2 AM):  I fin\u00adish merg\u00ading  sympy-0.7.0  in\u00adto  in\u00adte\u00adgra\u00adtion3. \n \nThat's right, it took me over three week\u00ads---al\u00admost a mon\u00adth---\u00adto merge  sympy-0.7.0  in\u00adto  in\u00adte\u00adgra\u00adtion3  (grant\u00aded, I worked on oth\u00ader things at the same time, such as the  SciPy 2011 con\u00adfer\u00adence, but to me, any merge that takes longer than a day to com\u00adplete is a prob\u00adlem).  This is be\u00adcause git de\u00adcid\u00aded that I need\u00aded to fix as a merge con\u00adflict just about ev\u00adery sin\u00adgle change in the re\u00adlease branch since the base of  in\u00adte\u00adgra\u00adtion3.  The to\u00adtal was over 100 files.  You can see the fi\u00adnal merge com\u00admit  here. \n So I start\u00aded  git merge\u00adtool, with\u00adout which this whole or\u00addeal would have been 10 times worse.  The merge\u00adtool, which on my com\u00adput\u00ader is open\u00addif\u00adf, i.e., File Merge, gave the cor\u00adrect change by de\u00adfault in most cas\u00ades, so I ac\u00adtu\u00adal\u00adly did not have to man\u00adu\u00adal\u00adly fix the ma\u00adjor\u00adi\u00adty of the con\u00adflict\u00ads.  But I did have to go through and do a lot of them.  I had to man\u00adu\u00adal\u00adly check each dif\u00adfer\u00adence in the polys, as I had made sev\u00ader\u00adal changes there in the course of work\u00ading on  in\u00adte\u00adgra\u00adtion3.  In sev\u00ader\u00adal oc\u00adci\u00adsaion\u00ads, I had to re\u00adsearch a change us\u00ading  git log -S  and fan\u00adcy meth\u00adod\u00ads.  And I no\u00adticed at least two re\u00adgres\u00adsions in the polys, which I fixed. \n merge\u00adtool was use\u00adless against  risch.py  and  test_risch.py, be\u00adcause in my branch I had re\u00adnamed these to  heurisch.py  and  test_heurisch.py.  For\u00adtu\u00adnate\u00adly, these were not re\u00adal\u00adly mod\u00adi\u00adfied much by me, so I could ba\u00adsi\u00adcal\u00adly just re\u00adplace them with the  sympy-0.7.0  ver\u00adsion\u00ads. \n Once I fin\u00adished merg\u00ading I had to deal with test fail\u00adures.  This was part\u00adly ex\u00adpect\u00aded, as my branch has al\u00adways had test fail\u00adures due to my hack dis\u00adabling al\u00adge\u00adbra\u00adic sub\u00adsti\u00adtu\u00adtion in  exp, which is re\u00adquired for  risch_in\u00adte\u00adgrate()  to work, but there were al\u00adso sev\u00ader\u00adal un\u00adre\u00adlat\u00aded ones.    \n Some of these were caused by wrong merge con\u00adflict res\u00ado\u00adlu\u00adtions by me.  So I went through  git diff sympy-0.7.0  change by change and made sure that noth\u00ading was dif\u00adfer\u00adent that I did\u00adn't want to be.  I would rec\u00adom\u00admend do\u00ading this for any big merge. \n Then, I had to fix a few bugs that caused test fail\u00adures.  Sev\u00ader\u00adal se\u00adman\u00adtics were changed in the re\u00adlease.  I think the ones that I had to change were the re\u00adnam\u00ading of  has_any_sym\u00adbols  to just  has, the re\u00adnam\u00ading of  Poly.as_ba\u00adsic()  to  Poly.as_\u00adex\u00adpr(), and the swap\u00adping of the mean\u00adings of  quo  and  exquo  in the polys.  There were al\u00adso some doctest fail\u00adures due to the change to lex\u00adi\u00adco\u00adgraph\u00adic or\u00adder\u00ading in the print\u00ader. \n Af\u00adter all that, there were two re\u00adgres\u00adsions that caused test fail\u00adures.  The first was the fol\u00adlow\u00ading: \n Be\u00adfore: \n [code lang=\"py\"] \n In [1]: In\u00adte\u00adgral((\u00adex\u00adp(xlog(x))log(x)), x).\u00adsub\u00ads(\u00adex\u00adp(xlog(x)), x*x) \n Out\u00ad[1]:   \n \u2320               \n \u23ae  x            \n \u23ae x \u22c5log(x) dx \n \u2321               \n [/\u00adcode] \n Af\u00adter: \n [code lang=\"py\"] \n In [1]: In\u00adte\u00adgral((\u00adex\u00adp(xlog(x))log(x)), x).\u00adsub\u00ads(\u00adex\u00adp(xlog(x)), x*x) \n Out\u00ad[1]:   \n \u2320                      \n \u23ae  x\u22c5log(x)            \n \u23ae \u212f        \u22c5log(x) dx \n \u2321                      \n [/\u00adcode] \n This sub\u00adsti\u00adtu\u00adtion is nec\u00ades\u00adsary be\u00adcause the Risch al\u00adgo\u00adrithm re\u00adquires ex\u00adpres\u00adsions like $la\u00adtex xx$ to be rewrit\u00adten as $la\u00adtex e{x\\log(x)}$ be\u00adfore it can in\u00adte\u00adgrate them, but I try to con\u00advert them back af\u00adter in\u00adte\u00adgrat\u00ading so that the us\u00ader gets the same thing in the re\u00adsult that he en\u00adtered.  I cre\u00adat\u00aded  is\u00adsue 2571  for this. \n The sec\u00adond was that I had sev\u00ader\u00adal places in my doc\u00adstrings with things like \n \n\nGiven a derivation D on k[t] and f, g in k(t) with f weakly normalized with respect to t, either raise NonElementaryIntegralException, in which case the equation Dy + f*y == g has no solution in k(t), or the quadruplet (a, b, c, h) such that a, h in k[t], b, c in k, and for any solution y in k(t) of Dy + f*y == g, q = y*h in k satisfies a*Dq + b*q == c.\n\n\n\nThe prob\u00adlem here is the \"raise NonEle\u00admen\u00adtary\u00adIn\u00adte\u00adgralEx\u00adcep\u00adtion,\" part.  The code qual\u00adi\u00adty check\u00ader things that this is an old style ex\u00adcep\u00adtion (like  raise Ex\u00adcep\u00adtion, mes\u00adsage), due to a poor\u00adly formed reg\u00adu\u00adlar ex\u00adpres\u00adsion.  I fixed this in a  pull re\u00adquest. \n The good news is that now a lot of stuff works that did\u00adn't be\u00adfore be\u00adcause of fix\u00ades that were re\u00adquired that on\u00adly ex\u00adist\u00aded in  mas\u00adter.  For ex\u00adam\u00adple, the fol\u00adlow\u00ading did not work be\u00adfore, but now does due to im\u00adprove\u00adments to  Root\u00adSum: \n [code lang=\"py\"] \n In [1]: risch_in\u00adte\u00adgrate(1/(\u00adex\u00adp(5*x) + ex\u00adp(x) + 1), x) \n Out\u00ad[1]: \n           \u239b    2                                                           \nx + Root\u00adSum\u239d21\u22c5z  + 6\u22c5z + 1, Lamb\u00adda(_i, _ilog(-3381_i4/4 - 3381*_i3/4   \n                                    \u239e          \u239b     3        2\n\n\n\n\n625_i2/2 - 125_i/2 + ex\u00adp(x) - 5))\u23a0 + Root\u00adSum\u239d161\u22c5z  + 115\u22c5z  + 19\u22c5z +   \n \n1, Lamb\u00adda(_i, _ilog(-3381_i4/4 - 3381*_i3/4 - 625_i2/2 - 125_i/2 + \n          \u239e\n\n\n\nex\u00adp(x) - 5))\u23a0 \n In [2]: can\u00adcel(risch_in\u00adte\u00adgrate(1/(\u00adex\u00adp(5*x) + ex\u00adp(x) + 1), x).d\u00adif\u00adf(x)) \n Out\u00ad[2]: \n      1      \n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n 5\u22c5x    x    \n\u212f    + \u212f  + 1 \n [/\u00adcode] \n The gen\u00ader\u00adal def\u00adi\u00adni\u00adtion of the log\u00ada\u00adrith\u00admic part of an in\u00adte\u00adgral is a sum over the roots of a poly\u00adno\u00admi\u00adal, which must be ex\u00adpressed as a  Root\u00adSum  in the gen\u00ader\u00adal case.  Pre\u00advi\u00adous\u00adly,  Root\u00adSum.d\u00adiff  did not work, but thanks to Ma\u00adteusz, an al\u00adgo\u00adrithm for com\u00adput\u00ading ex\u00adact\u00adly the Root\u00adSum where the Lamb\u00adda ex\u00adpres\u00adsion is a ra\u00adtio\u00adnal func\u00adtion was im\u00adple\u00adment\u00aded (see  this bit  from our SciPy tu\u00adto\u00adri\u00adal for an idea on how this work\u00ads), so now the Risch Al\u00adgo\u00adrithm can work with Root\u00adSum ob\u00adjects just as well with as an or\u00addi\u00adnary sum of log\u00ada\u00adrithm\u00ads. \n Al\u00adso, there was a bug in the square free al\u00adgo\u00adrithm in my branch that was fixed in  mas\u00adter  that was caus\u00ading wrong re\u00adsults (I don't re\u00admem\u00adber the ex\u00adpres\u00adsion that pro\u00adduced them right now), and al\u00adso there was a fix by me in  mas\u00adter  to make  is_ra\u00adtional_\u00adfunc\u00adtion()  faster, as it was sig\u00adnif\u00adi\u00adcant\u00adly slow\u00ading down the cal\u00adcu\u00adla\u00adtion of some in\u00adte\u00adgrals (for ex\u00adam\u00adple,  risch_in\u00adte\u00adgrate(Ad\u00add((ex\u00adp(ix) for i in range(1000)))), which is still slow to cal\u00adcu\u00adlate, but now it's be\u00adcause of oth\u00ader things). \n About big branch\u00ades \n So this merge, along with the poly12 fi\u00adas\u00adco (which by the way, I think part of the rea\u00adson git made me do all these merge con\u00adflict res\u00ado\u00adlu\u00adtions was be\u00adcause  polys12  was re\u00adbased from the  polys11  I had merged in\u00adto in\u00adte\u00adgra\u00adtion3), has shown me very clear\u00adly that it is very bad to go off with your own branch and do a lot of work and wait a long time be\u00adfore merg\u00ading it back in\u00adto the main re\u00adpo. \n This is what was done with  polys12.  Ma\u00adteusz had a lot of new poly\u00adno\u00admi\u00adals code that he de\u00advel\u00adoped in one big branch, and when it fi\u00adnal\u00adly came to merg\u00ading it back in, it was a mess.  This was for sev\u00ader\u00adal rea\u00adson\u00ads, which I do not want to dis\u00adcuss too much here, but it be\u00adcame clear to ev\u00adery\u00adone I think that do\u00ading this was bad, and that it would have been bet\u00adter to have sub\u00admit\u00adted many changes as pull re\u00adquests as they were made than keep\u00ading them all to\u00adgeth\u00ader in one big branch for a long time. \n This mod\u00adel al\u00adso af\u00adfect\u00aded my work, as I had to work off of lat\u00adest the polys branch, not  mas\u00adter, as my work re\u00adlied heav\u00adi\u00adly on the lat\u00adest and great\u00adest in the polys.    \n Well, with this merge of the main re\u00adpo in\u00adto my branch, I see that my branch is start\u00ading to be\u00adcome the same way.  I orig\u00adi\u00adnal\u00adly thought that I should fin\u00adish the Risch al\u00adgo\u00adrithm be\u00adfore sub\u00admit\u00adting it to be merged in\u00adto  mas\u00adter.  I know know that this is the wrong ap\u00adproach.  De\u00advel\u00adop\u00adment in  mas\u00adter  is too fast to keep code away from it for too long.  The di\u00adver\u00adgence makes it more and more dif\u00adfi\u00adcult to merge back with ev\u00adery time.  Fur\u00adther\u00admore, there are re\u00adgres\u00adsions that were nev\u00ader no\u00adticed to be re\u00adgres\u00adsions be\u00adcause the code that would have shown them ex\u00adist\u00aded on\u00adly in my branch.  Now I have to fix the\u00adse, where\u00adas if the code were in  mas\u00adter, the re\u00adgres\u00adsion would have nev\u00ader hap\u00adpened in the first place, be\u00adcause the au\u00adthor would have seen it im\u00adme\u00addi\u00adate\u00adly from the test fail\u00adures. \n I al\u00adso thought that I should wait to merge be\u00adcause there were so many bugs in my code.  But I see now that this is al\u00adso wrong.  Merg\u00ading with  mas\u00adter  will help me find these bugs, as peo\u00adple will ac\u00adtu\u00adal\u00adly use my code.  Sure, I've asked peo\u00adple to try out  risch_in\u00adte\u00adgrate(), and some peo\u00adple have (and I thank you), but hav\u00ading it in the de\u00adfault  in\u00adte\u00adgrate()  in  mas\u00adter  will re\u00adsult in find\u00ading more bugs in the code than I ev\u00ader would alone, which is ba\u00adsi\u00adcal\u00adly the way it is right now with the code liv\u00ading on\u00adly in my own branch. \n I would pre\u00adpare my code for merg\u00ading with  mas\u00adter  to\u00adday, if it weren't for this  ex\u00adp.\u00adsubs  hack, which caus\u00ades test fail\u00adures and is tech\u00adni\u00adcal\u00adly a re\u00adgres\u00adsion, but is re\u00adquired for the prepars\u00ading code to the Risch al\u00adgo\u00adrithm to work.  This is why I  wrote to the list  two weeks ago ask\u00ading for ad\u00advice on how to struc\u00adture the sub\u00adsti\u00adtu\u00adtion code so that we can nice\u00adly have var\u00adi\u00adous kinds of sub\u00adsti\u00adtu\u00adtions (e.g., ex\u00adact like I need and al\u00adge\u00adbra\u00adic like cur\u00adrent\u00adly ex\u00adists in  exp) liv\u00ading to\u00adgeth\u00ader with\u00adout clut\u00adter\u00ading up the code. \n There\u00adfore, I am go\u00ading to fo\u00adcus my en\u00ader\u00adgies on fix\u00ading this subs prob\u00adlem so I can get my code merged with  mas\u00adter.  Then, when this is done, I will con\u00adtin\u00adue my work on im\u00adple\u00adment\u00ading the re\u00admain\u00ading cas\u00ades of the Risch al\u00adgo\u00adrith\u00adm.    \n So let this tale be a warn\u00ading to peo\u00adple work\u00ading on a lot of code in a big branch.  This es\u00adpe\u00adcial\u00adly ap\u00adplies to our GSoC stu\u00addents, as it's ex\u00adtreme\u00adly easy to let your code ac\u00adcu\u00admu\u00adlate when you're a GSoC stu\u00addent (tech\u00adni\u00adcal\u00adly this branch of mine is a GSoC branch).  I see that some of our stu\u00addents are do\u00ading a bet\u00adter job of this than oth\u00ader\u00ads.  To those who have your code all in one big branch that has\u00adn't been merged, I rec\u00adom\u00admend you ready your branch for merge now.  And in the fu\u00adture, try to break your code up in\u00adto small but still mean\u00ading\u00adful chunks and sub\u00admit those as pull re\u00adquest\u00ads.  With git, it's easy to base the code you are cur\u00adrent\u00adly work\u00ading on on code that has\u00adn't been merged yet, while still keep\u00ading things in small chunks for the pull re\u00adquest\u00ads.    \n On the oth\u00ader hand, git will on\u00adly take you so far if you keep ev\u00adery\u00adthing in a big branch, be\u00adcause there are go\u00ading to be changes in  mas\u00adter  that will af\u00adfect your work, no mat\u00adter how iso\u00adlat\u00aded you think it is, and these are the sorts of things that it is im\u00adpos\u00adsi\u00adble for git to fix for you.  But if your code is in  mas\u00adter, it will be sup\u00adport\u00aded by ev\u00adery\u00adone, and any ma\u00adjor change that af\u00adfects it will have to fix it. For ex\u00adam\u00adple, if some\u00adone changes a print\u00ader and the doctests change, then he will have to change your doctest too if it's in  mas\u00adter, but if it's in your branch, then you will have to fix it when you next merge/re\u00adbase with\u00ad/a\u00adgainst  mas\u00adter.", 
      "loc": "/posts/2011/07/25/merging-integration3-with-sympy-0-7-0-nightmare/"
    }, 
    {
      "title": "The SciPy 2011 Conference", 
      "tags": "", 
      "text": "So this past week, I at\u00adtend\u00aded the SciPy 2011 con\u00adfer\u00adence in Austin, TX, which was my first con\u00adfer\u00adence ev\u00ader.  Here are some high\u00adlights of the con\u00adfer\u00adence for me: \n \n    I met a  ton  of cool peo\u00adple.  This in\u00adclud\u00aded meet\u00ading sev\u00ader\u00adal peo\u00adple who I had pre\u00advi\u00adous\u00adly known from mail\u00ading lists in per\u00adson for the first time.  I met the SymPy de\u00advel\u00adop\u00aders Ma\u00adteusz Pa\u00adproc\u00adki and Andy Ter\u00adrel, and I al\u00adso had al\u00adready known or heard about peo\u00adple like Fer\u00adnan\u00addo Perez, Gael Varo\u00adquaux, and Robert Kern.  There are a lot of peo\u00adple out there who are ex\u00adcit\u00aded to be us\u00ading Python for their re\u00adsearch, which is a re\u00adal re\u00adfresh\u00ader from my uni\u00adver\u00adsi\u00adty, where ev\u00adery\u00adone is us\u00ading Mat\u00adlab and Maple. \n <li>Mateusz and I gave a tutorial on SymPy.  This was one of the four introductory track tutorials.  This was a great experience to teach SymPy to people.  You can see the <a href=\"http://mattpap.github.com/scipy-2011-tutorial/html/index.html\">Sphinx document</a> that we used, and there should eventually be a video posted at the <a href=\"http://conference.scipy.org/scipy2011/tutorials.php#mateusz\">SciPy 2011 website</a>.</li>\n\n<li>In addition to our tutorial, I attended some of the other tutorials.  I particularly enjoyed the NumPy tutorial. Having never used NumPy before, I now feel comfortable with the basics.  I also attended Gael Varoquaux's tutorial on scikits.learn and Corran Webster's tutorial on Matplotlib, Traits, and Chaco. My only regret is that the advanced track and introductory track tutorials were held at the same time, so I could not attend half of them.  I plan to watch the ones I missed online.</li>\n\n<li>The general conference was excellent.  Some of the talks that I particularly enjoyed were:\n\n\n\nThe key\u00adnotes.  I found Er\u00adic Jone's key\u00adnote par\u00adtic\u00adu\u00adlar\u00adly rel\u00ade\u00advant as the lead\u00ader of SymPy, as he talked about some of the good things to do and bad things to not do when lead\u00ading a sci\u00aden\u00adtif\u00adic projec\u00adt.  I al\u00adso en\u00adjoyed Per\u00adry Green\u00adfield\u00ad's talk about how the as\u00adtron\u00ado\u00admy com\u00admu\u00adni\u00adty moved from some old pro\u00adpri\u00adetary sys\u00adtem to Python. \n     Ma\u00adteusz gave a talk on his  FEMhub on\u00adline lab, which a was very im\u00adpres\u00adsive sys\u00adtem for us\u00ading Python en\u00adtire\u00adly in the web brows\u00ader. \n     By far the best talk of the en\u00adtire con\u00adfer\u00adence was Fer\u00adnan\u00addo Perez's talk on the new IPython 0.11, which will be com\u00ading out in about a week or so.  His de\u00admo of the new fea\u00adtures such as the QT con\u00adsole and html note\u00adbook were very im\u00adpres\u00adsive.  If you want to watch just one video from the con\u00adfer\u00adence, I would rec\u00adom\u00admend that one. \n     Mark Dew\u00ading gave a talk about a sys\u00adtem he wrote us\u00ading SymPy to do au\u00adto\u00admat\u00aded deriva\u00adtion of equa\u00adtion\u00ads.  The sys\u00adtem is im\u00adpres\u00adsive, and con\u00adtains some fea\u00adtures that would be nice to back\u00adport to SymPy.  He told me that he wants to do this, so fol\u00adlow the mail\u00ading list.  You can see what he has so far on his  deriva\u00adtion_\u00admod\u00adel\u00ading  branch at GitHub. \n     The light\u00adning talk\u00ads.  These are very short talks at the end of the con\u00adfer\u00adence that are on\u00adly five min\u00adutes long.  In ad\u00addi\u00adtion to many in\u00adter\u00adest\u00ading talk\u00ads, both Ma\u00adteusz and I gave a light\u00adning talk. Ma\u00adteusz gave a talk on  SymPy Live, which he re\u00adcent\u00adly im\u00adproved to do things like give La\u00adTeX out\u00adput, and I gave a talk on my work with the Risch al\u00adgo\u00adrith\u00adm.  I would al\u00adso high\u00adly rec\u00adom\u00admend watch this talk once they post the videos. \n     Again, re\u00adgret\u00adtably, I could not at\u00adtend half of the talks be\u00adcause they were held at the same time.  For\u00adtu\u00adnate\u00adly, they filmed all of them, so I hope to watch them all on\u00adline when they are post\u00aded (and I rec\u00adom\u00admend that you do too).\n    \n<li>The sprints were a great time for getting together and hacking together.  I worked with Min Ragan-Kelley to make isympy work with the new IPython.  Having fixed this, I now want to release 0.7.1 very soon, so I used some of the time during the sprints getting ready for that.  We already have <a href=\"https://github.com/sympy/sympy/wiki/Release-Notes-for-0.7.1\">preliminary release notes</a>, and my hope is to create a release candidate on Monday (tomorrow).  I also finished up my <a href=\"https://github.com/sympy/sympy/pull/491\">MathJax branch</a> and finished reviewing and pushed in Tom's first GSoC pull request, which has a lot of really cool stuff relating to converting hypergeometric functions and Meijer G-functions into standard elementary functions.  This will all be in the release.\n\n\n\nAl\u00adso at the sprints, Ma\u00adteusz worked on an ex\u00adten\u00adsion for our Sphinx docs that puts a SymPy Live con\u00adsole right in the doc\u00ads.  You can then click on \"e\u00adval\u00adu\u00adate\" next to any of the code ex\u00adam\u00adples, and it will run it in SymPy live.  And of course, you can then ed\u00adit it and play around with it.  He al\u00adready had a work\u00ading ver\u00adsion of this by the end of the sprints (with a few bugs stil\u00adl), but I don't think he has pushed it to GitHub yet.  I think this is go\u00ading to be a land\u00admark change for our doc\u00adu\u00admen\u00adta\u00adtion.  SymPy Live runs on the App En\u00adgine, so this ap\u00adproach can be ap\u00adplied to any li\u00adbrary that can run in pure Python 2.5, and I think a lot of such projects are go\u00ading to be jeal\u00adous this and want to start us\u00ading it, be\u00adcause it's very im\u00adpres\u00adsive and use\u00adful. \n We al\u00adso had a cou\u00adple of peo\u00adple from the con\u00adfer\u00adence come to our ta\u00adble and work on SymPy.  These were peo\u00adple who were new to SymPy, and I think at\u00adtend\u00aded our tu\u00adto\u00adri\u00adal.  One of them, Em\u00adma Hogan, worked a lit\u00adtle bit on im\u00adprov\u00ading our doc\u00adu\u00admen\u00adta\u00adtion, and has sub\u00admit\u00adted a  pull re\u00adquest. \n\n\n <li>Austin, TX is a nice city with lots of fun places to go, but it is also very humid, which is something I could barely stand (I am used to the same heat, but in Albuquerque it is dry heat).  One interesting thing that some of us went and saw was the bats.  The bridge over this lake in Austin has over a million bats living under it, and at night they all fly out to feed.  </li>\n\n\n\n\n\nThere's all kinds of fun and in\u00adter\u00adest\u00ading stuff that hap\u00adpened that I did not men\u00adtion here.  If you are in\u00adter\u00adest\u00aded in sci\u00adence and Python, I would high\u00adly rec\u00adom\u00admend at\u00adtend\u00ading a fu\u00adture SciPy con\u00adfer\u00adence.", 
      "loc": "/posts/2011/07/17/the-scipy-2011-conference/"
    }, 
    {
      "title": "SymPy 0.7.0 released", 
      "tags": "", 
      "text": "Cross posted on the official SymPy blog\nSymPy 0.7.0 has been re\u00adleased on June 28, 2011.   It is avail\u00adable athttp://sympy.orgThe source dis\u00ad\u00adtri\u00adbu\u00ad\u00adtion can be down\u00adload\u00ad\u00aded from:http://sympy.\u00ad\u00adgoogle\u00ad\u00adcode.\u00ad\u00adcom/\u00ad\u00adfiles/sympy-0.6.7.\u00ad\u00adtar.gzYou can get the Win\u00ad\u00addows in\u00ad\u00adstal\u00adl\u00ader here:http://sympy.\u00ad\u00adgoogle\u00ad\u00adcode.\u00ad\u00adcom/\u00ad\u00adfiles/sympy-0.6.7.win32.exeAnd the html doc\u00adu\u00ad\u00admen\u00ad\u00adta\u00ad\u00adtion here:http://sympy.\u00ad\u00adgoogle\u00ad\u00adcode.\u00ad\u00adcom/\u00ad\u00adfiles/sympy-0.6.7-\u00ad\u00addoc\u00ads-ht\u00adm\u00adl.zipAbout SymPySymPy is a Python li\u00adbrary for sym\u00adbol\u00adic math\u00ade\u00admat\u00adic\u00ads. It aims to be\u00adcome a ful\u00adl-fea\u00adtured com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtem (CAS) while keep\u00ading the code as sim\u00adple as pos\u00adsi\u00adble in or\u00adder to be com\u00adpre\u00adhen\u00adsi\u00adble and eas\u00adi\u00adly ex\u00adten\u00adsi\u00adble. SymPy is writ\u00adten en\u00adtire\u00adly in Python.Changes since last sta\u00adble re\u00adlease(from    http\u00ads://github.\u00ad\u00ad\u00adcom/sympy/sympy/wik\u00adi/Re\u00adlease-Notes-\u00ad\u00ad\u00adfor-0.7.0)Back\u00ad\u00adwards com\u00ad\u00adpat\u00adi\u00ad\u00adbil\u00adi\u00ad\u00adty breaksThis will be the last re\u00adlease of SymPy to sup\u00ad\u00ad\u00ad\u00adport Python 2.4. Drop\u00adping sup\u00ad\u00ad\u00ad\u00adport for Python 2.4 will let us move for\u00adward with things like sup\u00ad\u00ad\u00ad\u00adport\u00ading Python 3, and will let us use things that were in\u00ad\u00ad\u00ad\u00adtro\u00ad\u00ad\u00ad\u00adduced in Python 2.5, like with\u00ad\u00ad\u00ad\u00ad-s\u00ad\u00ad\u00ad\u00adtate\u00ad\u00ad\u00ad\u00adment con\u00ad\u00ad\u00ad\u00adtext man\u00adager\u00ads.no longer sup\u00ad\u00ad\u00ad\u00adport cre\u00adat\u00ading ma\u00adtri\u00adces with\u00ad\u00ad\u00ad\u00adout brack\u00ad\u00ad\u00ad\u00adets (see: is\u00ad\u00ad\u00ad\u00adsue 930)Re\u00ad\u00ad\u00ad\u00adnamed     sum()     to     sum\u00ad\u00ad\u00ad\u00adma\u00ad\u00ad\u00ad\u00adtion()     (see: 3e763a8, is\u00ad\u00ad\u00ad\u00adsues 1376, 1727). This was changed so that it no longer over\u00adrides the built-in     sum(). The un\u00ade\u00ad\u00ad\u00adval\u00adu\u00adat\u00aded sum\u00ad\u00ad\u00ad\u00adma\u00ad\u00ad\u00ad\u00adtion is still called     Sum().Re\u00ad\u00ad\u00ad\u00adnamed     ab\u00ads()     to     Ab\u00ads()     (see: 64a12a4, is\u00ad\u00ad\u00ad\u00adsue 1727). This was al\u00ad\u00ad\u00ad\u00adso changed so that it no longer over\u00adrides the built-in     ab\u00ads(). Note that be\u00ad\u00ad\u00ad\u00adcause of     abs     mag\u00adic, you can still do     ab\u00ads(\u00adex\u00adpr)     with the built-in     ab\u00ads(), and it will re\u00ad\u00ad\u00ad\u00adturn     Ab\u00ads(\u00adex\u00adpr).Re\u00ad\u00ad\u00ad\u00adnamed     max_()     and     min_()     to now     Max()     and     Min()     (see: 99a271e, is\u00ad\u00ad\u00ad\u00adsue 2153)Changed be\u00adhav\u00adiour of     sym\u00adbol\u00ads().     sym\u00adbol\u00ads('xyz')     gives now a sin\u00ad\u00ad\u00ad\u00adgle sym\u00adbol ('xyz'), not three ('x',     'y'     and     'z') (see: f6452a8). Usesym\u00adbol\u00ads('x,y,z')     or     sym\u00adbol\u00ads('x y z')     to get three sym\u00adbol\u00ads. The 'each_char' op\u00ad\u00ad\u00ad\u00adtion will still work but is be\u00ading de\u00adp\u00adre\u00ad\u00ad\u00ad\u00adcat\u00aded.Split class     Ba\u00adsic     in\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adto new class\u00ades     Ex\u00adpr,     Bool\u00adean     (see: a0ab479, 635d89c). Class\u00ades that are de\u00adsigned to be part of stan\u00ad\u00ad\u00ad\u00addard sym\u00adbol\u00adic ex\u00adpres\u00ad\u00ad\u00ad\u00adsions (like     x2sin(x)) should sub\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adclass from     Ex\u00adpr. More gen\u00ader\u00adic ob\u00ad\u00ad\u00ad\u00adjects that do not work in sym\u00adbol\u00adic ex\u00adpres\u00ad\u00ad\u00ad\u00adsions but still want the ba\u00adsic SymPy struc\u00ad\u00ad\u00ad\u00adture like     .args     and ba\u00adsic meth\u00adods like     .sub\u00ad\u00ad\u00ad\u00ads()     should on\u00ad\u00ad\u00ad\u00adly sub\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adclass from     Ba\u00adsic.as_ba\u00adsic()     method was re\u00ad\u00ad\u00ad\u00adnamed to     as_\u00adex\u00adpr()     to re\u00adflect changes in the core (see: e61819d, 80d\u00adfe91)Meth\u00adods     as_\u00ad\u00ad\u00ad\u00adco\u00ade\u00adf\u00adf_terms     and     as_\u00ad\u00ad\u00ad\u00adco\u00ade\u00adf\u00adf_\u00ad\u00ad\u00ad\u00adfac\u00ad\u00ad\u00ad\u00adtors     were re\u00ad\u00ad\u00ad\u00adnamed to     as_\u00ad\u00ad\u00ad\u00adco\u00ade\u00adf\u00adf_\u00ad\u00ad\u00ad\u00admul     and     as_\u00ad\u00ad\u00ad\u00adco\u00ade\u00adf\u00adf_add, re\u00adspec\u00ad\u00ad\u00ad\u00adtive\u00ad\u00ad\u00ad\u00adly.Re\u00ad\u00ad\u00ad\u00admoved the     trim()     func\u00ad\u00ad\u00ad\u00adtion. The func\u00ad\u00ad\u00ad\u00adtion is re\u00ad\u00ad\u00ad\u00addun\u00ad\u00ad\u00ad\u00addant with the new polys (see be\u00adlow). Use the     can\u00adcel()     func\u00ad\u00ad\u00ad\u00adtion in\u00ad\u00ad\u00ad\u00adstead.Ma\u00adjor ChangesPolysNew in\u00ad\u00ad\u00ad\u00adter\u00ad\u00ad\u00ad\u00adnal rep\u00adre\u00adsen\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtions of dense and sparse poly\u00adno\u00admi\u00adals (see: 6aecd\u00adb7, 31c9aa4)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded al\u00ad\u00ad\u00ad\u00adgo\u00adrithms for re\u00adal and com\u00ad\u00ad\u00ad\u00adplex root iso\u00adla\u00ad\u00ad\u00ad\u00adtion and coun\u00adt\u00ading (see: 3a\u00ad\u00ad\u00ad\u00adcac67, 4b75\u00ad\u00ad\u00ad\u00addae, fa1206e, 103b928, 45c9b22, 8870c8b, b348b30)Im\u00adproved Gr\u00f6b\u00adn\u00ader bases al\u00ad\u00ad\u00ad\u00adgo\u00adrithm (see: ff65e9f, 891e4de, 310a585)Field iso\u00ad\u00ad\u00ad\u00admor\u00adphism al\u00ad\u00ad\u00ad\u00adgo\u00adrithm (see: b097b01, 08482bf)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded ef\u00ad\u00ad\u00ad\u00adfi\u00ad\u00ad\u00ad\u00adcient or\u00adthog\u00ado\u00ad\u00ad\u00ad\u00adnal poly\u00adno\u00admi\u00adals (see: b8f\u00adb\u00add59)Added con\u00ad\u00ad\u00ad\u00adfig\u00adu\u00adra\u00ad\u00ad\u00ad\u00adtion frame\u00ad\u00ad\u00ad\u00adwork for polys (see: 33d8cd\u00adb, 7e\u00adb81c9)Func\u00ad\u00ad\u00ad\u00adtion for com\u00adput\u00ading min\u00adi\u00ad\u00ad\u00ad\u00admal poly\u00adno\u00admi\u00adals (see: 88bf187, f800f95)Func\u00ad\u00ad\u00ad\u00adtion for gen\u00ader\u00adat\u00ading Vi\u00adete's for\u00ad\u00ad\u00ad\u00admu\u00adlas (see: 1027408)root\u00ads()     sup\u00ad\u00ad\u00ad\u00adports more class\u00ades of poly\u00adno\u00admi\u00adals (e.g. cy\u00ad\u00ad\u00ad\u00adclo\u00ad\u00ad\u00ad\u00adtomic) (see: d8c8768, 75c8d2d)Added a func\u00ad\u00ad\u00ad\u00adtion for rec\u00adog\u00adniz\u00ading cy\u00ad\u00ad\u00ad\u00adclo\u00ad\u00ad\u00ad\u00adtom\u00adic poly\u00adno\u00admi\u00adals (see: b9c2a9a)Added a func\u00ad\u00ad\u00ad\u00adtion for com\u00adput\u00ading Horner form of poly\u00adno\u00admi\u00adals (see: 8d235c7)Added a func\u00ad\u00ad\u00ad\u00adtion for com\u00adput\u00ading sym\u00admet\u00adric re\u00ad\u00ad\u00ad\u00adduc\u00ad\u00ad\u00ad\u00adtions of poly\u00adno\u00admi\u00adals (see: 6d560f3)Added gen\u00ader\u00ada\u00ad\u00ad\u00ad\u00adtors of Swin\u00adn\u00ader\u00ad\u00ad\u00ad\u00adton-Dy\u00ader, cy\u00ad\u00ad\u00ad\u00adclo\u00ad\u00ad\u00ad\u00adtomic, sym\u00admet\u00adric, ran\u00ad\u00ad\u00ad\u00addom and in\u00ad\u00ad\u00ad\u00adter\u00adpo\u00adlat\u00ading poly\u00adno\u00admi\u00adals (see: dad03d\u00add, 6c\u00adcf20c, dc728d6, 2f17684, 3004d\u00adb8)Added a func\u00ad\u00ad\u00ad\u00adtion com\u00adput\u00ading iso\u00adla\u00ad\u00ad\u00ad\u00adtion in\u00ad\u00ad\u00ad\u00adter\u00ad\u00ad\u00ad\u00advals of al\u00adge\u00adbra\u00adic num\u00adbers (see: 37a58f1)Poly\u00adno\u00admi\u00adal di\u00advi\u00ad\u00ad\u00ad\u00adsion (di\u00adv(),     rem(),     quo()) now de\u00ad\u00ad\u00ad\u00adfaults to a field (see: a72d188)Added wrap\u00adpers for nu\u00admer\u00adi\u00ad\u00ad\u00ad\u00adcal root find\u00ad\u00ad\u00ad\u00ading al\u00ad\u00ad\u00ad\u00adgo\u00adrithms (see: 0d98945, f638fcf)Added sym\u00adbol\u00adic ca\u00ad\u00ad\u00ad\u00adpa\u00ad\u00ad\u00ad\u00adbil\u00adi\u00adties to     fac\u00ad\u00ad\u00ad\u00adtor(),     sqf()     and re\u00adlat\u00aded func\u00ad\u00ad\u00ad\u00adtions (see: d521c7f, 548120b, f6f74e6, b1c49cd, 3527b64)to\u00adgeth\u00ad\u00ad\u00ad\u00ader()     was sig\u00adnif\u00adi\u00ad\u00ad\u00ad\u00adcan\u00adt\u00ad\u00ad\u00ad\u00adly im\u00adproved (see: dc327fe)Added sup\u00ad\u00ad\u00ad\u00adport for it\u00ader\u00adable con\u00ad\u00ad\u00ad\u00adtain\u00aders to     gcd()     and     lcm()     (see: e920870)Added a func\u00ad\u00ad\u00ad\u00adtion for con\u00adstruc\u00adt\u00ading do\u00ad\u00ad\u00ad\u00admains from co\u00ade\u00adf\u00ad\u00ad\u00ad\u00adfi\u00ad\u00ad\u00ad\u00adcient con\u00ad\u00ad\u00ad\u00adtain\u00aders (see: a8f20e6)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded great\u00adest fac\u00ad\u00ad\u00ad\u00adto\u00adri\u00adal fac\u00ad\u00ad\u00ad\u00adtor\u00adiza\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adtion (see: d4d\u00adb\u00adb\u00adb5)Added par\u00ad\u00ad\u00ad\u00adtial frac\u00ad\u00ad\u00ad\u00adtion de\u00ad\u00ad\u00ad\u00adcom\u00adpo\u00adsi\u00ad\u00ad\u00ad\u00adtion al\u00ad\u00ad\u00ad\u00adgo\u00adrithm based on un\u00adde\u00adter\u00admined co\u00ade\u00adf\u00ad\u00ad\u00ad\u00adfi\u00ad\u00ad\u00ad\u00adcient ap\u00adproach (see: 9769d49, 496f08f)RootOf     and     Root\u00ad\u00ad\u00ad\u00adSum     were sig\u00adnif\u00adi\u00ad\u00ad\u00ad\u00adcan\u00adt\u00ad\u00ad\u00ad\u00adly im\u00adproved (see: f3e432, 4c88be6, 41502d7)Added sup\u00ad\u00ad\u00ad\u00adport for gmpy (GNU Mul\u00adti\u00ad\u00ad\u00ad\u00adple Pre\u00ad\u00ad\u00ad\u00adci\u00ad\u00ad\u00ad\u00adsion Arith\u00admet\u00adic Li\u00adbrary) (see: 38e1683)Al\u00adlow to com\u00adpile     sympy.polys     with Cython (see: af\u00adb3886)Im\u00adproved con\u00ad\u00ad\u00ad\u00adfig\u00adu\u00adra\u00ad\u00ad\u00ad\u00adtion of var\u00adi\u00adables in     Poly     (see: 22c4061)Added doc\u00adu\u00ad\u00ad\u00ad\u00admen\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtion based on West\u00ad\u00ad\u00ad\u00ader's ex\u00adam\u00ad\u00ad\u00ad\u00adples (see: 1c23792)Ir\u00adre\u00ad\u00ad\u00ad\u00adducibil\u00adi\u00ad\u00ad\u00ad\u00adty test\u00ading over fi\u00adnite fields (see: 17e8f1f)Al\u00adlow sym\u00admet\u00adric and non-sym\u00admet\u00adric rep\u00adre\u00adsen\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtions over fi\u00adnite fields (see: 60f\u00adbf\u00adf4)More con\u00ad\u00ad\u00ad\u00adsis\u00ad\u00ad\u00ad\u00adtent fac\u00ad\u00ad\u00ad\u00adtor\u00adiza\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adtion forms from     fac\u00ad\u00ad\u00ad\u00adtor()     and     sqf()     (see: 5d\u00adf77f5)Added sup\u00ad\u00ad\u00ad\u00adport for au\u00ad\u00ad\u00ad\u00adto\u00ad\u00ad\u00ad\u00admat\u00adic recog\u00adni\u00ad\u00ad\u00ad\u00adtion al\u00adge\u00adbra\u00adic ex\u00adten\u00ad\u00ad\u00ad\u00adsions (see: 7de602c)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded Collins' mod\u00ad\u00ad\u00ad\u00adu\u00adlar al\u00ad\u00ad\u00ad\u00adgo\u00adrithm for com\u00adput\u00ading re\u00ad\u00ad\u00ad\u00adsul\u00ad\u00ad\u00ad\u00adtants (see: 950969b)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded Berlekam\u00adp's al\u00ad\u00ad\u00ad\u00adgo\u00adrithm for fac\u00ad\u00ad\u00ad\u00adtor\u00adiza\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adtion over fi\u00adnite fields (see: 70353e9)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded Trager's al\u00ad\u00ad\u00ad\u00adgo\u00adrithm for fac\u00ad\u00ad\u00ad\u00adtor\u00adiza\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adtion over al\u00adge\u00adbra\u00adic num\u00adber fields (see: bd0be06)Im\u00adproved Wang's al\u00ad\u00ad\u00ad\u00adgo\u00adrithm for ef\u00ad\u00ad\u00ad\u00adfi\u00ad\u00ad\u00ad\u00adcient fac\u00ad\u00ad\u00ad\u00adtor\u00adiza\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adtion of mul\u00adti\u00ad\u00ad\u00ad\u00advar\u00adi\u00adate poly\u00adno\u00admi\u00adals (see: 425e225)Quan\u00ad\u00ad\u00adtumSym\u00adbol\u00adic, ab\u00ads\u00ad\u00ad\u00adtract dirac no\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtion in     sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum. This in\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adcludes op\u00ader\u00ada\u00ad\u00ad\u00ad\u00adtors, states (bras and ket\u00ads), com\u00ad\u00ad\u00ad\u00admu\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtors, an\u00adti\u00ad\u00ad\u00ad\u00adcom\u00ad\u00ad\u00ad\u00admu\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtors, dag\u00adger, in\u00ad\u00ad\u00ad\u00adn\u00ader prod\u00aduc\u00adt\u00ads, out\u00ad\u00ad\u00ad\u00ader prod\u00aduc\u00adt\u00ads, ten\u00ad\u00ad\u00ad\u00adsor prod\u00aducts and Hilbert spa\u00adcesSym\u00adbol\u00adic quan\u00ad\u00ad\u00ad\u00adtum com\u00adput\u00ading frame\u00ad\u00ad\u00ad\u00adwork that is based on the gen\u00ader\u00adal ca\u00ad\u00ad\u00ad\u00adpa\u00ad\u00ad\u00ad\u00adbil\u00adi\u00adties in     sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum. This in\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adcludes qubits (sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum.qubit), gates (sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum.\u00ad\u00ad\u00ad\u00adgate), Grover's al\u00ad\u00ad\u00ad\u00adgo\u00adrithm (sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum.\u00ad\u00ad\u00ad\u00adgrover), the quan\u00ad\u00ad\u00ad\u00adtum Fouri\u00ader tran\u00ads\u00ad\u00ad\u00ad\u00adform (sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum.qft), Shor's al\u00ad\u00ad\u00ad\u00adgo\u00adrithm (sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum.shor) and cir\u00adcuit plot\u00adt\u00ading (sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum.\u00ad\u00ad\u00ad\u00adcir\u00adcuit\u00ad\u00ad\u00ad\u00adplot)Sec\u00adond quan\u00adti\u00adza\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adtion frame\u00ad\u00ad\u00ad\u00adwork that in\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adclues cre\u00ada\u00ad\u00ad\u00adtion/ani\u00adhi\u00adla\u00ad\u00ad\u00ad\u00adtion op\u00ader\u00ada\u00ad\u00ad\u00ad\u00adtors for both Fer\u00ad\u00ad\u00admi\u00adons and Bosons and Wick\u00ad\u00ad\u00ad\u00ad's the\u00ado\u00adrem for Fer\u00ad\u00ad\u00admi\u00adons (sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.sec\u00adondquant).Sym\u00adbol\u00adic quan\u00ad\u00ad\u00ad\u00adtum an\u00adgu\u00adlar mo\u00ad\u00ad\u00ad\u00admen\u00ad\u00ad\u00ad\u00adtum (spin) al\u00adge\u00adbra (sympy.\u00ad\u00ad\u00ad\u00adphysic\u00ads.quan\u00ad\u00ad\u00ad\u00adtum.spin)Hy\u00ad\u00ad\u00ad\u00addro\u00ad\u00ad\u00ad\u00adgen wave func\u00ad\u00ad\u00ad\u00adtions (Schroedinger) and en\u00ader\u00ad\u00ad\u00ad\u00adgies (both Schroedinger and Dirac)Wave func\u00ad\u00ad\u00ad\u00adtions and en\u00ader\u00ad\u00ad\u00ad\u00adgies for 1D har\u00ad\u00ad\u00ad\u00admon\u00adic os\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adcil\u00adla\u00ad\u00ad\u00ad\u00adtorWave func\u00ad\u00ad\u00ad\u00adtions and en\u00ader\u00ad\u00ad\u00ad\u00adgies for 3D spher\u00adi\u00ad\u00ad\u00ad\u00adcal\u00ad\u00ad\u00ad\u00adly sym\u00admet\u00adric har\u00ad\u00ad\u00ad\u00admon\u00adic os\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adcil\u00adla\u00ad\u00ad\u00ad\u00adtorWign\u00ader and Cle\u00adb\u00adsch Gor\u00ad\u00ad\u00ad\u00addan co\u00ade\u00adf\u00ad\u00ad\u00ad\u00adfi\u00ad\u00ad\u00ad\u00adcientsEv\u00adery\u00adthing elseIm\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00adment symar\u00adray, pro\u00advid\u00ading numpy nd-ar\u00adrays of sym\u00adbol\u00ads.up\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00addate mp\u00ad\u00ad\u00ad\u00admath to 0.16Add a ten\u00ad\u00ad\u00ad\u00adsor mod\u00ad\u00ad\u00ad\u00adule (see:     http://\u00ad\u00ad\u00ad\u00adcode.\u00ad\u00ad\u00ad\u00adgoogle.\u00ad\u00ad\u00ad\u00adcom/p/sympy/wik\u00adi/\u00ad\u00ad\u00ad\u00adCode\u00ad\u00ad\u00ad\u00adGen\u00ader\u00ada\u00ad\u00ad\u00ad\u00adtion\u00adRe\u00ad\u00ad\u00ad\u00adport)A lot of stuff was be\u00ading im\u00ad\u00ad\u00ad\u00adport\u00aded with     from sympy im\u00ad\u00ad\u00ad\u00adport          that should\u00adn't have been (like     sys). This has been fixed.As\u00ad\u00ad\u00adsump\u00ad\u00ad\u00adtion\u00ads:Re\u00adfineAdded pred\u00adi\u00ad\u00ad\u00ad\u00adcates (see: 7c0b857, 53f0e1a, d1d\u00add6a3..)Added query han\u00addlers for al\u00adge\u00adbra\u00adic num\u00adbers (see: f3bee7a)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00adment a SAT solver (see:     http://\u00ad\u00ad\u00ad\u00adcode.\u00ad\u00ad\u00ad\u00adgoogle.\u00ad\u00ad\u00ad\u00adcom/p/sympy/wik\u00adi/\u00ad\u00ad\u00ad\u00adSu\u00adper\u00adchargin\u00ad\u00ad\u00ad\u00adgAs\u00ad\u00ad\u00ad\u00adsump\u00ad\u00ad\u00ad\u00adtion\u00ads\u00adRe\u00ad\u00ad\u00ad\u00adport, 2d96329, acf\u00adbe75, etc.)Con\u00adcreteFi\u00ad\u00ad\u00ad\u00adnal\u00adized im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtion of Gosper's al\u00ad\u00ad\u00ad\u00adgo\u00adrithm (see: 0f187e5, 5888024)Re\u00ad\u00ad\u00ad\u00admoved re\u00ad\u00ad\u00ad\u00addun\u00ad\u00ad\u00ad\u00addant     Sum2     and re\u00adlat\u00aded class\u00ades (see: ef1f6a7)Core:Split     Atom     in\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adto     Atom     and     Atom\u00ad\u00ad\u00ad\u00adic\u00adEx\u00adpr     (see: 965aa91)Var\u00adi\u00adous     sympi\u00ad\u00ad\u00ad\u00adfy()     im\u00adprove\u00ad\u00ad\u00ad\u00admentsAdded func\u00ad\u00ad\u00ad\u00adtion\u00adal\u00adi\u00ad\u00ad\u00ad\u00adty for ac\u00ad\u00ad\u00ad\u00adtion verbs (many func\u00ad\u00ad\u00ad\u00adtions can be called both as glob\u00adal func\u00ad\u00ad\u00ad\u00adtions and as meth\u00adods e.g.     a.sim\u00ad\u00ad\u00ad\u00adpli\u00ad\u00ad\u00ad\u00adfy() == sim\u00ad\u00ad\u00ad\u00adpli\u00ad\u00ad\u00ad\u00adfy(a))Im\u00adprove han\u00addling of ra\u00ad\u00ad\u00ad\u00adtio\u00ad\u00ad\u00ad\u00adnal strings (see: 053a045, is\u00ad\u00ad\u00ad\u00adsue 1778)Ma\u00adjor changes to fac\u00ad\u00ad\u00ad\u00adtor\u00ading of in\u00ad\u00ad\u00ad\u00adte\u00adgers (see: 273f450, is\u00ad\u00ad\u00ad\u00adsue 2003)Op\u00adti\u00admized     .has()     (see: c83c9b0, is\u00ad\u00ad\u00ad\u00adsue 1980; d86d08f)Im\u00adprove\u00ad\u00ad\u00ad\u00adments to pow\u00ader (see: c8661e\u00adf, is\u00ad\u00ad\u00ad\u00adsue 1963)Added range and lex\u00adi\u00ad\u00ad\u00ad\u00adco\u00ad\u00ad\u00ad\u00adgraph\u00adic syn\u00ad\u00ad\u00ad\u00adtax to     sym\u00adbol\u00ads()     and     var()     (see: f6452a8, 9ae\u00adb220, 957745a)Added     mod\u00ad\u00ad\u00ad\u00adu\u00adlus     ar\u00adgu\u00ad\u00ad\u00ad\u00adment to     ex\u00ad\u00ad\u00ad\u00adpand()     (see: 1ea5be8)Al\u00adlow to con\u00advert     In\u00ad\u00ad\u00ad\u00adter\u00ad\u00ad\u00ad\u00adval     to re\u00adla\u00ad\u00ad\u00ad\u00adtion\u00adal form (see: 4c269fe)SymPy won't ma\u00adnip\u00adu\u00adlate mi\u00adnus sign of ex\u00adpres\u00ad\u00ad\u00ad\u00adsions any more (see: 6a26941, 9c6bf0f, e9f4a0a)Re\u00adal     and     .is_Re\u00adal     were re\u00ad\u00ad\u00ad\u00adnamed to     Float     and     .is_Float.     Re\u00adal     and     .is_Re\u00adal     still re\u00ad\u00ad\u00ad\u00admain as de\u00adp\u00adre\u00ad\u00ad\u00ad\u00adcat\u00aded short\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adcuts to     Float     andis_Float     for back\u00ad\u00ad\u00ad\u00adwards com\u00ad\u00ad\u00ad\u00adpat\u00adi\u00ad\u00ad\u00ad\u00adbil\u00adi\u00ad\u00ad\u00ad\u00adty. (see: abe1c49)Meth\u00adods co\u00ad\u00ad\u00ad\u00adeff and as_\u00ad\u00ad\u00ad\u00adco\u00ade\u00adf\u00ad\u00ad\u00ad\u00adfi\u00ad\u00ad\u00ad\u00adcient are now non-\u00ad\u00ad\u00ad\u00adcom\u00ad\u00ad\u00ad\u00admu\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtive aware. (see a4ea170)Ge\u00adom\u00ade\u00adtry:Var\u00adi\u00adous im\u00adprove\u00ad\u00ad\u00ad\u00adments to El\u00adlipseUp\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00addat\u00aded doc\u00adu\u00ad\u00ad\u00ad\u00admen\u00ad\u00ad\u00ad\u00adta\u00ad\u00ad\u00ad\u00adtion to numpy stan\u00ad\u00ad\u00ad\u00addardPoly\u00ad\u00ad\u00ad\u00adgon and Line im\u00adprove\u00ad\u00ad\u00ad\u00admentsAl\u00adlow all ge\u00adom\u00ade\u00adtry ob\u00ad\u00ad\u00ad\u00adjects to ac\u00ad\u00ad\u00ad\u00adcept a tu\u00ad\u00ad\u00ad\u00adple as     Point     argsIn\u00ad\u00ad\u00adte\u00ad\u00ad\u00adgral\u00ads:Var\u00adi\u00adous im\u00adprove\u00ad\u00ad\u00ad\u00adments (see eg. is\u00ad\u00ad\u00ad\u00adsues 1772, 1999, 1992, 1987.. etc)isympyFixed the     -p     switch (see: e8cb04a)Caching can be dis\u00ad\u00ad\u00ad\u00adabled us\u00ading     -C     switch (see: 0d8d748)Ground types can be set us\u00ading     -t     switch (see: 75734f8)Print\u00ad\u00ad\u00ad\u00ading or\u00adder\u00ading can be set us\u00ading     -o     switch (see: fc\u00adc6b13, 4ec9d\u00adc5)Log\u00adicim\u00ad\u00ad\u00ad\u00adplies ob\u00ad\u00ad\u00ad\u00adject ad\u00adheres to neg\u00ada\u00ad\u00ad\u00ad\u00adtive nor\u00ad\u00ad\u00ad\u00admal formCre\u00adate new bool\u00adean class,     log\u00adic.\u00ad\u00ad\u00ad\u00adboolal\u00adg.\u00ad\u00ad\u00ad\u00adBool\u00adeanAdded XOR op\u00ader\u00ada\u00ad\u00ad\u00ad\u00adtor () sup\u00ad\u00ad\u00ad\u00adportAdded If-then-else (ITE) sup\u00ad\u00ad\u00ad\u00adportAdded the dpll al\u00ad\u00ad\u00ad\u00adgo\u00adrithmFunc\u00ad\u00ad\u00adtion\u00ads:Added Piece\u00ad\u00ad\u00ad\u00adwise, B-s\u00ad\u00ad\u00ad\u00adplinesSpher\u00adi\u00ad\u00ad\u00ad\u00adcal Bessel func\u00ad\u00ad\u00ad\u00adtion of the sec\u00adond kind im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00adedAdd se\u00adries ex\u00ad\u00ad\u00ad\u00adpan\u00ad\u00ad\u00ad\u00adsions of mul\u00adti\u00ad\u00ad\u00ad\u00advar\u00adi\u00adate func\u00ad\u00ad\u00ad\u00adtions (see: d4d351d)Ma\u00adtri\u00adces:Add el\u00ade\u00ad\u00ad\u00ad\u00admen\u00adt\u00ad\u00ad\u00ad\u00adwise prod\u00aduct (Hadamard pro\u00ad\u00ad\u00ad\u00adduc\u00adt)Ex\u00ad\u00ad\u00ad\u00adtend\u00aded QR fac\u00ad\u00ad\u00ad\u00adtor\u00adiza\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adtion for gen\u00ader\u00adal full ranked mxn ma\u00adtri\u00adcesRe\u00ad\u00ad\u00ad\u00admove de\u00adp\u00adre\u00ad\u00ad\u00ad\u00adcat\u00aded func\u00ad\u00ad\u00ad\u00adtions     ze\u00adro(),     ze\u00adron\u00adm(),     one()     (see: 5da0884)Added cholesky and LDL fac\u00ad\u00ad\u00ad\u00adtor\u00adiza\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adtion\u00ads, and re\u00adspec\u00ad\u00ad\u00ad\u00adtive solves.Added func\u00ad\u00ad\u00ad\u00adtions for ef\u00ad\u00ad\u00ad\u00adfi\u00ad\u00ad\u00ad\u00adcient tri\u00adan\u00adgu\u00adlar and di\u00adag\u00ado\u00ad\u00ad\u00ad\u00adnal solves.SMa\u00adtrix     was re\u00ad\u00ad\u00ad\u00adnamed to     Sparse\u00ad\u00ad\u00ad\u00adMa\u00adtrix     (see: acd1685)PhysicsSee the Quan\u00ad\u00ad\u00ad\u00adtum sec\u00ad\u00ad\u00ad\u00adtionPrint\u00ad\u00ad\u00ading:Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded pret\u00ad\u00ad\u00ad\u00adty print\u00ad\u00ad\u00ad\u00ading of bi\u00adno\u00admi\u00adals (see: 58c1\u00ad\u00ad\u00ad\u00addad)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded pret\u00ad\u00ad\u00ad\u00adty print\u00ad\u00ad\u00ad\u00ading of Sum() (see: 84f2c22, 95b4321)sympy.print\u00ad\u00ad\u00ad\u00ading     now sup\u00ad\u00ad\u00ad\u00adports or\u00adder\u00ading of terms and fac\u00ad\u00ad\u00ad\u00adtors (see: 859b\u00adb33)Lex\u00adi\u00ad\u00ad\u00ad\u00adco\u00ad\u00ad\u00ad\u00adgraph\u00adic or\u00adder is now the de\u00ad\u00ad\u00ad\u00adfault. Now fi\u00ad\u00ad\u00ad\u00adnal\u00ad\u00ad\u00ad\u00adly things will print as     x2 + x + 1     in\u00ad\u00ad\u00ad\u00adstead of     1 + x + x2, how\u00adev\u00ader se\u00adries still print us\u00ading re\u00ad\u00ad\u00ad\u00adversed or\u00adder\u00ading, e.g.     x - x3/6 + O(x5). You can get the old or\u00adder (and oth\u00ad\u00ad\u00ad\u00ader or\u00adder\u00adings) by set\u00adt\u00ading the     -o     op\u00ad\u00ad\u00ad\u00adtion to isympy (see: 08b4932, a30c5a3)Se\u00adries:Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00adment a func\u00ad\u00ad\u00ad\u00adtion to cal\u00adcu\u00adlate residues,     residue()Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00adment nseries and lseries to han\u00ad\u00ad\u00ad\u00addle     x0 != 0, se\u00adries should be more ro\u00ad\u00ad\u00ad\u00adbust now (see: 2c99999, is\u00ad\u00ad\u00ad\u00adsues 2122-2124)Im\u00adprove\u00ad\u00ad\u00ad\u00adments to Gruntz al\u00ad\u00ad\u00ad\u00adgo\u00adrithmSim\u00ad\u00ad\u00adpli\u00ad\u00ad\u00adfy:Added     use()     (see: 147c142)rat\u00adsim\u00adp()     now us\u00ades     can\u00adcel()     and     re\u00ad\u00ad\u00ad\u00adduced()     (see: 108f\u00adb41)Im\u00ad\u00ad\u00ad\u00adple\u00ad\u00ad\u00ad\u00admen\u00adt\u00aded EPath (see: 696139d, bf90689)a new key\u00ad\u00ad\u00ad\u00adword     ra\u00ad\u00ad\u00ad\u00adtio\u00ad\u00ad\u00ad\u00adnal     was added to nsim\u00ad\u00ad\u00ad\u00adpli\u00ad\u00ad\u00ad\u00adfy which will re\u00ad\u00ad\u00ad\u00adplace Floats with Ra\u00ad\u00ad\u00ad\u00adtio\u00ad\u00ad\u00ad\u00adnal ap\u00adprox\u00ad\u00ad\u00ad\u00adi\u00ad\u00ad\u00ad\u00adma\u00ad\u00ad\u00ad\u00adtion\u00ads. (see: 053a045)Solver\u00ads:ODE im\u00adprove\u00ad\u00ad\u00ad\u00adments (see: d12a2aa, 3542041; 73f\u00adb9ac)Added sup\u00ad\u00ad\u00ad\u00adport for solv\u00ading in\u00ad\u00ad\u00ad\u00ade\u00adqual\u00adi\u00adties (see: 328e\u00adaba, 8455147, f8f\u00ad\u00ad\u00ad\u00adcaa7)Util\u00adi\u00adties:Im\u00adprove cartes, for gen\u00ader\u00adat\u00ading the Carte\u00adsian prod\u00aduct (see: b1b10ed)Added a func\u00ad\u00ad\u00ad\u00adtion com\u00adput\u00ading topo\u00adlog\u00adi\u00ad\u00ad\u00ad\u00adcal sort of graphs (see: b2ce27b)Al\u00adlow to set\u00adup a cus\u00ad\u00ad\u00ad\u00adtom\u00adized print\u00ad\u00ad\u00ad\u00ader in     lam\u00adb\u00add\u00adi\u00ad\u00ad\u00ad\u00adfy()     (see: c1ad905)flat\u00adten()     was sig\u00adnif\u00adi\u00ad\u00ad\u00ad\u00adcan\u00adt\u00ad\u00ad\u00ad\u00adly im\u00adproved (see: 31ed8d7)Ma\u00adjor im\u00adprove\u00ad\u00ad\u00ad\u00adments to the For\u00ad\u00ad\u00ad\u00adtran code gen\u00ader\u00ada\u00ad\u00ad\u00ad\u00adtor (see:     http://\u00ad\u00ad\u00ad\u00adcode.\u00ad\u00ad\u00ad\u00adgoogle.\u00ad\u00ad\u00ad\u00adcom/p/sympy/wik\u00adi/\u00ad\u00ad\u00ad\u00adCode\u00ad\u00ad\u00ad\u00adGen\u00ader\u00ada\u00ad\u00ad\u00ad\u00adtion\u00adRe\u00ad\u00ad\u00ad\u00adport, 3383aa3, 7ab2\u00ad\u00ad\u00ad\u00adda2, etc.)In ad\u00addi\u00ad\u00ad\u00ad\u00adtion to the more no\u00adtice\u00adable changes list\u00aded above, there have been nu\u00admer\u00adous oth\u00ad\u00ad\u00ad\u00ader smal\u00adl\u00ad\u00ader ad\u00addi\u00ad\u00ad\u00ad\u00adtion\u00ads, im\u00adprove\u00ad\u00ad\u00ad\u00adments and bug fix\u00ades in the ~2000 com\u00admits in this re\u00adlease. See the git log for a full list of all changes. The com\u00ad\u00ad\u00ad\u00admand     git log sympy-0.6.7..sympy-0.7.0     will show all com\u00admits made be\u00adtween this re\u00adlease and the last. You can al\u00ad\u00ad\u00ad\u00adso see the is\u00ad\u00ad\u00ad\u00adsues closed since the last re\u00adlease     here.Au\u00adthorsThe fol\u00adlow\u00ading peo\u00ad\u00ad\u00ad\u00adple con\u00adtrib\u00adut\u00aded at least one patch to this re\u00adlease (names are giv\u00aden in al\u00adpha\u00ad\u00ad\u00ad\u00adbet\u00adi\u00ad\u00ad\u00ad\u00adcal or\u00adder by last name). A to\u00ad\u00ad\u00ad\u00adtal of 64 peo\u00ad\u00ad\u00ad\u00adple con\u00adtrib\u00adut\u00aded to this re\u00adlease. Peo\u00ad\u00ad\u00ad\u00adple with a * by their names con\u00adtrib\u00adut\u00aded a patch for the first time for this re\u00adlease. Thir\u00ad\u00ad\u00ad\u00adty-\u00ad\u00ad\u00ad\u00adsev\u00aden peo\u00ad\u00ad\u00ad\u00adple con\u00adtrib\u00adut\u00aded for the first time for this re\u00adlease. Over half of the peo\u00ad\u00ad\u00ad\u00adple who con\u00adtrib\u00adut\u00aded to this re\u00adlease con\u00adtrib\u00adut\u00aded for the first time!Thanks to ev\u00adery\u00adone who con\u00adtrib\u00adut\u00aded to this re\u00adlease!Tom Bach\u00ad\u00ad\u00ad\u00admannTomas Bam\u00adbasMatthew BrettOnd\u0159ej \u010cert\u00edkRe\u00ad\u00ad\u00ad\u00adna\u00ad\u00ad\u00ad\u00adto Coutin\u00adhoAd\u00addi\u00ad\u00ad\u00ad\u00adson Cug\u00adi\u00adniMatt Cur\u00adryRaf\u00ad\u00ad\u00ad\u00adfaele De FeoMark Dew\u00adingThomas DixonHarold ErbinPavel Fe\u00ad\u00ad\u00ad\u00addo\u00ad\u00ad\u00ad\u00adtovGilbert GedeOlek\u00adsan\u00ad\u00ad\u00ad\u00addr Gi\u00adt\u00adu\u00adliarBri\u00adan GrangerAlex\u00adey U. Gud\u00adchenko\u00d8yvind JensenFredrik Jo\u00adhan\u00ads\u00ad\u00ad\u00ad\u00adsonFe\u00adlix KaiserYuri KaradzhovGary KerrKibeom KimNicholas J.S. Ki\u00ad\u00ad\u00ad\u00adnarAna\u00ad\u00ad\u00ad\u00adtolii Ko\u00ad\u00ad\u00ad\u00advalSe\u00adbas\u00ad\u00ad\u00ad\u00adtian Kr\u00e4merRyan KraussGre\u00ad\u00ad\u00ad\u00adgo\u00adry Ksion\u00ad\u00ad\u00ad\u00addaPri\u00adit LaesVladimir La\u00ad\u00ad\u00ad\u00adgunovRo\u00ad\u00ad\u00ad\u00adnan LamyTo\u00ad\u00ad\u00ad\u00admo La\u00ad\u00ad\u00ad\u00adzovichSap\u00ad\u00ad\u00ad\u00adtarshi Man\u00ad\u00ad\u00ad\u00addalDavid MarekJack Mc\u00ad\u00ad\u00ad\u00adCaf\u00adferyBen\u00ad\u00ad\u00ad\u00adjamin Mc\u00ad\u00ad\u00ad\u00adDon\u00adaldAaron Meur\u00aderChris\u00ad\u00ad\u00ad\u00adtian Muise\u00d3s\u00ad\u00ad\u00ad\u00adcar N\u00e1\u00ad\u00ad\u00ad\u00adjeraJezreel NgSher\u00adjil OzairMa\u00ad\u00ad\u00ad\u00adteusz Pa\u00adproc\u00ad\u00ad\u00ad\u00adkiJames Pear\u00ad\u00ad\u00ad\u00adsonFer\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00adnan\u00ad\u00ad\u00ad\u00addo PerezVladimir Per\u00adi\u0107Mario Per\u00adni\u00ad\u00ad\u00ad\u00adciNico\u00adlas Pourcelotray\u00ad\u00ad\u00ad\u00admanMatthew Rock\u00ad\u00ad\u00ad\u00adlinChris\u00ad\u00ad\u00ad\u00adtian Schu\u00adbertAn\u00ad\u00ad\u00ad\u00addre de For\u00adti\u00ader SmitChris SmithCrist\u00f3v\u00e3o SousaAk\u00adshay Srini\u00ad\u00ad\u00ad\u00advasanVinzent Stein\u00adbergPra\u00ad\u00ad\u00ad\u00adful\u00adlku\u00ad\u00ad\u00ad\u00admar P. TaleAndy R. Ter\u00adrelKazuo ThowToon Ver\u00ads\u00ad\u00ad\u00adtrae\u00adlenSean VigLu\u00ad\u00ad\u00ad\u00adca WeihsThomas Wiec\u00ad\u00ad\u00ad\u00adkiShai 'Deshe' Wybors\u00ad\u00ad\u00ad\u00adkiJeremias Yehdegho*", 
      "loc": "/posts/2011/06/29/sympy-0-7-0-released/"
    }, 
    {
      "title": "import_module (the (hopefully) last fix for 0.7.0)", 
      "tags": "", 
      "text": "So ev\u00adery\u00adthing seemed to be ready to go for the 0.7.0 re\u00adlease, when some\u00adone  point\u00aded out  a test fail\u00adure in Python 2.5.    \n It turned out that there is a bug in numpy (see the  numpy is\u00adsue page  for more in\u00adfor\u00adma\u00adtion), that was caus\u00ading the quan\u00adtum mod\u00adule to fail en\u00adtire\u00adly when im\u00adport\u00aded in Python 2.5 with numpy in\u00adstalled. \n Be\u00adcause there was no easy way around the bug, the so\u00adlu\u00adtion was to dis\u00adable numpy com\u00adplete\u00adly in Python 2.5 in the quan\u00adtum mod\u00adule.  But this en\u00adtailed writ\u00ading the fol\u00adlow\u00ading code id\u00adiom \n [code lan\u00adguage=\"python\"] \n im\u00adport sys \n im\u00adport warn\u00adings \n numpy_\u00adsup\u00adport\u00aded = True \n if sys.ver\u00adsion_in\u00adfo < (2, 6):\n    warn\u00adings.warn(\"\u00adCan\u00adnot use numpy in Python 2.4/2.5.\")\n    numpy_\u00adsup\u00adport\u00aded = False\nelse:\n    try:\n        im\u00adport numpy as np\n    ex\u00adcept Im\u00adportEr\u00adror:\n        numpy_\u00adsup\u00adport\u00aded = False\n[/\u00adcode] \n in all the half dozen files that im\u00adport numpy in the quan\u00adtum mod\u00adule.    \n So clear\u00adly, SymPy need\u00aded a more cen\u00adtral\u00adized way to han\u00addle im\u00adport\u00ading op\u00adtion\u00adal ex\u00adter\u00adnal mod\u00adules.  Hence, I wrote the  im\u00adport_\u00admod\u00adule()  func\u00adtion.  The func\u00adtion at\u00adtempts to im\u00adport a mod\u00adule giv\u00aden it's name. It re\u00adturns the mod\u00adule if it can be im\u00adport\u00aded and None if it can\u00adnot.  It sup\u00adports check\u00ading the ver\u00adsion of Python or the ver\u00adsion of the li\u00adbrary and not im\u00adport\u00ading it if ei\u00adther are too old.  It al\u00adso sup\u00adports emit\u00adting warn\u00adings when the mod\u00adule is not avail\u00adable or the ver\u00adsion is too old.  Thus, the above id\u00adiom re\u00adduces to \n [code lan\u00adguage=\"python\"] \n from sympy.ex\u00adter\u00adnal im\u00adport im\u00adport_\u00admod\u00adule \n np = im\u00adport_\u00admod\u00adule('numpy', min_python_ver\u00adsion=(2, 6)) \n [/\u00adcode] \n And that's it. The func\u00adtion will au\u00adto\u00admat\u00adi\u00adcal\u00adly warn if numpy can\u00adnot be im\u00adport\u00aded be\u00adcause the Python ver\u00adsion is too old. \n Any kind of  numpy_\u00adsup\u00adport\u00aded  vari\u00adable in the code can be re\u00adplaced by test\u00ading the  np  vari\u00adable it\u00adself, like \n [code lan\u00adguage=\"python\"] \n if np:\n    # Do some numpy stuff\nelse:\n    # np is None\n    # Do what\u00adev\u00ader you do when it is not avail\u00adable\n[/\u00adcode] \n This method has an ad\u00addi\u00adtion\u00adal ad\u00advan\u00adtage, which is that the warn\u00adings can be cus\u00adtom\u00adized by set\u00adting vari\u00adable hook\u00ads.  So, for ex\u00adam\u00adple, the test run\u00adner can dis\u00adable all warn\u00adings by do\u00ading \n [code lan\u00adguage=\"python\"] \n im\u00adport sympy.ex\u00adter\u00adnal \n sympy.ex\u00adter\u00adnal.im\u00adport\u00adtool\u00ads.WARN_OLD_VER\u00adSION = False \n sympy.ex\u00adter\u00adnal.im\u00adport\u00adtool\u00ads.WARN_NOT_IN\u00adSTALLED = False \n [/\u00adcode] \n I ac\u00adtu\u00adal\u00adly did make the test run\u00adner do this, and al\u00adso set both to True when the  SYMPY_DE\u00adBUG  en\u00advi\u00adron\u00adment vari\u00adable is set to True (by de\u00adfault,  WARN_NOT_IN\u00adSTALLED  is False and  WARN_OLD_VER\u00adSION  is True). \n There are some caveat\u00ads.  First, note that the func\u00adtion does it's mag\u00adic us\u00ading the built-in  im\u00adport()  func\u00adtion.  To im\u00adport a sub\u00admod\u00adule (like  sympy.quan\u00adtum), you need to pass some stuff to the  from\u00adlist  ar\u00adgu\u00adment of  im\u00adport().  It's al\u00adso a good idea to pass names to this if you plan to repli\u00adcate  from mod\u00adule im\u00adport stuff  (in\u00adstead of just  im\u00adport mod\u00adule), be\u00adcause some mod\u00adules use lazy im\u00adport\u00ading and oth\u00ader mag\u00adic that pre\u00advent you from ac\u00adcess\u00ading names di\u00adrect\u00adly from  mod\u00adule.stuff  with\u00adout im\u00adport\u00ading  stuff  first. \n To do this, just pass the ar\u00adgu\u00adments to  im\u00adport()  to  im\u00adport_\u00admod\u00adule()  us\u00ading the  im\u00adportkwargs  key\u00adword ar\u00adgu\u00admen\u00adt, like \n [code lan\u00adguage=\"python\"] \n from sympy.ex\u00adter\u00adnal im\u00adport im\u00adport_\u00admod\u00adule \n Do this instead of \"from matplotlib import pyplot\" or \"import matplotlib.pyplot as pyplot\"\nmat\u00adplotlib = im\u00adport_\u00admod\u00adule('\u00admat\u00adplotlib',  im\u00adportkwargs={'from\u00adlist':['py\u00adplot']}) \n py\u00adplot = mat\u00adplotlib.py\u00adplot \n [/\u00adcode] \n Sec\u00adond, for mod\u00adule ver\u00adsion check\u00ading it looks at  mod\u00adule.ver\u00adsion.  Some mod\u00adules use a dif\u00adfer\u00adent method (for ex\u00adam\u00adple, gmpy).  You can use the oth\u00ader method by pass\u00ading the prop\u00ader ar\u00adgu\u00adments to  im\u00adport_\u00admod\u00adule().  For ex\u00adam\u00adple, ver\u00adsions of gmpy low\u00ader than 1.03 have a bug that pre\u00advent its use in SymPy (ba\u00adsi\u00adcal\u00adly,  in\u00adt(large mpz)  did not au\u00adto\u00admat\u00adi\u00adcal\u00adly con\u00advert the num\u00adber to a  long).  So to im\u00adport gmpy, but on\u00adly if it's ver\u00adsion 1.03 or new\u00ader, you would use \n [code lan\u00adguage=\"python\"] \n from sympy.ex\u00adter\u00adnal im\u00adport im\u00adport_\u00admod\u00adule \n gmpy = im\u00adport_\u00admod\u00adule('gmpy', min_\u00admod\u00adule_ver\u00adsion='1.03',\n    mod\u00adule_ver\u00adsion_at\u00adtr='ver\u00adsion', mod\u00adule_ver\u00adsion_at\u00adtr_\u00adcal\u00adl_args=())\n[/\u00adcode] \n This tells it to check the ver\u00adsion of gmpy us\u00ading  gmpy.ver\u00adsion(), and to im\u00adport it on\u00adly if it's at least 1.03 (note that this works by the fact that Python lex\u00adi\u00adco\u00adgraph\u00adi\u00adcal\u00adly com\u00adpares strings and tu\u00adples, so  '1.02' < '1.03'  re\u00adturns True). \n The sympy.ex\u00adter\u00adnal mod\u00adule is com\u00adplete\u00adly in\u00adde\u00adpen\u00addent of the rest of SymPy (it does not call  sympy/init.py), so you can use it even out\u00adside of sympy with\u00adout the per\u00adfor\u00admance penal\u00adty that im\u00adport\u00ading all of sympy might bring.    \n So, hope\u00adful\u00adly this is the last is\u00adsue to fix for the 0.7.0 re\u00adlease.  You can still test it at  http\u00ads://github.\u00adcom/sympy/sympy/tree/0.7.0.  If peo\u00adple wan\u00adt, I will cre\u00adate an\u00adoth\u00ader re\u00adlease can\u00addi\u00addate.  Oth\u00ader\u00adwise, I will re\u00adlease 0.7.0 fi\u00adnal on Mon\u00adday (bar\u00adring any fur\u00adther prob\u00adlem\u00ads).", 
      "loc": "/posts/2011/06/24/import_module-the-hopefully-last-fix-for-0-7-0/"
    }, 
    {
      "title": "Fixing bugs in the release candidate", 
      "tags": "", 
      "text": "This week, I most\u00adly worked on fix\u00ading bugs that peo\u00adple found in the  re\u00adlease can\u00addi\u00addate  I re\u00adleased last week.  I dis\u00adcov\u00adered right af\u00adter re\u00adleas\u00ading it that it did not work in Python 2.4 or 2.5 be\u00adcause of a syn\u00adtax er\u00adror.  So I fixed those and cre\u00adat\u00aded SymPy 0.7.0.r\u00adc2 (source;  win\u00addows in\u00adstall\u00ader).    \n Things were go\u00ading pret\u00adty smooth\u00adly with that, un\u00adtil Re\u00adna\u00adto Coutin\u00adho dis\u00adcov\u00adered that there were test fail\u00adures in Python 2.4 on Win\u00addows, and that the tests failed if ran twice in the same ses\u00adsion (i.e., by us\u00ading  test()  in isympy).  I was able to fix the fail\u00adures re\u00adsult\u00ading from two ses\u00adsion\u00ads, which were al\u00admost all caused by a test mod\u00adi\u00adfy\u00ading some glob\u00adal val\u00adue or be\u00ading writ\u00adten in a way that did not al\u00adlow it to pass when run twice.  But I do not have a Win\u00addows ma\u00adchine, so I could\u00adn't re\u00adpro\u00adduce the Win\u00addows fail\u00adures. \n For\u00adtu\u00adnate\u00adly, yes\u00adter\u00adday, Re\u00adna\u00adto, Chris Smith, and I were able to de\u00adbug the prob\u00adlems over IR\u00adC.  The main prob\u00adlem was that sympy/\u00adcore/e\u00advalf.py had code \n [code lan\u00adguage=\"py\"] \n INF = 1e1000 \n MI\u00adNUS_INF = -1e1000 \n [/\u00adcode] \n These were in\u00adtend\u00aded to give  float('in\u00adf')  and  float('-in\u00adf'), re\u00adspec\u00adtive\u00adly (float\u00ading point in\u00adfin\u00adi\u00adty and neg\u00ada\u00adtive in\u00adfin\u00adi\u00adty). And they did do this\u2026 on all plat\u00adforms ex\u00adcept for Python 2.4 on Win\u00addows.  From what I can tell from what Chris told me, on that plat\u00adform it in\u00adstead gives 1.0.  Strange\u00adly,  float('in\u00adf')  did not give float\u00ading point in\u00adfin\u00adi\u00adty ei\u00adther.  We dis\u00adcov\u00adered that  float(mp\u00admath\u00ad_in\u00adf)  did give float\u00ading point in\u00adfin\u00adi\u00adty, where  mp\u00admath\u00ad_inf  is mp\u00admath\u00ad's in\u00adfin\u00adi\u00adty.  This of course al\u00adso works in all oth\u00ader plat\u00adform\u00ads, so chang\u00ading it made the code work ev\u00adery\u00adwhere. \n Af\u00adter that, there was on\u00adly one test fail\u00adure left in Win\u00addows (o\u00adrig\u00adi\u00adnal\u00adly there were dozens of er\u00adrors, but all but one were caused by the above prob\u00adlem).  It turns out that the  sub\u00adpro\u00adcess  mod\u00adule from the code\u00adgen mod\u00adule was caus\u00ading the test run\u00adner to fail en\u00adtire\u00adly.  Our so\u00adlu\u00adtion was to skip this test com\u00adplete\u00adly in Python 2.4 on Win\u00addows. \n So now we had all tests pass\u00ading on all plat\u00adforms with all ground type\u00ads, even if run twice from with\u00adin the same ses\u00adsion. \n But it turned out there was still one more er\u00adror lurk\u00ading, found by Re\u00adna\u00adto.  A bunch of mp\u00admath tests failed in Python 2.4 when gmpy was in\u00adstalled.  I had nev\u00ader got\u00adten gmpy to com\u00adpile, so I have on\u00adly had it in\u00adstalled on my ma\u00adchine for those Python ex\u00ade\u00adcuta\u00adbles in\u00adstalled by fink (2.5-2.7, 64-bit).    \n It turns out that mp\u00admath us\u00ades gmpy if it is in\u00adstalled.  There were a few places in the code where it was do\u00ading things like line 1947 of mp\u00admath\u00ad/libm\u00adp/gam\u00admaze\u00adta.py, shown be\u00adlow: \n [code lan\u00adguage=\"py\"] \n re\u00adturn mpf_\u00adpos(s\u00admal\u00adl\u00ad_\u00adfac\u00adto\u00adri\u00adal_\u00adcache[n-1], prec, rnd) \n [/\u00adcode] \n The prob\u00adlem was that  n  was an  mpz, or gmpy in\u00adte\u00adger.  But Python 2.4 and ealier do not sup\u00adport non-int types as the in\u00addex to list\u00ads.  It was\u00adn't un\u00adtil Python 2.5's  in\u00addex  method that non-in\u00adt/\u00adlong types were able to be used as slice in\u00addices.    \n This id\u00adiom was be\u00ading used in sev\u00ader\u00adal places through\u00adout the code, so rather than try to patch them al\u00adl, we de\u00adcid\u00aded to just dis\u00adable the gmpy back\u00adend in mp\u00admath for Python 2.4.  This is\u00adsue had nev\u00ader come up be\u00adfore to my knowl\u00adedge, so it seems that he was the first per\u00adson to run the mp\u00admath tests in Python 2.4 with gmpy in\u00adstalled.    \n So now tests should be pass\u00ading ev\u00adery\u00adwhere in the  0.7.0 branch.  Please con\u00adtin\u00adue to test it, though.  If it will make it eas\u00adi\u00ader to test, I will cre\u00adate a 0.7.0.r\u00adc3 with all the lat\u00adest fix\u00ades.  Oth\u00ader\u00adwise, bar\u00adring any fur\u00adther ma\u00adjor fix\u00ades, I will re\u00adlease 0.7.0 fi\u00adnal in about a week. \n And a big thanks for Re\u00adna\u00adto Coutin\u00adho and Chris Smith for help\u00ading me de\u00adbug and fix these bugs.", 
      "loc": "/posts/2011/06/17/fixing-bugs-in-the-release-candidate/"
    }, 
    {
      "title": "SymPy 0.7.0.rc1 is out!", 
      "tags": "", 
      "text": "My blog post is a lit\u00adtle late this week be\u00adcause I want\u00aded to be able to an\u00adnounce this.  I have re\u00adleased the first re\u00adlease can\u00addi\u00addate for SymPy 0.7.0 (see  this pre\u00advi\u00adous blog post  for a lit\u00adtle bit of what's new since the last re\u00adlease).  You can down\u00adload source (Lin\u00adux/\u00adMac OS X ver\u00adsion)  here  and the Win\u00addows in\u00adstall\u00ader  here.  Please down\u00adload it at test it. \n Un\u00adfor\u00adtu\u00adnate\u00adly, I dis\u00adcov\u00adered soon af\u00adter re\u00adleas\u00ading it that the code does not work in Python 2.4 or 2.5.  I will soon re\u00adlease SymPy 0.7.0.r\u00adc2 to fix this. Please test it in Python 2.6 and 2.7 un\u00adtil then, or test the  0.7.0 branch  of the of\u00adfi\u00adcial SymPy repos\u00adi\u00adto\u00adry. \n If ev\u00adery\u00adthing goes smooth\u00adly, then the full re\u00adlease should be out in a week or so.  Watch this blog or the  of\u00adfi\u00adcial SymPy blog  for the an\u00adnounce\u00admen\u00adt.", 
      "loc": "/posts/2011/06/13/sympy-0-7-0-rc1-is-out/"
    }, 
    {
      "title": "Nondeterminism", 
      "tags": "mathjax", 
      "text": "So from Sat\u00adur\u00adday to Wednes\u00adday of this week, I was on va\u00adca\u00adtion to the Grand Canyon with\u00adout my com\u00adput\u00ader.  There\u00adfore, I did not do a whole lot with re\u00adspect to SymPy this week.  The va\u00adca\u00adtion was very fun, though.  My fam\u00adi\u00adly and I hiked to the bot\u00adtom of the Grand Canyon and stayed a day at the bot\u00adtom in a lodge at Phan\u00adtom Ranch, then hiked back up.  I would high\u00adly rec\u00adom\u00admend it to any\u00adone who does not mind do\u00ading a lit\u00adtle hik\u00ading.    \n Re\u00adgard\u00ading what I did do, oth\u00ader than catch\u00ading up on the email from when I was gone, I did some more work fin\u00adish\u00ading patch\u00ades for the re\u00adlease.  We are now  very  close to hav\u00ading a re\u00adlease.  All the re\u00admain\u00ading  block\u00ading is\u00adsues  ei\u00adther have patch\u00ades that need to be re\u00adviewed, or de\u00adci\u00adsions that need to be made. \n I al\u00adso did some work on the Risch Al\u00adgo\u00adrith\u00adm, though it was\u00adn't very much.  One of my fa\u00advorite ways to \"do work\" on the code is to stress test  risch_in\u00adte\u00adgrate()  and if I find a bug or find that it runs too slow, see what needs to be done to fix it.  This week, I dis\u00adcov\u00adered that  risch_in\u00adte\u00adgrate()  has a bit of non\u00adde\u00adter\u00admin\u00adism built in\u00adto it.  Ac\u00adtu\u00adal\u00adly, I al\u00adready knew this, but I re\u00adcent\u00adly found an ex\u00adam\u00adple that demon\u00adstrates it very nice\u00adly.  The prob\u00adlem is that when it builds the ex\u00adten\u00adsion to in\u00adte\u00adgrate the func\u00adtion,  risch_in\u00adte\u00adgrate()  us\u00ades  .atom\u00ads()  to get the parts of the ex\u00adpres\u00adsion (for ex\u00adam\u00adple,  ex\u00adpr.atom\u00ads(log)  gets all the log\u00ada\u00adrithms in  ex\u00adpr).  But  .atom\u00ads()  re\u00adturns a set (I be\u00adlieve this is for per\u00adfor\u00admance rea\u00adson\u00ads, though I'm not cer\u00adtain).  So we get things like \n Hov\u00ader over the code and click on the left\u00ad-\u00admost, \"view source\" icon (a pa\u00adper icon with  < >  over it) to view with\u00adout break\u00ads.  Opens in a new win\u00addow. \n [code lan\u00adguage=\"py\"] \n In [1]: a = Ad\u00add((log(x*i) for i in range(10))) \n In [2]: a \n Out\u00ad[2]: \n            \u239b 2\u239e      \u239b 3\u239e      \u239b 4\u239e      \u239b 5\u239e      \u239b 6\u239e      \u239b 7\u239e      \u239b 8\u239e      \u239b 9\u239e\nlog(x) + log\u239dx \u23a0 + log\u239dx \u23a0 + log\u239dx \u23a0 + log\u239dx \u23a0 + log\u239dx \u23a0 + log\u239dx \u23a0 + log\u239dx \u23a0 + log\u239dx \u23a0 \n In [3]: b = risch_in\u00adte\u00adgrate(a, x) \n In [4]: b \n Out\u00ad[4]: \n                \u239b 4\u239e\n        45\u22c5x\u22c5log\u239dx \u23a0\n-45\u22c5x + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n             4      \n[/\u00adcode] \n This is cor\u00adrec\u00adt, since we have \n [code lan\u00adguage=\"py\"] \n In [5]: ex\u00adpand(b.d\u00adif\u00adf(x) - a) \n Out\u00ad[5]: 0 \n [/\u00adcode] \n (re\u00admem\u00adber that $la\u00adtex \\log{(xn)}=n\\log{(x)}$).  The in\u00adte\u00adgral can be ex\u00adpressed in terms of any of the log\u00ada\u00adrithms in the ex\u00adpres\u00adsion.  It hap\u00adpens to be ex\u00adpressed in terms of $la\u00adtex \\log{(x4)}$ be\u00adcause that hap\u00adpened to be the first one that came out of  a.atom\u00ads(log)  dur\u00ading it\u00ader\u00ada\u00adtion.  This is prob\u00adlem\u00adat\u00adic.  First, it's not ex\u00adact\u00adly what is ex\u00adpect\u00aded.  The ide\u00adal so\u00adlu\u00adtion would be if the an\u00adswer was writ\u00adten in terms of $la\u00adtex \\log{(x)}$.    \n But it's ac\u00adtu\u00adal\u00adly worse than that.  Like I men\u00adtioned, this is non\u00adde\u00adter\u00admin\u00adis\u00adtic.  It de\u00adpends on the or\u00adder of it\u00ader\u00ada\u00adtion through a set, which is not guar\u00adan\u00adteed to be in any par\u00adtic\u00adu\u00adlar or\u00adder.  In\u00addeed, if I run the fol\u00adlow\u00ading in 32-bit Python 2.7 and again in 64-bit Python 2.7), the out\u00adput is ex\u00adact\u00adly the same ex\u00adcept for  i  = 64 to  i  = 77. \n [code lan\u00adguage=\"py\"] \n for i in range(100):\n    print risch_in\u00adte\u00adgrate(Ad\u00add((log(x*j) for j in range(i))), x)\n[/\u00adcode] \n The ac\u00adtu\u00adal out\u00adput seems to fol\u00adlow a pat\u00adtern, though it's had to dis\u00adcern ex\u00adact\u00adly what it is.  The out\u00adput for 32-bit is  http\u00ads://gist.github.\u00adcom/1008685  and the out\u00adput for 64-bit is  http\u00ads://gist.github.\u00adcom/1008684  (sor\u00adry, I for\u00adgot to print  i; just sub\u00adtract 4 from the line num\u00adber).    \n So this has got\u00adten me think\u00ading about how to re\u00adduce non\u00adde\u00adter\u00admin\u00adis\u00adm.  Clear\u00adly, I need to sort the re\u00adsult of  .atom\u00ads(), or else  risch_in\u00adte\u00adgrate()  might re\u00adturn a dif\u00adfer\u00adent (though equiv\u00ada\u00adlen\u00adt) re\u00adsult on dif\u00adfer\u00adent plat\u00adform\u00ads. Ac\u00adtu\u00adal\u00adly, I've seen  list(set)  re\u00adturn a dif\u00adfer\u00adent re\u00adsult in the  same  Python ses\u00adsion.  That means that you could po\u00adten\u00adtial\u00adly get some\u00adthing like  risch_in\u00adte\u00adgrate(\u00adex\u00adpr, x) == risch_in\u00adte\u00adgrate(\u00adex\u00adpr, x) => False! \n The prob\u00adlem is how to sort the atom\u00ads.  We re\u00adcent\u00adly added a  sort_key()  func\u00adtion that can be passed as a key to  sort\u00aded(), which is com\u00adplete\u00adly de\u00adter\u00admin\u00adis\u00adtic and plat\u00adform in\u00adde\u00adpen\u00adden\u00adt.  That would solve the de\u00adter\u00admin\u00adism prob\u00adlem, but ac\u00adtu\u00adal\u00adly, I think this re\u00adquires more thought.  The or\u00adder that the dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion is built in can af\u00adfect not on\u00adly the form of the re\u00adsult\u00ading anti\u00adderiv\u00ada\u00adtive (though it will al\u00adways be equiv\u00ada\u00adlen\u00adt, up to a con\u00adstan\u00adt), but al\u00adso the speed with which it is com\u00adput\u00aded.  To take an ex\u00adam\u00adple from  is\u00adsue 2010, the is\u00adsue about  risch_in\u00adte\u00adgrate()  (y\u00adou may al\u00adso  rec\u00adog\u00adnize  this ex\u00adam\u00adple if you are a reg\u00adu\u00adlar read\u00ader of this blog), the  han\u00addle_\u00adfirst  key\u00adword ar\u00adgu\u00adment to  risch_in\u00adte\u00adgrate()  af\u00adfects if it builds the ex\u00adten\u00adsion tow\u00ader look\u00ading for log\u00ada\u00adrithms first or ex\u00adpo\u00adnen\u00adtials first.  Which\u00adever comes last is what is in\u00adte\u00adgrat\u00aded first (the tow\u00ader is in\u00adte\u00adgrat\u00aded from the top to the bot\u00adtom).  If the last ex\u00adten\u00adsion was an ex\u00adpo\u00adnen\u00adtial, then it us\u00ades the ex\u00adpo\u00adnen\u00adtial al\u00adgo\u00adrith\u00adm.  If it was a log\u00ada\u00adrith\u00adm, then it us\u00ades the log\u00ada\u00adrithm al\u00adgo\u00adrith\u00adm.  These are com\u00adplete\u00adly dif\u00adfer\u00adent al\u00adgo\u00adrithm\u00ads, and in\u00addeed the re\u00adsults can ap\u00adpear in dif\u00adfer\u00adent forms (and some\u00adtimes, one will raise NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror while the oth\u00ader will work be\u00adcause I have im\u00adple\u00adment\u00aded the ex\u00adpo\u00adnen\u00adtial al\u00adgo\u00adrithm more com\u00adplete\u00adly than the log\u00ada\u00adrith\u00admic one).  It al\u00adso af\u00adfects the speed be\u00adcause the in\u00adte\u00adgrand might be of a dif\u00adfer\u00adent \"type\" in the dif\u00adfer\u00adent ex\u00adten\u00adsion\u00ads.  In the ex\u00adam\u00adple be\u00adlow, the an\u00adswers are dif\u00adfer\u00adent be\u00adcause it tries to make the ar\u00adgu\u00adment of the log\u00ada\u00adrith\u00admic part mon\u00adic with re\u00adspect to the ex\u00adpo\u00adnen\u00adtial or the log\u00ada\u00adrith\u00adm, re\u00adspec\u00adtive\u00adly. Al\u00adso no\u00adtice the speed dif\u00adfer\u00adence.  This can be ex\u00adas\u00adper\u00adat\u00aded more for in\u00adte\u00adgrands of dif\u00adfer\u00adent forms than this one. \n [code lan\u00adguage=\"py\"] \n In [1]: f = (x(x + 1)((x2ex\u00adp(2x2) - log(x + 1)2)2 +\n   ...: 2xex\u00adp(3x2)(x - (2x3 + 2x2 + x + 1)log(x + 1))))/((x +\n   ...: 1)log(x + 1)2 - (x3 + x2)ex\u00adp(2x2))2 \n In [2]: f \n Out\u00ad[2]: \n          \u239b                          2                                                   \u239e\n          \u239c\u239b                       2\u239e                                                   2\u239f\n          \u239c\u239c     2           2  2\u22c5x \u239f        \u239b    \u239b           2      3\u239e           \u239e  3\u22c5x \u239f\nx\u22c5(1 + x)\u22c5\u239d\u239d- log (1 + x) + x \u22c5\u212f    \u23a0  + 2\u22c5x\u22c5\u239dx - \u239d1 + x + 2\u22c5x  + 2\u22c5x \u23a0\u22c5log(1 + x)\u23a0\u22c5\u212f    \u23a0 \n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                                                2                         \n                         \u239b                                    2\u239e                          \n                         \u239c   2                  \u239b 2    3\u239e  2\u22c5x \u239f                          \n                         \u239dlog (1 + x)\u22c5(1 + x) - \u239dx  + x \u23a0\u22c5\u212f    \u23a0                            \n In [3]: risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='log') \n Out\u00ad[3]: \n       \u239b              \u239b 2\u239e\u239e                   \u239b                \u239b 2\u239e\u239e                             \n       \u239clog(1 + x)    \u239dx \u23a0\u239f                   \u239c  log(1 + x)    \u239dx \u23a0\u239f          \u239b 2\u239e               \n    log\u239c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u212f    \u239f                log\u239c- \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u212f    \u239f       2  \u239dx \u23a0               \n       \u239d    x             \u23a0                   \u239d      x             \u23a0      x \u22c5\u212f    \u22c5log(1 + x)    \nx + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - log(1 + x) - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n               2                                       2                                        2\n                                                                              2           3  2\u22c5x \n                                                                       - x\u22c5log (1 + x) + x \u22c5\u212f      \n In [4]: risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='\u00adex\u00adp') \n Out\u00ad[4]: \n       \u239b                \u239b 2\u239e\u239e                   \u239b                \u239b 2\u239e\u239e        \u239b 2\u239e             \n       \u239c                \u239dx \u23a0\u239f                   \u239c                \u239dx \u23a0\u239f        \u239dx \u23a0             \n    log\u239dlog(1 + x) + x\u22c5\u212f    \u23a0                log\u239dlog(1 + x) - x\u22c5\u212f    \u23a0     x\u22c5\u212f    \u22c5log(1 + x) \nx + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - log(1 + x) - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                2                                        2                                    2\n                                                                            2           2  2\u22c5x \n                                                                         log (1 + x) - x \u22c5\u212f      \n In [5]: %timeit risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='log') \n 1 loop\u00ads, best of 3: 1.49 s per loop \n In [6]: %timeit risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='\u00adex\u00adp') \n 1 loop\u00ads, best of 3: 1.21 s per loop \n In [7]: can\u00adcel(risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='log').d\u00adif\u00adf(x) - f) \n Out\u00ad[7]: 0 \n In [8]: can\u00adcel(risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='\u00adex\u00adp').d\u00adif\u00adf(x) - f) \n Out\u00ad[8]: 0 \n [/\u00adcode] \n So what I think I re\u00adal\u00adly need to do is to do some re\u00adsearch on what or\u00adder of build\u00ading the tow\u00ader makes it the most ef\u00adfi\u00adcien\u00adt.  Al\u00adso,  han\u00addle_\u00adfirst  needs to be mod\u00adi\u00adfied to be more dy\u00adnam\u00adic than just look\u00ading at ex\u00adpo\u00adnen\u00adtials or log\u00ada\u00adrithms first, but al\u00adso con\u00adsid\u00ader\u00ading which ex\u00adpo\u00adnen\u00adtials or log\u00ada\u00adrithms to look at first, and the oth\u00aders might be rewrit\u00adten in terms of those (this need\u00aded to be done any\u00adway to make it work for three types of ex\u00adten\u00adsion\u00ads: ex\u00adpo\u00adnen\u00adtial\u00ads, log\u00ada\u00adrithm\u00ads, and tan\u00adgents).    \n There can al\u00adso be more heuris\u00adtics for this.  Cur\u00adrent\u00adly, there are heuris\u00adtics for ex\u00adpo\u00adnen\u00adtials to pre\u00adfer rewrit\u00ading $la\u00adtex e{2x}$ as $la\u00adtex \\left\u00ad({e{x}}\\right)2$ in\u00adstead of rewrit\u00ading $la\u00adtex e{x}$ as $la\u00adtex \\sqrt{e{2x}}$ (this is nec\u00ades\u00adsary not on\u00adly for keep\u00ading things in terms of the nicer look\u00ading gcds but al\u00adso be\u00adcause  risch_in\u00adte\u00adgrate()  does\u00adn't know how to han\u00addle al\u00adge\u00adbra\u00adic ex\u00adten\u00adsions like square root\u00ads). I did\u00adn't re\u00adal\u00adize it at the time, but the corol\u00adlary heuris\u00adtic for log\u00ada\u00adrithms should try to re\u00adwrite $la\u00adtex \\log{(x2)}$ in terms of $la\u00adtex \\log{(x)}$ and not the oth\u00ader way around.  We can use the ex\u00adact same gcd al\u00adgo\u00adrithm (called  in\u00adte\u00adger_pow\u00ader\u00ads()  in  risch.py, and I now re\u00adal\u00adize that it should ac\u00adtu\u00adal\u00adly be called  in\u00adte\u00adger_\u00admul\u00adti\u00adples()) as we do for the ex\u00adpo\u00adnen\u00adtial, on\u00adly use the pow\u00aders of the ar\u00adgu\u00adments in\u00adstead of co\u00adef\u00adfi\u00adcients.  This might re\u00adquire some fac\u00adtor\u00adiza\u00adtion to do com\u00adplete\u00adly cor\u00adrect\u00adly, so it cer\u00adtain\u00adly re\u00adquires some thought.    \n Up\u00addate \n I dis\u00adcov\u00adered that there's an eas\u00adi\u00ader way to show the non\u00adde\u00adter\u00admin\u00adism of the above than run\u00adning it on dif\u00adfer\u00adent ar\u00adchi\u00adtec\u00adtures.  You just have to change the vari\u00adable of in\u00adte\u00adgra\u00adtion: \n [code lan\u00adguage=\"py\"] \n In [1]: a = Ad\u00add((log(x*i) for i in range(10))) \n In [2]: risch_in\u00adte\u00adgrate(a, x) \n Out\u00ad[2]: \n                \u239b 4\u239e\n        45\u22c5x\u22c5log\u239dx \u23a0\n-45\u22c5x + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n             4        \n In [3]: b = Ad\u00add((log(y*i) for i in range(10))) \n In [4]: risch_in\u00adte\u00adgrate(b, y) \n Out\u00ad[4]: -45\u22c5y + 45\u22c5y\u22c5log(y) \n In [5]: c = Ad\u00add((log(z*i) for i in range(10))) \n In [6]: risch_in\u00adte\u00adgrate(c, z) \n Out\u00ad[6]: \n                \u239b 2\u239e\n        45\u22c5z\u22c5log\u239dz \u23a0\n-45\u22c5z + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n             2      \n[/\u00adcode] \n Clear\u00adly the code for this needs to be do\u00ading some canon\u00adi\u00adcal\u00adiza\u00adtion.", 
      "loc": "/posts/2011/06/05/nondeterminism/"
    }, 
    {
      "title": "Update for the Beginning of the Summer", 
      "tags": "mathjax", 
      "text": "So the Google Sum\u00admer of Code cod\u00ading pe\u00adri\u00adod of\u00adfi\u00adcial\u00adly start\u00aded on Mon\u00adday, and in sol\u00adi\u00addar\u00adi\u00adty with the stu\u00addents, I will be blog\u00adging once a week about var\u00adi\u00adous things.  Some of the posts will just be about what I have done that week.  Oth\u00aders will be con\u00adtin\u00adu\u00ada\u00adtions of my Risch Al\u00adgo\u00adrithm se\u00adries of blog posts (see parts  0,  1,  2, and  3).    \n This week, I will do the for\u00admer.  I have spend the past sev\u00ader\u00adal weeks pre\u00adpar\u00ading for the re\u00adlease.  The main thing right now is to clear out  the is\u00adsues that are block\u00ading the re\u00adlease.  I merged in a branch that in\u00adclud\u00aded all of my polys re\u00adlat\u00aded fix\u00ades from my in\u00adte\u00adgra\u00adtion3 branch. Along with sim\u00adi\u00adlar branch from ear\u00adli\u00ader that had some non-polys re\u00adlat\u00aded fix\u00ades (like some fix\u00ades to the in\u00adte\u00adgral\u00ads), all of my fix\u00ades from in\u00adte\u00adgra\u00adtion3 not di\u00adrect\u00adly re\u00adlat\u00aded to my im\u00adple\u00admen\u00adta\u00adtion of the Risch Al\u00adgo\u00adrithm should no be in mas\u00adter.   \n Once those is\u00adsues are fixed, I should be ready to make a re\u00adlease can\u00addi\u00addate for the re\u00adlease.  The last re\u00adlease was over a year ago (March 2010), and we've racked up  quite a few changes  since then.  A few big ones are: \n \n       The new polys.  This is (in my opin\u00adion) the big\u00adgest change.  Be\u00adcause of the new polys, ev\u00adery\u00adthing is faster, and sim\u00adpli\u00adfi\u00adca\u00adtion is far more pow\u00ader\u00adful than it was be\u00adfore.  This is for a few rea\u00adson\u00ads.  The big\u00adgest rea\u00adson is that the new polys al\u00adlow poly\u00adno\u00admi\u00adals in any kind of ex\u00adpres\u00adsion, not just Sym\u00adbol\u00ads.  This means that you can do things like fac\u00adtor the ex\u00adpres\u00adsion $la\u00adtex \\cos2{x} + 2\\\u00adcos{x} + 1$.  As you can imag\u00adine, many sim\u00adpli\u00adfi\u00adca\u00adtions of com\u00adplex ex\u00adpres\u00adsions are noth\u00ading more than poly\u00adno\u00admi\u00adal sim\u00adpli\u00adfi\u00adca\u00adtion\u00ads, where the poly\u00adno\u00admi\u00adal is in some func\u00adtion.  \n In ad\u00addi\u00ad\u00adtion to this, the new polys have a much faster im\u00ad\u00adple\u00ad\u00admen\u00ad\u00adta\u00ad\u00adtion, and if you have gmpy in\u00ad\u00adstalled, it will use that and be even faster.  There are al\u00ad\u00adso sev\u00ader\u00adal faster al\u00ad\u00adgo\u00adrith\u00adm\u00ads, like a faster al\u00ad\u00adgo\u00adrithm for mul\u00adti\u00ad\u00advar\u00adi\u00adate fac\u00ad\u00adtor\u00adiza\u00ad\u00ad\u00adtion, that have been im\u00ad\u00adple\u00ad\u00admen\u00adt\u00aded. These all lead to blaz\u00ading fast sim\u00ad\u00adpli\u00ad\u00adfi\u00ad\u00adca\u00ad\u00adtion and poly\u00adno\u00admi\u00adal minip\u00adu\u00adla\u00ad\u00adtion in SymPy. \n <li><strong>The Quantum Module</strong>.  Unfortunatly, I can't say much about this, since I don't know anything about quantum physics.  Furthermore, at the time of the writing of this blog post, that part of the release notes hasn't been written yet.  Suffice it say that thanks to two GSoC projects from last summer (see <a href=\"http://code.google.com/p/sympy/wiki/SymbolicQMReport\" target=\"_blank\">this</a> and <a href=\"http://code.google.com/p/sympy/wiki/Quantum_Computation_Report\" target=\"_blank\">this</a> page), we now have a quantum physics module.  A lot of the stuff in that module, from my understanding, is unique to SymPy, which is very exciting.  (By the way, if you're interested in this, Brian Granger can tell you more about it).</li>\n\n<li><strong>Various backwards incompatible changes</strong>.  We've taken advantage of the fact that this will be a point release (0.7.0) to clean up some old cruft.\n\n\n\n\n    We've re\u00adnamed the func\u00adtions  ab\u00ads()  and  sum()  to  Ab\u00ads()  and  sum\u00adma\u00adtion(), re\u00adspec\u00adtive\u00adly, be\u00adcause they con\u00adflict\u00aded with built-in names (although thanks to  abs  mag\u00adic,  ab\u00ads(\u00adex\u00adpr)  will still work with the built-in  ab\u00ads()  func\u00adtion).    \n <li>This will be the last release to support Python 2.4.  This will be a big benefit to not have to support Python 2.4 anymore after this release.  There were <a href=\"http://docs.python.org/whatsnew/2.5.html\" target=\"_blank\">a ton of features</a> added in Python 2.5 that we have had to either manually re-implement (like any() and all()), or have had to do without (like the with statement).    Also, this will make porting to Python 3 much easier (this is one of our GSoC projects).  </li>\n\n\n\n<li>We split the class Basic, which is the base class of all SymPy types, into Basic and a subclass Expr.  Mathematical objects like <code>cos(x)</code> or <code>x*y*z**2</code> are instances of Expr.  Objects that do not make sense in mathematical expressions, but still want to have some of the standard SymPy methods like .args and .subs() are Basic.  For example, a Set object is Basic, but not Expr.</li></ul></li>\n\n\n\n<li><strong>Lots of little bug fixes and new features</strong>.  See the <a href=\"https://github.com/sympy/sympy/wiki/Release-Notes-for-0.7.0\" target=\"_blank\">release notes</a>.</li>\n\n\n\n\n\nOnce we have the re\u00adlease out, I plan to go back to work on the Risch Al\u00adgo\u00adrith\u00adm.  I am very close to fin\u00adish\u00ading the ex\u00adpo\u00adnen\u00adtial case, which means that once I do, any tran\u00adscen\u00adden\u00adtal el\u00ade\u00admen\u00adtary func\u00adtion built up of on\u00adly ex\u00adpo\u00adnen\u00adtial ex\u00adten\u00adsions could be in\u00adte\u00adgrat\u00aded or proven not to have an el\u00ade\u00admen\u00adtary in\u00adte\u00adgral by my al\u00adgo\u00adrith\u00adm.  I al\u00adso want to start get\u00adting the code ready to merge with the main code base, so that it can go in the next re\u00adlease (0.7.1).    \n Fi\u00adnal\u00adly, I want to an\u00adnounce that I have been se\u00adlect\u00aded for a  stu\u00addent spon\u00adsor\u00adship  to the SciPy 2011 con\u00adfer\u00adence in Austin, TX in the week of Ju\u00adly 11. Ma\u00adteusz and I will be pre\u00adsent\u00ading a tu\u00adto\u00adri\u00adal on SymPy.  This will be the first time I have ev\u00ader at\u00adtend\u00aded a con\u00adfer\u00adence, and I am very ex\u00adcit\u00aded.", 
      "loc": "/posts/2011/05/26/update-for-the-beginning-of-the-summer/"
    }, 
    {
      "title": "Advice for Future Prospective GSoC Students", 
      "tags": "", 
      "text": "So now that Google has  an\u00adnounced the re\u00adsults  of Google Sum\u00admer of Code, I want to write down some gen\u00ader\u00adal things that I no\u00adticed when re\u00adview\u00ading ap\u00adpli\u00adca\u00adtions while they are still fresh in my mind.    \n Note that none of these things ap\u00adply to any spe\u00adcif\u00adic stu\u00addent who ap\u00adplied to SymPy.  Many of these things are things that I no\u00adticed that peo\u00adple did right.    \n Most of this should ap\u00adply to any or\u00adga\u00adni\u00adza\u00adtion, though some of them might be SymPy speci\u00adfic, since that is the lens that I am view\u00ading this through.  These aren't re\u00adal\u00adly in any par\u00adtic\u00adu\u00adlar or\u00adder.    \n \n    Ful\u00adfill all the re\u00adquire\u00adments.  This is kind of a no brain\u00ader, and as it turns out, al\u00admost all stu\u00addents who ap\u00adplied to SymPy did in\u00addeed do this.  For SymPy, this means that you should sub\u00admit a patch by the dead\u00adline. Oth\u00ader or\u00adga\u00adni\u00adza\u00adtions might have oth\u00ader re\u00adquire\u00adments.  If you don't ful\u00adfill the re\u00adquire\u00adments, it does\u00adn't mat\u00adter how good your ap\u00adpli\u00adca\u00adtion is; you won't be el\u00adi\u00adgi\u00adble and hence won't be ac\u00adcept\u00aded. \n     Dis\u00adcuss your pro\u00adpos\u00adal on the mail\u00ading list.  A pro\u00adpos\u00adal sub\u00admit\u00adted out of the blue has a poor chance of be\u00ading ac\u00adcept\u00aded.  First, we like to see that you will be in\u00advolved in the com\u00admu\u00adni\u00adty, and if you don't dis\u00adcuss the pro\u00adpos\u00adal at al\u00adl, it shows bad\u00adly.  Sec\u00adond, it is very like\u00adly that we will not like some\u00adthing about your pro\u00adpos\u00adal, or will have ques\u00adtions (see the next point).  If you don't dis\u00adcuss it at al\u00adl, you are mak\u00ading a shot in the dark.  Even if the pro\u00adpos\u00adal is good, it could be re\u00adject\u00aded sim\u00adply be\u00adcause it's not some\u00adthing that we feel that we wan\u00adt. And you don't want to ac\u00adci\u00adden\u00adtal\u00adly sub\u00admit a pro\u00adpos\u00adal to do some\u00adthing that has al\u00adready been im\u00adple\u00adment\u00aded.  \n It's im\u00ad\u00adpor\u00ad\u00adtant to dis\u00ad\u00ad\u00adcuss it on the pub\u00ad\u00adlic mail\u00ading list, not just with a spe\u00ad\u00adcif\u00adic men\u00ad\u00adtor.  Even if that men\u00ad\u00adtor is the ex\u00adpert on your project sub\u00ad\u00ad\u00adject and would like\u00ad\u00adly be the per\u00ad\u00adson to men\u00ad\u00adtor you if you are ac\u00ad\u00adcep\u00adt\u00aded, you need to re\u00admem\u00adber that all the men\u00ad\u00adtors re\u00adview the pro\u00ad\u00adpos\u00adals and de\u00ad\u00adcide who to ac\u00ad\u00adcep\u00adt.   Al\u00ad\u00adso, this year for SymPy, we are try\u00ading to put an em\u00adpha\u00ad\u00adsis on stu\u00ad\u00addents do\u00ading things pub\u00ad\u00adlicly with the whole com\u00ad\u00admu\u00adni\u00ad\u00adty, in\u00ad\u00adstead of just with their men\u00ad\u00adtors. \n     Ask the men\u00adtors for ad\u00advice on your pro\u00adpos\u00adal, and then fol\u00adlow it.  Again, most stu\u00addents who ap\u00adplied to SymPy were good on this one too.  We re\u00adquest that all stu\u00addents put their pro\u00adpos\u00adals on the GitHub wik\u00adi, so that the men\u00adtors can take a look at them and give ad\u00advice.  If you feel un\u00adcom\u00adfort\u00adable putting your ap\u00adpli\u00adca\u00adtion in a pub\u00adlic place, send it to some men\u00adtors pri\u00advate\u00adly.  \n But the most im\u00ad\u00adpor\u00ad\u00adtant thing here is to ac\u00ad\u00adtu\u00adal\u00ad\u00adly fol\u00adlow any ad\u00advice that the men\u00ad\u00adtors give you.  If they tell you that you should ex\u00ad\u00adpand your time\u00ad\u00adline sec\u00ad\u00adtion, you should ex\u00ad\u00adpand your time\u00ad\u00adline sec\u00ad\u00adtion.  If they tell you you should dis\u00ad\u00ad\u00adcuss the im\u00ad\u00adple\u00ad\u00admen\u00ad\u00adta\u00ad\u00adtion more, you should do that (see the next point).  If you don't fol\u00adlow the ad\u00advice, it looks to the men\u00ad\u00adtor like you did\u00adn't lis\u00adten to him, which does\u00adn't make you ap\u00ad\u00adpear like a good can\u00addi\u00ad\u00addate for ac\u00ad\u00adcep\u00ad\u00adtance.  Al\u00ad\u00adso, the things that they tell you to im\u00adprove will tend to be the things that they will look at when re\u00adview\u00ading your pro\u00ad\u00adpos\u00adal.     \n     Don't just dis\u00adcuss the the\u00ado\u00adry.  I sus\u00adpect that this may be more of a prob\u00adlem with SymPy than for oth\u00ader or\u00adga\u00adni\u00adza\u00adtion\u00ads, be\u00adcause SymPy is very math based, so many of the pro\u00adpos\u00adals to SymPy in\u00advolve com\u00adplex math\u00ade\u00admat\u00adic\u00ads. One of the big\u00adgest is\u00adsues I saw in pro\u00adpos\u00adals was that stu\u00addents dis\u00adcussed the the\u00ado\u00adry of what they want\u00aded to im\u00adple\u00adment too much and not enough of the ac\u00adtu\u00adal im\u00adple\u00admen\u00adta\u00adtion. It's easy to do this, but dis\u00adcussing the im\u00adple\u00admen\u00adta\u00adtion is ac\u00adtu\u00adal\u00adly more im\u00adpor\u00adtant than the the\u00ado\u00adry of what you want to do.  \n An easy way to do this is to give a \"fake\" ex\u00adam\u00ad\u00adple ses\u00ad\u00adsion show\u00ading how your code might work af\u00adter it is com\u00ad\u00adplet\u00aded.  For ex\u00adam\u00ad\u00adple, if you were writ\u00ading a pro\u00ad\u00adpos\u00adal for a PDE solver, you might in\u00ad\u00ad\u00adclude some\u00adthing like  \n  [code lan\u00adguage=\"py\"]  \n  >>> u = Func\u00ad\u00adtion('u')  \n  >>> # Solve the Heat Equa\u00ad\u00adtion in one di\u00ad\u00admen\u00ad\u00adsion  \n  >>> pde\u00ads\u00adolve(u(x, t).d\u00adif\u00adf(t) - c*2u(x, t).d\u00adif\u00adf(x, x), u(x), {u(x, 0):f(x), u(0, t):0, u(0, pi):0}, method\u00ad\u00ad='sep\u00ada\u00adra\u00ad\u00adtion of var\u00adi\u00adables')     \n  2/piSum(In\u00adte\u00ad\u00adgral(f(x)sin(nx), x)sin(nx)ex\u00adp(-n2*c2*t), (n, 1, oo))  \n  >>> # Use Fouri\u00ader Tran\u00ads\u00ad\u00adforms to get d'Alem\u00adbert's So\u00adlu\u00ad\u00adtion to the Wave Equa\u00ad\u00adtion  \n  >>> \u2026  \n  [/\u00ad\u00adcode]  \n  in your pro\u00ad\u00adpos\u00adal.  Just say\u00ading \"I plan to im\u00ad\u00adple\u00ad\u00adment solvers for PDEs us\u00ading sep\u00ada\u00adra\u00ad\u00adtion of var\u00adi\u00adables and Fouri\u00ader Tran\u00ads\u00ad\u00adfor\u00adm\u00ads\" tells us on\u00ad\u00adly what we al\u00adready know, which is that you can solve PDEs us\u00ading sep\u00ada\u00adra\u00ad\u00adtion of var\u00adi\u00adables and Fouri\u00ader Tran\u00ads\u00ad\u00adfor\u00adm\u00ads.  What we don't know is how it will look.  The above ex\u00adam\u00ad\u00adple shows how the PDE, in\u00adi\u00ad\u00adtial/bound\u00ad\u00adary con\u00addi\u00ad\u00adtion\u00ads, and method are en\u00adtered by the user, and how the out\u00ad\u00adput look\u00ads.      \n  A more ad\u00ad\u00advanced thing that you can do is to give ac\u00ad\u00adtu\u00adal pro\u00ad\u00adto\u00ad\u00adtype code. This is not re\u00adquired, but it can show that you are ded\u00adi\u00ad\u00adcat\u00aded enough to get a start, and can de\u00admon\u00ads\u00adtrate how things will work for more com\u00ad\u00adpli\u00ad\u00adcat\u00aded pro\u00adjec\u00adt\u00ads. \n     But the\u00ado\u00adry is im\u00adpor\u00adtant too.  This might al\u00adso be a prob\u00adlem more in SymPy, but maybe not.  The math\u00ade\u00admat\u00adi\u00adcal back\u00adgrounds of SymPy de\u00advel\u00adop\u00aders ranges quite a bit.  For ex\u00adam\u00adple, I know a lot about the com\u00adpli\u00adcat\u00aded Risch Al\u00adgo\u00adrithm for sym\u00adbol\u00adic in\u00adte\u00adgra\u00adtion that the ma\u00adjor\u00adi\u00adty of peo\u00adple (even among SymPy de\u00advel\u00adop\u00ader\u00ads) know hard\u00adly any\u00adthing about, but I know ba\u00adsi\u00adcal\u00adly noth\u00ading about quan\u00adtum me\u00adchan\u00adic\u00ads.  So that more men\u00adtors can have a chance to even have a clue about what you are talk\u00ading about when they are re\u00adview\u00ading your pro\u00adpos\u00adal, you should try to ex\u00adplain things to a gen\u00ader\u00adal au\u00addi\u00adence, at least in the in\u00adtro\u00adduc\u00adtion of your pro\u00adpos\u00adal.  It can al\u00adso help to ex\u00adplain why your project would be use\u00adful, so that even if some\u00adone does\u00adn't know what it is, they can see why it would be nice to have.  This does\u00adn't mean that you should sac\u00adri\u00adfice de\u00adtails by dumb\u00ading ev\u00adery\u00adthing down.  There's a pret\u00adty good chance that some\u00adone will un\u00adder\u00adstand what you are talk\u00ading about in your specific\u00ads, but you should al\u00adso ex\u00adplain things from the oth\u00ader end.\n If you are im\u00ad\u00adple\u00ad\u00admen\u00adt\u00ading a spe\u00ad\u00adcif\u00adic al\u00ad\u00adgo\u00adrith\u00adm, maybe you could give a brief over\u00adview of the al\u00ad\u00adgo\u00adrith\u00adm.  This will not on\u00ad\u00adly ex\u00ad\u00adplain things to the men\u00ad\u00adtors who might not know how it work\u00ads, but al\u00ad\u00adso it shows that you know how it works too. \n     Be in\u00advolved in the com\u00admu\u00adni\u00adty.  We un\u00adder\u00adstand that stu\u00addents have class\u00ades dur\u00ading the ap\u00adpli\u00adca\u00adtion pe\u00adri\u00adod, but the more you in\u00advolve your\u00adself in the com\u00admu\u00adni\u00adty be\u00adyond the patch re\u00adquire\u00adment (or what\u00adev\u00ader re\u00adquire\u00adment some oth\u00ader org might have), the bet\u00adter your chances of be\u00ading ac\u00adcept\u00aded. Ev\u00adery org has to take risks ac\u00adcept\u00ading stu\u00addents, be\u00adcause there is al\u00adways the chance that they will fail.  This is not good for any\u00adone: the stu\u00addent does\u00adn't get paid the full stipend and the or\u00adga\u00adni\u00adza\u00adtion loos\u00ades not on\u00adly the project that would have been im\u00adple\u00adment\u00aded, but al\u00adso the slot that they could have giv\u00aden to some\u00adone who would\u00adn't have failed.  In\u00advolv\u00ading your\u00adself in the com\u00admu\u00adni\u00adty ear\u00adly is the best way to show the com\u00admu\u00adni\u00adty that you are a low risk for fail\u00adure. \n     The pro\u00adpos\u00adal is the most im\u00adpor\u00adtant thing.  But don't as\u00adsume that just be\u00adcause you are in\u00advolved in the com\u00admu\u00adni\u00adty that you will be ac\u00adcept\u00aded.  The most im\u00adpor\u00adtant thing is the pro\u00adpos\u00adal.  If you don't have a good pro\u00adpos\u00adal, we will not even con\u00adsid\u00ader the rest of your ac\u00adtiv\u00adi\u00adty.  So you should fo\u00adcus most of your en\u00ader\u00adgy on writ\u00ading a high qual\u00adi\u00adty pro\u00adpos\u00adal.  The qual\u00adi\u00adty of the patch and your in\u00advolve\u00adment in the com\u00admu\u00adni\u00adty are sec\u00adondary con\u00adsid\u00ader\u00ada\u00adtions af\u00adter the qual\u00adi\u00adty of the pro\u00adpos\u00adal.  These might be used to nar\u00adrow down the list of good pro\u00adpos\u00adals to fit the num\u00adber of slots Google gives us and the num\u00adber of men\u00adtors we have avail\u00adable, but the first phase is al\u00adways to nar\u00adrow down the list based on the qual\u00adi\u00adty of the pro\u00adpos\u00adal\u00ads. \n     Use a con\u00adsis\u00adtant nick\u00adname, prefer\u00adably one based on your re\u00adal name.   This is some\u00adthing that I think most peo\u00adple do not re\u00adal\u00adize.  If your re\u00adal name is John Smith, and your IRC nick, GitHub han\u00addle, Google Code han\u00addle, and GSoC link_id are all jsmith, it makes it very easy for me to as\u00adso\u00adciate in my mind: \"OK, that per\u00adson who just sub\u00admit\u00adted that patch is the same per\u00adson I talked to on IRC last week, and I re\u00admem\u00adber read\u00ading his pro\u00adpos\u00adal on google-me\u00adlange.\u00adcom.\"  But if your re\u00adal name is John Smith, your IRC nick is free\u00adbird, your GitHub han\u00addle is mr.nice, your Google Code han\u00addle is smithy, and your link_id on google-me\u00adlange.\u00adcom is johnh\u00adsmith, I can have a very hard time as\u00adso\u00adci\u00adat\u00ading your work in one place with your work in an\u00adoth\u00ader (my apolo\u00adgies if those are any\u00adbodys' re\u00adal nick\u00adnames; I just made them up to make the point here).  Maybe you ac\u00adtu\u00adal\u00adly have been very ac\u00adtive in the IRC chan\u00adnel, but it is hard for me to re\u00adal\u00adize that based on your nick vs. your re\u00adal name.  This year for SymPy, we had 25 ap\u00adpli\u00adca\u00adtions by 25 stu\u00addents.  None of these stu\u00addents were mem\u00adbers of the SymPy com\u00admu\u00adni\u00adty a few months ago.  It's very hard for the oth\u00ader men\u00adtors and I to keep track of which nick\u00adnames as\u00adso\u00adciate with which peo\u00adple, and in the end, we may mis\u00adtak\u00aden\u00adly be\u00adlieve that you haven't done as much as you re\u00adal\u00adly have.  Your best bet is to use one nick\u00adname ev\u00adery\u00adwhere, and to make it based on your re\u00adal name, so that we can eas\u00adi\u00adly tell who it is even based on the nick\u00adname.  If your name is com\u00admon enough that no one per\u00admu\u00adta\u00adtion is guar\u00adan\u00adteed to be avail\u00adable ev\u00adery\u00adwhere, at least try to be con\u00adsis\u00adtent with your nick\u00adname, or just use dif\u00adfer\u00adent per\u00admu\u00adta\u00adtions of your re\u00adal name based on what site you are on. \n \nThat's all I can think of for now.  I kind of wish I had thought of two more, so I could make it \"Ten pieces of ad\u00advice,\" but what\u00adev\u00ader.  If any SymPy men\u00adtors or men\u00adtors from oth\u00ader projects feel that some\u00adthing is miss\u00ading, I would love to hear about it in the com\u00adments.", 
      "loc": "/posts/2011/04/27/advice-for-future-prospective-gsoc-students/"
    }, 
    {
      "title": "Accepted GSoC Students Announced", 
      "tags": "", 
      "text": "(Cross posted on the Official SymPy Blog)\nSo Google has announced the results of Google Summer of Code. I am proud to announce that we got nine slots from Google.  The following projects have been accepted: \n(Pro\u00adjec\u00adt, Stu\u00adden\u00adt, Men\u00adtor, Link to pro\u00adpos\u00adal on the wik\u00adi)   \n - Def\u00adi\u00adnite In\u00adte\u00adgra\u00adtion us\u00ading Mei\u00adjer G-\u00adfunc\u00adtion\u00ads, Tom Bach\u00adman\u00adn, Aaron Meur\u00ader,  Pro\u00adpos\u00adal \n \n \n Py\u00adDy, Gilbert Gede, Luke Pe\u00adter\u00ad\u00adson,   Pro\u00ad\u00adpos\u00adal  \n   \n  \n Po\u00adsi\u00ad\u00adtion and Mo\u00ad\u00admen\u00ad\u00adtum Bases for Quan\u00ad\u00adtum Me\u00adchan\u00adic\u00ads, To\u00ad\u00admo La\u00ad\u00adzovich, Bri\u00adan Granger,   Pro\u00ad\u00adpos\u00adal  \n   \n  \n Com\u00adbi\u00ad\u00adna\u00ad\u00adtorics pack\u00ad\u00adage for Sympy, Sap\u00ad\u00adtarshi Man\u00ad\u00addal, Chris\u00ad\u00adtian Muise,   Pro\u00ad\u00adpos\u00adal  \n   \n  \n Sym\u00adbol\u00adic Lin\u00adear Al\u00adge\u00adbra, Sher\u00adjil Ozair, Vinzent Stein\u00adberg,   Pro\u00ad\u00adpos\u00adal  \n   \n  \n Port\u00ading to Python 3, Vladimir Per\u00adi\u0107, Ro\u00ad\u00adnan Lamy,   Pro\u00ad\u00adpos\u00adal  \n   \n  \n SymPy Stat\u00ads: Ran\u00ad\u00addom Var\u00adi\u00adables, Matthew Rock\u00ad\u00adlin, Andy Ter\u00adrel,   Pro\u00ad\u00adpos\u00adal  \n   \n  \n Sym\u00adbol\u00adic Cle\u00adb\u00adsch-\u00ad\u00adGor\u00ad\u00addon co\u00ade\u00adf\u00ad\u00adfi\u00ad\u00adcients/Wign\u00ader sym\u00adbols and Im\u00ad\u00adple\u00ad\u00admen\u00adt\u00ading Ad\u00addi\u00ad\u00adtion of Spin An\u00adgu\u00adlar Mo\u00ad\u00admen\u00ad\u00adta, Sean Vig, Ond\u0159ej \u010cert\u00edk,   Pro\u00ad\u00adpos\u00adal  \n   \n  \n Im\u00ad\u00adple\u00ad\u00admen\u00adt\u00ading F5, Jeremias Yehdegho, Ma\u00ad\u00adteusz Pa\u00adprock\u00ad\u00adi,   Pro\u00ad\u00adpos\u00adal  \n   \n \nJoin me in con\u00adgrat\u00adu\u00adlat\u00ading these stu\u00addents on their ac\u00adcep\u00adtance.     \n In case you don't know for some rea\u00adson, Google Sum\u00admer of Code is a pro\u00adgram where Google pays stu\u00addents to write code for open source project\u00ads.  SymPy was ac\u00adcept\u00aded as a men\u00adtor\u00ading or\u00adga\u00adni\u00adza\u00adtion this year.  The goal of the sum\u00admer is to help the stu\u00addents learn new skill\u00ads, in par\u00adtic\u00adu\u00adlar in our case:   \n \n \n con\u00adtribut\u00ading to open source     \n   \n  \n work\u00ading with the com\u00ad\u00admu\u00adni\u00ad\u00adty     \n   \n  \n learn git, pull re\u00adquest\u00ads, re\u00adviews     \n   \n  \n teach them how to re\u00adview oth\u00ad\u00ader's peo\u00ad\u00adple patch\u00ades     \n   \n  \n do use\u00ad\u00adful work for SymPy     \n   \n  \n have fun, and en\u00ad\u00adcour\u00adage the stu\u00ad\u00addents to stay around     \n   \n \nAl\u00adso see my  pre\u00advi\u00adous blog post  about it.", 
      "loc": "/posts/2011/04/27/accepted-gsoc-students-announced/"
    }, 
    {
      "title": "SymPy is a Google Summer of Code 2011 Mentoring Organization", 
      "tags": "", 
      "text": "I am proud to an\u00adnounce that SymPy has been ac\u00adcept\u00aded as a men\u00adtor\u00ading or\u00adga\u00adni\u00adza\u00adtion for Google Sum\u00admer of Code 2011.  This is great news for the projec\u00adt.  Al\u00adthough we have par\u00adtic\u00adi\u00adpat\u00aded in the past un\u00adder the um\u00adbrel\u00adla of the Python Soft\u00adware Foun\u00adda\u00adtion and Port\u00adland State Uni\u00adver\u00adsi\u00adty men\u00adtor\u00ading or\u00adga\u00adni\u00adza\u00adtion\u00ads, this is the first time that we have been ac\u00adcept\u00aded as a men\u00adtor\u00ading or\u00adga\u00adni\u00adza\u00adtion.  Out of 417 or\u00adga\u00adni\u00adza\u00adtions that ap\u00adplied to Google, 175 were ac\u00adcept\u00aded, 50 of which were new. \n In case you don't know, Google Sum\u00admer of Code is a pro\u00adgram run by Google ev\u00adery year where they pay col\u00adlege stu\u00addents all around the world to write code for open source project\u00ads. Each stu\u00addent has a men\u00adtor as\u00adsigned to him/her, who helps the stu\u00addent get start\u00aded with in\u00adter\u00adact\u00ading with open source (most stu\u00addents who are ac\u00adcept\u00aded have nev\u00ader par\u00adtic\u00adi\u00adpat\u00aded in open source be\u00adfore).    \n So now that were are ac\u00adcept\u00aded, stu\u00addents are open to ap\u00adpli\u00adca\u00adtion\u00ads.  The ac\u00adtu\u00adal ap\u00adpli\u00adca\u00adtion pe\u00adri\u00adod opens on March 28, and clos\u00ades on April 8 (see  the pro\u00adgram time\u00adline). \n To stu\u00addents: \n If you are in\u00adter\u00adest\u00aded in ap\u00adply\u00ading, please write the to mail\u00ading list and in\u00adtro\u00adduce your\u00adself.  The pro\u00adgram is open to any\u00adone world\u00adwide who is 18 years of age or old\u00ader who is en\u00adrolled in a high\u00ader ed\u00adu\u00adca\u00adtion in\u00adsti\u00adtu\u00adtion (this in\u00adcludes un\u00adder\u00adgrad\u00adu\u00adate and grad\u00adu\u00adate).  If you are in\u00adter\u00adest\u00aded in ap\u00adply\u00ading, here is what you should do (if you have not al\u00adready): \n \n \n As I said above, write to the list and in\u00ad\u00adtro\u00ad\u00adduce your\u00ad\u00adself.  You might al\u00ad\u00adso join our IRC chan\u00adnel, which is #sympy on freen\u00adode.  \n   \n  \n Start think\u00ading about what you want to ap\u00ad\u00adply to do.  See our   ideas page.  How\u00adev\u00ader, we are open to ideas that are not on that page. Any\u00adthing that fits in a com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtem would fit in SymPy.  If you have an idea not on that page, please dis\u00ad\u00ad\u00adcuss it on our mail\u00ading list, so we can see if it has not al\u00adready be im\u00ad\u00adple\u00ad\u00admen\u00adt\u00aded, and if it is fit\u00adt\u00ading for SymPy and for a pro\u00adjec\u00adt.  I rec\u00adom\u00ad\u00admend you ap\u00ad\u00adply to do some\u00adthing that you are in\u00ad\u00adter\u00adest\u00aded in per\u00ad\u00adson\u00adal\u00ad\u00adly.  \n   \n  \n We re\u00adquire for any stu\u00ad\u00addent to be ac\u00ad\u00adcep\u00adt\u00aded that he/she sub\u00ad\u00admit at least one patch to SymPy, which gets re\u00adviewed and pushed in.  See   is\u00ad\u00adsues la\u00ad\u00adbeled EasyToFix in our is\u00ad\u00adsue track\u00ad\u00ader   for some easy to fix is\u00ad\u00adsues that are a good place to start.  Don't wor\u00adry if you do not know how to send in a patch or use git.  We will help you (that is the whole point of the pro\u00ad\u00adgram).  Just ask on the mail\u00ading list, on the is\u00ad\u00adsue page, or on IR\u00adC.  \n   \n  \n You should start think\u00ading about your ap\u00ad\u00adpli\u00ad\u00adca\u00ad\u00adtion.  See our   ap\u00ad\u00adpli\u00ad\u00adca\u00ad\u00adtion tem\u00ad\u00adplate   (it will al\u00ad\u00adso be at our page on the Google site).  If you like, you can start a page on our wi\u00ad\u00adki to write your pro\u00ad\u00adpos\u00adal.  If you do this, we will help you ed\u00adit it (though un\u00adder\u00ad\u00ads\u00adtand that we will not help you write it).  Re\u00admem\u00adber that we want you to get ac\u00ad\u00adcep\u00adt\u00aded just as much as you do, so you can help im\u00adprove SymPy!  \n   \n \nTo SymPy de\u00advel\u00adop\u00ader\u00ads: \n \n \n We need peo\u00ad\u00adple who are will\u00ading to men\u00ad\u00adtor stu\u00ad\u00addents.  If you are will\u00ading to men\u00ad\u00adtor, please add your name to the bot\u00ad\u00adtom of the   ideas page.     \n   \n  \n Please ed\u00adit the ideas page to im\u00adprove for\u00ad\u00admat\u00adt\u00ading and add new ideas.  \n   \n \nGood luck to all stu\u00addents who plan on ap\u00adply\u00ading!", 
      "loc": "/posts/2011/03/18/sympy-is-a-google-summer-of-code-2011-mentoring-organization/"
    }, 
    {
      "title": "True is True is False is True is False", 
      "tags": "", 
      "text": "Time for  an\u00adoth\u00ader   one  of my WTF Python blog post\u00ads.  Yes\u00adter\u00adday, I ran\u00addom\u00adly typed this in a Python ses\u00adsion (it was late at night): \n [code lan\u00adguage=\"py\"] \n >>> True is True is False is True is False \n False \n [/\u00adcode] \n First a lit\u00adtle back\u00adground, in case you don't know.  The  is  op\u00ader\u00ada\u00adtor in Python does ex\u00adact ob\u00adject com\u00adpar\u00adi\u00adson in mem\u00ado\u00adry. Un\u00adlike  ==, which on\u00adly com\u00adpares it two ob\u00adjects are equal,  is  on\u00adly re\u00adturns True if both ar\u00adgu\u00adments have the same mem\u00ado\u00adry ad\u00address.  So you can have some\u00adthing like: \n [code lan\u00adguage=\"py\"] \n >>> a = 12345 \n >>> b = 12345 \n >>> a == b \n True \n >>> a is b \n False \n [/\u00adcode] \n Now, there are a hand\u00adful of Python built-ins that are al\u00adways equal one an\u00adoth\u00ader with the  is  op\u00ader\u00ada\u00adtor.   True  and  False  are two such con\u00adstants: \n [code lan\u00adguage=\"py\"] \n >>> a = True \n >>> b = True \n >>> a == b \n True \n >>> a is b \n True \n >>> c = False \n >>> d = False \n >>> c == d \n True \n >>> c is d \n True \n [/\u00adcode] \n Now, go\u00ading back to the above, we see that each  is  re\u00adturns  True  or  False, which is then eval\u00adu\u00adat\u00aded with the next one.  Or at least that is what you would think is hap\u00adpen\u00ading.  But go back and look at it again, and see if you can fig\u00adure out what it should eval\u00adu\u00adate to.  You could prob\u00ada\u00adbly guess that some\u00adthing was amiss from the fact that I was blog\u00adging about it.  If you haven't fig\u00adured it out al\u00adready, look at the fol\u00adlow\u00ading: \n [code lan\u00adguage=\"py\"] \n >>> True is True is False is True is False \n False \n >>> (((True is True) is False) is True) is False \n True \n >>> True is (True is (False is (True is False))) \n True \n [/\u00adcode] \n So it seems that  is  does not as\u00adso\u00adciate to the left or to the right.  Let's see if we can fig\u00adure out what is go\u00ading on.  First of\u00adf,  True is True, etc. do be\u00adhave as you ex\u00adpect them to: \n [code lan\u00adguage=\"py\"] \n >>> True is True \n True \n >>> False is False \n True \n >>> True is False \n False \n >>> False is True \n False \n [/\u00adcode] \n It is when we start us\u00ading mul\u00adti\u00adple  iss in the same state\u00adment that we start see\u00ading prob\u00adlem\u00ads: \n [code lan\u00adguage=\"py\"] \n >>> False is False is False \n True \n >>> (False is False) is False \n False \n [/\u00adcode] \n So what's go\u00ading on here?   False is False  is True, so maybe it is short\u00ad-\u00adcir\u00adcuit\u00ading some\u00adhow.    \n [code lan\u00adguage=\"py\"] \n >>> True is False is False \n False \n >>> False is False is True \n False \n [/\u00adcode] \n No, that is not it.  Those re\u00adduce to  False is False  and  True is True  when as\u00adso\u00adci\u00adat\u00ading to the left, re\u00adspec\u00adtive\u00adly, and  True is True  and  True is True  when as\u00adso\u00adci\u00adat\u00ading to the right.    \n Fi\u00adnal\u00adly, at this point, it oc\u00adcurs to me what is re\u00adal\u00adly go\u00ading on.  Have you fig\u00adured it out too (or maybe you al\u00adready knew all along)?  Maybe you can guess it from this state\u00admen\u00adt, which us\u00ades  None, an\u00adoth\u00ader built-in ob\u00adject that al\u00adways com\u00adpares equal to it\u00adself with the  is  op\u00ader\u00ada\u00adtor: \n [code lan\u00adguage=\"py\"] \n >>> None is None is None \n True \n [/\u00adcode] \n So you see what is hap\u00adpen\u00ading?   is  does\u00adn't as\u00adso\u00adciate at al\u00adl.  Rather, us\u00ading mul\u00adti\u00adple  iss in one state\u00adment does mul\u00adti\u00adple com\u00adpar\u00adisons at once.  Any  a is b is \u2026 x  will re\u00adturn  True  if  a,  b, \u2026, and  x  are all equal by the  is  op\u00ader\u00ada\u00adtor (they share the same iden\u00adti\u00adty or mem\u00ado\u00adry ad\u00address), and  False  oth\u00ader\u00adwise.  Ac\u00adtu\u00adal\u00adly, this is\u00adn't sur\u00adpris\u00ading, since  ==  works the same way: \n [code lan\u00adguage=\"py\"] \n >>> False == False == False \n True \n >>> (False == False) == False \n False \n [/\u00adcode] \n This syn\u00adtax can ac\u00adtu\u00adal\u00adly be use\u00adful to test equal\u00adi\u00adty of three or more items at once ef\u00adfi\u00adcient\u00adly (Python will not eval\u00adu\u00adate the same op\u00ader\u00adand more than on\u00adce, and it short cir\u00adcuit\u00ads).  But it can be con\u00adfus\u00ading when com\u00adpar\u00ading with  True  or  False, since  a is b  and  a == b  them\u00adselves eval\u00adu\u00adate to one of those val\u00adues.  So re\u00admem\u00adber that it is NOT as\u00adso\u00adcia\u00adtive in any way.  Rather, it acts as an n-way com\u00adpar\u00adi\u00adson.   \n Fi\u00adnal\u00adly, as  this ta\u00adble  of op\u00ader\u00ada\u00adtor prece\u00addence in Python shows,  is  and  ==  have the same prece\u00addence in Python.  There\u00adfore, it should be pos\u00adsi\u00adble to com\u00adbine the two in these same state\u00admen\u00adt.  In\u00addeed, you can: \n [code lan\u00adguage=\"py\"] \n >>> a = 12345 \n >>> b = 12345 \n >>> c = b \n >>> a == b == c \n True \n >>> a is b is c \n False \n >>> # Be\u00adcause this is False \n ...   \n >>> a is b \n False \n >>> # But this is True \n ...   \n >>> b is c \n True \n >>> # So we get \n ...   \n >>> a == b is c \n True \n [/\u00adcode]", 
      "loc": "/posts/2011/03/15/true-is-true-is-false-is-true-is-false/"
    }, 
    {
      "title": "I am now the SymPy project leader", 
      "tags": "", 
      "text": "You can imag\u00adine my sur\u00adprise when I opened my email last Mon\u00adday and saw this mes\u00adsage from On\u00addrej: \n \nHi Aaron, \n would you like to be\u00adcome the main main\u00adtain\u00ader/pro\u00adject lead\u00ader for sympy? \n In the last year, it is clear\u00adly you, who does most of the work, and \n al\u00adso your blog has quite some vis\u00adi\u00adbil\u00adi\u00adty now. \n It'd be cool to do some re\u00adlease from time to time. Ma\u00adteusz is \n fin\u00adish\u00ading is poly's branch, so prob\u00ada\u00adbly his code would go in\u00adto the \n re\u00adlease. \n \n\nSo I guess now I am the project lead\u00ader for SymPy.  As to what ex\u00adact\u00adly this mean\u00ads, I am not yet en\u00adtire\u00adly sure, but so far it has meant that I get to do a lot more work than be\u00adfore (yay!). \n Ac\u00adtu\u00adal\u00adly, the work is be\u00adcause I have spent the last week work\u00ading non\u00adstop to get things ready to do a re\u00adlease.  I should have a re\u00adlease can\u00addi\u00addate for SymPy 0.7.0 ready some time next week.  I'll post more here about what's change, but this is go\u00ading to be a big re\u00adlease.  The big\u00adgest change will be the new polys, which makes things much faster and more pow\u00ader\u00adful.    \n Al\u00adso, I will try to post things here re\u00adlat\u00ading to SymPy as a whole, not just my work.    \n On\u00addrej, by the way, is\u00adn't go\u00ading any\u00adwhere. He plans on do\u00ading some work on ways to get SymPy out to more peo\u00adple by writ\u00ading more/\u00adbet\u00adter web and mo\u00adbile in\u00adter\u00adfaces for it.  A big thanks to On\u00addrej and the SymPy com\u00admu\u00adni\u00adty for mak\u00ading such an awe\u00adsome piece of soft\u00adware!", 
      "loc": "/posts/2011/01/09/i-am-now-the-sympy-project-leader/"
    }, 
    {
      "title": "2010 in review", 
      "tags": "", 
      "text": "Here's some silly thing that WordPress sent me:\n                    <p>The stats helper monkeys at WordPress.com mulled over how this blog did in 2010, and here's a high level summary of its overall blog health:</p>\n\n                    <p align=\"center\"><img style=\"border:1px solid #ddd;background:#f5f5f5;padding:20px;\" src=\"http://s0.wp.com/i/annual-recap/meter-healthy4.gif\" width=\"250\" height=\"183\" alt=\"Healthy blog!\"></p>\n            <p align=\"center\">The <em>Blog-Health-o-Meter\u2122</em> reads This blog is on fire!.</p>\n\n            <h2>Crunchy numbers</h2>\n\n\n\n\n        <a href=\"/2009/07/code-block-2.png\"><img src=\"http://asmeurersympy.files.wordpress.com/2009/07/code-block-2.png?w=288\" alt=\"Featured image\" style=\"max-height:230px;float:right;border:1px solid #ddd;background:#fff;margin:0 0 1em 1em;padding:6px;\"></a>\n\n\n    <p>A Boeing 747-400 passenger jet can hold 416 passengers.  This blog was viewed about <strong>6,800</strong> times in 2010.  That's about 16 full 747s.</p>\n\n    <p></p><p>In 2010, there were <strong>16</strong> new posts, growing the total archive of this blog to 41 posts. There were <strong>7</strong> pictures uploaded, taking up a total of 1mb. </p>\n\n            <p>The busiest day of the year was July 4th with <strong>103</strong> views. The most popular post that day was <a style=\"color:#08c;\" href=\"http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/\">The Risch Algorithm: Part 1</a>.</p>\n            <br>\n\n            <h2>Where did they come from?</h2>\n\n                        <p>The top referring sites in 2010 were <strong><a href=\"http://code.google.com\">code.google.com</a></strong>, <strong><a href=\"http://planet.sympy.org\">planet.sympy.org</a></strong>, <strong><a href=\"http://www.facebook.com\">facebook.com</a></strong>, <strong><a href=\"http://www.stackoverflow.com\">stackoverflow.com</a></strong>, and <strong><a href=\"http://socghop.appspot.com\">socghop.appspot.com</a></strong>.</p>\n                            <p>Some visitors came searching, mostly for <strong><a href=\"http://www.google.com/search?q=risch%20algorithm\">risch algorithm</a></strong>, <strong><a href=\"http://www.google.com/search?q=pudb\">pudb</a></strong>, <strong><a href=\"http://www.google.com/search?q=integrate%20exponential\">integrate exponential</a></strong>, <strong><a href=\"http://www.google.com/search?q=equations%20with%20homogeneous%20coefficients\">equations with homogeneous coefficients</a></strong>, and <strong><a href=\"http://www.google.com/search?q=xcode%20trailing%20whitespace\">xcode trailing whitespace</a></strong>.</p>\n\n\n\nI have linked the search terms to their re\u00adspec\u00adtive Google search\u00ades, so you can see how far up my blog posts are in the re\u00adsults list. \n \n\n        <h2>Attractions in 2010</h2>\n        <p>These are the posts and pages that got the most views in 2010.</p>\n\n\n                            <div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">1</div>\n                <a style=\"margin-right:10px;\" href=\"http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/\">The Risch Algorithm: Part 1</a> <span style=\"color:#999;font-size:8pt;\">June 2010</span><br>3 comments\n\n                            <div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">2</div>\n                <a style=\"margin-right:10px;\" href=\"http://asmeurersympy.wordpress.com/2009/11/13/how-to-get-both-32-bit/\">How to get both 32-bit and 64-bit Python in Snow Leopard</a> <span style=\"color:#999;font-size:8pt;\">November 2009</span><br>5 comments and 1 Like on WordPress.com,\n\n                            <div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">3</div>\n                <a style=\"margin-right:10px;\" href=\"http://asmeurersympy.wordpress.com/2009/07/20/modifying-a-list-while-looping-through-it-in-python/\">Modifying a list while looping through it in Python</a> <span style=\"color:#999;font-size:8pt;\">July 2009</span><br>13 comments\n\n                            <div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">4</div>\n                <a style=\"margin-right:10px;\" href=\"http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/\">Integration of exponential functions</a> <span style=\"color:#999;font-size:8pt;\">July 2010</span><br>3 comments\n\n                            <div style=\"clear:left;float:left;font-size:24pt;line-height:1em;margin:-5px 10px 20px 0;\">5</div>\n                <a style=\"margin-right:10px;\" href=\"http://asmeurersympy.wordpress.com/2009/05/31/first-order-differential-equations-with-homogeneous-coefficients/\">First Order Differential Equations with Homogeneous Coefficients</a> <span style=\"color:#999;font-size:8pt;\">May 2009</span><br>2 comments\n\n\n\nI won\u00adder where things are com\u00ading from from Face\u00adbook.  I do not have an ac\u00adcount there, so I can't search it to find out.", 
      "loc": "/posts/2011/01/02/2010-in-review/"
    }, 
    {
      "title": "Major API Change for the Risch Algorithm Functions", 
      "tags": "mathjax", 
      "text": "I have been able to get to work again on the Risch Al\u00adgo\u00adrithm now that I have a month win\u00adter break from class\u00ades.  So the first thing I did was com\u00admit a bunch of bug fix\u00ades that had been sit\u00adting there since the end of the sum\u00admer.  Then, I set out to make a ma\u00adjor in\u00adter\u00adnal API change to the en\u00adtire Risch Al\u00adgo\u00adrith\u00adm. \n Let me give some back\u00adground.  When I first start\u00aded pro\u00adgram\u00adming the Risch Al\u00adgo\u00adrithm at the be\u00adgin\u00adning of the sum\u00admer, I did\u00adn't have a very good idea of how dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsions worked yet (re\u00admem\u00adber that I pro\u00adgrammed the al\u00adgo\u00adrithm as I learned it from Bron\u00adstein's book).  Let me use the func\u00adtion  deriva\u00adtion()  to demon\u00adstrate how the API has changed.   deriva\u00adtion()  takes the Poly  p  in  t  and com\u00adputes the de\u00adriv\u00ada\u00adtive (t  is some tran\u00adscen\u00adden\u00adtal ex\u00adten\u00adsion, like $la\u00adtex ex$).  Al\u00adso, the in\u00adte\u00adgra\u00adtion vari\u00adable is  x.  The first in\u00adter\u00adnal API that I used was \n deriva\u00adtion(p, D, x, t) \n where  D  is a Poly of the de\u00adriv\u00ada\u00adtive of  t, and  x  and  t  are Sym\u00adbols (see  this com\u00admit).   The prob\u00adlem here is that  p  might not be in just one sym\u00adbol,  t, but in many. This would hap\u00adpen when\u00adev\u00ader the func\u00adtion had more than one tran\u00adscen\u00adden\u00adtal func\u00adtion, or ex\u00adten\u00adsion, in it.  So, for ex\u00adam\u00adple, $la\u00adtex ex\\log{x}$ would have this prob\u00adlem. Sur\u00adpris\u00ading\u00adly, ac\u00adcord\u00ading to the git log, it took me un\u00adtil Ju\u00adly 4 to fig\u00adure this out (that above linked com\u00admit, which is the first oc\u00adcur\u00adrence of this func\u00adtion and when I start\u00aded the full al\u00adgo\u00adrith\u00adm, dates from June 7, so it took me al\u00admost a mon\u00adth!), af\u00adter which I had al\u00adready writ\u00adten a good por\u00adtion of the Risch Al\u00adgo\u00adrith\u00adm.  I changed the API to \n deriva\u00adtion(p, D, x, T) \n where  T  is a list of the ex\u00adten\u00adsion vari\u00adables and  D  is a list of the deriva\u00adtions of the re\u00adspec\u00adtive el\u00ade\u00adments of  T  with re\u00adspect to the low\u00ader el\u00ade\u00adments and x (see  this com\u00admit).  Now, the deriva\u00adtion of  x  is al\u00adways  Poly(1, x), so I did\u00adn't think it was nec\u00ades\u00adsary to in\u00adclude it.  But it turns out that it is eas\u00adi\u00ader to just al\u00adways in\u00adclude this in  D  rather than try to spe\u00adcial case it in the code.  Al\u00adso, the low\u00adest ex\u00adten\u00adsion vari\u00adable,  x, is\u00adn't used very of\u00adten in the code, so it al\u00adso does\u00adn't make much sense to keep it sep\u00ada\u00adrate from the rest of the vari\u00adables in  T.  Now this did\u00adn't take me as long to fig\u00adure out (Ju\u00adly 11).  There\u00adfore, I changed the API to just \n deriva\u00adtion(p, D, T) \n where the first el\u00ade\u00adment of  T  is al\u00adways  x  and the first el\u00ade\u00adment of  D  is al\u00adways  Poly(1, x)  (see  this com\u00admit). \n Now this API worked quite well for the re\u00admain\u00adder of the sum\u00admer.  How\u00adev\u00ader, at the very end, I dis\u00adcov\u00adered that a func\u00adtion re\u00adquired to han\u00addle some spe\u00adcial cas\u00ades in cer\u00adtain parts of the al\u00adgo\u00adrithm need\u00aded four more lists (the el\u00ade\u00adments of the ex\u00adten\u00adsion that are log\u00ada\u00adrithm\u00ads, the el\u00ade\u00adments of the ex\u00adten\u00adsion that are ex\u00adpo\u00adnen\u00adtial\u00ads, the ar\u00adgu\u00adments of those log\u00ada\u00adrithm\u00ads, and the ar\u00adgu\u00adments of those ex\u00adpo\u00adnen\u00adtial\u00ads).  I had pre\u00advi\u00adous\u00adly thought that these lists would on\u00adly be need\u00aded when cre\u00adat\u00ading the ex\u00adten\u00adsion at the be\u00adgin\u00adning of in\u00adte\u00adgra\u00adtion, but it turned out that this was not the case and that they could be need\u00aded in sev\u00ader\u00adal rather deep places in the al\u00adgo\u00adrith\u00adm.  The on\u00adly way to get them there would be to pass them through to ev\u00adery sin\u00adgle func\u00adtion in the al\u00adgo\u00adrith\u00adm.      \n So I was faced with a dilem\u00adma.  I did\u00adn't want to pass six ar\u00adgu\u00adments through each func\u00adtion just be\u00adcause a few might need them al\u00adl.  I knew that the an\u00adswer was to cre\u00adate an ob\u00adject to store all the da\u00adta for a dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion and to just pass this ob\u00adject around.  Un\u00adfor\u00adtu\u00adnate\u00adly, this hap\u00adpened at the very end of the sum\u00admer, so I had\u00adn't been able to do that un\u00adtil now.    \n This brings us to now.  Over the past cou\u00adple of week\u00ads, I cre\u00adat\u00aded an ob\u00adject called  Dif\u00adfer\u00aden\u00adtialEx\u00adten\u00adsion, and re\u00adplaced the API in the Risch Al\u00adgo\u00adrithm to use it.  See  this com\u00admit  and  this com\u00admit  and some of the ones in be\u00adtween to see what I did. More or less, the ob\u00adject is like a C struc\u00adt---it does lit\u00adtle more than hold a lot of in\u00adfor\u00adma\u00adtion as at\u00adtributes.  How\u00adev\u00ader, at the sug\u00adges\u00adtion of Ro\u00adnan Lamy on the  mail\u00ading list, I have moved all the rel\u00ade\u00advant code for build\u00ading the ex\u00adten\u00adsion from the  build_ex\u00adten\u00adsion()  func\u00adtion in\u00adto  Dif\u00adfer\u00aden\u00adtialEx\u00adten\u00adsion.init().  I have al\u00adso cre\u00adat\u00aded some \"mag\u00adic\" to han\u00addle the re\u00adcur\u00adsive na\u00adture of the al\u00adgo\u00adrith\u00adm.  A Dif\u00adfer\u00aden\u00adtialEx\u00adten\u00adsion ob\u00adject has an at\u00adtribute  lev\u00adel, which rep\u00adre\u00adsents the lev\u00adel of the ex\u00adten\u00adsion that the al\u00adgo\u00adrithm is work\u00ading in.  So you can store all the deriva\u00adtions of the ex\u00adten\u00adsion in  Dif\u00adfer\u00aden\u00adtialEx\u00adten\u00adsion.D, but on\u00adly have  Dif\u00adfer\u00aden\u00adtialEx\u00adten\u00adsion.d  point to the \"cur\u00adren\u00adt\" out\u00ader\u00admost deriva\u00adtion.  This re\u00adplaces things like \n D = D[:-1] \n T = T[:-1] \n     \n from the old API to just \n DE.decre\u00admen\u00adt_level() \n  \n (and then lat\u00ader on,  DE.in\u00adcre\u00admen\u00adt_level()).  The en\u00adtire API is now just \n deriva\u00adtion(p, DE) \n where  DE  is a  Dif\u00adfer\u00aden\u00adtialEx\u00adten\u00adsion  ob\u00adjec\u00adt.  Chang\u00ading the API of the en\u00adtire code base at this point was a bit of work, but I have fi\u00adnal\u00adly fin\u00adished it, and I must say, this is much clean\u00ader.  True, you now have to use  DE.t  ev\u00adery\u00adwhere in\u00adstead of  t  (with  t = T[-1]  at the top of the func\u00adtion), which is three char\u00adac\u00adters more space for ev\u00adery use, but I think in the end it is clean\u00ader.  For ex\u00adam\u00adple, the func\u00adtion that used to be \n is_log_deriv_k_t_rad\u00adi\u00adcal(\u00adfa, fd, L_K, E_K, L_args, E_args, D, T) \n is now just \n is_log_deriv_k_t_rad\u00adi\u00adcal(\u00adfa, fd, DE). \n Al\u00adso, be\u00adcause it is an ob\u00adjec\u00adt, I can do cool things like over\u00adride  Dif\u00adfer\u00aden\u00adtialEx\u00adten\u00adsion.str()  to print out a tu\u00adple of the most im\u00adpor\u00adtant at\u00adtributes of the ob\u00adjec\u00adt, mak\u00ading de\u00adbug\u00adging much eas\u00adi\u00ader (now there is just one print state\u00adment in\u00adstead of five).    \n An\u00adoth\u00ader thing I had to do was to al\u00adlow the cre\u00adation of these ob\u00adjects man\u00adu\u00adal\u00adly, be\u00adcause what is now  Dif\u00adfer\u00aden\u00adtialEx\u00adten\u00adsion.init()  can\u00adnot yet han\u00addle, for ex\u00adam\u00adple, tan\u00adgent ex\u00adten\u00adsion\u00ads, but some of the tests in\u00advolve those.  So I cre\u00adat\u00aded an  ex\u00adten\u00adsion  flag to  init()  to which you could pass a dic\u00adtio\u00adnary, and it would cre\u00adate a skele\u00adton ex\u00adten\u00adsion from that (see  this com\u00admit).  I made it smart enough to cre\u00adate some at\u00adtributes au\u00adto\u00admat\u00adi\u00adcal\u00adly, so I on\u00adly have to pass the list  D  in most test\u00ads---it cre\u00adates at\u00adtributes like  T  from that au\u00adto\u00admat\u00adi\u00adcal\u00adly.  Thus, this in some ways made the tests a lit\u00adtle sim\u00adpler, be\u00adcause I did\u00adn't have to wor\u00adry about  T  any more.    \n We'll see how things go, but this fourth API change should hope\u00adful\u00adly be the last.  This should al\u00adso make it much eas\u00adi\u00ader when\u00adev\u00ader I add trigono\u00admet\u00adric func\u00adtion sup\u00adport, where I will have to add even more at\u00adtributes to the ob\u00adjec\u00adt.  I won't have to change the code in any ex\u00adist\u00ading func\u00adtion (un\u00adless it specif\u00adi\u00adcal\u00adly needs to be able to know about trig ex\u00adten\u00adsion\u00ads), be\u00adcause, to them, the in\u00adfor\u00adma\u00adtion in  DE  will not change. \n So the good news be\u00adhind all of this, as I men\u00adtioned at the be\u00adgin\u00adning of this post, is that I can now write some al\u00adgo\u00adrithm that re\u00adquires those  L_K,  E_K,  L_args,  E_args  vari\u00adables from ar\u00adbi\u00adtrary places with\u00adin the al\u00adgo\u00adrith\u00adm.  This should al\u00adlow me to com\u00adplete\u00adly fin\u00adish the ex\u00adpo\u00adnen\u00adtial case.  So look for\u00adward soon to a  risch_in\u00adte\u00adgrate()  that can han\u00addle com\u00adplete\u00adly any tran\u00adscen\u00adden\u00adtal func\u00adtion of ex\u00adpo\u00adnen\u00adtials (ei\u00adther pro\u00adduce an in\u00adte\u00adgral or prove that no el\u00ade\u00admen\u00adtary in\u00adte\u00adgral ex\u00adist\u00ads).    \n And just to be clear, this does\u00adn't change any\u00adthing with  risch_in\u00adte\u00adgrate()---this is on\u00adly an in\u00adter\u00adnal change. And at the mo\u00admen\u00adt, it does\u00adn't add any fea\u00adtures, though that should soon change. So keep on test\u00ading it for me!  If you see any er\u00adrors along the lines of \"Vari\u00adable t not de\u00adfined,\" it prob\u00ada\u00adbly means that I missed that one when I was switch\u00ading the API due to poor test cov\u00ader\u00adage in that area of the code.  I would love to know about any er\u00adrors you find, or, in\u00addeed, any test\u00ading you do with  risch_in\u00adte\u00adgrate.  Re\u00admem\u00adber that you can ob\u00adtain my branch at  my GitHub ac\u00adcount (branch in\u00adte\u00adgra\u00adtion3).", 
      "loc": "/posts/2010/12/27/major-api-change-for-the-risch-algorithm-functions/"
    }, 
    {
      "title": "The Risch Algorithm: Part 3, Liouville's Theorem", 
      "tags": "mathjax", 
      "text": "So this is the last of\u00adfi\u00adcial week of the Sum\u00admer of Code pro\u00adgram, and my work is most\u00adly con\u00adsist\u00ading of re\u00admov\u00ading  NotIm\u00adple\u00adment\u00aded\u00adEr\u00adrors (i.e., im\u00adple\u00adment\u00ading stuff), and fix\u00ading bugs. None of this is par\u00adtic\u00adu\u00adlar\u00adly in\u00adter\u00adest\u00ading, so in\u00adstead of talk\u00ading about that, I fig\u00adured I would pro\u00adduce an\u00adoth\u00ader one of my Risch Al\u00adgo\u00adrithm blog post\u00ads.  It is rec\u00adom\u00admend\u00aded that you read parts  1  and  2  first, as well as my post on  ra\u00adtio\u00adnal func\u00adtion in\u00adte\u00adgra\u00adtion, which could be con\u00adsid\u00adered part 0. \n Li\u00adou\u00adville's The\u00ado\u00adrem \n Any\u00adone who's tak\u00aden cal\u00adcu\u00adlus in\u00adtu\u00aditive\u00adly knows that in\u00adte\u00adgra\u00adtion is hard, while dif\u00adfer\u00aden\u00adti\u00ada\u00adtion is easy.  For dif\u00adfer\u00aden\u00adti\u00ada\u00adtion, we can pro\u00adduce the de\u00adriv\u00ada\u00adtive of any el\u00ade\u00admen\u00adtary func\u00adtion, and we can do so eas\u00adi\u00adly, us\u00ading a sim\u00adple al\u00adgo\u00adrithm con\u00adsist\u00ading of the sum and prod\u00aduct rules, the chain rule, and the rules for the de\u00adriv\u00ada\u00adtive of all the var\u00adi\u00adous el\u00ade\u00admen\u00adtary func\u00adtion\u00ads.  But for in\u00adte\u00adgra\u00adtion, we have to try to work back\u00adward\u00ads.    \n There are two things that make in\u00adte\u00adgra\u00adtion dif\u00adfi\u00adcult.  First is the ex\u00adis\u00adtence of func\u00adtions that sim\u00adply do not have any el\u00ade\u00admen\u00adtary anti\u00adderiv\u00ada\u00adtive.  $la\u00adtex e{-x2}$ is per\u00adhaps the most fa\u00admous ex\u00adam\u00adple of such a func\u00adtion, since it aris\u00ades from the nor\u00admal dis\u00adtri\u00adbu\u00adtion in sta\u00adtis\u00adtics.  But there are many oth\u00ader\u00ads.  $la\u00adtex \\s\u00adin{(x2)}$, $la\u00adtex \\frac{1}{\\log{(x)}}$, and $la\u00adtex xx$ are some oth\u00ader ex\u00adam\u00adples of fa\u00admous non-in\u00adte\u00adgrable func\u00adtion\u00ads.    \n The sec\u00adond prob\u00adlem is that no one sin\u00adgle sim\u00adple rule for work\u00ading back\u00adwards will al\u00adways be ap\u00adpli\u00adca\u00adble.  We know that u-\u00adsub\u00adsti\u00adtu\u00adtion and in\u00adte\u00adgra\u00adtion by parts are the re\u00adverse of the chain rule and the prod\u00aduct rule, re\u00adspec\u00adtive\u00adly.  But those meth\u00adods will on\u00adly work if those rules were the ones that were ap\u00adplied orig\u00adi\u00adnal\u00adly, and then on\u00adly if you chose the right $la\u00adtex u$ and $la\u00adtex dv$.    \n But there is a much sim\u00adpler ex\u00adam\u00adple that gets right down to the point with Li\u00adou\u00adville's the\u00ado\u00adrem.  The pow\u00ader rule, which is that $la\u00adtex \\frac{d}{dx}xn=nx{n-1}$ is eas\u00adi\u00adly re\u00adversed for in\u00adte\u00adgra\u00adtion.  Giv\u00aden the pow\u00ader rule for dif\u00adfer\u00aden\u00adti\u00ada\u00adtion, it's easy to see that the re\u00adverse rule should be $la\u00adtex \\in\u00adt{xndx}=\\frac{x{n+1}}{n+1}$.  This works fine, ex\u00adcept that were are di\u00advid\u00ading some\u00adthing, $la\u00adtex n+1$.  In math\u00ade\u00admat\u00adic\u00ads, when\u00adev\u00ader we do that, we have to en\u00adsure that what\u00adev\u00ader we di\u00advide by is not 0. In this case, it means that we must as\u00adsert $la\u00adtex n\\neq -1$.  This ex\u00adcludes $la\u00adtex \\in\u00adt{\\frac{1}{x}dx}$.  We know from cal\u00adcu\u00adlus that this in\u00adte\u00adgral re\u00adquires us to in\u00adtro\u00adduce a spe\u00adcial func\u00adtion, the nat\u00adu\u00adral log\u00ada\u00adrith\u00adm.    \n But we see that $la\u00adtex n=-1$ is the on\u00adly ex\u00adcep\u00adtion to the pow\u00ader rule, so that the in\u00adte\u00adgral of any (Lau\u00adrent) poly\u00adno\u00admi\u00adal is again a (Lau\u00adren\u00adt) poly\u00adno\u00admi\u00adal, plus a log\u00ada\u00adrith\u00adm.  Re\u00adcall from part 0 (Ra\u00adtio\u00adnal Func\u00adtion In\u00adte\u00adgra\u00adtion) that the same thing is true for any ra\u00adtio\u00adnal func\u00adtion: the in\u00adte\u00adgral is again a ra\u00adtio\u00adnal func\u00adtion, plus a log\u00ada\u00adrithm (we can com\u00adbine mul\u00adti\u00adple log\u00ada\u00adrithms in\u00adto one us\u00ading the log\u00ada\u00adrith\u00admic iden\u00adti\u00adties, so as\u00adsume for sim\u00adplic\u00adi\u00adty that there is just one).  The ar\u00adgu\u00adment is very sim\u00adi\u00adlar, too.  As\u00adsume that we have split the de\u00adnom\u00adi\u00adna\u00adtor ra\u00adtio\u00adnal func\u00adtion in\u00adto lin\u00adear fac\u00adtors in the  al\u00adge\u00adbra\u00adic split\u00adting field  (such as the com\u00adplex num\u00adber\u00ads).  Then per\u00adform a par\u00adtial frac\u00adtions de\u00adcom\u00adpo\u00adsi\u00adtion on the ra\u00adtio\u00adnal func\u00adtion.  Each term in the de\u00adcom\u00adpo\u00adsi\u00adtion will be ei\u00adther a poly\u00adno\u00admi\u00adal, or of the form $la\u00adtex \\frac{a}{(x - b)n}$. The in\u00adte\u00adgra\u00adtion of these terms is the same as with the pow\u00ader rule, mak\u00ading the sub\u00adsti\u00adtu\u00adtion $la\u00adtex u = x - b$. When $la\u00adtex n\\geq 2$, the in\u00adte\u00adgral will be $la\u00adtex \\frac{-1}{n - 1}\\frac{a}{(x - b){n - 1}}$; when $la\u00adtex n = 1$, the in\u00adte\u00adgral will be $la\u00adtex a\\log{(x - b)}$.  Now com\u00adpu\u00adta\u00adtion\u00adal\u00adly, we don't want to work with the al\u00adge\u00adbra\u00adic split\u00adting field, but it turns out that we don't need to ac\u00adtu\u00adal\u00adly com\u00adpute it to find the in\u00adte\u00adgral.  But the\u00ado\u00adry is what we are deal\u00ading with here, so don't wor\u00adry about that.    \n Now the key ob\u00adser\u00adva\u00adtion about dif\u00adfer\u00aden\u00adti\u00ada\u00adtion, as I have point\u00aded out in the ear\u00adli\u00ader parts of this blog post se\u00adries,  is that the de\u00adriv\u00ada\u00adtive of an el\u00ade\u00admen\u00adtary func\u00adtion can be ex\u00adpressed in terms of it\u00adself, in par\u00adtic\u00adu\u00adlar, as a poly\u00adno\u00admi\u00adal in it\u00adself.  To put it an\u00adoth\u00ader way, func\u00adtions like $la\u00adtex ex$, $la\u00adtex \\tan{(x)}$, and $la\u00adtex \\log{(x)}$ all sat\u00adis\u00adfy lin\u00adear dif\u00adfer\u00aden\u00adtial equa\u00adtions with ra\u00adtio\u00adnal co\u00adef\u00adfi\u00adcients (e.g., for the\u00adse, $la\u00adtex y'=y$, $la\u00adtex y'=1 + y2$, and $la\u00adtex y'=\\frac{1}{x}$).    \n Now, the the\u00ado\u00adry gets more com\u00adpli\u00adcat\u00aded, but it turns out that, us\u00ading a care\u00adful anal\u00ady\u00adsis of this fac\u00adt, we can prove a sim\u00adi\u00adlar re\u00adsult to the one about ra\u00adtio\u00adnal func\u00adtions to any el\u00ade\u00admen\u00adtary func\u00adtion. In a nut\u00adshel\u00adl, Li\u00adou\u00adville's The\u00ado\u00adrem says this:  if an el\u00ade\u00admen\u00adtary func\u00adtion has an el\u00ade\u00admen\u00adtary in\u00adte\u00adgral, then that in\u00adte\u00adgral is a com\u00adposed on\u00adly of func\u00adtions from the orig\u00adi\u00adnal in\u00adte\u00adgrand, plus a fi\u00adnite num\u00adber of log\u00ada\u00adrithms of func\u00adtions from the in\u00adte\u00adgrand, which can be con\u00adsid\u00adered one log\u00ada\u00adrith\u00adm, as men\u00adtioned above (\"\u00adfunc\u00adtions from\" more specif\u00adi\u00adcal\u00adly means a ra\u00adtio\u00adnal func\u00adtion in the terms from our el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion).  Here is the for\u00admal state\u00adment of the the\u00ado\u00adrem. \n The\u00ado\u00adrem (Liou\u00adville's The\u00ado\u00adrem - Strong ver\u00adsion) \n Let $la\u00adtex K$ be a dif\u00adfer\u00aden\u00adtial field, $la\u00adtex C=\\\u00admath\u00adrm{\u00adCon\u00adst}(K)$, and $la\u00adtex f\\in K$. If there ex\u00adist an el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion $la\u00adtex E$ of $la\u00adtex K$ and $la\u00adtex g \\in E$ such that $la\u00adtex Dg =f$, then there are $la\u00adtex v \\in K$, $la\u00adtex c_1, \\dot\u00ads, c_n\\in \\bar{C}$, and $la\u00adtex u_1, \\dot\u00ads,u_n\\in K(c_1,\\\u00addot\u00ads,c_n)*$ such that   \n \n\n$latex f = Dv + \\sum_{i=1}n c_i\\frac{Du_i}{u_i}$.\n\n\n\n \n Look\u00ading close\u00adly at the for\u00admal state\u00adment of the the\u00ado\u00adrem, we can see that it says the same thing as my \"in a nut\u00adshel\u00adl\" state\u00admen\u00adt.  $la\u00adtex K$ is the dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion, say of $la\u00adtex \\math\u00adb\u00adb{Q}(x)$, that con\u00adtains all of our el\u00ade\u00admen\u00adtary func\u00adtions (see  part 2).  $la\u00adtex E$ is an ex\u00adten\u00adsion of $la\u00adtex K$.  The whole state\u00adment of the the\u00ado\u00adrem is that $la\u00adtex E$ need not be ex\u00adtend\u00aded from $la\u00adtex K$ by any\u00adthing more than some log\u00ada\u00adrithm\u00ads.   $la\u00adtex f$ is our orig\u00adi\u00adnal func\u00adtion and $la\u00adtex g=\\int f$.  Re\u00adcall from  part 1  that $la\u00adtex Dg = \\frac{\u00adDu}{u}$ is just an\u00adoth\u00ader way of say\u00ading that $la\u00adtex g = \\log{(u)}$.  The rest of the for\u00admal state\u00adment is some specifics deal\u00ading with the con\u00adstant field, which as\u00adsure us that we do not need to in\u00adtro\u00adduce any new con\u00adstants in the in\u00adte\u00adgra\u00adtion. This fact is ac\u00adtu\u00adal\u00adly im\u00adpor\u00adtant to the de\u00adcid\u00adabil\u00adi\u00adty of the Risch Al\u00adgo\u00adrith\u00adm, be\u00adcause many prob\u00adlems about con\u00adstants are ei\u00adther un\u00adknown or un\u00adde\u00adcid\u00adable (such as the tran\u00adscen\u00addence de\u00adgree of $la\u00adtex \\math\u00adb\u00adb{Q}(e, \\pi)$).  But this en\u00adsures us that as long as we start with a con\u00adstant field that is com\u00adputable, our con\u00adstant field for our anti\u00adderiv\u00ada\u00adtive will al\u00adso be com\u00adputable, and will in fact be the same field, ex\u00adcept for some pos\u00adsi\u00adble al\u00adge\u00adbra\u00adic ex\u00adten\u00adsions (the $la\u00adtex c_i$).    \n At this point, I want to point out that even though my work this sum\u00admer has been on\u00adly on the pure\u00adly tran\u00adscen\u00adden\u00adtal case of the Risch Al\u00adgo\u00adrith\u00adm, Li\u00adou\u00adville's The\u00ado\u00adrem is true for all el\u00ade\u00admen\u00adtary func\u00adtion\u00ads, which in\u00adcludes al\u00adge\u00adbra\u00adic func\u00adtion\u00ads.  How\u00adev\u00ader, if you re\u00adview the proof of the the\u00ado\u00adrem, the proof of the al\u00adge\u00adbra\u00adic part is com\u00adplete\u00adly dif\u00adfer\u00adent from the proof of the tran\u00adscen\u00adden\u00adtal part, which is the first clue that the al\u00adge\u00adbra\u00adic part of the al\u00adgo\u00adrithm is com\u00adplete\u00adly dif\u00adfer\u00adent from the tran\u00adscen\u00adden\u00adtal part (and al\u00adso a clue that it is hard\u00ader). \n Li\u00adou\u00adville's The\u00ado\u00adrem is what al\u00adlows us to prove that a giv\u00aden func\u00adtion does not have an el\u00ade\u00admen\u00adtary an\u00adtideriva\u00adtive, by giv\u00ading us the form that any anti\u00adderiv\u00ada\u00adtive must have.  We first per\u00adform the same Her\u00admite Re\u00adduc\u00adtion from the  ra\u00adtio\u00adnal in\u00adte\u00adgra\u00adtion case. Then, a gen\u00ader\u00adal\u00adiza\u00adtion of the same Lazard-Ri\u00ado\u00adboo-\u00adTrager Al\u00adgo\u00adrithm due to Roth\u00adstein al\u00adlows us to find the log\u00ada\u00adrith\u00admic part of any in\u00adte\u00adgral (the $la\u00adtex \\sum_{i=1}n c_i\\frac{\u00adDu_i}{u_i}$ from Li\u00adou\u00adville's The\u00ado\u00adrem).    \n Now a dif\u00adfer\u00adence here is that some\u00adtimes, the part of the in\u00adte\u00adgrand that cor\u00adre\u00adsponds to the $la\u00adtex \\frac{a}{x - b}$ for gen\u00ader\u00adal func\u00adtions does\u00adn't al\u00adways have an el\u00ade\u00admen\u00adtary in\u00adte\u00adgral (these are called  sim\u00adple  func\u00adtion\u00ads.  I think I will talk about them in more de\u00adtail in a fu\u00adture post in this se\u00adries).   An ex\u00adam\u00adple of this is $la\u00adtex \\frac{1}{\\log{(x)}}$.  Suf\u00adfice it to say that any el\u00ade\u00admen\u00adtary in\u00adte\u00adgral of $la\u00adtex \\frac{1}{\\log{(x)}}$ must be part of some log-ex\u00adten\u00adsion of $la\u00adtex \\math\u00adb\u00adb{Q}(x, \\log{(x)})$, and that we can prove that no such log\u00ada\u00adrith\u00admic ex\u00adten\u00adsion ex\u00adists in the course of try\u00ading to com\u00adpute it with the Lazard-Ri\u00ado\u00adboo-Roth\u00adstein-\u00adTrager Al\u00adgo\u00adrith\u00adm. \n In the ra\u00adtio\u00adnal func\u00adtion case, af\u00adter we found the ra\u00adtio\u00adnal part and the log\u00ada\u00adrith\u00admic part, we were prac\u00adti\u00adcal\u00adly done, be\u00adcause the on\u00adly re\u00admain\u00ading part was a poly\u00adno\u00admi\u00adal.  Well, for the gen\u00ader\u00adal tran\u00adscen\u00adden\u00adtal func\u00adtion case, we are left with an ana\u00adlogue, which are called  re\u00adduced  func\u00adtion\u00ads, and we are far from done.  This is the hard\u00adest part of the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrith\u00adm.  This will al\u00adso be the top\u00adic of a fu\u00adture post in this se\u00adries.  Suf\u00adfice it to say that this is where most of the proofs of non-in\u00adte\u00adgra\u00adbil\u00adi\u00adty come from, in\u00adclud\u00ading the oth\u00ader in\u00adte\u00adgrals than $la\u00adtex \\frac{1}{\\log{(x)}}$ that I gave above.    \n Con\u00adclu\u00adsion \n That's it for now.  Orig\u00adi\u00adnal\u00adly, I was al\u00adso go\u00ading to in\u00adclude a bit on the struc\u00adture the\u00ado\u00adrems too, but I think I am go\u00ading to save that for part 4 in\u00adstead.  I may or may not have an\u00adoth\u00ader post ready be\u00adfore the of\u00adfi\u00adcial end of cod\u00ading date for Google Sum\u00admer of Code, which is Mon\u00adday (three days from now).  I want to make a post with some nice graphs com\u00adpar\u00ading the tim\u00adings of the new  risch_in\u00adte\u00adgrate()  and the old  heurisch()  (what is cur\u00adrent\u00adly be\u00adhind SymPy's  in\u00adte\u00adgrate()).  But as I have said be\u00adfore, I plan on con\u00adtin\u00adu\u00ading cod\u00ading the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm be\u00adyond the pro\u00adgram un\u00adtil I fin\u00adish it, and even be\u00adyond that (there are lots of cool ways that the al\u00adgo\u00adrithm can be ex\u00adtend\u00aded to work with spe\u00adcial func\u00adtion\u00ads, there's def\u00adi\u00adnite in\u00adte\u00adgra\u00adtion with Mei\u00adjer-G func\u00adtion\u00ads, and there's of course the al\u00adge\u00adbra\u00adic part of the al\u00adgo\u00adrith\u00adm, which is a much larg\u00ader chal\u00adlenge).  And along with it, I plan to con\u00adtin\u00adue keep\u00ading you up\u00addat\u00aded with blog post\u00ads, in\u00adclud\u00ading at least all the Risch Al\u00adgo\u00adrithm se\u00adries posts that I have promised (I have count\u00aded at least three top\u00adics that I have ex\u00adplic\u00adit\u00adly promised but haven't done yet).  And of course, there will be the manda\u00adto\u00adry GSoC wrap-up blog post, de\u00adtail\u00ading my work for the sum\u00admer.    \n Please con\u00adtin\u00adue to test my pro\u00adto\u00adtype  risch_in\u00adte\u00adgrate()  func\u00adtion in my  in\u00adte\u00adgra\u00adtion3  branch, and tell me what you think (or if you find a bug).", 
      "loc": "/posts/2010/08/14/the-risch-algorithm-part-3-liouvilles-theorem/"
    }, 
    {
      "title": "Prototype risch_integrate() function ready for testing!", 
      "tags": "mathjax", 
      "text": "So to\u00adday I fi\u00adnal\u00adly fin\u00adished up the pro\u00adto\u00adtype func\u00adtion I talked about  last week.  The func\u00adtion is called  risch_in\u00adte\u00adgrate()  and is avail\u00adable at my  in\u00adte\u00adgra\u00adtion3  branch.  Un\u00adlike the in\u00adner lev\u00adel func\u00adtions I have show\u00adcased in  pre\u00advi\u00adous   blog posts, this func\u00adtion does not re\u00adquire you to do sub\u00adsti\u00adtu\u00adtion for dum\u00admy vari\u00adables and man\u00adu\u00adal\u00adly cre\u00adate a list of deriva\u00adtives, etc.  All you have to do is pass it a func\u00adtion and the in\u00adte\u00adgra\u00adtion vari\u00adable, and it will re\u00adturn the re\u00adsult, just like nor\u00admal  in\u00adte\u00adgrate(). I have spent the past few days work\u00ading on a mon\u00adster of a func\u00adtion called  build_ex\u00adten\u00adsion()  that does this prepars\u00ading work for you.  The rea\u00adson that the func\u00adtion was so hard to write is that the tran\u00adscen\u00adden\u00adtal Risch Al\u00adgo\u00adrithm is very pick\u00ady.   Ev\u00adery  dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion has to be tran\u00adscen\u00adden\u00adtal over the pre\u00advi\u00adous ex\u00adten\u00adsion\u00ads.  This means that if you have a func\u00adtion like $la\u00adtex ex + e{\\frac{x}{2}}$, you can\u00adnot write this as $la\u00adtex t_0 + t_1$ with $la\u00adtex t_0=ex$ and $la\u00adtex t_1=e{\\frac{x}{2}}$ be\u00adcause $la\u00adtex t_0$ and $la\u00adtex t_1$ will each be al\u00adge\u00adbra\u00adic over the oth\u00ader ($la\u00adtex t_0=t_12$).  You al\u00adso can\u00adnot let $la\u00adtex t_0=e{x}$ and re\u00adwrite the whole in\u00adte\u00adgral in terms of $la\u00adtex t_0$ be\u00adcause you will get $la\u00adtex t_0 + \\sqrt{t_0}$, which is an al\u00adge\u00adbra\u00adic func\u00adtion.  The on\u00adly way that you can do it is to let $la\u00adtex t_0=e{\\frac{x}{2}}$, and then your func\u00adtion will be $la\u00adtex t_02 + t_0$.    \n Now, for\u00adtu\u00adnate\u00adly, there is an al\u00adgo\u00adrithm that pro\u00advides nec\u00ades\u00adsary and suf\u00adfi\u00adcient con\u00addi\u00adtions for de\u00adter\u00admin\u00ading if an ex\u00adten\u00adsion is al\u00adge\u00adbra\u00adic over the pre\u00advi\u00adous ones.  It's called the Risch Struc\u00adture The\u00ado\u00adrem\u00ads.  My first or\u00adder of busi\u00adness this week was to fin\u00adish im\u00adple\u00adment\u00ading these.  This is ac\u00adtu\u00adal\u00adly the rea\u00adson that I we had to wait un\u00adtil now to get this pro\u00adto\u00adtype func\u00adtion.  The Struc\u00adture The\u00ado\u00adrems are at the very end of Bron\u00adstein's book, and the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm is not cor\u00adrect with\u00adout them (name\u00adly, it is not cor\u00adrect if you add an al\u00adge\u00adbra\u00adic ex\u00adten\u00adsion).  I just re\u00adcent\u00adly got to them in my read\u00ading.  Ac\u00adtu\u00adal\u00adly, I skipped some work on tan\u00adgent in\u00adte\u00adgra\u00adtion so I could get to them first.  I hope to talk a lit\u00adtle about them in a fu\u00adture \"Risch In\u00adte\u00adgra\u00adtion\" blog post, though be aware that they re\u00adquire some ex\u00adtreme\u00adly in\u00adtense al\u00adge\u00adbra\u00adic ma\u00adchin\u00adery to prove, so I won't be giv\u00ading any proof\u00ads. \n Even though these al\u00adgo\u00adrithms can tell me, for ex\u00adam\u00adple, that I should\u00adn't have added $la\u00adtex t_0=ex$ above be\u00adcause it makes $la\u00adtex e{\\frac{x}{2}}=\\sqrt{t_0}$, that means that I have to go back and restart my search for an ex\u00adten\u00adsion so that I can try to get $la\u00adtex t_0=e{\\frac{x}{2}}$ in\u00adstead.  So I wrote a sim\u00adple func\u00adtion that takes the ar\u00adgu\u00adments of the ex\u00adpo\u00adnen\u00adtials and de\u00adter\u00admines the low\u00adest com\u00admon fac\u00adtor.  This heuris\u00adtic saves a lot of time.    \n I al\u00adso no\u00adticed (ac\u00adtu\u00adal\u00adly, Chris Smith in\u00adad\u00adver\u00adtent\u00adly point\u00aded it out to me; su\u00adper thanks to him), that the Struc\u00adture The\u00ado\u00adrem al\u00adgo\u00adrithms on\u00adly tell you if the terms are the same as mono\u00admi\u00adal\u00ads.  It would tell you that $la\u00adtex ex = e{x + 1}$ be\u00adcause both sat\u00adis\u00adfy $la\u00adtex Dt=t$.  There\u00adfore, I had to al\u00adso mod\u00adi\u00adfy the struc\u00adture the\u00ado\u00adrem al\u00adgo\u00adrithms to pull out any con\u00adstant ter\u00adm.    \n It can still be nec\u00ades\u00adsary to restart build\u00ading the ex\u00adten\u00adsion even with the above heuris\u00adtic.  For ex\u00adam\u00adple, if you have $la\u00adtex ex + e{x2} + e{\\frac{x}{2} + x2}$, and start with $la\u00adtex t_0=ex$ and $la\u00adtex t_1=e{x2}$, then the struc\u00adture the\u00ado\u00adrems will tell you that $la\u00adtex e{x/2 + x2} = \\sqrt{t_0}t_1$, which we can\u00adnot use be\u00adcause of the rad\u00adi\u00adcal.  The so\u00adlu\u00adtion it us\u00ades is to split it up as $la\u00adtex ex + e{x2} + e{\\frac{x}{2}}e{x2}$ (the struc\u00adture the\u00ado\u00adrems tell you ex\u00adact\u00adly how to do this so you are split\u00adting in terms of the oth\u00ader ex\u00adpo\u00adnen\u00adtial\u00ads) and then restart the ex\u00adten\u00adsion build\u00ading en\u00adtire\u00adly.  This can be an ex\u00adpen\u00adsive op\u00ader\u00ada\u00adtion, be\u00adcause you have to re\u00adbuild $la\u00adtex t_0$ and $la\u00adtex t_1$, but this time, the heuris\u00adtic func\u00adtion I wrote from above han\u00addles the $la\u00adtex e{\\frac{x}{2}}$ cor\u00adrect\u00adly, mak\u00ading $la\u00adtex t_0=e{\\frac{x}{2}}$, with the fi\u00adnal an\u00adswer $la\u00adtex t_02 + t_1 + t_0t_1$.  I could have prob\u00ada\u00adbly made it smarter by on\u00adly go\u00ading back to be\u00adfore the con\u00adflict\u00ading ex\u00adten\u00adsion\u00ads, but this was quite a bit more work, and adds more dif\u00adfi\u00adcul\u00adties such as non-triv\u00adial re\u00adla\u00adtion\u00adship\u00ads, so I just took the lazy way and restart\u00aded com\u00adplete\u00adly.  It does\u00adn't take  that  much time.    \n Of course, some\u00adtimes, you can\u00adnot add a new ex\u00adpo\u00adnen\u00adtial, no mat\u00adter how you add the ex\u00adten\u00adsion\u00ads.  The clas\u00adsic ex\u00adam\u00adple is $la\u00adtex e{\\frac{\\log{(x)}}{2}}$, which you can see is ac\u00adtu\u00adal\u00adly equal to $la\u00adtex \\sqrt{x}$, an al\u00adge\u00adbra\u00adic func\u00adtion.  There\u00adfore, I had to im\u00adple\u00adment some tricky log\u00adic to keep the  build_ex\u00adten\u00adsion()  func\u00adtion from try\u00ading again in\u00adfin\u00adite\u00adly.  I hope I did it right, so that it nev\u00ader in\u00adfi\u00adnite loop\u00ads, and nev\u00ader fails when it re\u00adal\u00adly can be done.  On\u00adly time and test\u00ading will tel\u00adl. \n It is ex\u00adact\u00adly the same for log\u00ada\u00adrithm\u00ads, ex\u00adcept in that case, when a new log\u00ada\u00adrithm is al\u00adge\u00adbra\u00adic in terms of old ones, it can be writ\u00adten as a lin\u00adear com\u00adbi\u00adna\u00adtion of them.  This means that there are nev\u00ader any rad\u00adi\u00adcals to wor\u00adry about, though you do al\u00adso have to wor\u00adry about con\u00adstants.  For ex\u00adam\u00adple, $la\u00adtex \\log{(x)}$ looks the same as $la\u00adtex \\log{(2x)}$ be\u00adcause they both sat\u00adis\u00adfy $la\u00adtex Dt=\\frac{1}{x}$.  An ex\u00adam\u00adple of a log\u00ada\u00adrithm that is al\u00adge\u00adbra\u00adic over old ones is $la\u00adtex \\log{(x2 - 1)}$ over $la\u00adtex \\log{(x + 1)}$ and $la\u00adtex \\log{(x - 1)}$, be\u00adcause $la\u00adtex \\log{(x2 - 1)}=\\log{((x + 1)(x - 1))}=\\log{(x + 1)} + \\log{(x - 1)}$.    \n The par\u00adal\u00adlels be\u00adtween ex\u00adpo\u00adnen\u00adtials and log\u00ada\u00adrithms are amaz\u00ading.  For the struc\u00adture the\u00ado\u00adrem\u00ads, the ex\u00adpo\u00adnen\u00adtial case is ex\u00adact\u00adly the same as the log\u00ada\u00adrith\u00admic case ex\u00adcept re\u00adplac\u00ading ad\u00addi\u00adtion with mul\u00adti\u00adpli\u00adca\u00adtion and mul\u00adti\u00adpli\u00adca\u00adtion with ex\u00adpo\u00adnen\u00adti\u00ada\u00adtion.  For the ex\u00adpo\u00adnen\u00adtial case, you need the ar\u00adgu\u00adments of the al\u00adready added log\u00ada\u00adrithms to find the al\u00adge\u00adbra\u00adic de\u00adpen\u00addence, and the ar\u00adgu\u00adments of the al\u00adready added ex\u00adpo\u00adnen\u00adtials to find the con\u00adstant ter\u00adm.  For the log\u00ada\u00adrith\u00admic case, you need the ar\u00adgu\u00adments of the al\u00adready added ex\u00adpo\u00adnen\u00adtials to find the al\u00adge\u00adbra\u00adic de\u00adpen\u00addence, and the ar\u00adgu\u00adments of the al\u00adready added log\u00ada\u00adrithms to find the con\u00adtent ter\u00adm. Ev\u00adery\u00adthing else is ex\u00adact\u00adly the same, ex\u00adcept for the shift in op\u00ader\u00ada\u00adtors.  Of course, I re\u00adal\u00adize why these things are, math\u00ade\u00admat\u00adi\u00adcal\u00adly, but the sym\u00adme\u00adtry still amaz\u00ading to me.  I will hope\u00adful\u00adly ex\u00adplain in more de\u00adtail in my fu\u00adture Struc\u00adture The\u00ado\u00adrems post.    \n So on\u00adto the  risch_in\u00adte\u00adgrate()  func\u00adtion.  Here is the text that I have ba\u00adsi\u00adcal\u00adly put in my  com\u00admit mes\u00adsage, the  apt\u00adly num\u00adbered is\u00adsue  that I have cre\u00adat\u00aded for it, and the  post to the mail\u00ading list  (it's not so much that I am lazy as that I was re\u00adal\u00adly ex\u00adcit\u00aded to get this out there). \n \nI have ready in my in\u00adte\u00adgra\u00adtion3 branch a pro\u00adto\u00adtype risch_in\u00adte\u00adgrate() func\u00adtion that is a user-lev\u00adel func\u00adtion for the full Risch Al\u00adgo\u00adrithm I have been im\u00adple\u00adment\u00ading this sum\u00admer.  Pull from http://github.\u00adcom/as\u00admeur\u00ader/sympy/tree/in\u00adte\u00adgra\u00adtion3. \n This is NOT ready to go in.  It is a pro\u00adto\u00adtype func\u00adtion that I am mak\u00ading avail\u00adable so peo\u00adple can try out the new al\u00adgo\u00adrithm and hope\u00adful\u00adly help me to find the bugs in it.  Please pass it your fa\u00advorite non-ele\u00admen\u00adtary in\u00adte\u00adgrals and see if it can de\u00adter\u00admine that they are not el\u00ade\u00admen\u00adtary.  If you try to pass it a very crazy func\u00adtion at ran\u00addom, the chances are pret\u00adty high that it will not be el\u00ade\u00admen\u00adtary.  So a bet\u00adter way to test it is to come up with a crazy func\u00adtion, then dif\u00adfer\u00aden\u00adti\u00adate it. Then pass the de\u00adriv\u00ada\u00adtive and see if it can give you your orig\u00adi\u00adnal func\u00adtion back.  Note that it will prob\u00ada\u00adbly not look ex\u00adact\u00adly the same as your orig\u00adi\u00adnal func\u00adtion, and may dif\u00adfer by a con\u00adstan\u00adt.  You should ver\u00adi\u00adfy by dif\u00adfer\u00aden\u00adti\u00adat\u00ading the re\u00adsult you get and call\u00ading can\u00adcel() (or sim\u00adpli\u00adfy(), but usu\u00adal\u00adly can\u00adcel() is enough) on the dif\u00adfer\u00adence. \n So you can re\u00adview the code too, if you like, but just know that things are not sta\u00adble yet, and this is\u00adn't strict\u00adly a branch for re\u00adview.    \n So far, this func\u00adtion on\u00adly sup\u00adports ex\u00adpo\u00adnen\u00adtials and log\u00ada\u00adrithm\u00ads. \n Sup\u00adport for trigono\u00admet\u00adric func\u00adtions is planned.  Al\u00adge\u00adbra\u00adic func\u00adtions are \n not sup\u00adport\u00aded. If the func\u00adtion re\u00adturns an un\u00adeval\u00adu\u00adat\u00aded In\u00adte\u00adgral, it means \n that it has proven the in\u00adte\u00adgral to be non-ele\u00admen\u00adtary.  Note that sev\u00ader\u00adal \n cas\u00ades are still not im\u00adple\u00adment\u00aded, so you may get NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror \n in\u00adstead. Even\u00adtu\u00adal\u00adly, these will all be elim\u00adi\u00adnat\u00aded, and the on\u00adly \n NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror you should see from this func\u00adtion is \n NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror(\"Al\u00adge\u00adbra\u00adic ex\u00adten\u00adsions are not sup\u00adport\u00aded.\") \n This func\u00adtion has not been in\u00adte\u00adgrat\u00aded in any way with the al\u00adready \n ex\u00adist\u00ading in\u00adte\u00adgrate() yet, and you can use it to com\u00adpare. \n Ex\u00adam\u00adples: \n [code lan\u00adguage=\"py\"] \n In [1]: risch_in\u00adte\u00adgrate(\u00adex\u00adp(x**2), x) \n Out\u00ad[1]: \n \u2320 \n \u23ae  \u239b 2\u239e \n \u23ae  \u239dx \u23a0 \n \u23ae \u212f     dx \n \u2321 \n In [2]: risch_in\u00adte\u00adgrate(x*100ex\u00adp(x), x).d\u00adif\u00adf(x) \n Out\u00ad[2]:\n 100  x\nx   \u22c5\u212f \n In [3]: %timeit risch_in\u00adte\u00adgrate(x*100ex\u00adp(x), x).d\u00adif\u00adf(x) \n 1 loop\u00ads, best of 3: 270 ms per loop \n In [4]: in\u00adte\u00adgrate(x*100ex\u00adp(x), x) \n ... hangs ... \n In [5]: risch_in\u00adte\u00adgrate(x/log(x), x) \n Out\u00ad[5]: \n \u2320 \n \u23ae   x \n \u23ae \u2500\u2500\u2500\u2500\u2500\u2500 dx \n \u23ae log(x) \n \u2321 \n In [6]: risch_in\u00adte\u00adgrate(log(x)**10, x).d\u00adif\u00adf(x) \n Out\u00ad[6]:\n   10\nlog  (x) \n In [7]: in\u00adte\u00adgrate(log(x)**10, x).d\u00adif\u00adf(x) \n Out\u00ad[7]:\n   10\nlog  (x) \n In [8]: %timeit risch_in\u00adte\u00adgrate(log(x)**10, x).d\u00adif\u00adf(x) \n 10 loop\u00ads, best of 3: 159 ms per loop \n In [9]: %timeit in\u00adte\u00adgrate(log(x)**10, x).d\u00adif\u00adf(x) \n 1 loop\u00ads, best of 3: 2.35 s per loop \n [/\u00adcode] \n Be warned that things are still very bug\u00adgy and you should al\u00adways ver\u00adi\u00adfy \n re\u00adsults by dif\u00adfer\u00aden\u00adti\u00adat\u00ading.  Usu\u00adal\u00adly, can\u00adcel(d\u00adif\u00adf(re\u00adsult, x) - re\u00adsult) \n should be enough.  This should go to 0. \n So please, please, PLEASE, try out this func\u00adtion and re\u00adport any bugs that you find.  It is not nec\u00ades\u00adsary to re\u00adport NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror bugs, be\u00adcause I al\u00adready know about those (I put them in there), and as I men\u00adtioned above, they are all planned to dis\u00adap\u00adpear.  Al\u00adso, I am con\u00adtin\u00adu\u00adal\u00adly up\u00addat\u00ading my branch with fix\u00ades, so you should do a \"git pul\u00adl\" and try again be\u00adfore you re\u00adport any\u00adthing. \n Al\u00adso, I am aware that there are test fail\u00adures.  This is be\u00adcause I had to hack ex\u00adp._e\u00adval_\u00adsub\u00ads() to on\u00adly do ex\u00adact sub\u00adsti\u00adtu\u00adtion (no al\u00adge\u00adbra\u00adic sub\u00adsti\u00adtu\u00adtion).  It's just a quick hack workaround, and I should even\u00adtu\u00adal\u00adly get a re\u00adal fix.    \n Fi\u00adnal\u00adly, I'm think\u00ading there needs to be a way to dif\u00adfer\u00aden\u00adti\u00adate be\u00adtween an un\u00adeval\u00adu\u00adat\u00aded In\u00adte\u00adgral be\u00adcause the in\u00adte\u00adgra\u00adtor failed and an un\u00adeval\u00adu\u00adat\u00aded In\u00adte\u00adgral be\u00adcause it has proven the in\u00adte\u00adgral to be non-ele\u00admen\u00adtary.  Any ideas? \n \n\nAl\u00adso, look\u00ading at the in\u00adte\u00adgral from the pre\u00advi\u00adous blog post, you can get the dif\u00adfer\u00adent re\u00adsults by us\u00ading the  han\u00addle_log  ar\u00adgu\u00adment to  risch_in\u00adte\u00adgrate(): \n If  han\u00addle_\u00adfirst == 'log'  (the de\u00adfault right now), then it will gath\u00ader all log\u00ada\u00adrithms first, and then ex\u00adpo\u00adnen\u00adtials (in\u00adso\u00admuch as it can do it in that or\u00adder).  If  han\u00addle_\u00adfirst='\u00adex\u00adp', it gath\u00aders ex\u00adpo\u00adnen\u00adtials first.  The dif\u00adfer\u00adence is that the Risch Al\u00adgo\u00adrithm in\u00adte\u00adgrates re\u00adcur\u00adsive\u00adly, one ex\u00adten\u00adsion at a time, start\u00ading with the out\u00ader-\u00admost one. So if you have an ex\u00adpres\u00adsion with both log\u00ada\u00adrithms and ex\u00adpo\u00adnen\u00adtial\u00ads, such that they do not de\u00adpend on each oth\u00ader,  han\u00addle_\u00adfirst == 'log'  will in\u00adte\u00adgrate the ex\u00adpo\u00adnen\u00adtials first, be\u00adcause they will be gath\u00adered last (be at the top of the tow\u00ader of ex\u00adten\u00adsion\u00ads), and  han\u00addle_\u00adfirst == 'ex\u00adp'  will in\u00adte\u00adgrate the log\u00ada\u00adrithms first.  Right now, I have de\u00adfault\u00aded to 'log' be\u00adcause the ex\u00adpo\u00adnen\u00adtial in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm is slight\u00adly more com\u00adplete.  If you get  NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror  with one, it is pos\u00adsi\u00adble (though I don't know for sure yet) that you might get an an\u00adswer with the oth\u00ader.    \n Al\u00adso, they can give dif\u00adfer\u00adent look\u00ading re\u00adsult\u00ads, and at dif\u00adfer\u00adent speed\u00ads.  For ex\u00adam\u00adple: \n Hov\u00ader over the code and click on the left\u00ad-\u00admost, \"view source\" icon (a pa\u00adper icon with  < >  over it) to view with\u00adout break\u00ads.  Opens in a new win\u00addow. \n [code lan\u00adguage=\"py\"] \n In [1]: f = (x(x + 1)((x2ex\u00adp(2x2) - log(x + 1)2)2 +\n   ...: 2xex\u00adp(3x2)(x - (2x3 + 2x2 + x + 1)log(x + 1))))/((x +\n   ...: 1)log(x + 1)2 - (x3 + x2)ex\u00adp(2x2))2 \n In [2]: f \n Out\u00ad[2]: \n          \u239b                          2                                                   \u239e\n          \u239c\u239b                       2\u239e                                                   2\u239f\n          \u239c\u239c     2           2  2\u22c5x \u239f        \u239b    \u239b           2      3\u239e           \u239e  3\u22c5x \u239f\nx\u22c5(1 + x)\u22c5\u239d\u239d- log (1 + x) + x \u22c5\u212f    \u23a0  + 2\u22c5x\u22c5\u239dx - \u239d1 + x + 2\u22c5x  + 2\u22c5x \u23a0\u22c5log(1 + x)\u23a0\u22c5\u212f    \u23a0 \n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                                                2                         \n                         \u239b                                    2\u239e                          \n                         \u239c   2                  \u239b 2    3\u239e  2\u22c5x \u239f                          \n                         \u239dlog (1 + x)\u22c5(1 + x) - \u239dx  + x \u23a0\u22c5\u212f    \u23a0                            \n In [3]: risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='log') \n Out\u00ad[3]: \n       \u239b              \u239b 2\u239e\u239e                   \u239b                \u239b 2\u239e\u239e                             \n       \u239clog(1 + x)    \u239dx \u23a0\u239f                   \u239c  log(1 + x)    \u239dx \u23a0\u239f          \u239b 2\u239e               \n    log\u239c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u212f    \u239f                log\u239c- \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u212f    \u239f       2  \u239dx \u23a0               \n       \u239d    x             \u23a0                   \u239d      x             \u23a0      x \u22c5\u212f    \u22c5log(1 + x)    \nx + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - log(1 + x) - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n               2                                       2                                        2\n                                                                              2           3  2\u22c5x \n                                                                       - x\u22c5log (1 + x) + x \u22c5\u212f      \n In [4]: risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='\u00adex\u00adp') \n Out\u00ad[4]: \n       \u239b                \u239b 2\u239e\u239e                   \u239b                \u239b 2\u239e\u239e        \u239b 2\u239e             \n       \u239c                \u239dx \u23a0\u239f                   \u239c                \u239dx \u23a0\u239f        \u239dx \u23a0             \n    log\u239dlog(1 + x) + x\u22c5\u212f    \u23a0                log\u239dlog(1 + x) - x\u22c5\u212f    \u23a0     x\u22c5\u212f    \u22c5log(1 + x) \nx + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - log(1 + x) - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                2                                        2                                    2\n                                                                            2           2  2\u22c5x \n                                                                         log (1 + x) - x \u22c5\u212f      \n In [5]: %timeit risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='log') \n 1 loop\u00ads, best of 3: 1.49 s per loop \n In [6]: %timeit risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='\u00adex\u00adp') \n 1 loop\u00ads, best of 3: 1.21 s per loop \n In [7]: can\u00adcel(risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='log').d\u00adif\u00adf(x) - f) \n Out\u00ad[7]: 0 \n In [8]: can\u00adcel(risch_in\u00adte\u00adgrate(f, x, han\u00addle_\u00adfirst='\u00adex\u00adp').d\u00adif\u00adf(x) - f) \n Out\u00ad[8]: 0 \n [/\u00adcode] \n So go now, and pull my  branch, and try this func\u00adtion out.  And re\u00adport any prob\u00adlems that you have back to me, ei\u00adther through the mail\u00ading list, IR\u00adC, is\u00adsue 2010, or as a com\u00adment to this blog post (I don't re\u00adal\u00adly care how).", 
      "loc": "/posts/2010/08/05/prototype-risch_integrate-function-ready-for-testing/"
    }, 
    {
      "title": "Integration of primitive functions", 
      "tags": "mathjax", 
      "text": "Integration of Primitive Functions\nSo this past week, I had an\u00adoth\u00ader break through in my projec\u00adt.  The  first break through, as you may re\u00adcal\u00adl, was the com\u00adple\u00adtion of the  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial()  func\u00adtion, which al\u00adlowed for the in\u00adte\u00adgra\u00adtion in hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial ex\u00adten\u00adsion\u00ads, in\u00adclud\u00ading prov\u00ading the nonex\u00adis\u00adtence of el\u00ade\u00admen\u00adtary in\u00adte\u00adgral\u00ads.  Now I have worked my way up to this lev\u00adel on the oth\u00ader ma\u00adjor half of the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm (ac\u00adtu\u00adal\u00adly, ma\u00adjor third; more on that lat\u00ader): in\u00adte\u00adgra\u00adtion of prim\u00adi\u00adtive el\u00ade\u00adments.    \n This time, I can re\u00adfer you to my  pre\u00advi\u00adous blog post  for def\u00adi\u00adni\u00adtion\u00ads.  The chief thing here is that there is now a func\u00adtion in my  in\u00adte\u00adgra\u00adtion3  branch called  in\u00adte\u00adgrate_prim\u00adi\u00adtive(), and it is used pri\u00admar\u00adi\u00adly for in\u00adte\u00adgrat\u00ading func\u00adtions with log\u00ada\u00adrithm\u00ads. \n So, how about some ex\u00adam\u00adples?  The first one comes from  Al\u00adgo\u00adrithms for com\u00adput\u00ader al\u00adge\u00adbra By Kei\u00adth O. Ged\u00addes, Stephen R. Cza\u00adpor, George Labahn  (ex\u00adam\u00adple 12.8).  I like it be\u00adcause it con\u00adtains both ex\u00adpo\u00adnen\u00adtials and log\u00ada\u00adrithm\u00ads, in a way that they do not de\u00adpend on each oth\u00ader, so it can be in\u00adte\u00adgrat\u00aded with ei\u00adther  in\u00adte\u00adgrate_prim\u00adi\u00adtive()  or  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial().  In ei\u00adther case, the poly\u00adno\u00admi\u00adal part is $la\u00adtex \\frac{x}{x + 1}$, so re\u00adcur\u00adsive\u00adly call\u00ading the oth\u00ader func\u00adtion is not re\u00adquired.  (for those of you who have been fol\u00adlow\u00ading my  in\u00adte\u00adgra\u00adtion3  branch, you may no\u00adtice that this is bla\u00adtant\u00adly tak\u00aden from the com\u00admit his\u00adto\u00adry). \n Hov\u00ader over the code and click on the left\u00ad-\u00admost, \"view source\" icon (a pa\u00adper icon with  < >  over it) to view with\u00adout break\u00ads.  Opens in a new win\u00addow. \n [code lan\u00adguage=\"py\"] \n In [1]: from sympy.in\u00adte\u00adgral\u00ads.risch im\u00adport in\u00adte\u00adgrate_prim\u00adi\u00adtive, \n in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial \n In [2]: f = (x(x + 1)((x2ex\u00adp(2x2) - log(x + 1)2)2 + \n 2xex\u00adp(3x2)(x - (2x3 + 2x*2 + x + 1)log(x + 1))))/((x + \n 1)log(x + 1)2 - (x3 + x2)ex\u00adp(2x2))*2 \n In [3]: f \n Out\u00ad[3]:\n          \u239b                          2                                                   \u239e\n          \u239c\u239b                       2\u239e                                                   2\u239f\n          \u239c\u239c     2           2  2\u22c5x \u239f        \u239b    \u239b           2      3\u239e           \u239e  3\u22c5x \u239f\nx\u22c5(1 + x)\u22c5\u239d\u239d- log (1 + x) + x \u22c5\u212f    \u23a0  + 2\u22c5x\u22c5\u239dx - \u239d1 + x + 2\u22c5x  + 2\u22c5x \u23a0\u22c5log(1 + x)\u23a0\u22c5\u212f    \u23a0 \n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                                                2\n                         \u239b                                    2\u239e\n                         \u239c   2                  \u239b 2    3\u239e  2\u22c5x \u239f\n                         \u239dlog (1 + x)\u22c5(1 + x) - \u239dx  + x \u23a0\u22c5\u212f    \u23a0 \n In [4]: var('t0, t1') \n Out\u00ad[4]: (t\u2080, t\u2081) \n In [5]: a, d = map(lamb\u00adda i: Poly(i, t1), f.\u00adsub\u00ads(\u00adex\u00adp(x**2), \n t0).\u00adsub\u00ads(log(x + 1), t1).as_nu\u00admer_\u00adde\u00adnom()) \n In [6]: a \n Out\u00ad[6]: \n Poly((x + x2)*t14 + (-2t02*x3 - 2t02*x4)t1*2 + \n (-2t03*x2 - 4t03*x3 - 6t03*x4 - 8t03*x5 - \n 4t03*x6)t1 + 2t03*x3 + 2t03*x4 + t0   4x*5 + \n t04*x6, t1, do\u00admain='Z\u00adZ[x,t0]') \n In [7]: d \n Out\u00ad[7]: Poly((1 + 2x + x2)*t14 + (-2t02*x2 - 4*t02*x3 - \n 2t02*x4)t12 + t04x4 + 2*t04x5 + t04x*6, t1, \n do\u00admain='Z\u00adZ[x,t0]') \n In [8]: D = [Poly(1, x), Poly(2xt0, t0), Poly(1/(x + 1), t1)] \n In [9]: r = in\u00adte\u00adgrate_prim\u00adi\u00adtive(a, d, D, [x, t0, t1], [lamb\u00adda x: log(x + \n 1), lamb\u00adda x: ex\u00adp(x**2)]) \n In [10]: r \n Out\u00ad[10]: \n \u239b   \u239b                \u239b 2\u239e\u239e      \u239b                \u239b 2\u239e\u239e        \u239b 2\u239e                                \u239e \n \u239c   \u239c                \u239dx \u23a0\u239f      \u239c                \u239dx \u23a0\u239f        \u239dx \u23a0                \u2320               \u239f \n \u239clog\u239dlog(1 + x) + x\u22c5\u212f    \u23a0   log\u239dlog(1 + x) - x\u22c5\u212f    \u23a0     x\u22c5\u212f    \u22c5log(1 + x)     \u23ae   x           \u239f \n \u239c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u23ae \u2500\u2500\u2500\u2500\u2500 dx, True\u239f \n \u239c            2                           2                                    2   \u23ae 1 + x         \u239f \n \u239c                                                           2           2  2\u22c5x    \u2321               \u239f \n \u239d                                                        log (1 + x) - x \u22c5\u212f                       \u23a0 \n [/\u00adcode] \n An ex\u00adpla\u00adna\u00adtion:   f  is the func\u00adtion we are in\u00adte\u00adgrat\u00ading.  Prepars\u00ading is not im\u00adple\u00adment\u00aded yet, so we have to do it man\u00adu\u00adal\u00adly in  [5].   [8]  is the list of deriva\u00adtions of the mono\u00admi\u00adals we are work\u00ading with,  [x, t0, t1], which rep\u00adre\u00adsent $la\u00adtex x$, $la\u00adtex e{x2}$, and $la\u00adtex \\log{(x + 1)}$, re\u00adspec\u00adtive\u00adly. Be\u00adcause the out\u00ader\u00admost mono\u00admi\u00adal is a log\u00ada\u00adrithm (prim\u00adi\u00adtive), we call  in\u00adte\u00adgrate_prim\u00adi\u00adtive()  on it.  The last ar\u00adgu\u00adment of the func\u00adtion is the back sub\u00adsti\u00adtu\u00adtion list, in re\u00adverse or\u00adder be\u00adcause that is the or\u00adder we have to back sub\u00adsti\u00adtute in.  We can see the re\u00adsult con\u00adtains an un\u00adeval\u00adu\u00adat\u00aded In\u00adte\u00adgral.  This is be\u00adcause the re\u00adcur\u00adsive calls to in\u00adte\u00adgrate over the small\u00ader ex\u00adten\u00adsions have not yet been im\u00adple\u00adment\u00aded.  In the fi\u00adnal ver\u00adsion,  in\u00adte\u00adgrate()  will au\u00adto\u00admat\u00adi\u00adcal\u00adly call  rat\u00adin\u00adt()  in this case on it to give the com\u00adplete an\u00adswer.  The sec\u00adond ar\u00adgu\u00adment of the re\u00adsult, True, in\u00addi\u00adcates that the in\u00adte\u00adgral was el\u00ade\u00admen\u00adtary and that this is the com\u00adplete in\u00adte\u00adgral. \n Be\u00adcause the ex\u00adten\u00adsions did not de\u00adpend on each oth\u00ader, we could have al\u00adso in\u00adte\u00adgrat\u00aded in $la\u00adtex \\math\u00adb\u00adb{Q}(x, \\log{(x + 1)}, e{x2})$ in\u00adstead of $la\u00adtex \\math\u00adb\u00adb{Q}(x, e{x2}, \\log{(x + 1)})$: \n [code lan\u00adguage=\"py\"] \n In [11]: a1, d1 = map(lamb\u00adda i: Poly(i, t0), f.\u00adsub\u00ads(\u00adex\u00adp(x**2), t0).\u00adsub\u00ads(log(x + 1), t1).as_nu\u00admer_\u00adde\u00adnom()) \n In [12]: D1 = [Poly(1, x), Poly(1/(x + 1), t1), Poly(2xt0, t0)] \n In [13]: r1 = in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a1, d1, D1, [x, t1, t0], [lamb\u00adda x: ex\u00adp(x**2), lamb\u00adda x: log(x + 1)]) \n In [14]: r1 \n Out\u00ad[14]: \n \u239b   \u239b              \u239b 2\u239e\u239e      \u239b                \u239b 2\u239e\u239e                                                \u239e \n \u239c   \u239clog(1 + x)    \u239dx \u23a0\u239f      \u239c  log(1 + x)    \u239dx \u23a0\u239f          \u239b 2\u239e                                  \u239f \n \u239clog\u239c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u212f    \u239f   log\u239c- \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u212f    \u239f       2  \u239dx \u23a0                  \u2320               \u239f \n \u239c   \u239d    x             \u23a0      \u239d      x             \u23a0      x \u22c5\u212f    \u22c5log(1 + x)       \u23ae   x           \u239f \n \u239c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 - \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 + \u23ae \u2500\u2500\u2500\u2500\u2500 dx, True\u239f \n \u239c           2                          2                                        2   \u23ae 1 + x         \u239f \n \u239c                                                             2           3  2\u22c5x    \u2321               \u239f \n \u239d                                                      - x\u22c5log (1 + x) + x \u22c5\u212f                       \u23a0 \n [/\u00adcode] \n We can ver\u00adi\u00adfy by tak\u00ading the de\u00adriv\u00ada\u00adtive that the re\u00adsults in each case are anti\u00adderiv\u00ada\u00adtives of the orig\u00adi\u00adnal func\u00adtion,  f, even though they ap\u00adpear dif\u00adfer\u00aden\u00adt. \n [code lan\u00adguage=\"py\"] \n In [15]: can\u00adcel(r[0].d\u00adif\u00adf(x) - f) \n Out\u00ad[15]: 0 \n In [16]: can\u00adcel(r1[0].d\u00adif\u00adf(x) - f) \n Out\u00ad[16]: 0 \n [/\u00adcode] \n We can see in each case, the re\u00admain\u00ading un\u00adeval\u00adu\u00adat\u00aded  In\u00adte\u00adgral  was in $la\u00adtex \\math\u00adb\u00adb{Q}(x)$ on\u00adly, mean\u00ading that the re\u00adcur\u00adsive call to  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial()  or  in\u00adte\u00adgrate_prim\u00adi\u00adtive(), re\u00adspec\u00adtive\u00adly, would not have been nec\u00ades\u00adsary. Fi\u00adnal\u00adly, we can see that choos\u00ading the cor\u00adrect ex\u00adten\u00adsion to in\u00adte\u00adgrate over can make a dif\u00adfer\u00adence, time wise: \n [code lan\u00adguage=\"py\"] \n In [17]: %timeit in\u00adte\u00adgrate_prim\u00adi\u00adtive(a, d, D, [x, t0, t1], [lamb\u00adda x: log(x + 1), lamb\u00adda x: ex\u00adp(x**2)]) \n 1 loop\u00ads, best of 3: 1.91 s per loop \n In [18]: %timeit in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a1, d1, D1, [x, t1, t0], [lamb\u00adda x: ex\u00adp(x**2), lamb\u00adda x: log(x + 1)]) \n 1 loop\u00ads, best of 3: 2.63 s per loop \n [/\u00adcode] \n Just as with the ex\u00adpo\u00adnen\u00adtial case, the func\u00adtion can prove the in\u00adte\u00adgrals are non-ele\u00admen\u00adtary. This is the so-\u00adcalled  log\u00ada\u00adrith\u00admic in\u00adte\u00adgral: \n [code lan\u00adguage=\"py\"] \n In [19]: f1 = 1/log(x) \n In [20]: a, d = map(lamb\u00adda i: Poly(i, t1), f1.\u00adsub\u00ads(log(x), t1).as_nu\u00admer_\u00adde\u00adnom()) \n In [21]: a \n Out\u00ad[21]: Poly(1, t1, do\u00admain='Z\u00adZ') \n In [22]: d \n Out\u00ad[22]: Poly(t1, t1, do\u00admain='Z\u00adZ') \n In [23]: in\u00adte\u00adgrate_prim\u00adi\u00adtive(a, d, [Poly(1, x), Poly(1/x, t1)], [x, t1], [log]) \n Out\u00ad[23]: (0, False) \n [/\u00adcode] \n The sec\u00adond ar\u00adgu\u00admen\u00adt,  False, in\u00addi\u00adcates that the in\u00adte\u00adgral was non-ele\u00admen\u00adtary.  Name\u00adly, the func\u00adtion has proven that the func\u00adtion $la\u00adtex f - D(0) = \\frac{1}{\\log{(x)}}$ does not have an el\u00ade\u00admen\u00adtary an\u00adti-deriva\u00adtive over $la\u00adtex \\math\u00adb\u00adb{Q}(x, \\log{(x)})$ (see the  pre\u00advi\u00adous post  for more in\u00adfor\u00adma\u00adtion). \n Fi\u00adnal\u00adly, be aware that, just as with  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial()  many in\u00adte\u00adgrals will  raise  NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror, be\u00adcause the sub\u00adrou\u00adtines nec\u00ades\u00adsary to solve them have not yet been fin\u00adished. \n [code lan\u00adguage=\"py\"] \n In [25]: f = log(log(x))**2 \n In [26]: f.d\u00adif\u00adf(x) \n Out\u00ad[26]: \n 2\u22c5log(log(x)) \n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   x\u22c5log(x) \n In [27]: a, d = map(lamb\u00adda i: Poly(i, t1), \n can\u00adcel(f.d\u00adif\u00adf(x)).\u00adsub\u00ads(log(x), t0).\u00adsub\u00ads(log(t0), t1).as_nu\u00admer_\u00adde\u00adnom()) \n In [28]: a \n Out\u00ad[28]: Poly(2*t1, t1, do\u00admain='Z\u00adZ') \n In [29]: d \n Out\u00ad[29]: Poly(t0*x, t1, do\u00admain='Z\u00adZ[x,t0]') \n In [30]: D = [Poly(1, x), Poly(1/x, t0), Poly(1/(x*t0), t1)] \n In [31]: in\u00adte\u00adgrate_prim\u00adi\u00adtive(a, d, D, [x, t0, t1], [lamb\u00adda x: log(log(x)), log]) \n \nNotIm\u00adple\u00adment\u00aded\u00adEr\u00adror: Re\u00admain\u00ading cas\u00ades for Poly RDE not yet im\u00adple\u00adment\u00aded. \n [/\u00adcode] \n Now one thing that I want to add from the above ex\u00adam\u00adples tak\u00aden from the com\u00admit mes\u00adsage is that log\u00ada\u00adrithms are not the on\u00adly func\u00adtion that are prim\u00adi\u00adtive.  The Li func\u00adtion (the log\u00ada\u00adrith\u00admic in\u00adte\u00adgral, as above), con\u00adsid\u00adered as an el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion of $la\u00adtex \\math\u00adb\u00adb{Q}(x, \\log{(x)})$ is al\u00adso prim\u00adi\u00adtive.  But even among the com\u00admon\u00adly de\u00adfined el\u00ade\u00admen\u00adtary func\u00adtion\u00ads, there is one oth\u00ader, acr\u00adtan\u00adgents.    \n [code lan\u00adguage=\"py\"] \n In [32]: dif\u00adf(atan(x)**2, x) \n Out\u00ad[32]:   \n 2\u22c5atan(x) \n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n       2 \n  1 + x    \n In [33]: in\u00adte\u00adgrate_prim\u00adi\u00adtive(Poly(2*t, t), Poly(1 + x2, t), [Poly(1, x), Poly(1/(1 + x2), t)], [x, t], [atan]) \n Out\u00ad[33]:   \n \u239b    2         \u239e \n \u239datan (x), True\u23a0 \n In [34]: in\u00adte\u00adgrate_prim\u00adi\u00adtive(Poly(t, t), Poly(x, t), [Poly(1, x), Poly(1/(1 + x**2), t)], [x, t], [atan]) \n Out\u00ad[34]:   \n \u239b\u2320                  \u239e \n \u239c\u23ae atan(x)          \u239f \n \u239c\u23ae \u2500\u2500\u2500\u2500\u2500\u2500\u2500 dx, False\u239f \n \u239c\u23ae    x             \u239f \n \u239d\u2321                  \u23a0 \n [/\u00adcode] \n Due to a bug in the code right now, the fi\u00adnal ver\u00adsion re\u00adturns the non-ele\u00admen\u00adtary in\u00adte\u00adgral in the fi\u00adnal re\u00adsult.  Suf\u00adfice it to say that it has proven that $la\u00adtex \\int {\\frac{\\arc\u00adtan{(x)}}{x} dx}$ is non-ele\u00admen\u00adtary. As far as I know, this is\u00adn't any spe\u00adcial func\u00adtion.  Ac\u00adtu\u00adal\u00adly, it's just a ran\u00addom func\u00adtion con\u00adtain\u00ading arc\u00adtan that looked non-ele\u00admen\u00adtary to me that I plugged in and found out that I was cor\u00adrec\u00adt.  It's very sim\u00adi\u00adlar in form to the  ex\u00adpo\u00adnen\u00adtial in\u00adte\u00adgral  (Ei) or the  Sine/\u00adCo\u00adsine In\u00adte\u00adgral  (Si/\u00adCi), which is how I guessed that it would be non-ele\u00admen\u00adtary.  Maybe it should be called ATi(). \n Sta\u00adtus Up\u00addate \n So it has come to my at\u00adten\u00adtion that the sug\u00adgest\u00aded \"pen\u00adcils down\" date is one week from Mon\u00adday, and the hard \"pen\u00adcils down\" date is two weeks from Mon\u00adday (see the  Google Sum\u00admer of Code Time\u00adline).  Now, no mat\u00adter how fast I work, my work can\u00adnot be pushed in un\u00adtil Ma\u00adteusz's lat\u00adest polys branch gets pushed in, be\u00adcause my work is based on top of it.  I plan on con\u00adtin\u00adu\u00ading work on the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm be\u00adyond the sum\u00admer un\u00adtil I fin\u00adish the tran\u00adscen\u00adden\u00adtal part of the al\u00adgo\u00adrith\u00adm, and even af\u00adter that, I want to look in\u00adto im\u00adple\u00adment\u00ading oth\u00ader in\u00adte\u00adgra\u00adtion re\u00adlat\u00aded things, like def\u00adi\u00adnite in\u00adte\u00adgra\u00adtion us\u00ading  Mei\u00adjer G-\u00adfunc\u00adtion\u00ads,  and the al\u00adge\u00adbra\u00adic part of the al\u00adgo\u00adrith\u00adm.  But for now, these are the things that I need to do for the tran\u00adscen\u00adden\u00adtal part, which is this sum\u00admer's work: \n 1. Im\u00adple\u00adment the prepars\u00ading al\u00adgo\u00adrithm\u00ads.    This part is two-\u00adfold.  First, I need to im\u00adple\u00adment al\u00adgo\u00adrithms based on the Risch Struc\u00adture The\u00ado\u00adrem\u00ads, which al\u00adlow me to de\u00adter\u00admine if an ex\u00adten\u00adsion is al\u00adge\u00adbra\u00adic or not (if it is al\u00adge\u00adbraic, we can\u00adnot in\u00adte\u00adgrate it be\u00adcause on\u00adly the tran\u00adscen\u00adden\u00adtal part is im\u00adple\u00adment\u00aded).  The oth\u00ader part will be the func\u00adtion that ac\u00adtu\u00adal\u00adly goes through an ex\u00adpres\u00adsion and tries to build up a dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion from it so it can be in\u00adte\u00adgrat\u00aded.  This can be a tricky part. For ex\u00adam\u00adple, if we want to in\u00adte\u00adgrate $la\u00adtex f = ex + e{\\frac{x}{2}}$, we want to first choose $la\u00adtex t_1=e{\\frac{x}{2}}$ so that $la\u00adtex f = t_12 + t_1$, be\u00adcause if we choose $la\u00adtex t_1=ex$, then $la\u00adtex t_2=e{\\frac{x}{2}}=\\sqrt{t_1}$ will be al\u00adge\u00adbra\u00adic over $la\u00adtex \\math\u00adb\u00adb{Q}(x, t_1)$.  This is one case where we might try adding an al\u00adge\u00adbra\u00adic ex\u00adten\u00adsions but where it can be avoid\u00aded.  The so\u00adlu\u00adtion will have to be to go through and find the com\u00admon de\u00adnom\u00adi\u00adna\u00adtors of the ex\u00adpo\u00adnen\u00adtial\u00ads.  I'm al\u00adso con\u00adsid\u00ader\u00ading that this might hap\u00adpen in more ad\u00advanced ways, so it could be nec\u00ades\u00adsary for the func\u00adtion to back\u00adtrack in the ex\u00adten\u00adsion tree to see if it can do it in an en\u00adtire\u00adly tran\u00adscen\u00adden\u00adtal way.  For\u00adtu\u00adnate\u00adly, the Risch Struc\u00adture The\u00ado\u00adrems give us a de\u00adci\u00adsion pro\u00adce\u00addure for de\u00adter\u00admin\u00ading if an ex\u00adten\u00adsion can be writ\u00adten in terms of the pre\u00advi\u00adous ex\u00adten\u00adsions (is al\u00adge\u00adbra\u00adic over it), but this will still be a very hard func\u00adtion to get right. \n 2. Fin\u00adish the re\u00admain\u00ading cas\u00ades for  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial()  and  in\u00adte\u00adgrate_prim\u00adi\u00adtive().  As you could see in this post, as well as in the  pre\u00advi\u00adous one, there are many in\u00adte\u00adgrals that can\u00adnot yet be in\u00adte\u00adgrat\u00aded be\u00adcause the spe\u00adcial cas\u00ades for them have not been im\u00adple\u00adment\u00aded yet.  Most of these ac\u00adtu\u00adal\u00adly re\u00adly on im\u00adple\u00adment\u00ading the struc\u00adture the\u00ado\u00adrem al\u00adgo\u00adrithms from  1, and im\u00adple\u00adment\u00ading them once that is fin\u00adished will not take long, be\u00adcause they will just be straight copy\u00ading of the pseu\u00addocode from Bron\u00adstein's book.  But some of them, par\u00adtic\u00adu\u00adlar\u00adly ones from the prim\u00adi\u00adtive case, are not spelt out so well in Bron\u00adstein's book, and will re\u00adquire more think\u00ading (and thus time) on my part.  I should note that the Struc\u00adture The\u00ado\u00adrem al\u00adgo\u00adrithms are al\u00adso this way. \n   3. Im\u00adple\u00adment the hy\u00adper\u00adtan\u00adgent case.    The abil\u00adi\u00adty to in\u00adte\u00adgrate in tan\u00adgent ex\u00adten\u00adsions is the oth\u00ader  third  I men\u00adtioned above.  Since tan\u00adgents re\u00adquire more spe\u00adcial cas\u00ading, I plan on do\u00ading this on\u00adly af\u00adter I have fin\u00adished  1  and  2.  This is ac\u00adtu\u00adal\u00adly not much work, be\u00adcause most of the al\u00adgo\u00adrithms for solv\u00ading the par\u00adtic\u00adu\u00adlar sub\u00adprob\u00adlem for tan\u00adgents (called the  Cou\u00adpled Risch Dif\u00adfer\u00aden\u00adtial Equa\u00adtion) are ex\u00adact\u00adly the same as those for solv\u00ading the sub\u00adprob\u00adlem for hy\u00adper\u00adex\u00adpo\u00adnen\u00adtials (the  Risch Dif\u00adfer\u00aden\u00adtial Equa\u00adtion), which are al\u00adready (most\u00adly) im\u00adple\u00adment\u00aded in the hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial part.  There are on\u00adly a few ex\u00adtra func\u00adtions that need to be writ\u00adten for it.  Al\u00adso, you will still be able to in\u00adte\u00adgrate func\u00adtions that con\u00adtain tan\u00adgents, such as $la\u00adtex e{\\\u00adtan{(x)}}$ (re\u00adcall  last time  that we showed that  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial()  can prove that this does not have an el\u00ade\u00admen\u00adtary in\u00adte\u00adgral).  It just won't be able to in\u00adte\u00adgrate when the top-\u00admost ex\u00adten\u00adsion is a tan\u00adgen\u00adt. \n So here is what I plan on do\u00ading.  Right now, I am go\u00ading to fo\u00adcus my work on  1, since most of  2  can't be done un\u00adtil it is any\u00adway.  But more im\u00adpor\u00adtant\u00adly, I want to have a pro\u00adto\u00adtype user-lev\u00adel func\u00adtion for the Risch Al\u00adgo\u00adrith\u00adm.  The rea\u00adson I want this is so that peo\u00adple can try it out, with\u00adout hav\u00ading to do the prepars\u00ading like I did above, but rather they can just call  risch_in\u00adte\u00adgrate(f, x), and it will re\u00adturn the in\u00adte\u00adgral of  f, prove that it is non-ele\u00admen\u00adtary and re\u00adduce it in\u00adto the el\u00ade\u00admen\u00adtary and non-ele\u00admen\u00adtary part\u00ads, or ex\u00adplain why it can\u00adnot do it (ei\u00adther be\u00adcause the func\u00adtion is not tran\u00adscen\u00adden\u00adtal or be\u00adcause some\u00adthing is not im\u00adple\u00adment\u00aded yet).  My chief de\u00adsire for do\u00ading this is so that peo\u00adple can try out my code and find the bugs in it for me.  I have al\u00adready found many crit\u00adi\u00adcal er\u00adrors in the code (re\u00adturns a wrong re\u00adsult), and I want to iron these out be\u00adfore any\u00adthing goes in.  The best way to do this will be to re\u00adlease a work\u00ading user-lev\u00adel func\u00adtion and hope that peo\u00adple try it out for me.    \n Al\u00adso, even if  2  and  3  are not fin\u00adished, if I have  1, I can in\u00adte\u00adgrate it with  in\u00adte\u00adgrate()  (no pun in\u00adtend\u00aded) and just have it bail if it rais\u00ades  NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror  I will need to come up with a way to dif\u00adfer\u00aden\u00adti\u00adate be\u00adtween this and the case where it re\u00adturns an un\u00adeval\u00adu\u00adat\u00aded  In\u00adte\u00adgral  be\u00adcause it has proven that an el\u00ade\u00admen\u00adtary anti\u00adderiv\u00ada\u00adtive does not ex\u00adist.  Any sug\u00adges\u00adtion\u00ads? \n I plan on con\u00adtin\u00adu\u00ading work af\u00adter the sum\u00admer un\u00adtil I fin\u00adish  1  through  3, though I won't pre\u00adtend that my work won't slow down con\u00adsid\u00ader\u00adably when I start class\u00ades in Au\u00adgust.  I al\u00adso prom\u00adise to fin\u00adish the  Risch Al\u00adgo\u00adrithm posts  that I promised. \n And for what it's worth, I plan on work\u00ading my ass off this next two week\u00ads.", 
      "loc": "/posts/2010/07/31/integration-of-primitive-functions/"
    }, 
    {
      "title": "The Risch Algorithm: Part 2, Elementary Functions", 
      "tags": "mathjax", 
      "text": "In  Part 1  of this se\u00adries of blog post\u00ads, I gave what I be\u00adlieved to be the pre\u00adreq\u00adui\u00adsites to un\u00adder\u00adstand\u00ading the math\u00ade\u00admat\u00adics be\u00adhind the Risch Al\u00adgo\u00adrithm (a\u00adside from a ba\u00adsic un\u00adder\u00adstand\u00ading of de\u00adriv\u00ada\u00adtives and in\u00adte\u00adgrals from cal\u00adcu\u00adlus).  In this post, I will elab\u00ado\u00adrate on what is meant by \"ele\u00admen\u00adtary func\u00adtion,\" a term that is thrown around a lot when talk\u00ading about Risch in\u00adte\u00adgra\u00adtion. \n The usu\u00adal def\u00adi\u00adni\u00adtion of el\u00ade\u00admen\u00adtary func\u00adtion giv\u00aden in cal\u00adcu\u00adlus is any func\u00adtion that is a con\u00adstan\u00adt, a poly\u00adno\u00admi\u00adal, an ex\u00adpo\u00adnen\u00adtial ($la\u00adtex ex$, $la\u00adtex 2x$), a log\u00ada\u00adrithm ($la\u00adtex \\l\u00adn({x})$, $la\u00adtex \\log_{10}({x})$), one of the stan\u00addard trig func\u00adtions or their in\u00advers\u00ades (s\u00adin, cos, tan, arc\u00adsin, ar\u00adc\u00adcos, arc\u00adtan, etc.), and any com\u00adbi\u00adna\u00adtion of these func\u00adtions via ad\u00addi\u00adtion, sub\u00adtrac\u00adtion, mul\u00adti\u00adpli\u00adca\u00adtion, di\u00advi\u00adsion, tak\u00ading pow\u00ader\u00ads, and com\u00adpo\u00adsi\u00adtion.  Thus, even a func\u00adtion as crazy as    is el\u00ade\u00admen\u00adtary, by this def\u00adi\u00adni\u00adtion.    \n But for the rig\u00ador\u00adous def\u00adi\u00adni\u00adtion of an el\u00ade\u00admen\u00adtary func\u00adtion, we must take in\u00adto con\u00adsid\u00ader\u00ada\u00adtion what field we are work\u00ading over.  Be\u00adfore I get in\u00adto that, I need some def\u00adi\u00adni\u00adtion\u00ads.  Sup\u00adpose that $la\u00adtex k$ is the field we are work\u00ading over.  You can imag\u00adine that $la\u00adtex k=\\\u00admath\u00adb\u00adb{Q}(x)$, the field of ra\u00adtio\u00adnal func\u00adtions in x with ra\u00adtio\u00adnal num\u00adber co\u00adef\u00adfi\u00adcients.  As with the pre\u00advi\u00adous post, imag\u00adine $la\u00adtex t$ as a func\u00adtion, for ex\u00adam\u00adple, $la\u00adtex t = f(x)$.  Let $la\u00adtex K$ be a dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion of $la\u00adtex k$.  We have not de\u00adfined this, but it ba\u00adsi\u00adcal\u00adly means that our deriva\u00adtion $la\u00adtex D$ works the same in $la\u00adtex K$ as it does in $la\u00adtex k$.  You can imag\u00adine here that $la\u00adtex K=k[t]$.    \n We say that $la\u00adtex t \\in K$ is a  prim\u00adi\u00adtive  over $la\u00adtex k$ if $la\u00adtex Dt \\in k$.  In oth\u00ader word\u00ads, the de\u00adriv\u00ada\u00adtive of $la\u00adtex t$ is does not con\u00adtain $la\u00adtex t$, on\u00adly el\u00ade\u00adments of $la\u00adtex k$.  Ob\u00advi\u00adous\u00adly, by the def\u00adi\u00adni\u00adtion of a deriva\u00adtion (see the  last post  in the se\u00adries), any el\u00ade\u00adment of $la\u00adtex k$ is a prim\u00adi\u00adtive over $la\u00adtex K$, be\u00adcause the de\u00adriv\u00ada\u00adtive of any el\u00ade\u00adment of a field is again an el\u00ade\u00adment of that field (y\u00adou can see this by the def\u00adi\u00adni\u00adtion of a deriva\u00adtion, al\u00adso giv\u00aden in the last post).  But al\u00adso if $la\u00adtex t=log(a)$ for some $la\u00adtex a \\in k$, then $la\u00adtex t$ is a prim\u00adi\u00adtive over $la\u00adtex k$, be\u00adcause $la\u00adtex Dt=\\frac{\u00adDa}{a}\\in k$.    \n We say that $la\u00adtex t \\in K*$ is a  hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial  over $la\u00adtex k$ if $la\u00adtex \\frac{Dt}{t}\\in k$.  Writ\u00adten an\u00adoth\u00ader way, $la\u00adtex Dt=at$ for some $la\u00adtex a\\in k$.  We know from cal\u00adcu\u00adlus that the func\u00adtions that sat\u00adis\u00adfy dif\u00adfer\u00aden\u00adtial equa\u00adtions of the type $la\u00adtex \\frac{dy}{dx}=ay$ are ex\u00adact\u00adly the ex\u00adpo\u00adnen\u00adtial func\u00adtion\u00ads, i.e., $la\u00adtex y=e{\\in\u00adt{a\\ dx}}$.    \n The last class of func\u00adtions that needs to be con\u00adsid\u00adered is  al\u00adge\u00adbra\u00adic func\u00adtions.  I will not go in\u00adto depth on al\u00adge\u00adbra\u00adic func\u00adtion\u00ads, be\u00adcause my work this sum\u00admer is on\u00adly on in\u00adte\u00adgrat\u00ading pure\u00adly tran\u00adscen\u00adden\u00adtal func\u00adtion\u00ads.  There\u00adfore, the on\u00adly con\u00adcern we shall have with al\u00adge\u00adbra\u00adic func\u00adtions in re\u00adla\u00adtion to the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm is to make sure that what\u00adev\u00ader func\u00adtion we are in\u00adte\u00adgrat\u00ading is  not  al\u00adge\u00adbraic, be\u00adcause the tran\u00adscen\u00adden\u00adtal al\u00adgo\u00adrithms will not be valid if they are.  Hope\u00adful\u00adly in a fu\u00adture post I will be able to dis\u00adcuss the Risch Struc\u00adture The\u00ado\u00adrem\u00ads, which give nec\u00ades\u00adsary and suf\u00adfi\u00adcient con\u00addi\u00adtions for de\u00adterming if a Li\u00adou\u00advil\u00adlian func\u00adtion (see next para\u00adgraph) is al\u00adge\u00adbra\u00adic.    \n Now, we say that a func\u00adtion $la\u00adtex t \\in K$ is  Li\u00adou\u00advil\u00adlian  over $la\u00adtex k$ if $la\u00adtex t$ is al\u00adge\u00adbraic, a prim\u00adi\u00adtive, or a hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial over $la\u00adtex k$.  For $la\u00adtex t\\in K$ to be a  Li\u00adou\u00advil\u00adlian mono\u00admi\u00adal  over $la\u00adtex k$, we have the ad\u00addi\u00adtion\u00adal con\u00addi\u00adtion that $la\u00adtex \\math\u00adrm{\u00adCon\u00adst}(k) = \\math\u00adrm{\u00adCon\u00adst}(k(t))$. This just means that we can\u00adnot con\u00adsid\u00ader some\u00adthing like $la\u00adtex \\log({2})$ over $la\u00adtex \\math\u00adb\u00adb{Q}$ as a Li\u00adou\u00advil\u00adlian mono\u00admi\u00adal.  Oth\u00ader\u00adwise (I be\u00adlieve) we could run in\u00adto un\u00adde\u00adcid\u00adabil\u00adi\u00adty prob\u00adlem\u00ads.    \n We call $la\u00adtex t \\in K$ a  log\u00ada\u00adrithm  over $la\u00adtex k$ if $la\u00adtex Dt=\\frac{D\u00adb}{b}$ for some $la\u00adtex b \\in k$, i.e., $la\u00adtex t=\\log({b})$.  We call $la\u00adtex t \\in K$ an  ex\u00adpo\u00adnen\u00adtial  over $la\u00adtex k$ if $la\u00adtex \\frac{Dt}{t}=D\u00adb$ (or $la\u00adtex Dt=t\u00adD\u00adb$) for some $la\u00adtex b \\in k$, i.e., $la\u00adtex t=eb$.  Note the dif\u00adfer\u00adence be\u00adtween an  ex\u00adpo\u00adnen\u00adtial  mono\u00admi\u00adal and a  hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial  mono\u00admi\u00adal.    \n We can fi\u00adnal\u00adly give the rig\u00ador\u00adous def\u00adi\u00adni\u00adtion of an el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion.  $la\u00adtex K$ is an  el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion  of $la\u00adtex k$ if there are $la\u00adtex t_1, \\dot\u00ads, t_n \\in K$ such that $la\u00adtex K=k(t_1,\\\u00addot\u00ads,t_n)$ and $la\u00adtex t_i$ is el\u00ade\u00admen\u00adtary over $la\u00adtex k(t_1, \\dot\u00ads, t_{i-1})$ for all $la\u00adtex i \\in {1,\\\u00addot\u00ads,n}$.  An  el\u00ade\u00admen\u00adtary func\u00adtion    is any el\u00ade\u00adment of an el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion of $la\u00adtex \\math\u00adb\u00adb{C}(x)$ with the deriva\u00adtion $la\u00adtex D=\\frac{d}{dx}$.  A func\u00adtion $la\u00adtex f\\in k$ has an  el\u00ade\u00admen\u00adtary in\u00adte\u00adgral  over $la\u00adtex k$ if there ex\u00adists an el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion $la\u00adtex K$ of $la\u00adtex k$ and $la\u00adtex g\\in K$ such that $la\u00adtex Dg=f$, i.e., $la\u00adtex f=\\in\u00adt{g}$.    \n Usu\u00adal\u00adly, we start with $la\u00adtex \\math\u00adb\u00adb{Q}(x)$, the field of ra\u00adtio\u00adnal func\u00adtions in x with ra\u00adtio\u00adnal num\u00adber co\u00adef\u00adfi\u00adcients. We then build up an el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion one func\u00adtion at a time, with each func\u00adtion ei\u00adther be\u00ading a log\u00ada\u00adrithm or ex\u00adpo\u00adnen\u00adtial of what we have al\u00adready built up, or al\u00adge\u00adbra\u00adic over it.  As I not\u00aded above, we will ig\u00adnore al\u00adge\u00adbra\u00adic func\u00adtions here.  We gen\u00ader\u00adal\u00adly start with $la\u00adtex \\math\u00adb\u00adb{Q}$ be\u00adcause it is com\u00adputable (im\u00adpor\u00adtant prob\u00adlems such as the ze\u00adro equiv\u00ada\u00adlence prob\u00adlem or the prob\u00adlem of de\u00adter\u00admin\u00ading cer\u00adtain field iso\u00admor\u00adphisms are de\u00adcid\u00adable), but the above def\u00adi\u00adni\u00adtion lets us start with any sub\u00adfield of $la\u00adtex \\math\u00adb\u00adb{C}$.    \n Now you may be won\u00adder\u00ading: we've cov\u00adered al\u00adge\u00adbra\u00adic func\u00adtion\u00ads, ex\u00adpo\u00adnen\u00adtials and log\u00ada\u00adrithm\u00ads, and ob\u00advi\u00adous\u00adly ra\u00adtio\u00adnal func\u00adtions are el\u00ade\u00adments of $la\u00adtex \\math\u00adb\u00adb{Q}(x)$, but what about trigono\u00admet\u00adric func\u00adtion\u00ads?  Well, from a the\u00ado\u00adret\u00adi\u00adcal stand point, we can make our lives eas\u00adi\u00ader by notic\u00ading that all the com\u00admon trigono\u00admet\u00adric func\u00adtions can be rep\u00adre\u00adsent\u00aded as ex\u00adpo\u00adnen\u00adtials and log\u00ada\u00adrithms over $la\u00adtex \\math\u00adb\u00adb{Q}(i)$.  For ex\u00adam\u00adple, $la\u00adtex \\cos{x} = \\frac{e{ix} + e{-ix}}{2}$.  You can see  here  that all the com\u00admon trig func\u00adtions can be rep\u00adre\u00adsent\u00aded as com\u00adplex ex\u00adpo\u00adnen\u00adtials or log\u00ada\u00adrithms like this.  How\u00adev\u00ader, from an al\u00adgo\u00adrith\u00admic stand\u00adpoint, we don't want do con\u00advert all trig ex\u00adpres\u00adsions in\u00adto com\u00adplex ex\u00adpo\u00adnen\u00adtials and log\u00ada\u00adrithms in or\u00adder to in\u00adte\u00adgrate them.  For one thing, our fi\u00adnal re\u00adsult will be in terms of com\u00adplex ex\u00adpo\u00adnen\u00adtials and log\u00ada\u00adrithm\u00ads, not the orig\u00adi\u00adnal func\u00adtions we start\u00aded with, and con\u00advert\u00ading them back may or may not be an easy thing to do.  Al\u00adso, aside from the fact that we have dif\u00adfer\u00adent func\u00adtions than we were ex\u00adpect\u00ading, we al\u00adso will end up with an an\u00adswer con\u00adtain\u00ading $la\u00adtex \\sqrt{-1}$, even if our orig\u00adi\u00adnal in\u00adte\u00adgrand did not.    \n For\u00adtu\u00adnate\u00adly, the in\u00adte\u00adgrat\u00ading tan\u00adgents di\u00adrect\u00adly is a solved prob\u00adlem, just like in\u00adte\u00adgrat\u00ading al\u00adge\u00adbraic, ex\u00adpo\u00adnen\u00adtial, or log\u00ada\u00adrith\u00admic func\u00adtions is solved.  We can't in\u00adte\u00adgrate func\u00adtions like $la\u00adtex \\s\u00adin{x}$ or $la\u00adtex \\cos{x}$ di\u00adrect\u00adly as mono\u00admi\u00adals like we can with $la\u00adtex \\tan{x}$ or $la\u00adtex ex$, be\u00adcause the de\u00adriv\u00ada\u00adtives of sin and cos are not poly\u00adno\u00admi\u00adals in their re\u00adspec\u00adtive selves with co\u00adef\u00adfi\u00adcients in $la\u00adtex \\math\u00adb\u00adb{C}(x)$.  How\u00adev\u00ader, we can use a trick or two to in\u00adte\u00adgrate them.  One way is to re\u00adwrite $la\u00adtex \\cos{x}=\\frac{1 - \\tan2{\\frac{x}{2}}}{1 + \\tan2{\\frac{x}{2}}}$ and pro\u00adceed to in\u00adte\u00adgrate it as a tan\u00adgen\u00adt.  An\u00adoth\u00ader al\u00adter\u00adna\u00adtive is to write $la\u00adtex \\cos{x}=\\frac{1}{\\sec{x}}=\\sqrt{\\frac{1}{\\sec2{x}}}=\\sqrt{\\frac{1}{\\\u00adtan2{x} + 1}}$.  This func\u00adtion is al\u00adge\u00adbra\u00adic over $la\u00adtex \\math\u00adb\u00adb{Q}(x, \\tan{(x)})$, but if we do not al\u00adready have $la\u00adtex \\tan{x}$ in our dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion, it is tran\u00adscen\u00adden\u00adtal, and we can re\u00adwrite it as $la\u00adtex e{-\\frac{\\log{(1 + \\tan2{x})}}{2}}$ (this is used in Bron\u00adstein's tex\u00adt, so I be\u00adlieve what I just said is cor\u00adrec\u00adt, though I haven't ver\u00adi\u00adfied it with the struc\u00adture the\u00ado\u00adrems just yet).   These both work us\u00ading the rel\u00ade\u00advant iden\u00adti\u00adties for sin too.  Of course, there is still the prob\u00adlem of rewrit\u00ading the fi\u00adnal in\u00adte\u00adgrand back in terms of sin or cos.  Oth\u00ader\u00adwise, you will get some\u00adthing like $la\u00adtex \\frac{2ex\\\u00adtan({\\frac{x}{2}}) - \\tan2({\\frac{x}{2}})ex + ex}{2 + 2\\\u00adtan2({\\frac{x}{2}})}$ in\u00adstead of $la\u00adtex \\frac{ex(\\s\u00adin{(x)} + \\cos{(x)})}{2}$ for $la\u00adtex \\in\u00adt{\\\u00adcos{(x)}exdx}$.  Bron\u00adstein does\u00adn't elab\u00ado\u00adrate on this too much in his book, so it is some\u00adthing that I will have to fig\u00adure out on my own. \n The sec\u00adond op\u00adtion I gave above leads nice\u00adly in\u00adto the main point I want\u00aded to make here about el\u00ade\u00admen\u00adtary func\u00adtion\u00ads.  No\u00adtice that ev\u00adery\u00adwhere in the def\u00adi\u00adni\u00adtions above, things de\u00adpend on the field we are work\u00ading in.  There\u00adfore, $la\u00adtex e{\\\u00adtan{x}}$ can\u00adnot be an el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion over $la\u00adtex \\math\u00adb\u00adb{Q}(x)$, but it can be over $la\u00adtex \\math\u00adb\u00adb{Q}(x, \\tan{x})$.  Al\u00adso, the  er\u00adror func\u00adtion, de\u00adfined as $la\u00adtex \\math\u00adrm{er\u00adf}{(x)} = \\frac{2}{\\sqrt{\\pi}}\\in\u00adt{e{-x2}dx}$ can\u00adnot be an el\u00ade\u00admen\u00adtary ex\u00adten\u00adsion over $la\u00adtex \\math\u00adb\u00adb{Q}(x)$, but it can over $la\u00adtex \\math\u00adb\u00adb{Q}(x, e{-x2})$. In fact this is how we can in\u00adte\u00adgrate in terms of some spe\u00adcial func\u00adtion\u00ads, in\u00adclud\u00ading the er\u00adror func\u00adtion: by man\u00adu\u00adal\u00adly adding $la\u00adtex e{-x2}$ (or what\u00adev\u00ader) to our dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion.   There\u00adfore, the usu\u00adal def\u00adi\u00adni\u00adtion of an el\u00ade\u00admen\u00adtary an\u00adti-derivaitve and the above Risch Al\u00adgo\u00adrithm def\u00adi\u00adni\u00adtion of an el\u00ade\u00admen\u00adtary in\u00adte\u00adgral co\u00adin\u00adcide on\u00adly when the ex\u00adten\u00adsion con\u00adsists on\u00adly of el\u00ade\u00admen\u00adtary func\u00adtions of the form of the usu\u00adal def\u00adi\u00adni\u00adtion (note that above, our fi\u00adnal fields are $la\u00adtex \\math\u00adb\u00adb{Q}(x, \\tan{x}, e{\\\u00adtan{x}})$ and $la\u00adtex \\math\u00adb\u00adb{Q}(x, e{-x2}, \\math\u00adrm{er\u00adf}{(x)})$, re\u00adspec\u00adtive\u00adly).    \n Orig\u00adi\u00adnal\u00adly, I was al\u00adso go\u00ading to talk about Li\u00adou\u00adville's The\u00ado\u00adrem in this blog post, but I think it has al\u00adready got\u00adten long enough (read \"I'm get\u00adting tired\"), so I'll put that off un\u00adtil next time.", 
      "loc": "/posts/2010/07/24/the-risch-algorithm-part-2-elementary-functions/"
    }, 
    {
      "title": "A hard week", 
      "tags": "mathjax", 
      "text": "Af\u00adter last week's  break\u00adthrough, work this week has been very slow.  I start\u00aded work\u00ading on the Para\u00admet\u00adric Risch Dif\u00adfer\u00aden\u00adtial Equa\u00adtion Prob\u00adlem, which is al\u00admost iden\u00adti\u00adcal to the Risch Dif\u00adfer\u00aden\u00adtial Equa\u00adtion Prob\u00adlem in how it is solved, ex\u00adcept there are a few ex\u00adtra step\u00ads.  Un\u00adfor\u00adtu\u00adnate\u00adly, be\u00adcause it is so sim\u00adi\u00adlar, Bron\u00adstein breezes through the de\u00adscrip\u00adtion.  This is fine for the parts that are the same, but he is a lit\u00adtle un\u00adclear on how some of the new parts fit in.  Al\u00adso, his pseu\u00addocode has a line more or less say\u00ading   \n [code] \n if r1 = \u2026 = rn = 0 then\n    N = -1\nelse\n    N = max(deg(r1), \u2026, deg(rn)) \n for i from 0 to N\n    for j from 1 to m\n        Mij = co\u00adef\u00adfi\u00adcien\u00adt(r\u00adj, ti) \n [/\u00adcode] \n where M is a ma\u00adtrix.  It is not very clear what this is sup\u00adposed to mean in the case where N = -1.  Ob\u00advi\u00adous\u00adly, you can't have a a ma\u00adtrix with neg\u00ada\u00adtive di\u00admen\u00adsion\u00ads.  Clear\u00adly, this means that this par\u00adtic\u00adu\u00adlar func\u00adtion does\u00adn't ap\u00adply some\u00adhow in this case, but I am not re\u00adal\u00adly even sure where it fits in to the whole al\u00adgo\u00adrithm at this point in read\u00ading.  Af\u00adter read\u00ading a few more pages in, it gives a few hints here and there on how it is to be used, but nev\u00ader is it ex\u00adplic\u00adit\u00adly shown, in pseu\u00addocode or oth\u00ader\u00adwise.  So for now, I think my best bet is to read ahead and get a fuller un\u00adder\u00adstand\u00ading of the com\u00adplete func\u00adtion be\u00adfore I try im\u00adple\u00adment\u00ading any\u00adthing (this is what I had been do\u00ading be\u00adfore, but I caught up to my\u00adself).    \n Al\u00adso, on an un\u00adre\u00adlat\u00aded note, I just found out to\u00adday that I passed my  Google Sum\u00admer of Code midterm eval\u00adu\u00ada\u00adtion.  This means that I will re\u00adceive half of my stipend for the pro\u00adgram (the oth\u00ader half comes af\u00adter pass\u00ading the fi\u00adnal eval\u00adu\u00ada\u00adtion at the end of the sum\u00admer), and that I can con\u00adtin\u00adue work\u00ading on my project in the pro\u00adgram.    \n ED\u00adIT: \n Lat\u00ader in the tex\u00adt, it runs through an ex\u00adam\u00adple and says \"\u2026 $la\u00adtex dc = -1$, hence M and A are 0 by 0 ma\u00adtri\u00adces.\"  So ob\u00advi\u00adous\u00adly, that is what was mean\u00adt.", 
      "loc": "/posts/2010/07/17/a-hard-week/"
    }, 
    {
      "title": "Integration of exponential functions", 
      "tags": "mathjax", 
      "text": "So for the first time this sum\u00admer, I missed my blog\u00adging dead\u00adline.  I have been on va\u00adca\u00adtion for the past few week\u00ads, and have spent a good bit of the last week in the car, driv\u00ading home. But that's not my ex\u00adcuse.  I was on va\u00adca\u00adtion the week be\u00adfore, when I wrote up my  lengthy blog post on the Risch Al\u00adgo\u00adrithm.  My ex\u00adcuse is that I want\u00aded to fin\u00adish up my  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial()  func\u00adtion be\u00adfore I post\u00aded, so I could write about it.  Well, I fin\u00adished it on Thurs\u00adday (to\u00adday is Sun\u00adday, the post was due Fri\u00adday), but I ran in\u00adto un\u00adex\u00adpect\u00aded bugs (imag\u00adine that) that has post\u00adponed it ac\u00adtu\u00adal\u00adly work\u00ading un\u00adtil now. I al\u00adso end\u00aded up do\u00ading API changes 3 dif\u00adfer\u00adent times (they are ba\u00adsi\u00adcal\u00adly in\u00adcre\u00admen\u00adtal\u00adly all one change, from sup\u00adport\u00ading on\u00adly one ex\u00adten\u00adsion to prop\u00ader\u00adly sup\u00adport\u00ading mul\u00adti\u00adple ex\u00adten\u00adsion\u00ads.  Look for long com\u00admits in my re\u00adcent com\u00admit his\u00adto\u00adry in my branch if you are in\u00adter\u00adest\u00aded).    \n So here is the func\u00adtion.  It in\u00adte\u00adgrates ex\u00adpo\u00adnen\u00adtial func\u00adtion\u00ads.  You still have to man\u00adu\u00adal\u00adly cre\u00adate the dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion, as be\u00adfore.  Here are some ex\u00adam\u00adples.  You can try them in my  in\u00adte\u00adgra\u00adtion2  branch (I have re\u00adbased over Ma\u00adteusz's lat\u00adest polys9up\u00addate.  The lat\u00adest branch is al\u00adways in\u00adte\u00adgra\u00adtionn, where  n  is the largest in\u00adte\u00adger avail\u00adable).    \n Hov\u00ader over the code and click on the left\u00ad-\u00admost, \"view source\" icon (a pa\u00adper icon with  < >  over it) to view with\u00adout break\u00ads.  Opens in a new win\u00addow. \n [code lan\u00adguage=\"py\"] \n In [1]: from sympy.in\u00adte\u00adgral\u00ads.risch im\u00adport * \n In [2]: var('t1, t') \n Out\u00ad[2]: (t\u2081, t) \n In [3]: r = ex\u00adp(2tan(x))tan(x) + tan(x) + ex\u00adp(\u00adtan(x)) \n In [4]: r \n Out\u00ad[4]: \n 2\u22c5\u00adtan(x)                    tan(x)\n\u212f        \u22c5tan(x) + tan(x) + \u212f        \n In [5]: rd = r.d\u00adif\u00adf(x) \n In [6]: rd \n Out\u00ad[6]: \n    \u239b         2   \u239e  2\u22c5\u00adtan(x)             2      \u239b       2   \u239e  2\u22c5\u00adtan(x)   \u239b       2   \u239e  tan(x)\n1 + \u239d2 + 2\u22c5\u00adtan (x)\u23a0\u22c5\u212f        \u22c5tan(x) + tan (x) + \u239d1 + tan (x)\u23a0\u22c5\u212f         + \u239d1 + tan (x)\u23a0\u22c5\u212f        \n In [7]: a, d = map(lamb\u00adda i: Poly(i, t), rd.\u00adsub\u00ads(\u00adtan(x), t1).\u00adsub\u00ads(\u00adex\u00adp(t1), t).as_nu\u00admer_\u00adde\u00adnom()) # Man\u00adu\u00adal\u00adly cre\u00adate the ex\u00adten\u00adsion \n In [8]: a \n Out\u00ad[8]: Poly((1 + 2t1 + t12 + 2*t13)t2 + (1 + t12)t + 1 + t1*2, t, do\u00admain='Z\u00adZ[t1]') \n In [9]: d \n Out\u00ad[9]: Poly(1, t, do\u00admain='Z\u00adZ') \n In [10]: in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a, d, [Poly(1, x), Poly(1 + t12, t1), Poly((1 + t12)*t, t)], [x, t1, t], [lamb\u00adda x: ex\u00adp(\u00adtan(x)), tan]) \n Out\u00ad[10]:   \n \u239b                   \u2320                                 \u239e \n \u239c 2\u22c5\u00adtan(x)          \u23ae \u239b       2   \u239e       tan(x)      \u239f \n \u239c\u212f        \u22c5tan(x) + \u23ae \u239d1 + tan (x)\u23a0 dx + \u212f      , True\u239f \n \u239d                   \u2321                                 \u23a0 \n [/\u00adcode] \n We have to man\u00adu\u00adal\u00adly build up the dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion ([7]).  The first el\u00ade\u00adment is $la\u00adtex x$, which is al\u00adready there.  Nex\u00adt, we add $la\u00adtex t_1 = \\tan{x}$, and fi\u00adnal\u00adly $la\u00adtex t = e{\\\u00adtan{x}} = e{t_1}$.  The third ar\u00adgu\u00adment of  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial()  is what gives these vari\u00adables their iden\u00adti\u00adties: their de\u00adriv\u00ada\u00adtives.  The fourth ar\u00adgu\u00adment is the list of the ex\u00adten\u00adsion sym\u00adbol\u00ads, and the last ar\u00adgu\u00adment is a list of the func\u00adtions for which the sym\u00adbols stand for, in re\u00adverse or\u00adder (be\u00adcause we have to back sub\u00adsti\u00adtute in the so\u00adlu\u00adtion in re\u00adverse or\u00adder).    \n The un\u00adeval\u00adu\u00adat\u00aded In\u00adte\u00adgral in the so\u00adlu\u00adtion is due to the re\u00adcur\u00adsive na\u00adture of the Risch al\u00adgo\u00adrith\u00adm.  Even\u00adtu\u00adal\u00adly, an out\u00ader func\u00adtion in the al\u00adgo\u00adrithm will re\u00adcur\u00adsive\u00adly in\u00adte\u00adgrate un\u00adtil it reach\u00ades the ground field, $la\u00adtex \\math\u00adb\u00adb{Q}$.  It will al\u00adso do the prop\u00ader prepars\u00ading au\u00adto\u00admat\u00adi\u00adcal\u00adly as well.  The sec\u00adond el\u00ade\u00adment of the so\u00adlu\u00adtion,  True, in\u00addi\u00adcates that the in\u00adte\u00adgral is el\u00ade\u00admen\u00adtary, and thus the giv\u00aden so\u00adlu\u00adtion is the com\u00adplete in\u00adte\u00adgral of the orig\u00adi\u00adnal in\u00adte\u00adgrand, which we can see ($la\u00adtex \\int (1 + \\tan2{x})dx=\\\u00adtan{x}$).    \n An\u00adoth\u00ader ex\u00adam\u00adple: \n [code lan\u00adguage=\"py\"] \n In [1]: from sympy.in\u00adte\u00adgral\u00ads.risch im\u00adport * \n In [2]: var('t') \n Out\u00ad[2]: (t,) \n In [3]: rd = ex\u00adp(-x**2) \n In [4]: rd \n Out\u00ad[4]: \n   2\n -x \n\u212f     \n In [5]: a, d = map(lamb\u00adda i: Poly(i, t), rd.\u00adsub\u00ads(\u00adex\u00adp(x**2), t).as_nu\u00admer_\u00adde\u00adnom()) \n In [6]: a \n Out\u00ad[6]: Poly(1, t, do\u00admain='Z\u00adZ') \n In [7]: d \n Out\u00ad[7]: Poly(t, t, do\u00admain='Z\u00adZ') \n In [8]: in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a, d, [Poly(1, x), Poly(2xt, t)], [x, t], [lamb\u00adda x: ex\u00adp(x**2)]) \n Out\u00ad[8]: (0, False) \n [/\u00adcode] \n Here the sec\u00adond ar\u00adgu\u00adment of the so\u00adlu\u00adtion is  False, which in\u00addi\u00adcates that the al\u00adgo\u00adrithm has proven that the in\u00adte\u00adgral of $la\u00adtex e{-x2}$ is not el\u00ade\u00admen\u00adtary!   The first ar\u00adgu\u00adment 0 in\u00addi\u00adcates that ac\u00adtu\u00adal\u00adly it is the in\u00adte\u00adgral of $la\u00adtex e{-x2} - \\frac{d}{dx}(0)$ that is not el\u00ade\u00admen\u00adtary, i.e., the Risch al\u00adgo\u00adrithm will re\u00adduce an in\u00adte\u00adgrand in\u00adto an in\u00adte\u00adgrat\u00aded func\u00adtion part and non-ele\u00admen\u00adtary part.  For ex\u00adam\u00adple: \n [code lan\u00adguage=\"py\"] \n In [1]: from sympy.in\u00adte\u00adgral\u00ads.risch im\u00adport * \n In [2]: var('t1, t') \n Out\u00ad[2]: (t\u2081, t) \n In [3]: rd = ex\u00adp(x)/\u00adtan(x) + ex\u00adp(x)/(1 + ex\u00adp(x)) \n In [4]: rd \n Out\u00ad[4]: \n   x        x \n  \u212f        \u212f   \n\u2500\u2500\u2500\u2500\u2500\u2500 + \u2500\u2500\u2500\u2500\u2500\u2500\n     x   tan(x)\n1 + \u212f            \n In [5]: a, d = map(lamb\u00adda i: Poly(i, t), rd.\u00adsub\u00ads(\u00adex\u00adp(x), t).\u00adsub\u00ads(\u00adtan(x), t1).as_nu\u00admer_\u00adde\u00adnom()) \n In [6]: a \n Out\u00ad[6]: Poly(t*2 + (1 + t1)t, t, do\u00admain='Z\u00adZ[t1]') \n In [7]: d \n Out\u00ad[7]: Poly(t1*t + t1, t, do\u00admain='Z\u00adZ[t1]') \n In [8]: in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a, d, [Poly(1, x), Poly(1 + t1**2, t1), Poly(t, t)], [x, t1, t], [ex\u00adp, tan]) \n Out\u00ad[8]:   \n \u239b   \u239b     x\u239e       \u239e \n \u239dlog\u239d1 + \u212f \u23a0, False\u23a0 \n [/\u00adcode] \n This in\u00addi\u00adcates that the in\u00adte\u00adgral of $la\u00adtex (\\frac{ex}{\\\u00adtan{x}} + \\frac{ex}{1 + ex}) - \\frac{d}{dx}(\\log{(1 + ex)}) = \\frac{ex}{\\\u00adtan{x}}$ is not el\u00ade\u00admen\u00adtary.  That is one ad\u00advan\u00adtage that the new al\u00adgo\u00adrithm will have over the present one.  Cur\u00adrent\u00adly, the present al\u00adgo\u00adrithm just re\u00adturns an un\u00adeval\u00adu\u00adat\u00aded In\u00adte\u00adgral for the above  rd, but the new one will be able to re\u00adturn $la\u00adtex \\log{(1 + ex)} + \\in\u00adt{\\frac{ex}{\\\u00adtan{x}}dx}$.  It will be able to do this even if rd were rewrit\u00adten as $la\u00adtex \\frac{ex \\tan{x} + ex + e{2x}}{ex \\tan{x} + \\tan{x}}$ (no\u00adtice that this is ex\u00adact\u00adly what  .as_nu\u00admer_\u00adde\u00adnom()  is do\u00ading any\u00adway in  [5], as you can see in  [6]  and  [7]).  Fur\u00adther\u00admore, it will have ac\u00adtu\u00adal\u00adly  proven  that the re\u00admain\u00ading $la\u00adtex \\in\u00adt{\\frac{ex}{\\\u00adtan{x}}dx}$ is non-ele\u00admen\u00adtary.  I plan on hav\u00ading some kind of mark\u00ader in the pret\u00adty print\u00aded un\u00adeval\u00adu\u00adat\u00aded  In\u00adte\u00adgral  to in\u00addi\u00adcate this.  Sug\u00adges\u00adtions on what this should be are wel\u00adcome.    \n Fi\u00adnal\u00adly, the full al\u00adgo\u00adrithm ap\u00adpears to be faster (prob\u00ada\u00adbly asymp\u00adtot\u00adi\u00adcal\u00adly faster) than the cur\u00adrent im\u00adple\u00admen\u00adta\u00adtion: \n [code lan\u00adguage=\"py\"] \n In [1]: from sympy.in\u00adte\u00adgral\u00ads.risch im\u00adport * \n In [2]: var('t1, t') \n Out\u00ad[2]: (t\u2081, t) \n In [3]: rd = ex\u00adp(x)x*4 \n In [4]: a, d = map(lamb\u00adda i: Poly(i, t), rd.\u00adsub\u00ads(\u00adex\u00adp(x), t).as_nu\u00admer_\u00adde\u00adnom()) \n In [5]: in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a, d, [Poly(1, x), Poly(t, t)], [x, t], [lamb\u00adda x: ex\u00adp(x)]) \n Out\u00ad[5]:   \n \u239b    x    4  x         x      3  x       2  x      \u239e \n \u239d24\u22c5\u212f  + x \u22c5\u212f  - 24\u22c5x\u22c5\u212f  - 4\u22c5x \u22c5\u212f  + 12\u22c5x \u22c5\u212f , True\u23a0 \n In [6]: %timeit in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a, d, [Poly(1, x), Poly(t, t)], [x, t], [ex\u00adp]) \n 10 loop\u00ads, best of 3: 28 ms per loop \n In [7]: in\u00adte\u00adgrate(rd, x) \n Out\u00ad[7]: \n    x    4  x         x      3  x       2  x\n24\u22c5\u212f  + x \u22c5\u212f  - 24\u22c5x\u22c5\u212f  - 4\u22c5x \u22c5\u212f  + 12\u22c5x \u22c5\u212f   \n In [8]: %timeit in\u00adte\u00adgrate(rd, x) \n 1 loop\u00ads, best of 3: 218 ms per loop \n [/\u00adcode] \n Of course, keep in mind that I am tim\u00ading what will be an in\u00adter\u00adnal func\u00adtion against a full func\u00adtion.  But if you in\u00adcrease the ex\u00adpo\u00adnent on x, you find that there is no way the ad\u00addi\u00adtion of prepars\u00ading time (which should\u00adn't be af\u00adfect\u00aded by such a change) will cause it to be\u00adcome as slow as the cur\u00adrent  in\u00adte\u00adgrate().  Like I said, I am pret\u00adty sure that it is as\u00adymp\u00adtot\u00adic.  For ex\u00adam\u00adple: \n [code lan\u00adguage=\"py\"] \n In [1]: from sympy.in\u00adte\u00adgral\u00ads.risch im\u00adport * \n In [2]: var('t1, t') \n Out\u00ad[2]: (t\u2081, t) \n In [3]: rd = ex\u00adp(x)x*10 \n In [4]: a, d = map(lamb\u00adda i: Poly(i, t), rd.\u00adsub\u00ads(\u00adex\u00adp(x), t).as_nu\u00admer_\u00adde\u00adnom()) \n In [5]: in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a, d, [Poly(1, x), Poly(t, t)], [x, t], [lamb\u00adda x: ex\u00adp(x)]) \n Out\u00ad[5]:   \n \u239b         x    10  x              x           3  x          5  x        7  x       9  x       8  x         6  x           4  x            2  x      \u239e \n \u239d3628800\u22c5\u212f  + x  \u22c5\u212f  - 3628800\u22c5x\u22c5\u212f  - 604800\u22c5x \u22c5\u212f  - 30240\u22c5x \u22c5\u212f  - 720\u22c5x \u22c5\u212f  - 10\u22c5x \u22c5\u212f  + 90\u22c5x \u22c5\u212f  + 5040\u22c5x \u22c5\u212f  + 151200\u22c5x \u22c5\u212f  + 1814400\u22c5x \u22c5\u212f , True\u23a0 \n In [6]: %timeit in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a, d, [Poly(1, x), Poly(t, t)], [x, t], [ex\u00adp]) \n 10 loop\u00ads, best of 3: 42 ms per loop \n In [7]: in\u00adte\u00adgrate(rd, x) \n Out\u00ad[7]: \n         x    10  x              x           3  x          5  x        7  x       9  x       8  x         6  x           4  x            2  x\n3628800\u22c5\u212f  + x  \u22c5\u212f  - 3628800\u22c5x\u22c5\u212f  - 604800\u22c5x \u22c5\u212f  - 30240\u22c5x \u22c5\u212f  - 720\u22c5x \u22c5\u212f  - 10\u22c5x \u22c5\u212f  + 90\u22c5x \u22c5\u212f  + 5040\u22c5x \u22c5\u212f  + 151200\u22c5x \u22c5\u212f  + 1814400\u22c5x \u22c5\u212f   \n In [8]: %timeit in\u00adte\u00adgrate(rd, x) \n 1 loop\u00ads, best of 3: 2.78 s per loop \n [/\u00adcode] \n There is one thing I should men\u00adtion.  I haven't im\u00adple\u00adment\u00aded all the cas\u00ades in  rischDE(), which is the sub\u00adprob\u00adlem for ex\u00adpo\u00adnen\u00adtial func\u00adtions (more on this in a fu\u00adture \"The Risch Al\u00adgo\u00adrith\u00adm\" post).  So some in\u00adte\u00adgrals will fail with a  NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror, in\u00addi\u00adcat\u00ading that there is a func\u00adtion that I still need to im\u00adple\u00adment to solve the in\u00adte\u00adgral: \n [code lan\u00adguage=\"py\"] \n In [1]: from sympy.in\u00adte\u00adgral\u00ads.risch im\u00adport * \n In [2]: var('t1, t') \n Out\u00ad[2]: (t\u2081, t) \n In [3]: rd = (ex\u00adp(x) - xex\u00adp(2x)*\u00adtan(x))/\u00adtan(x) \n In [4]: a, d = map(lamb\u00adda i: Poly(i, t), rd.\u00adsub\u00ads(\u00adex\u00adp(x), t).\u00adsub\u00ads(\u00adtan(x), t1).as_nu\u00admer_\u00adde\u00adnom()) \n In [5]: a \n Out\u00ad[5]: Poly(-t1xt**2 + t, t, do\u00admain='Z\u00adZ[x,t1]') \n In [6]: d \n Out\u00ad[6]: Poly(t1, t, do\u00admain='Z\u00adZ[t1]') \n In [7]: in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial(a, d, [Poly(1, x), Poly(1 + t1**2, t1), Poly(t, t)], [x, t1, t], [ex\u00adp, tan]) \n \n... \n NotIm\u00adple\u00adment\u00aded\u00adEr\u00adror: The abil\u00adi\u00adty to solve the para\u00admet\u00adric log\u00ada\u00adrith\u00admic de\u00adriv\u00ada\u00adtive prob\u00adlem is re\u00adquired to solve this RDE \n [/\u00adcode] \n So feel free to give this a try and let me know what you think.  You will have to do the prepars\u00ading as I have done above, which means that you al\u00adso have to be care\u00adful that any ex\u00adten\u00adsion that you make is not the de\u00adriv\u00ada\u00adtive or log\u00ada\u00adrith\u00admic de\u00adriv\u00ada\u00adtive of an el\u00ade\u00adment of the field you have al\u00adready built up.  You al\u00adso can\u00adnot use al\u00adge\u00adbra\u00adic func\u00adtion\u00ads, as I men\u00adtioned be\u00adfore, in\u00adclud\u00ading things like $la\u00adtex e\\frac{\\log{x}}{2}$ (func\u00adtions like these are called the log\u00ada\u00adrith\u00admic de\u00adriv\u00ada\u00adtives of k(t)-rad\u00adi\u00adcal\u00ads, which I will al\u00adso dis\u00adcuss in a fu\u00adture \"The Risch Al\u00adgo\u00adrith\u00adm\" post).  If you just use sim\u00adple ex\u00adten\u00adsions like  t1 = tan(x);t=\u00adex\u00adp(x)  like I have above, you won't need to wor\u00adry about this.  Each de\u00adriv\u00ada\u00adtive Poly should be in the vari\u00adable that it is the de\u00adriv\u00ada\u00adtive of (e.g., start with  Poly(1, x), then add  Poly(1 + t12, t1),  Poly(t2*(1 + t12), t2), etc.).  Ev\u00adery\u00adthing else should be a Poly in  t, the last el\u00ade\u00adment of the ex\u00adten\u00adsion.  And in cause you did\u00adn't get it, the last ex\u00adten\u00adsion must be an ex\u00adpo\u00adnen\u00adtial func\u00adtion.    \n Al\u00adso, I did\u00adn't have to do it in any of the above ex\u00adam\u00adples, but the first and sec\u00adond ar\u00adgu\u00adments to  in\u00adte\u00adgrate_hy\u00adper\u00adex\u00adpo\u00adnen\u00adtial()   must  be can\u00adceled (a, d = a.\u00adcan\u00adcel(d, in\u00adclude=True)  will do this for you), or you will get a wrong re\u00adsult!  I spent a good day of de\u00adbug\u00adging un\u00adtil I fig\u00adured this out.  The ex\u00adis\u00adtence of oth\u00ader bugs did\u00adn't help.", 
      "loc": "/posts/2010/07/12/integration-of-exponential-functions/"
    }, 
    {
      "title": "The Risch Algorithm: Part 1", 
      "tags": "mathjax", 
      "text": "My work this week is\u00adn't very in\u00adter\u00adest\u00ading, even in\u00adso\u00admuch as my work any week is in\u00adter\u00adest\u00ading, so this week I have elect\u00aded to start a se\u00adries of blog posts about the Risch Al\u00adgo\u00adrithm in gen\u00ader\u00adal.  I will start out with the ba\u00adsics in this post. \n Any\u00adone who has tak\u00aden Cal\u00adcu\u00adlus knows a hand\u00adful of heuris\u00adtics to cal\u00adcu\u00adlate in\u00adte\u00adgral\u00ads.  u-\u00adsub\u00adsti\u00adtu\u00adtion, par\u00adtial frac\u00adtion\u00ads, in\u00adte\u00adgra\u00adtion by part\u00ads, trigono\u00admet\u00adric sub\u00adsti\u00adtu\u00adtion, and ta\u00adble in\u00adte\u00adgra\u00adtion are a few of the more pop\u00adu\u00adlar ones.  These are gen\u00ader\u00adal enough to work for most in\u00adte\u00adgrals that are en\u00adcoun\u00adtered in prob\u00adlems in Physic\u00ads, En\u00adgi\u00adneer\u00ading, and so on, as well as most of those gen\u00ader\u00adat\u00aded by solv\u00ading dif\u00adfer\u00aden\u00adtial equa\u00adtions from the same field\u00ads.  But these fall short in a cou\u00adple of ways.  First of\u00adf, they are just heuris\u00adtic\u00ads.  If they fail, it does not mean that no in\u00adte\u00adgral ex\u00adist\u00ads.  This means that they are use\u00adless for prov\u00ading that cer\u00adtain func\u00adtion\u00ads, such as $la\u00adtex e{-x2}$ do not have in\u00adte\u00adgral\u00ads, no mat\u00adter how hard you try to find them.  Sec\u00adond, they work for on\u00adly rel\u00ada\u00adtive\u00adly sim\u00adple func\u00adtion\u00ads.  For ex\u00adam\u00adple, sup\u00adpose you have a ra\u00adtio\u00adnal func\u00adtion in $la\u00adtex \\log{x}$ and $la\u00adtex x$.  An ex\u00adam\u00adple would be $la\u00adtex \\frac{(\\log{x})2 + 2\\log{x} + x2 + 1}{x\\log{x} + 2x3}$.  We are not in\u00adter\u00adest\u00aded in in\u00adte\u00adgrat\u00ading this func\u00adtion, but rather in find\u00ading it back giv\u00aden its deriva\u00adtive, $la\u00adtex - \\frac{1 + 7 x{2} \\log{x} + \\log{x} + (\\log{x})2 + 3 x{2} + 6 x{2} (\\log{x})2 + (\\log{x})3 + 2 x{4}}{4 x{4} \\log{x} + x{2} (\\log{x})2 + 4 x{6}}$.  The on\u00adly method I named above that would come even close to be\u00ading ap\u00adpli\u00adca\u00adble to this in\u00adte\u00adgrand is par\u00adtial frac\u00adtion\u00ads.  This re\u00adquires mul\u00adti\u00advari\u00adate par\u00adtial frac\u00adtion de\u00adcom\u00adpo\u00adsi\u00adtion (with re\u00adspect to $la\u00adtex x$ and $la\u00adtex \\log{x}$), and gives $la\u00adtex -{\\frac {2\\,{x}{2}+1+\\log{x} }{{x}{2}}}+{\\frac {-1+8\\,{x}{4}-16\\,{x}{6}-{x}{2}}{ \\left( \\log{x} +2\\,{x}{2} \\right) {2}{x}{2}}}+{\\frac {-3\\,{x}{2}+12\\,{x}{4}-1}{ \\left( \\log{x} +2\\,{x}{2} \\right) {x}{2}}}$, which brings us no clos\u00ader to a so\u00adlu\u00adtion.   \n The rea\u00adson that I start\u00aded with a func\u00adtion and then com\u00adput\u00aded its de\u00adriv\u00ada\u00adtive was to show how easy it is to come up with a very com\u00adpli\u00adcat\u00aded func\u00adtion that has an el\u00ade\u00admen\u00adtary an\u00adti-deriva\u00adtive.  There\u00adfore, we see that the meth\u00adods from cal\u00adcu\u00adlus are not the ones to use if we want an in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm that is com\u00adplete.  The Risch In\u00adte\u00adgra\u00adtion Al\u00adgo\u00adrithm is based on a com\u00adplete\u00adly dif\u00adfer\u00adent ap\u00adproach.  At its core lies Li\u00adou\u00adville's The\u00ado\u00adrem, which gives us the form of any el\u00ade\u00admen\u00adtary an\u00adti-deriva\u00adtive.   (I wish to point out at this point that heuris\u00adtics like this are still use\u00adful in a com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtem such as SymPy as fast pre\u00adproces\u00adsors to the full in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrith\u00adm). \n The Risch Al\u00adgo\u00adrithm works by do\u00ading poly\u00adno\u00admi\u00adal ma\u00adnip\u00adu\u00adla\u00adtions on the in\u00adte\u00adgrand, which is en\u00adtire\u00adly de\u00adter\u00admin\u00adis\u00adtic (non-heuris\u00adtic), and gives us the pow\u00ader of all the the\u00ado\u00adrems of al\u00adge\u00adbra, al\u00adlow\u00ading us to ac\u00adtu\u00adal\u00adly prove that an\u00adti-deriva\u00adtives can\u00adnot ex\u00adist when they don't.  To start of\u00adf, we have to look at deriva\u00adtion\u00ads.  As I said, ev\u00adery\u00adthing with the Risch Al\u00adgo\u00adrithm is looked at al\u00adge\u00adbra\u00adi\u00adcal\u00adly (as op\u00adposed to an\u00ada\u00adlyt\u00adi\u00adcal\u00adly).  The first thing to look at is the de\u00adriv\u00ada\u00adtive it\u00adself.  We de\u00adfine a deriva\u00adtion as any func\u00adtion $la\u00adtex D$ on a ring $la\u00adtex R$ that sat\u00adis\u00adfies two prop\u00ader\u00adties: \n \n \n $la\u00ad\u00adtex D(a + b) = Da + Db$ (Sum Rule),  \n   \n  \n $la\u00ad\u00adtex D(ab) = aDb + bDa$ (Prod\u00aduct Rule)  \n   \n \nfor any $la\u00adtex a, b \\in R$.  Fur\u00adther\u00admore, de\u00adfine the set of con\u00adstant el\u00ade\u00adments as $la\u00adtex Con\u00adst_D(R) = {a \\in R\\\u00adtex\u00adtr\u00adm{ such that }Da = 0}$.  From just these two rules, you can prove all the rules from cal\u00adcu\u00adlus such as the pow\u00ader rule and the quo\u00adtient rule.  Defin\u00ading things al\u00adge\u00adbra\u00adi\u00adcal\u00adly lets us avoid an\u00ada\u00adlyt\u00adic prob\u00adlem\u00ads, such as dis\u00adcon\u00adti\u00adnu\u00adities and the need to prove con\u00adver\u00adgence all the time.  An\u00adoth\u00ader prob\u00adlem from anal\u00ady\u00adsis is the mul\u00adti\u00adval\u00adue na\u00adture of cer\u00adtain func\u00adtion\u00ads, name\u00adly the nat\u00adu\u00adral log\u00ada\u00adrith\u00adm.  We get around this by defin\u00ading $la\u00adtex \\log{a}$ as the unique func\u00adtion sat\u00adis\u00adfy\u00ading $la\u00adtex D\\log{a} = \\frac{\u00adDa}{a}$, for $la\u00adtex a \\neq 0$.   From this def\u00adi\u00adni\u00adtion we can prove the fa\u00admous log\u00ada\u00adrith\u00admic iden\u00adti\u00adties $la\u00adtex \\log{ab} = \\log{a} + \\log{b}$ and $la\u00adtex \\log{an} = n\\log{a}$ for log\u00ada\u00adrith\u00admic deriva\u00adtives, again us\u00ading on\u00adly the two rules for a deriva\u00adtion giv\u00aden above.  For ex\u00adam\u00adple, $la\u00adtex D\\log{ab}=\\frac{D\u00adab}{ab}=\\frac{aDb + bDa}{ab} = \\frac{b\u00adDa}{ab} + \\frac{aD\u00adb}{ab} = $$la\u00adtex \\frac{\u00adDa}{a} + \\frac{D\u00adb}{b}=D\\log{a} + D\\log{b}=D(\\log{a} + \\log{b})$.    \n The above def\u00adi\u00adni\u00adtion for the nat\u00adu\u00adral log\u00ada\u00adrithm gives the first in\u00adsight in\u00adto how the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm work\u00ads.  We de\u00adfine tran\u00adscen\u00adden\u00adtal func\u00adtions in terms of their de\u00adriv\u00ada\u00adtives.  So if $la\u00adtex t = ex$, then $la\u00adtex Dt/t = 1$.  We can de\u00adfine all of the trigono\u00admet\u00adric func\u00adtions in terms of $la\u00adtex ex$ and $la\u00adtex \\log{x}$ if we use $la\u00adtex \\sqrt{-1}$, but we can al\u00adso avoid this.  For ex\u00adam\u00adple, if $la\u00adtex t = \\tan{x}$, then $la\u00adtex Dt = 1 + t2$ be\u00adcause $la\u00adtex \\frac{d}{dx}\\\u00adtan{x} = \\sec2{x} = 1 + \\tan2{x}$.    \n We say that $la\u00adtex t\\in K$ is a  mono\u00admi\u00adal  over the field $la\u00adtex k$ with re\u00adspect to a deriva\u00adtion $la\u00adtex D$ if it sat\u00adis\u00adfies \n \n \n $la\u00ad\u00adtex t$ is tran\u00ads\u00adcen\u00ad\u00adden\u00ad\u00adtal over $la\u00ad\u00adtex k$,  \n   \n  \n $la\u00ad\u00adtex D[t]\\in k[t]$.  \n   \n \nThe first con\u00addi\u00adtion is nec\u00ades\u00adsary be\u00adcause the we are on\u00adly go\u00ading to deal with the trance\u00adnen\u00adtal ver\u00adsion of the Risch Al\u00adgo\u00adrithm (the al\u00adge\u00adbra\u00adic case is solved too, but the so\u00adlu\u00adtion method is quite dif\u00adfer\u00aden\u00adt, and I am not im\u00adple\u00adment\u00ading it this sum\u00admer).  The sec\u00adond con\u00addi\u00adtion just says that the de\u00adriv\u00ada\u00adtive of t is a poly\u00adno\u00admi\u00adal in t and a ra\u00adtio\u00adnal func\u00adtion in x.  The func\u00adtions I men\u00adtioned above all sat\u00adis\u00adfy these prop\u00ader\u00adties for $la\u00adtex K = \\math\u00adb\u00adb{Q}$.  The\u00ado\u00adrems in anal\u00ady\u00adsis show that $la\u00adtex \\log{x}$, $la\u00adtex ex$, and $la\u00adtex \\tan{x}$ are all tran\u00adscen\u00adden\u00adtal over $la\u00adtex \\math\u00adb\u00adb{Q}[x]$.  This is ac\u00adtu\u00adal\u00adly the on\u00adly use of anal\u00ady\u00adsis that we make in the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrith\u00adm.  Al\u00adso, we see that if $la\u00adtex t_1=\\log{x}$, $la\u00adtex t_2=ex$, and $la\u00adtex t_3=\\\u00adtan{x}$, then $la\u00adtex Dt_1=\\frac{1}{x}$, $la\u00adtex Dt_2=t_2$, and $la\u00adtex Dt_3=1 + t_32$, which are all poly\u00adno\u00admi\u00adals in their re\u00adspec\u00adtive $la\u00adtex t_i$ and ra\u00adtio\u00adnal func\u00adtions in $la\u00adtex x$.  In the al\u00adgo\u00adrith\u00adm, $la\u00adtex K$ is ac\u00adtu\u00adal\u00adly a tow\u00ader of mono\u00admi\u00adal ex\u00adten\u00adsions of $la\u00adtex \\math\u00adb\u00adb{Q}$, so $la\u00adtex t_n$ is a mono\u00admi\u00adal over $la\u00adtex \\math\u00adb\u00adb{Q}(x, t_1, \\dot\u00ads, t_{n-1})$.   This al\u00adlows us to work with func\u00adtions like $la\u00adtex e{\\\u00adtan{x}}$.  We can't make $la\u00adtex t=e{\\\u00adtan{x}}$ di\u00adrect\u00adly be\u00adcause $la\u00adtex \\frac{d}{dx}e{\\\u00adtan{x}} = (1 + \\tan2{x})e{\\\u00adtan{x}}$ is not a poly\u00adno\u00admi\u00adal in $la\u00adtex t$ (it al\u00adso con\u00adtains $la\u00adtex \\tan{x}$) .  But if we let $la\u00adtex t_1$ be such that $la\u00adtex Dt_1=1 + t_12$, i.e., $la\u00adtex t_1=\\\u00adtan{x}$, then we can let $la\u00adtex t_2$ be such that $la\u00adtex Dt_2=(1 + t_12)t_2$, i.e., $la\u00adtex t_2=e{\\\u00adtan{x}}$.  Re\u00admem\u00adber that the $la\u00adtex t_i$ are all \"func\u00adtion\u00ads\" of x, but there is no need to write $la\u00adtex t=t(x)$ as long as we re\u00admem\u00adber that $la\u00adtex Dt\\neq 0$, i.e., $la\u00adtex t\\not \\in Con\u00adst_D(K)$.  This is an\u00adoth\u00ader ad\u00advan\u00adtage of us\u00ading al\u00adge\u00adbra\u00adic over an\u00ada\u00adlyt\u00adic meth\u00adod\u00ads; it al\u00adlows us to re\u00adduce an in\u00adte\u00adgral down to a ra\u00adtio\u00adnal func\u00adtion in the \"sym\u00adbol\u00ads\" $la\u00adtex x$ and $la\u00adtex t_1, t_2, \\dot\u00ads, t_n$.  By con\u00adven\u00adtion, we make the first ex\u00adten\u00adsion $la\u00adtex t_0$ such that $la\u00adtex Dt_0=1$, i.e., $la\u00adtex t_0=x$.  I will just call it $la\u00adtex x$ here in\u00adstead of $la\u00adtex t_0$, to avoid con\u00adfu\u00adsion.    \n This is the prepars\u00ading that I al\u00adlud\u00aded to in an  ear\u00adli\u00ader post  that I have not im\u00adple\u00adment\u00aded yet.  The rea\u00adson that I haven't im\u00adple\u00adment\u00aded it yet is not just be\u00adcause I haven't got\u00adten around to it.  We have to be care\u00adful when we build up the ex\u00adten\u00adsion that each el\u00ade\u00adment is in\u00addeed tran\u00adscen\u00adden\u00adtal over the al\u00adready built-up field $la\u00adtex k$.  For ex\u00adam\u00adple, al\u00adthough it ap\u00adpears tran\u00adscen\u00adden\u00adtal, the func\u00adtion $la\u00adtex e{\\frac{1}{2}\\log{(1 + x2)}}$ is re\u00adal\u00adly al\u00adge\u00adbra\u00adic be\u00adcause it equals $la\u00adtex \\sqrt{1 + x2}$.  There are ad\u00addi\u00adtion\u00adal re\u00adquire\u00adments, such that each ex\u00adten\u00adsion is not the de\u00adriv\u00ada\u00adtive of log\u00ada\u00adrith\u00admic de\u00adriv\u00ada\u00adtive of an el\u00ade\u00adment of $la\u00adtex k$ (see al\u00adso the ex\u00adam\u00adple I gave in the pre\u00advi\u00adous post).  This is the part that I was talk\u00ading about in my  pre\u00advi\u00adous post  that is not writ\u00adten out as much as the oth\u00ader al\u00adgo\u00adrithms in Bron\u00adstein's book.  So this is al\u00adgo\u00adrith\u00admi\u00adcal\u00adly solved, just like the rest of the Al\u00adgo\u00adrith\u00adm, but it is non-triv\u00adial and may end up be\u00ading the hard\u00adest part of the al\u00adgo\u00adrithm for me to im\u00adple\u00admen\u00adt, just be\u00adcause it will prob\u00ada\u00adbly re\u00adquire the most fig\u00adur\u00ading out on my part.    \n So we can see that we can con\u00advert a tran\u00adscen\u00adden\u00adtal in\u00adte\u00adgral, such as the one above, in\u00adto a ra\u00adtio\u00adnal func\u00adtion in x and mono\u00admi\u00adal ex\u00adten\u00adsions $la\u00adtex t_1, t_2, \\dot\u00ads, t_n$.  For ex\u00adam\u00adple, the above in\u00adte\u00adgrand would be\u00adcome $la\u00adtex - \\frac{1 + t + t{2} + 3 x{2} + 6 t{2} x{2} + 7 t x{2} + t{3} + 2 x{4}}{t{2} x{2} + 4 t x{4} + 4 x{6}}$.  We then per\u00adform cer\u00adtain poly\u00adno\u00admi\u00adal ma\u00adnip\u00adu\u00adla\u00adtions on this in\u00adte\u00adgrand, us\u00ading the fact that $la\u00adtex Dx=1$ and $la\u00adtex Dt=\\frac{1}{x}$.  For the tran\u00adscen\u00adden\u00adtal case of the Risch Al\u00adgo\u00adrith\u00adm, this is sim\u00adi\u00adlar to the ra\u00adtio\u00adnal func\u00adtion in\u00adte\u00adgra\u00adtion that I out\u00adlined in  this post, and has Li\u00adou\u00adville's The\u00ado\u00adrem at its core.  This is where I will start off next time.", 
      "loc": "/posts/2010/06/30/the-risch-algorithm-part-1/"
    }, 
    {
      "title": "Quick Update", 
      "tags": "mathjax", 
      "text": "I've spend most of this week sit\u00adting in a car, so while I have been able to do some work, I haven't had much time to write up a blog post.  So, to com\u00adply with  On\u00addrej's rule, here is a quick up\u00addate. \n I have been work\u00ading my way through Bron\u00adstein's book.  I fin\u00adished the out\u00ader al\u00adgo\u00adrith\u00admic lay\u00ader of the im\u00adplan\u00adta\u00adtion.  Ba\u00adsi\u00adcal\u00adly, the al\u00adgo\u00adrithm does poly\u00adno\u00admi\u00adals ma\u00adnip\u00adu\u00adla\u00adtion on the in\u00adte\u00adgrand.  It first re\u00adduces the in\u00adte\u00adgrand in\u00adto small\u00ader in\u00adte\u00adgral\u00ads, un\u00adtil it gets to an in\u00adte\u00adgral where a sub\u00adprob\u00adlem must be solved to solve it.  The sub\u00adprob\u00adlem that must be solved dif\u00adfers de\u00adpend\u00ading on the type of the in\u00adte\u00adgral.  The first one that comes up in Bron\u00adstein's text is the Risch Dif\u00adfer\u00aden\u00adtial Equa\u00adtion, which aris\u00ades from the in\u00adte\u00adgra\u00adtion of ex\u00adpo\u00adnen\u00adtial func\u00adtion\u00ads.  (I will ex\u00adplain all of these thing in more de\u00adtail in a fu\u00adture blog post).  At this point, the al\u00adgo\u00adrithms be\u00adgin to re\u00adcur\u00adsive\u00adly de\u00adpend on each oth\u00ader, re\u00adquir\u00ading me to im\u00adple\u00adment more and more al\u00adgo\u00adrithms at a time in or\u00adder for each to work.  To make things worse, a very fun\u00adda\u00admen\u00adtal set of al\u00adgo\u00adrithms are on\u00adly de\u00adscribed in the tex\u00adt, not giv\u00aden in pseu\u00addo-\u00adcode, so I have had to fig\u00adure those things out.   These are al\u00adgo\u00adrithms to de\u00adter\u00admine if a dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion is a de\u00adriv\u00ada\u00adtive or log\u00ada\u00adrith\u00admic de\u00adriv\u00ada\u00adtive of el\u00ade\u00adments that have al\u00adready been ex\u00adtend\u00aded.  Again, I will ex\u00adplain bet\u00adter in a fu\u00adture post, but the idea is that you re\u00adplace el\u00ade\u00adments in an in\u00adte\u00adgrand with dum\u00admy vari\u00adables, but each el\u00ade\u00adment has to be tran\u00adscen\u00adden\u00adtal over the pre\u00advi\u00adous el\u00ade\u00adments.  So if you have $la\u00adtex \\int (ex + e{x2} + e{x + x*2})dx$, and you set $la\u00adtex t_1 = ex$ and $la\u00adtex t_2 = e{x2}$ ($la\u00adtex Dt_1 = t_1$ and $la\u00adtex Dt_2 = 2x\u00adt_2$), then you can\u00adnot make $la\u00adtex t_3 = e{x + x2}$ be\u00adcause $la\u00adtex e{x + x2} = t_1t_2$.  The abil\u00adi\u00adty to de\u00adter\u00admine if an el\u00ade\u00adment is a de\u00adriv\u00ada\u00adtive or a log\u00ada\u00adrith\u00admic de\u00adriv\u00ada\u00adtive of an el\u00ade\u00adment of the al\u00adready build dif\u00adfer\u00aden\u00adtial ex\u00adten\u00adsion is im\u00adpor\u00adtant not on\u00adly for build\u00ading up the ex\u00adten\u00adsion for the in\u00adte\u00adgrand (ba\u00adsi\u00adcal\u00adly the prepars\u00ading), but al\u00adso for solv\u00ading some of the cas\u00ades of the sub\u00adprob\u00adlems such as the Risch Dif\u00adfer\u00aden\u00adtial Equa\u00adtion prob\u00adlem. \n So I am still fig\u00adur\u00ading out some of the de\u00adtails on that one.  The de\u00adscrip\u00adtion in the book is pret\u00adty good (this is prob\u00ada\u00adbly the best writ\u00adten math text\u00adbook I have ev\u00ader seen), but I still have had to fig\u00adure out some of the math\u00ade\u00admat\u00adi\u00adcal de\u00adtails on pa\u00adper (which is some\u00adthing I en\u00adjoy any\u00adway, but it can be more stress\u00adful).  Hope\u00adful\u00adly by the next time I can have some code that is work\u00ading enough to ac\u00adtu\u00adal\u00adly demon\u00adstrate solv\u00ading some com\u00adplex in\u00adte\u00adgral\u00ads, (with man\u00adu\u00adal prepars\u00ading), and even more ex\u00adcit\u00ading\u00adly, prove that some non-ele\u00admen\u00adtary in\u00adte\u00adgral\u00ads, such as the clas\u00adsic $la\u00adtex \\int e{-x2}dx$, are in\u00addeed so.   And I al\u00adso hope to have some more ex\u00adpla\u00adna\u00adtions on how the Risch al\u00adgo\u00adrithm works in fu\u00adture post\u00ads.", 
      "loc": "/posts/2010/06/26/quick-update/"
    }, 
    {
      "title": "Strange Python Behavior (can someone please explain to me what is going on here?)", 
      "tags": "", 
      "text": "Every once in a while, seemingly really simple Python code does something completely unexpected for me. Look at the following snippet of Python code.  This is run straight from the 2.6.5 interpreter, with no other commands executed.  Do you notice anything strange?\n[code lan\u00adguage=\"py\"] \n $python \n Python 2.6.5 (r265:79359, Mar 24 2010, 01:32:55)   \n [GCC 4.0.1 (Ap\u00adple In\u00adc. build 5493)] on dar\u00adwin \n Type \"help\", \"copy\u00adright\", \"cred\u00adit\u00ads\" or \"li\u00adcense\" for more in\u00adfor\u00adma\u00adtion. \n >>>; l = lamb\u00adda i: a[i] \n >>> l \n <func\u00adtion at=\"\" 0x39e7f0=\"\"> \n >>> H = [(1, 2), (3, 4)] \n >>> [l(0) + l(1) for a in H] \n [3, 7] \n [/\u00adcode] \n Did you spot it?  Here is a hin\u00adt. Run\u00adning a dif\u00adfer\u00adent but sim\u00adi\u00adlar ses\u00adsion: \n [code lan\u00adguage=\"py\"] \n $python \n Python 2.6.5 (r265:79359, Mar 24 2010, 01:32:55)   \n [GCC 4.0.1 (Ap\u00adple In\u00adc. build 5493)] on dar\u00adwin \n Type \"help\", \"copy\u00adright\", \"cred\u00adit\u00ads\" or \"li\u00adcense\" for more in\u00adfor\u00adma\u00adtion. \n >>> l = lamb\u00adda i: a[i] \n >>> l \n <func\u00adtion at=\"\" 0x39e7f0=\"\"> \n >>> l(0) \n Trace\u00adback (most re\u00adcent call last):\n  File \"\", line 1, in \n  File \"\", line 1, in \nNameEr\u00adror: glob\u00adal name 'a' is not de\u00adfined \n [/\u00adcode] \n Do you see it now?  I de\u00adfined the lamb\u00adda func\u00adtion  l  in terms of  a  with\u00adout defin\u00ading first defin\u00ading  a!  And fur\u00adther\u00admore, it just works when  a  is de\u00adfined.  This is ac\u00adtu\u00adal\u00adly in\u00adde\u00adpen\u00addent of the fact that we are work\u00ading in a list com\u00adpre\u00adhen\u00adsion, as this con\u00adtin\u00adu\u00ada\u00adtion of the pre\u00advi\u00adous ses\u00adsion shows: \n [code lan\u00adguage=\"py\"] \n >>> a = [3, 4, 5] \n >>> l(0) \n 3 \n [/\u00adcode] \n But I want to ex\u00adpand on the list com\u00adpre\u00adhen\u00adsion ex\u00adam\u00adple, be\u00adcause there even more biz\u00adzare things go\u00ading on here.  Restart\u00ading a new ses\u00adsion again: \n [code lan\u00adguage=\"py\"] \n $python \n Python 2.6.5 (r265:79359, Mar 24 2010, 01:32:55)   \n [GCC 4.0.1 (Ap\u00adple In\u00adc. build 5493)] on dar\u00adwin \n Type \"help\", \"copy\u00adright\", \"cred\u00adit\u00ads\" or \"li\u00adcense\" for more in\u00adfor\u00adma\u00adtion. \n >>> l = lamb\u00adda i: a[i] \n >>> H = [(1, 2), (3, 4)] \n >>> [l(0) + l(1) for a in H] \n [3, 7] \n >>> (l(0) + l(1) for a in H) \n <gen\u00ader\u00ada\u00adtor ob\u00adjec\u00adt=\"\" at=\"\" 0x3a4350=\"\"> \n >>> list((l(0) + l(1) for a in H)) \n [7, 7] \n [/\u00adcode] \n So, if you are as\u00adtute and have been us\u00ading Python for long enough, you should be able to catch what is go\u00ading on here.  If you don't know, here is a hint (con\u00adtin\u00adu\u00ada\u00adtion of pre\u00advi\u00adous ses\u00adsion): \n [code lan\u00adguage=\"py\"] \n >>> a \n (3, 4) \n [/\u00adcode] \n So, as you may know, in Python 2.6 and ear\u00adlier, list com\u00adpre\u00adhen\u00adsion in\u00addex vari\u00adables \"leek\" in\u00adto the lo\u00adcal names\u00adpace.  The strange thing here is that al\u00adthough the list com\u00adpre\u00adhen\u00adsion would re\u00adset it, the gen\u00ader\u00ada\u00adtor ver\u00adsion does not.  Well, nor\u00admal\u00adly, it does do this: \n [code lan\u00adguage=\"py\"] \n >>> x = 1 \n >>> [x for x in range(10)] \n [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \n >>> x \n 9 \n >>> del x \n >>> list((x for x in range(10))) \n [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \n >>> x \n Trace\u00adback (most re\u00adcent call last):\n  File \"\", line 1, in \nNameEr\u00adror: name 'x' is not de\u00adfined \n >>> x = 1 \n >>> list((x for x in range(10))) \n [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \n >>> x \n 1 \n [/\u00adcode] \n So the above bit has some\u00adthing to do with the way the  lamb\u00adda  func\u00adtion was de\u00adfined with the  a.  By the way, here is what hap\u00adpens with the gen\u00ader\u00ada\u00adtor com\u00adpre\u00adhen\u00adsion (is that what these are called?) if  a  is not de\u00adfined: \n [code lan\u00adguage=\"py\"] \n >>> del a \n >>> list((l(0) + l(1) for a in H)) \n Trace\u00adback (most re\u00adcent call last):\n  File \"\", line 1, in \n  File \"\", line 1, in \n  File \"\", line 1, in \nNameEr\u00adror: glob\u00adal name 'a' is not de\u00adfined \n [/\u00adcode] \n This is how I dis\u00adcov\u00adered this.  I had de\u00adfined a lamb\u00adda func\u00adtion us\u00ading an vari\u00adable that was then passed to a list com\u00adpre\u00adhen\u00adsion that used this vari\u00adable as the in\u00addex with\u00adout re\u00adal\u00adiz\u00ading it. But then I tried con\u00advert\u00ading this in\u00adto a gen\u00ader\u00ada\u00adtor com\u00adpre\u00adhen\u00adsion to see if it would be faster, and got the above er\u00adror.    \n Fi\u00adnal\u00adly, since the \"fea\u00adture\" of leak\u00ading list com\u00adpre\u00adhen\u00adsion loop vari\u00adables in\u00adto the lo\u00adcal names\u00adpace is  go\u00ading away  in Python 3, I ex\u00adpect\u00aded things to be\u00adhave at least a lit\u00adtle dif\u00adfer\u00adent\u00adly in Python 3.  I tried the above in a Python 3.1.2 in\u00adter\u00adpreter and got the fol\u00adlow\u00ading: \n [code lan\u00adguage=\"py\"] \n $python3 \n Python 3.1.2 (r312:79147, Mar 23 2010, 22:02:05)   \n [GCC 4.2.1 (Ap\u00adple In\u00adc. build 5646) (dot 1)] on dar\u00adwin \n Type \"help\", \"copy\u00adright\", \"cred\u00adit\u00ads\" or \"li\u00adcense\" for more in\u00adfor\u00adma\u00adtion. \n >>> l = lamb\u00adda i: a[i] \n >>> l \n <func\u00adtion at=\"\" 0x100585a68=\"\"> \n >>> H = [(1, 2), (3, 4)] \n >>> [l(0) + l(1) for a in H] \n Trace\u00adback (most re\u00adcent call last):\n  File \"\", line 1, in \n  File \"\", line 1, in \n  File \"\", line 1, in \nNameEr\u00adror: glob\u00adal name 'a' is not de\u00adfined \n >>> list((l(0) + l(1) for a in H)) \n Trace\u00adback (most re\u00adcent call last):\n  File \"\", line 1, in \n  File \"\", line 1, in \n  File \"\", line 1, in \nNameEr\u00adror: glob\u00adal name 'a' is not de\u00adfined \n [/\u00adcode] \n So in Python 3, both the list com\u00adpre\u00adhen\u00adsion and the gen\u00ader\u00ada\u00adtor com\u00adpre\u00adhen\u00adsions act the same, which is not too sur\u00adpris\u00ading.  I guess I should re\u00adcode that piece of code to make it fu\u00adture proof, al\u00adthough this does\u00adn't seem easy at the mo\u00admen\u00adt, and it may re\u00adquire con\u00advert\u00ading a one-\u00adlin\u00ader in\u00adto a six-\u00adlin\u00ader.  If you are in\u00adter\u00adest\u00aded, the piece of code is  here. \n So can any\u00adone pro\u00advide any in\u00adsight in\u00adto what is go\u00ading on with that lamb\u00adda func\u00adtion?  Run\u00adning it with the  -3  switch to  python2.6  did\u00adn't give any warn\u00adings re\u00adlat\u00aded to it.    \n Up\u00addate:  As I not\u00aded in a  com\u00adment, I fig\u00adured out how to make this fu\u00adture-proof.  I need to con\u00advert it from   \n [code lan\u00adguage=\"py\"] \n def residue_re\u00adduce_deriva\u00adtion(H, D, x, t, z):\n    lambda\u00adfunc = lamb\u00adda i: i*deriva\u00adtion(a[1], D, x, t).as_ba\u00adsic().\u00adsub\u00ads(z, i)/ \\\n         a[1].as_ba\u00adsic().\u00adsub\u00ads(z, i)\n    re\u00adturn S(\u00adsum([\u00adRoot\u00adSum(a[0].as_poly(z), lambda\u00adfunc) for a in H]))\n[/\u00adcode] \n to \n [code lan\u00adguage=\"py\"] \n def residue_re\u00adduce_deriva\u00adtion(H, D, x, t, z):\n    re\u00adturn S(\u00adsum((\u00adRoot\u00adSum(a[0].as_poly(z), lamb\u00adda i: i*deriva\u00adtion(a[1], D, x, t).as_ba\u00adsic().\u00adsub\u00ads(z, i)/ \\\n        a[1].as_ba\u00adsic().\u00adsub\u00ads(z, i)) for a in H)))\n[/\u00adcode] \n Thanks to all the com\u00admenters for the ex\u00adpla\u00adna\u00adtion\u00ads.    \n Al\u00adso, you may have no\u00adticed that I dis\u00adcov\u00adered that if you use  [code]  in\u00adstead of  <code>, you get these nicer code blocks that  ac\u00adtu\u00adal\u00adly re\u00adspect in\u00adden\u00adta\u00adtion!   Now I just need to fig\u00adure out how to make them syn\u00adtax high\u00adlight Python code. \n Up\u00addate 2:   [code='py']  col\u00adors it!  Sweet! \n Up\u00addate 3:  I just dis\u00adcov\u00adered that SymPy has a  Lamb\u00adda()  ob\u00adject that han\u00addles this bet\u00adter.  In par\u00adtic\u00adu\u00adlar, it pret\u00adty prints the code, and is what is al\u00adready be\u00ading used for  Root\u00adSum()  in the ra\u00adtio\u00adnal func\u00adtion in\u00adte\u00adgra\u00adtor, at least in Ma\u00adteusz's polys9.    \n [code lan\u00adguage=\"py\"] \n >>> in\u00adte\u00adgrate(1/(x**5 + 1), x) \n log(1 + x)/5 + Root\u00adSum(625_t4 + 125*_t3 + 25_t2 + 5_t + 1, Lamb\u00adda(_t, _tlog(x + 5*_t)))                                                     \n [/\u00adcode] \n Stil\u00adl, this has been a very good learn\u00ading ex\u00adpe\u00adri\u00adence.", 
      "loc": "/posts/2010/06/16/strange-python-behavior-can-someone-please-explain-to-me-what-is-going-on-here/"
    }, 
    {
      "title": "A Weeklog", 
      "tags": "", 
      "text": "These seem to be all the rave these days, so I figured, why not jump on the bandwagon:\n \n Aaron-Meur\u00ader:\u00addoc aaron\u00admeur\u00ader20100615153531(in\u00adte\u00adgra\u00adtion$)$git weekre\u00adport   \n Aaron Meur\u00ader (20):\n      Fix some bugs in Poly\n      Make Poly(s\u00adin(x)/x*t, t, do\u00admain='EX').\u00adclear_\u00adde\u00adnom\u00ads() work\n      Fix in\u00adte\u00adgrate to work cor\u00adrect\u00adly with heurisch.py\n      Use more ef\u00adfi\u00adcient gcdex\u00addio\u00adphan\u00adtine() al\u00adgo\u00adrith\u00adm\n      Add sup\u00adport for tak\u00ading the deriva\u00adtion over the co\u00adef\u00adfi\u00adcient do\u00admain in risch.py\n      Add (but do not yet use) split\u00adfac\u00adtor_sqf() in risch.py\n      Add poly\u00adno\u00admi\u00adal_re\u00adduce() to risch.py\n      Add tests for al\u00adgo\u00adrithms in risch.py in a new test_risch.py file\n      On\u00adly al\u00adlow co\u00ader\u00adcion to larg\u00ader do\u00admain\u00ads\n      Al\u00adlow co\u00ader\u00adcion from ZZ(a) to ZZ(a, b)\n      Fix doctest in new heurisch.py file\n      Add residue_re\u00adduce()\n      For\u00admat\u00adting fix\u00ades in doc\u00adstrings in sympy/polys/al\u00adge\u00adbra\u00adtool\u00ads.py\n      Add in\u00adclude\u00adPRS op\u00adtion to re\u00adsul\u00adtant func\u00adtion\u00ads\n      Add per\u00admute method to DM\u00adP\n      Add a test for the in\u00adclude\u00adPRS op\u00adtion of re\u00adsul\u00adtan\u00adt()\n      Have residue_re\u00adduce() make S_i mon\u00adic\n      Re\u00adwrite poly\u00adno\u00admi\u00adal_re\u00adduce() non-re\u00adcur\u00adsive\u00adly\n      Add in\u00adte\u00adgrate_hy\u00adper\u00adtan\u00adgen\u00adt_poly\u00adno\u00admi\u00adal()\n      Add in\u00adte\u00adgrate_non\u00adlin\u00adear_no_spe\u00adcial\u00ads()", 
      "loc": "/posts/2010/06/15/a-weeklog/"
    }, 
    {
      "title": "Integration of rational functions", 
      "tags": "mathjax", 
      "text": "So for this week's blog post I will try to ex\u00adplain how the gen\u00ader\u00adal al\u00adgo\u00adrithm for in\u00adte\u00adgrat\u00ading ra\u00adtio\u00adnal func\u00adtions work\u00ads.  Re\u00adcall that a  ra\u00adtio\u00adnal func\u00adtion  is the quo\u00adtient of two poly\u00adno\u00admi\u00adal\u00ads.  We know that us\u00ading com\u00admon de\u00adnom\u00adi\u00adna\u00adtors, we can con\u00advert the sum of any num\u00adber of ra\u00adtio\u00adnal func\u00adtions in\u00adto a sin\u00adgle quo\u00adtien\u00adt, $la\u00adtex \\frac{a_nxn + a_{n-1}x{n-1} + \\c\u00addots + a_2x2 + a_1x + a_0}{b_nxn + b_{n-1}x{n-1} + \\c\u00addots + b_2x2 + a_1x + a_0}$.  Al\u00adso, us\u00ading  poly\u00adno\u00admi\u00adal di\u00advi\u00adsion  we can re\u00adwrite any ra\u00adtio\u00adnal func\u00adtion as the sum of a poly\u00adno\u00admi\u00adal and the quo\u00adtient of two poly\u00adno\u00admi\u00adals such that the de\u00adgree of the nu\u00admer\u00ada\u00adtor is less than the de\u00adgree of the de\u00adnom\u00adi\u00adna\u00adtor ($la\u00adtex F(x) = \\frac{b(x)}{c(x)} = p(x) + \\frac{r(x)}{g(x)}$, with $la\u00adtex deg(r) < deg(g)$).  Fur\u00adther\u00admore, we know that the rep\u00adre\u00adsen\u00adta\u00adtion of a ra\u00adtio\u00adnal func\u00adtion is not unique.  For ex\u00adam\u00adple, $la\u00adtex \\frac{(x + 1)(x - 1)}{(x + 2)(x - 1)}$ is the same as $la\u00adtex \\frac{x + 1}{x + 2}$ ex\u00adcept at the point $la\u00adtex x = 1$, and $la\u00adtex \\frac{(x - 1)2}{x - 1}$ is the same as $la\u00adtex x - 1$ ev\u00adery\u00adwhere.  But by us\u00ading  Eu\u00adclid's al\u00adgo\u00adrithm  for find\u00ading the GCD of poly\u00adno\u00admi\u00adals on the nu\u00admer\u00ada\u00adtor and the de\u00adnom\u00adi\u00adna\u00adtor, along with poly\u00adno\u00admi\u00adal di\u00advi\u00adsion on each,  we can can\u00adcel all com\u00admon fac\u00adtors to get a rep\u00adre\u00adsen\u00adta\u00adtion that is unique (as\u00adsum\u00ading we ex\u00adpand all fac\u00adtors in\u00adto one poly\u00adno\u00admi\u00adal).  Fi\u00adnal\u00adly, us\u00ading poly\u00adno\u00admi\u00adal di\u00advi\u00adsion with re\u00admain\u00adder, we can re\u00adwrite any ra\u00adtio\u00adnal func\u00adtion $la\u00adtex F(x)$ as $la\u00adtex \\frac{a(x)}{b(x)} = p(x) + \\frac{a(x)}{d(x)}$, where $la\u00adtex a(x)$, $la\u00adtex b(x)$, $la\u00adtex c(x)$, $la\u00adtex d(x)$, and $la\u00adtex p(x)$ are all poly\u00adno\u00admi\u00adal\u00ads, and the de\u00adgree of $la\u00adtex a$ is less than the de\u00adgree of $la\u00adtex d$.    \n We know from cal\u00adcu\u00adlus that the in\u00adte\u00adgral of any ra\u00adtio\u00adnal func\u00adtion con\u00adsists of three part\u00ads: the poly\u00adno\u00admi\u00adal part, the ra\u00adtio\u00adnal part, and the log\u00ada\u00adrith\u00admic part (con\u00adsid\u00ader arc\u00adtan\u00adgents as com\u00adplex log\u00ada\u00adrithm\u00ads).  The poly\u00adno\u00admi\u00adal part is just the in\u00adte\u00adgral of $la\u00adtex p(x)$ above.  The ra\u00adtio\u00adnal part is an\u00adoth\u00ader ra\u00adtio\u00adnal func\u00adtion, and the log\u00ada\u00adrith\u00admic part, which is a sum of log\u00ada\u00adrithms of the form $la\u00adtex a\\log{s(x)}$, where $la\u00adtex a$ is an al\u00adge\u00adbra\u00adic con\u00adstant and $la\u00adtex s(x)$ is a poly\u00adno\u00admi\u00adal (note that if $la\u00adtex s(x)$ is a ra\u00adtio\u00adnal func\u00adtion, we can split it in\u00adto two log\u00ada\u00adrithms of poly\u00adno\u00admi\u00adals us\u00ading the log iden\u00adti\u00adties).    \n To find the ra\u00adtio\u00adnal part, we first need to know about square-free fac\u00adtor\u00adiza\u00adtion\u00ads.  An im\u00adpor\u00adtant re\u00adsult in al\u00adge\u00adbra is that any poly\u00adno\u00admi\u00adal with ra\u00adtio\u00adnal co\u00adef\u00adfi\u00adcients can be fac\u00adtored unique\u00adly in\u00adto ir\u00adre\u00adduc\u00adible poly\u00adno\u00admi\u00adals with ra\u00adtio\u00adnal co\u00adef\u00adfi\u00adcients, up to mul\u00adti\u00adpli\u00adca\u00adtion of a non-ze\u00adro con\u00adstant and re\u00adorder\u00ading of fac\u00adtors, sim\u00adi\u00adlar to how any in\u00adte\u00adger can be fac\u00adtored unique\u00adly in\u00adto primes up to mul\u00adti\u00adpli\u00adca\u00adtion of 1 and -1 and re\u00adorder\u00ading of fac\u00adtors (tech\u00adni\u00adcal\u00adly, it is with co\u00adef\u00adfi\u00adcients from a unique fac\u00adtor\u00adiza\u00adtion do\u00admain, for which the ra\u00adtio\u00adnals is a spe\u00adcial case, and up to mul\u00adti\u00adpli\u00adca\u00adtion of a unit, which for ra\u00adtio\u00adnals is ev\u00adery non-ze\u00adro con\u00adstan\u00adt).  A poly\u00adno\u00admi\u00adal is square-free if this unique fac\u00adtor\u00adiza\u00adtion does not have any poly\u00adno\u00admi\u00adals with pow\u00aders greater than 1.  An\u00adoth\u00ader the\u00ado\u00adrem from al\u00adge\u00adbra tells us that ir\u00adre\u00adduc\u00adible poly\u00adno\u00admi\u00adals over the ra\u00adtio\u00adnals do not have any re\u00adpeat\u00aded root\u00ads, and so giv\u00aden this, it is not hard to see that a poly\u00adno\u00admi\u00adal be\u00ading square-free is equiv\u00ada\u00adlent to it not hav\u00ading re\u00adpeat\u00aded root\u00ads.    \n A  square-free fac\u00adtor\u00adiza\u00adtion  of a poly\u00adno\u00admi\u00adal is a list of poly\u00adno\u00admi\u00adal\u00ads, $la\u00adtex P_1P_22 \\c\u00addots P_nn$, where each $la\u00adtex P_i$ is square-free (in oth\u00ader word\u00ads, $la\u00adtex P_1$ is the prod\u00aduct of all the fac\u00adtors of de\u00adgree 1, $la\u00adtex P_2$ is the prod\u00aduct of all the fac\u00adtors of de\u00adgree 2, and so on).  There is a rel\u00ada\u00adtive\u00adly sim\u00adple al\u00adgo\u00adrithm to com\u00adpute the square-free fac\u00adtor\u00adiza\u00adtion of a poly\u00adno\u00admi\u00adal, which is based on the fact that $la\u00adtex gcd(P, \\frac{d\u00adp}{dx})$ re\u00adduces the pow\u00ader of each ir\u00adre\u00adduc\u00adible fac\u00adtor by 1.  For ex\u00adam\u00adple: \n  \n (Sor\u00adry for the pic\u00adture.   Word\u00adPress code blocks do not work) \n It is not too hard to prove this us\u00ading the prod\u00aduct rule on the fac\u00adtor\u00adiza\u00adtion of P.  So you can see that by com\u00adput\u00ading $la\u00adtex \\frac{P}{gcd(P, \\frac{d\u00adP}{dx})}$, you can ob\u00adtain $la\u00adtex P_1P_2\\c\u00addots P_n$.  Then, by re\u00adcur\u00adsive\u00adly com\u00adput\u00ading $la\u00adtex A_0 = P$, $la\u00adtex A_1 = gcd(A_0, \\frac{\u00addA_0}{dx})$, $la\u00adtex A2 = gcd(A_1, \\frac{\u00addA_1}{dx})$, \u2026 and tak\u00ading the quo\u00adtient each time as above, we can find the square-free fac\u00adtors of P.    \n OK, so we know from par\u00adtial frac\u00adtion de\u00adcom\u00adpo\u00adsi\u00adtions we learned in cal\u00adcu\u00adlus that if we have a ra\u00adtio\u00adnal func\u00adtion of the form $la\u00adtex \\frac{Q(x)}{V(x)n}$ , where $la\u00adtex V(x)$ is square-free, the in\u00adte\u00adgral will be a ra\u00adtio\u00adnal func\u00adtion if $la\u00adtex n > 1$ and a log\u00ada\u00adrithm if $la\u00adtex n = 1$.  We can use the par\u00adtial frac\u00adtion de\u00adcom\u00adpo\u00adsi\u00adtion that is easy to find once we have the square-free fac\u00adtor\u00adiza\u00adtion of the de\u00adnom\u00adi\u00adna\u00adtor to re\u00adwrite the re\u00admain\u00ading ra\u00adtio\u00adnal func\u00adtion as a sum of terms of the form $la\u00adtex \\frac{Q}{V_kk}$, where $la\u00adtex V_i$ is square-free.  Be\u00adcause $la\u00adtex V$ is square-free, $la\u00adtex gcd(V, V')=1$, so the  Ex\u00adtend\u00aded Eu\u00adclidean Al\u00adgo\u00adrithm  gives us $la\u00adtex B_0$ and $la\u00adtex C_0$ such that $la\u00adtex B_0V + C_0V'=1$ (re\u00adcall that $la\u00adtex g$ is the gcd of $la\u00adtex p$ and $la\u00adtex q$ if and on\u00adly if there ex\u00adist $la\u00adtex a$ and $la\u00adtex b$ rel\u00ada\u00adtive\u00adly prime to $la\u00adtex g$ such that $la\u00adtex ap+bq=g$.  This holds true for in\u00adte\u00adgers as well as poly\u00adno\u00admi\u00adal\u00ads). Thus we can find $la\u00adtex B$ and $la\u00adtex C$ such that $la\u00adtex BV + CV'= \\frac{Q}{1-k}$.  Mul\u00adti\u00adply\u00ading through by $la\u00adtex \\frac{1-k}{Vk}$, $la\u00adtex \\frac{Q}{Vk}=-\\frac{(k-1)B\u00adV'}{Vk} + \\frac{(1-k)C}{V{k-1}}$, which is equal to $la\u00adtex \\frac{Q}{Vk} = (\\frac{B'}{V{k-1}} - \\frac{(k-1)B\u00adV'}{Vk}) + \\frac{(1-k)C-B'}{V{k-1}}$.  You may no\u00adtice that the term in the paren\u00adthe\u00adsis is just the de\u00adriv\u00ada\u00adtive of  $la\u00adtex \\frac{B}{V{k-1}}$, so we get $la\u00adtex \\in\u00adt\\frac{Q}{Vk}=\\frac{B}{V{k-1}} + \\in\u00adt\\frac{(1-k)C - B'}{V{k-1}}$.  This is called Her\u00admite Re\u00adduc\u00adtion.  We can re\u00adcur\u00adsive\u00adly re\u00adduce the in\u00adte\u00adgral on the right hand side un\u00adtil the $la\u00adtex k=1$. Note that there are more ef\u00adfi\u00adcient ways of do\u00ading this that do not ac\u00adtu\u00adal\u00adly re\u00adquire us to com\u00adpute the par\u00adtial frac\u00adtion de\u00adcom\u00adpo\u00adsi\u00adtion, and there is al\u00adso a lin\u00adear ver\u00adsion due to Mack (this one is quadrat\u00adic), and an even more ef\u00adfi\u00adcient al\u00adgo\u00adrithm called the Horow\u00aditz-Ostro\u00adgrad\u00adsky Al\u00adgo\u00adrith\u00adm, that does\u00adn't even re\u00adquire a square-free de\u00adcom\u00adpo\u00adsi\u00adtion.    \n So when we have fin\u00adished the Her\u00admite Re\u00adduc\u00adtion, we are left with in\u00adte\u00adgrat\u00ading ra\u00adtio\u00adnal func\u00adtions with pure\u00adly square-free de\u00adnom\u00adi\u00adna\u00adtors.  We know from cal\u00adcu\u00adlus that these will have log\u00ada\u00adrith\u00admic in\u00adte\u00adgral\u00ads, so this is the log\u00ada\u00adrith\u00admic part.    \n First, we need to look at re\u00adsul\u00adtants and PRSs. The  re\u00adsul\u00adtant  of two poly\u00adno\u00admi\u00adals is de\u00adfined as dif\u00adfer\u00adences of the roots of the two poly\u00adno\u00admi\u00adal\u00ads, i.e., $la\u00adtex re\u00adsul\u00adtan\u00adt(A, B) = \\prod_{i=1}n\\prod_{j=1}m (\\al\u00adpha_i - \\be\u00adta_j)$, where $la\u00adtex A = (x - \\al\u00adpha_1)\\c\u00addot\u00ads(x - \\al\u00adpha_n)$ and $la\u00adtex B = (x - \\be\u00adta_1)\\c\u00addot\u00ads(x - \\be\u00adta_m)$ are mon\u00adic poly\u00adno\u00admi\u00adals split in\u00adto lin\u00adear fac\u00adtors.  Clear\u00adly, the re\u00adsul\u00adtant of two poly\u00adno\u00admi\u00adals is 0 if and on\u00adly if the two poly\u00adno\u00admi\u00adals share a root. It is an im\u00adpor\u00adtant re\u00adsult that the re\u00adsul\u00adtant of two poly\u00adno\u00admi\u00adals can be com\u00adput\u00aded from on\u00adly their co\u00adef\u00adfi\u00adcients by tak\u00ading the de\u00adter\u00admi\u00adnant of the  Sylvester Ma\u00adtrix  of the two poly\u00adno\u00admi\u00adal\u00ads.  How\u00adev\u00ader, it is more ef\u00adfi\u00adcient\u00adly cal\u00adcu\u00adlat\u00aded us\u00ading a poly\u00adno\u00admi\u00adal re\u00admain\u00adder se\u00adquence  (PRS) (sor\u00adry, there does\u00adn't seem to be a Wikipedia ar\u00adti\u00adcle), which in ad\u00addi\u00adtion to giv\u00ading the re\u00adsul\u00adtant of A and B, al\u00adso gives a se\u00adquence of poly\u00adno\u00admi\u00adals with some use\u00adful prop\u00ader\u00adties that I will dis\u00adcuss be\u00adlow.  A poly\u00adno\u00admi\u00adal re\u00admain\u00adder se\u00adquence is a gen\u00ader\u00adal\u00adiza\u00adtion of the Eu\u00adclid\u00adi\u00adan al\u00adgo\u00adrithm where in each step, the re\u00admain\u00adder $la\u00adtex R_i$ is mul\u00adti\u00adplied by a con\u00adstant $la\u00adtex \\be\u00adta_i$.  The Fun\u00adda\u00admen\u00adtal PRS The\u00ado\u00adrem shows how to com\u00adpute spe\u00adcif\u00adic $la\u00adtex \\be\u00adta_i$ such that the re\u00adsul\u00adtant can be cal\u00adcu\u00adlat\u00aded from the poly\u00adno\u00admi\u00adals in the se\u00adquence.   \n Then, if we have $la\u00adtex \\frac{A}{D}$, left over from the Her\u00admite Re\u00adduc\u00adtion (so $la\u00adtex D$ square-free), let $la\u00adtex R=re\u00adsul\u00adtan\u00adt_t(A-t\\frac{d\u00adD}{dx}, D)$, where $la\u00adtex t$ is a new vari\u00adable, and $la\u00adtex \\al\u00adpha_i$ be the dis\u00adtinct roots of R.  Let $la\u00adtex p_i=\\gcd(A - \\al\u00adpha_i\\frac{d\u00adD}{dx}, D)$.  Then it turns out that the log\u00ada\u00adrith\u00admic part of the in\u00adte\u00adgral is just $la\u00adtex \\al\u00adpha_1\\log{p_1} + \\al\u00adpha_2\\log{p_2} + \\c\u00addots \\al\u00adpha_n\\log{p_n}$.  This is called the Roth\u00adstein-\u00adTrager Al\u00adgo\u00adrith\u00adm. \n How\u00adev\u00ader, this re\u00adquires find\u00ading the prime fac\u00adtor\u00adiza\u00adtion of the re\u00adsul\u00adtan\u00adt, which can be avoid\u00aded if a more ef\u00adfi\u00adcient al\u00adgo\u00adrithm called the Lazard-Ri\u00ado\u00adboo-\u00adTrager Al\u00adgo\u00adrithm is used. I will talk a lit\u00adtle bit about it.  It works by us\u00ading sub\u00adre\u00adsul\u00adtant poly\u00adno\u00admi\u00adal re\u00adminder se\u00adquences.   \n It turns out that the above $la\u00adtex gcd(A-\\al\u00adpha\\frac{d\u00adD}{dx}, D)$ will ap\u00adpear in the PRS of $la\u00adtex D$ and $la\u00adtex A-t\\frac{d\u00adD}{dx}$.  Fur\u00adther\u00admore, we can use the PRS to im\u00adme\u00addi\u00adate\u00adly find the re\u00adsul\u00adtant $la\u00adtex R=re\u00adsul\u00adtan\u00adt_t(A-t\\frac{d\u00adD}{dx}, D)$, which as we saw, is all we need to com\u00adpute the log\u00ada\u00adrith\u00admic part.    \n So that's ra\u00adtio\u00adnal in\u00adte\u00adgra\u00adtion.  I hope I haven't bored you too much, and that this made at least a lit\u00adtle sense.  I al\u00adso hope that it was all cor\u00adrec\u00adt.  Note that this en\u00adtire al\u00adgo\u00adrithm has al\u00adready been im\u00adple\u00adment\u00aded in SymPy, so if you plug a ra\u00adtio\u00adnal func\u00adtion in to  in\u00adte\u00adgrate(), you should get back a so\u00adlu\u00adtion.  How\u00adev\u00ader, I de\u00adscribe it here be\u00adcause the tran\u00adscen\u00adden\u00adtal case of the Risch Al\u00adgo\u00adrithm is just a gen\u00ader\u00adal\u00adiza\u00adtion of ra\u00adtio\u00adnal func\u00adtion in\u00adte\u00adgra\u00adtion. \n As for work up\u00addates, I found that the Poly ver\u00adsion of the heur\u00adsitic Risch al\u00adgo\u00adrithm was con\u00adsid\u00ader\u00adably slow\u00ader than the orig\u00adi\u00adnal ver\u00adsion, due to in\u00adef\u00adfi\u00adcien\u00adcies in the way the poly\u00adno\u00admi\u00adals are cur\u00adrent\u00adly rep\u00adre\u00adsent\u00aded in SymPy.  So I have put that aside, and I have start\u00aded im\u00adple\u00adment\u00ading al\u00adgo\u00adrithms from the full al\u00adgo\u00adrith\u00adm.  There's not much to say on that fron\u00adt.  It's te\u00addious work.  I copy the al\u00adgo\u00adrithm from Bron\u00adstein's book, then try make sure that it is cor\u00adrect based on the few ex\u00adam\u00adples giv\u00aden and from the math\u00ade\u00admat\u00adi\u00adcal back\u00adground given, and when I'm sat\u00adis\u00adfied, I move on to the next one.  Fol\u00adlow my  in\u00adte\u00adgra\u00adtion  branch if you are in\u00adter\u00adest\u00aded. \n In my next post, I'll try to de\u00adfine some terms, like \"ele\u00admen\u00adtary func\u00adtion,\" and in\u00adtro\u00adduce a lit\u00adtle dif\u00adfer\u00aden\u00adtial al\u00adge\u00adbra, so you can un\u00adder\u00adstand a lit\u00adtle bit of the na\u00adture of the gen\u00ader\u00adal in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrith\u00adm.", 
      "loc": "/posts/2010/06/11/integration-of-rational-functions/"
    }, 
    {
      "title": "PuDB, a better Python debugger", 
      "tags": "", 
      "text": "So  Chris\u00adtian Muise  un\u00adwit\u00adting\u00adly just re\u00admind\u00aded me on IRC that I for\u00adgot to men\u00adtion the main method that I used to learn how the heurisch func\u00adtion works in my last blog post.  I usu\u00adal\u00adly on\u00adly use a de\u00adbug\u00adger when I have a re\u00adal\u00adly hard bug I need to fig\u00adure out, when the print state\u00adments aren't enough.  The rea\u00adson for this is that the de\u00adbug\u00adger that I had been us\u00ading, win\u00adpdb, is, well, a pain to use.  There are so many lit\u00adtle bugs, at least in Mac OS X, that it is al\u00admost not worth while to use it un\u00adless I need to.  For ex\u00adam\u00adple, restart\u00ading a script from the de\u00adbug\u00adger does\u00adn't work.  If I pass a point that I want\u00aded to see, I have to com\u00adplete\u00adly close the win\u00adpdb win\u00addow and restart it from the com\u00admand line, which takes about half a minute.  Al\u00adso, win\u00adpdb us\u00ades it's own vari\u00adant of pdb, which seems to cause more prob\u00adlems than it cre\u00adates (like bug\u00adging me about sympy im\u00adport\u00ading pdb some\u00adwhere  ev\u00adery time  I start de\u00adbug\u00adging.) \n But I re\u00adal\u00adly want\u00aded to be able to step through the heurisch code to see ex\u00adact\u00adly how it work\u00ads, be\u00adcause many of the im\u00adple\u00admen\u00adta\u00adtion de\u00adtail\u00ads, such as gath\u00ader\u00ading the com\u00adpo\u00adnents of an ex\u00adpres\u00adsion, will be sim\u00adi\u00adlar if not ex\u00adact\u00adly the same in the full al\u00adgo\u00adrith\u00adm.  So I start\u00aded my quest for a bet\u00adter de\u00adbug\u00adger.  For me, the ide\u00adal de\u00adbug\u00adger is the C de\u00adbug\u00adger in XCode.  That de\u00adbug\u00adger has saved me in most of my pro\u00adgram\u00adming as\u00adsign\u00adments in C.  But it is on\u00adly for C based lan\u00adguages (C, Ob\u00adjec\u00adtive-C, prob\u00ada\u00adbly C++, \u2026), not Python.  So I did a Google search, and it turns out that there is a list of Python de\u00adbug\u00adgers  here.  So I went through them, and I did\u00adn't have to go far.  The very first one,  pudb, turns out to be awe\u00adsome! \n You can watch this  screen\u00adcast  to get a bet\u00adter idea of the fea\u00adtures, or even bet\u00adter in\u00adstall it and check them out.  The de\u00adbug\u00adger runs in the con\u00adsole, not in some half-hacked GUI (half-hacked is what any non-\u00adCo\u00adcoa GUI looks like in Mac OS X).  The on\u00adly down side to this is that you have to use the key\u00adboard to do ev\u00adery\u00adthing, but it ends up not be\u00ading too bad.  And you can press '?' at any time to see the pos\u00adsi\u00adble com\u00admand\u00ads.    \n To in\u00adstall it, just do  easy_in\u00adstall pudb.  To run it, just cre\u00adate a script of what you want to de\u00adbug, and do  python -m pud\u00adb.run my-scrip\u00adt.py    and it just work\u00ads! I have a line that says  alias pud\u00adb='python -m pud\u00adb.run'  in my  .pro\u00adfile, which makes it even eas\u00adi\u00ader to run.  If you want to set a break point in the code, you can ei\u00adther nav\u00adi\u00adgate there from with\u00adin pudb by press\u00ading 'm', or you add a line that says  from pudb im\u00adport set_\u00adtrace; set_\u00adtrace()  to the code (if you add the line to your code, you don't even need to cre\u00adate a scrip\u00adt.  Just ex\u00ade\u00adcute the code in IPython and when it hits that line, it will load the de\u00adbug\u00adger).    \n Some cool fea\u00adtures: \n \n \n IPython con\u00ad\u00adsole.  Just press '!' to go to a con\u00ad\u00adsole, where you can ma\u00adnip\u00adu\u00adlate var\u00adi\u00adables from the ex\u00ade\u00ad\u00adcut\u00aded names\u00ad\u00adpace, and you can choose an IPython con\u00ad\u00adsole.      \n   \n  \n Very easy to nav\u00adi\u00ad\u00adgate.  You just need to know the keys 's', 'n', and 't'.      \n   \n  \n View the code from else\u00adwhere than what is be\u00ading run.  Press\u00ading 'm' lets you view all im\u00ad\u00adport\u00aded mod\u00ad\u00adules.  You can eas\u00adi\u00ad\u00adly view points on the stack by choos\u00ading them.      \n   \n  \n If an ex\u00ad\u00adcep\u00ad\u00adtion is thrown, it   catch\u00ades it!  This may sound ob\u00advi\u00adous for a de\u00adbug\u00adger, but it is one of things that did\u00adn't work very well in win\u00adpdb.  You can view the trace\u00adback of the ex\u00ad\u00adcep\u00ad\u00adtion, and choose to restart   with\u00ad\u00adout hav\u00ading to close and re\u00adopen the de\u00adbug\u00adger.  Ac\u00ad\u00adtu\u00adal\u00ad\u00adly, it asks you if you want to restart ev\u00adery time the script fin\u00adish\u00ades too, which is al\u00ad\u00adso a great im\u00adprove\u00ad\u00adment over win\u00adpdb.      \n   \n \nThis is what it looks like.  Click for a big\u00adger pic\u00adture: \n  \n Some an\u00adnoy\u00adances (in case An\u00addreas Kloeck\u00adn\u00ader reads this): \n \n \n The de\u00ad\u00adfault dis\u00ad\u00ad\u00adplay for var\u00adi\u00adables is type, which is com\u00ad\u00adplete\u00ad\u00adly use\u00ad\u00adless. I have to man\u00adu\u00adal\u00ad\u00adly go through and change each to str so I can see what the var\u00adi\u00adable is.  Is there a way to change this de\u00ad\u00adfault?  \n   \n  \n It asks me ev\u00adery time if I want to use IPython.  I al\u00adways want to use IPython.  \n   \n  \n This is might be a Mac OS X Ter\u00admi\u00ad\u00adnal bug, but when I ex\u00ade\u00ad\u00adcute a state\u00ad\u00adment that takes a while to run, it does\u00adn't re\u00ad\u00addraw the pudb win\u00ad\u00addow un\u00adtil it fin\u00adish\u00ades.  This means that step\u00adping through a pro\u00ad\u00adgram \"flash\u00ades\" black from what is above pudb in the win\u00ad\u00addow, and if I run a state\u00ad\u00adment that takes forever, I loose the abil\u00adi\u00ad\u00adty to see where it is un\u00ad\u00adless I key\u00adboard in\u00ad\u00adter\u00adrup\u00adt. For\u00ad\u00adtu\u00ad\u00adnate\u00ad\u00adly, it catch\u00ades key\u00adboard in\u00ad\u00adter\u00adrup\u00adt\u00ads, so I can still see the trace\u00adback.  \n   \n  \n There is no way to re\u00ad\u00adsize the var\u00adi\u00adables win\u00ad\u00addow, or to scroll side\u00adways in it.  If I want to see what a long var\u00adi\u00adable ex\u00adpres\u00ad\u00adsion is, I have to go to the IPython con\u00ad\u00adsole and type it there.     \n   \n \nSome of these might be fix\u00adable and I just don't know it yet.  But even with them, this is still an or\u00adder of mag\u00adni\u00adtude im\u00adprove\u00adment over win\u00adpdb.  Now I can ac\u00adtu\u00adal\u00adly use the de\u00adbug\u00adger all the time in my cod\u00ading, in\u00adstead of just when I have a re\u00adal\u00adly tough bug and no oth\u00ader choice.    \n UP\u00adDATE: \n The first two were triv\u00adial to fix in a fork of the repos\u00adi\u00adto\u00adry (is\u00adn't open source awe\u00adsome?).  So if those are both\u00ader\u00ading you too, check out my branch\u00ades at  http://github.\u00adcom/as\u00admeur\u00ader/PuDB.  Maybe if I have some time I will make them glob\u00adal op\u00adtions us\u00ading en\u00advi\u00adron\u00adment vari\u00adables or some\u00adthing and  see if An\u00addreas wants to merge them back in\u00adto the main re\u00adpo.    \n As for the sec\u00adond one, I re\u00adal\u00adized that it might be a good thing, be\u00adcause you can see any\u00adthing that is print\u00aded.  Stil\u00adl, I would pre\u00adfer see\u00ading both, if pos\u00adsi\u00adble (and the black flash\u00ades are an\u00adnoy\u00ading).    \n UP\u00adDATE 2: \n You can re\u00adsize the side view by push\u00ading +/-, though there does\u00adn't seem to be a way to, say, make the vari\u00adables view big\u00adger and the break\u00adpoints view small\u00ader.   \n UP\u00adDATE 3: \n A while back On\u00addrej mod\u00adi\u00adfied the code to have a dif\u00adfer\u00adent col\u00ador the\u00adme, and I fol\u00adlowed suit.  See  this con\u00adver\u00adsa\u00adtion at GitHub.  So now, in\u00adstead of look\u00ading like a DOS ter\u00admi\u00adnal, in PuDB for me looks like this: \n    This is ex\u00adact\u00adly the same col\u00adors as my code in XCode, the ed\u00adi\u00adtor I use, with the Mid\u00adnight Theme.  It's pret\u00adty easy to change the col\u00adors to what\u00adev\u00ader you wan\u00adt.  Right now, you have to ed\u00adit the source, but On\u00addrej or I might some\u00adday make it so you can have themes.    \n Al\u00adso, hav\u00ading used this all sum\u00admer (and it was a life-saver hav\u00ading it in mul\u00adti\u00adple oc\u00adca\u00adsion\u00ads, and I am sure made my de\u00advel\u00adop\u00adment speed at least twice as fast in oth\u00ader\u00ads), I have one ad\u00addi\u00adtion\u00adal gripe.  It is too dif\u00adfi\u00adcult to ar\u00adrow up to the vari\u00adable that you want to ac\u00adcess in the vari\u00adables view.  It would be nice to have a page up\u00ad/\u00adpage down fea\u00adture there.    \n UP\u00adDATE 4: PuDB has since im\u00adproved a lot, in\u00adclude many fix\u00ades by my\u00adself. It now sup\u00adports themes, saved set\u00adtings, vari\u00adable name wrap\u00adping, and more. See  this fol\u00adlowup post.", 
      "loc": "/posts/2010/06/04/pudb-a-better-python-debugger/"
    }, 
    {
      "title": "Update for this week", 
      "tags": "", 
      "text": "So I start\u00aded writ\u00ading up a blog post on how ra\u00adtio\u00adnal func\u00adtion in\u00adte\u00adgra\u00adtion work\u00ads, but On\u00addrej  wants a blog post  ev\u00adery week by the end of I don't think I would do it jus\u00adtice by rush\u00ading to fin\u00adish it now (read: I'm to lazy to do it).  So in\u00adstead, I'll just give a short post (if that's pos\u00adsi\u00adble for me) on what I have been do\u00ading this week.    \n I fin\u00adished up writ\u00ading doctests for the poly\u00adno\u00admi\u00adals mod\u00adule for now (see  is\u00adsue 1949), so now this week I start\u00aded look\u00ading at the in\u00adte\u00adgra\u00adtor.  In par\u00adtic\u00adu\u00adlar, I went through each of the 40 is\u00adsues with the  In\u00adte\u00adgra\u00adtion la\u00adbel  and added them to a test file that I can mon\u00adi\u00adtor through\u00adout the sum\u00admer to see my progress.  It is the test_\u00adfail\u00ading_in\u00adte\u00adgral\u00ads.py file in my  In\u00adte\u00adgra\u00adtion branch, where all my work will be go\u00ading for the fore\u00adsee\u00adable fu\u00adture.  So if you want to fol\u00adlow my work, fol\u00adlow that branch.  Here are some ob\u00adser\u00adva\u00adtions from those is\u00adsues: \n \n \n in\u00ad\u00adte\u00ad\u00adgrate() can't han\u00ad\u00addle al\u00ad\u00admost all al\u00adge\u00adbra\u00adic in\u00ad\u00adte\u00ad\u00adgrals (func\u00ad\u00adtions with square root\u00ads, etc.).  It can han\u00ad\u00addle the de\u00adriv\u00ada\u00ad\u00adtive of ar\u00adc\u00adsin and ar\u00adc\u00ads\u00adinh be\u00ad\u00adcause of spe\u00ad\u00adcial code in heurisch.py, but that's about it.  Be\u00ad\u00adfore I can do any work on the Al\u00adge\u00adbra\u00adic Risch Al\u00ad\u00adgo\u00adrith\u00adm, I will need to im\u00ad\u00adple\u00ad\u00adment the tran\u00ads\u00adcen\u00ad\u00adden\u00ad\u00adtal al\u00ad\u00adgo\u00adrith\u00adm, so I think my tem\u00adpo\u00adrary so\u00adlu\u00ad\u00adtion for this may be to add pat\u00adtern match\u00ading heuris\u00adtics for some of the more com\u00ad\u00admon al\u00adge\u00adbra\u00adic in\u00ad\u00adte\u00ad\u00adgrals (any\u00adone know a good in\u00ad\u00adte\u00ad\u00adgral table?).      \n   \n  \n I fig\u00adured out why in\u00ad\u00adte\u00ad\u00adgrate hangs for\u00adev\u00ader with some in\u00ad\u00adte\u00ad\u00adgral\u00ads, such as the one in   is\u00ad\u00adsue 1441.  Here is, in a nut\u00adshel\u00adl, how the Heuris\u00adtic Risch al\u00ad\u00adgo\u00adrithm work\u00ads:  Take the in\u00ad\u00adte\u00ad\u00adgrand and split it in\u00ad\u00ad\u00adto com\u00adpo\u00ad\u00adnents.  For ex\u00adam\u00ad\u00adple, the com\u00adpo\u00ad\u00adnents of xcos(x)sin(x)2 are [x, cos(x), sin(x)].  Re\u00ad\u00adplace each of these com\u00adpo\u00ad\u00adnents with a dum\u00admy var\u00adi\u00adable, so if x = x0, cos(x) = x1, and sin(x) = x2, then the in\u00ad\u00adte\u00ad\u00adgrand is x0x1x22.  Al\u00ad\u00adso, com\u00ad\u00adpute the de\u00adriv\u00ada\u00ad\u00adtive of each com\u00adpo\u00ad\u00adnent in terms of the dum\u00admy var\u00adi\u00adables.  So the de\u00adriv\u00ada\u00ad\u00adtives of [x0, x1, x2] are [1, -x2, 2x1x2].  Then, us\u00ading the\u00adse, per\u00ad\u00adform some mag\u00adic to cre\u00adate some ra\u00ad\u00adtio\u00ad\u00adnal func\u00ad\u00adtions out of the com\u00adpo\u00ad\u00adnent dum\u00admy var\u00adi\u00adables.  Then, cre\u00adate a can\u00addi\u00ad\u00addate in\u00ad\u00adte\u00ad\u00adgral with a bunch of un\u00ad\u00adknowns [A1, A2, \u2026], which will be ra\u00ad\u00adtio\u00ad\u00adnal num\u00adber\u00ads, and a mul\u00adti\u00ad\u00adno\u00admi\u00adal of the An's and the xn's that should equal 0 if the can\u00addi\u00ad\u00addate in\u00ad\u00adte\u00ad\u00adgral is cor\u00adrec\u00adt.  Then, be\u00ad\u00adcause the xn's are not 0, and there is al\u00ad\u00adso some al\u00adge\u00adbra\u00adic in\u00ad\u00adde\u00adpen\u00ad\u00addence, you have the the An co\u00ade\u00adf\u00ad\u00adfi\u00ad\u00adcients of each term must equal 0.  So you get a sys\u00adtem of lin\u00adear equa\u00ad\u00adtions in the An's.  You then solve these equa\u00ad\u00adtion\u00ads, and plug the val\u00adues of the An's in\u00ad\u00ad\u00adto the can\u00addi\u00ad\u00addate in\u00ad\u00adte\u00ad\u00adgral to give you the so\u00adlu\u00ad\u00adtion, or, if the sys\u00adtem is in\u00ad\u00ad\u00adcon\u00ad\u00adsis\u00adten\u00adt, then if can\u00adnot find a so\u00adlu\u00ad\u00adtion, pos\u00adsi\u00adbly be\u00ad\u00adcause there is no el\u00ade\u00ad\u00admen\u00ad\u00adtary one.      \n   \n \nWell, that over sim\u00adpli\u00adfies a lot of things, but the point I want to make is that the in\u00adte\u00adgral from is\u00adsue 1441 cre\u00adates a sys\u00adtem of ~600 lin\u00adear equa\u00adtions in ~450 vari\u00adables, and solv\u00ading that equa\u00adtion is what caus\u00ades the in\u00adte\u00adgra\u00adtion to hang.  Al\u00adso, as Ma\u00adteusz, my men\u00adtor and the one who wrote the cur\u00adrent in\u00adte\u00adgra\u00adtion im\u00adple\u00admen\u00adta\u00adtion, point\u00aded out, quite a bit of time is spent in the heurisch al\u00adgo\u00adrithm do\u00ading ex\u00adpan\u00adsion on large Ba\u00adsic poly\u00adno\u00admi\u00adal\u00ads.  When I say Ba\u00adsic poly\u00adno\u00admi\u00adal\u00ads, I mean that they are SymPy ex\u00adpres\u00adsion\u00ads, in\u00adstead of Poly in\u00adstances.  Us\u00ading Poly should speed things up quite a bit, so my next move will be to con\u00advert heurisch() in\u00adto us\u00ading Poly wher\u00adev\u00ader ap\u00adpli\u00adca\u00adble.    \n \n \n There were a few bugs in the ra\u00ad\u00adtio\u00ad\u00adnal in\u00ad\u00adte\u00ad\u00adgra\u00ad\u00adtion, which I fixed in my branch.  The prob\u00adlem was in ra\u00ad\u00adtio\u00ad\u00adnal in\u00ad\u00adte\u00ad\u00adgrals with sym\u00adbol\u00adic co\u00ade\u00adf\u00ad\u00adfi\u00ad\u00adcients.  Be\u00ad\u00adcause the new polys are able to cre\u00adate poly\u00adno\u00admi\u00adals us\u00ading any ex\u00adpres\u00ad\u00adsion as a gen\u00ader\u00ada\u00ad\u00adtor, not just sym\u00adbol\u00ads, things like Poly(s\u00adin(y)x, x) cre\u00adates Poly(s\u00adin(y)x, x, do\u00ad\u00admain='Z\u00adZ[s\u00adin(y)]').  But us\u00ading the poly\u00adno\u00admi\u00adal ring or frac\u00ad\u00adtion field cre\u00adates prob\u00adlems with some things like di\u00advi\u00ad\u00adsion, where\u00adas we re\u00adal\u00ad\u00adly on\u00ad\u00adly want the do\u00ad\u00admain to be EX (ex\u00adpres\u00ad\u00adsion do\u00ad\u00admain) in this case.  So this was not too dif\u00ad\u00adfi\u00adcult to fix, and you can see the fix in my in\u00ad\u00adte\u00ad\u00adgra\u00ad\u00adtion branch.      \n   \n  \n Some in\u00ad\u00adte\u00ad\u00adgrals will re\u00adquire some good im\u00ad\u00adple\u00ad\u00admen\u00ad\u00adta\u00ad\u00adtion of spe\u00ad\u00adcial func\u00ad\u00adtions such as the hy\u00adper\u00adge\u00ado\u00admet\u00adric func\u00ad\u00adtion to work.  Some\u00ad\u00adtimes, you don't want to know what the non-ele\u00ad\u00admen\u00ad\u00adtary in\u00ad\u00adte\u00ad\u00adgral looks like, but you just want to cal\u00adcu\u00adlate a de\u00adf\u00adi\u00adnite in\u00ad\u00adte\u00ad\u00adgral.  The so\u00adlu\u00ad\u00adtion here is to use Mei\u00ad\u00adjer-G func\u00ad\u00adtion\u00ads, which are on the list of things to pos\u00adsi\u00adbly do at the end of the sum\u00admer if I have time.  \n   \n  \n An\u00adoth\u00ader bug that I plan on fix\u00ading (I haven't done it yet, but I know how to do it and it will be triv\u00adial), is this (is\u00ad\u00adsue 1888):  \n   \n \nIn [18]: print in\u00adte\u00adgrate(f(x).d\u00adif\u00adf(x)**2, x) \n 2D(f(x), x)f(x)/3 - 2xD(f(x), x, x)f(x)/3 + xD(f(x), x)**2/3 \n The prob\u00adlem is in the step where it com\u00adputes the de\u00adriv\u00ada\u00adtive of the com\u00adpo\u00adnents, it tries to com\u00adpute the de\u00adriv\u00ada\u00adtive of f(x).d\u00adif\u00adf(x) in terms of a dum\u00admy vari\u00adable, but it re\u00adduces to 0 be\u00adcause dif\u00adf(x2, x) == 0.  Thus, it treats f(x).d\u00adif\u00adf(x) like some\u00adthing that has a 0 third deriva\u00adtive, i.e., x**2.    \n Well that's it.  I knew I could\u00adn't make a short blog post :).  If you want to help, I have three branch\u00ades that need re\u00adview (1,  2,  3), and ex\u00adcept for the last one, my work is based on top of the oth\u00ader two, so none of my in\u00adte\u00adgra\u00adtion work can be pushed in un\u00adtil those two re\u00adviewed pos\u00adi\u00adtive\u00adly.", 
      "loc": "/posts/2010/06/04/update-for-this-week/"
    }, 
    {
      "title": "More information on my Google Summer of Code project this year", 
      "tags": "mathjax", 
      "text": "So, as I not\u00aded  here, I have been ac\u00adcept\u00aded in\u00adto the Google Sum\u00admer of Code pro\u00adgram again this year.  I men\u00adtioned that my project in\u00advolved im\u00adprov\u00ading the in\u00adte\u00adgra\u00adtor, but I did\u00adn't say much oth\u00ader than that.  So here I plan on say\u00ading a bit more.  If you want more de\u00adtail\u00ads, you can read my ap\u00adpli\u00adca\u00adtion  on the SymPy wi\u00adki.    \n My goal is to im\u00adprove the in\u00adte\u00adgra\u00adtor in SymPy, in oth\u00ader word\u00ads, the back end to the  in\u00adte\u00adgrate()  func\u00adtion.  This is no easy task.  Cur\u00adrent\u00adly, SymPy has a pret\u00adty dec\u00adnet in\u00adte\u00adgra\u00adtion en\u00adgine.  It is even able to solve some in\u00adte\u00adgrals that no oth\u00ader sys\u00adtem is known to be able to solve (the sec\u00adond in\u00adte\u00adgral  here). But, as I dis\u00adcov\u00adered of\u00adten many times through\u00adout my work on ODEs last year, the in\u00adte\u00adgra\u00adtor can of\u00adten leave some\u00adthing to be de\u00adsired.  There are two prob\u00adlems that I hope to ad\u00address.    \n First, the in\u00adte\u00adgra\u00adtor of\u00adten fails on el\u00ade\u00admen\u00adtary in\u00adte\u00adgral\u00ads.  This is be\u00adcause all of the in\u00adte\u00adgra\u00adtion in SymPy is based on a heuris\u00adtic called the Risch-Nor\u00adman al\u00adgo\u00adrith\u00adm.  Sym\u00adbol\u00adic in\u00adte\u00adgra\u00adtion has been com\u00adplete\u00adly solved in the form of the Risch al\u00adgo\u00adrith\u00adm, mean\u00ading that there ex\u00adists an al\u00adgo\u00adrithm to de\u00adter\u00admine if an el\u00ade\u00admen\u00adtary func\u00adtion has an el\u00ade\u00admen\u00adtary anti\u00adderiv\u00ada\u00adtive or not, and to find it if it does.  This al\u00adgo\u00adrith\u00adm, called the Risch al\u00adgo\u00adrith\u00adm, is ex\u00adtreme\u00adly com\u00adpli\u00adcat\u00aded, to the ex\u00adtent that no com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtem has ev\u00ader com\u00adplete\u00adly im\u00adple\u00adment\u00aded all the parts of it.  My plan is to be\u00adgin im\u00adple\u00adment\u00ading the full al\u00adgo\u00adrithm in SymPy.  I don't ex\u00adpect to fin\u00adish the whole thing -- as I said no one ev\u00ader has.  Rather, I hope to make a good head\u00adway in\u00adto what is known as the tran\u00adscen\u00adden\u00adtal part.  The Risch al\u00adgo\u00adrithm is bro\u00adken up in\u00adto four part\u00ads: ra\u00adtio\u00adnal part, the tran\u00adscen\u00adden\u00adtal part, the al\u00adge\u00adbra\u00adic part, and the mixed part.    \n The ra\u00adtio\u00adnal part is in\u00advolves in\u00adte\u00adgrat\u00ading ra\u00adtio\u00adnal func\u00adtions (func\u00adtions of the form $la\u00adtex \\frac{a_nxn + a_{n-1}x{n-1} + \\c\u00addots + a_2x2 + a_1x + a_0}{b_nxn + b_{n-1}x{n-1} + \\c\u00addots + b_2x2 + a_1x + a_0}$).  The ra\u00adtio\u00adnal part is the eas\u00adi\u00adest part in the sense that the al\u00adgo\u00adrithm is the sim\u00adplest, and al\u00adso that all ra\u00adtio\u00adnal func\u00adtion in\u00adte\u00adgrals are el\u00ade\u00admen\u00adtary (a term that I will de\u00adfine lat\u00ader).  Ra\u00adtio\u00adnal func\u00adtion in\u00adte\u00adgra\u00adtion is al\u00adready im\u00adple\u00adment\u00aded in sympy in ful\u00adl, though I may give a brief out\u00adline of how it works in a lat\u00ader post.    \n The tran\u00adscen\u00adden\u00adtal part is the part that I will be im\u00adple\u00adment\u00ading this sum\u00admer.  My guide will be  Sym\u00adbol\u00adic In\u00adte\u00adgra\u00adtion I: Tran\u00adscen\u00adden\u00adtal Func\u00adtions  by Manuel Bron\u00adstein, which de\u00adscribes and proves the tran\u00adscen\u00adden\u00adtal part of the al\u00adgo\u00adrithm in some 300+ pages.  I will try to ex\u00adplain a lit\u00adtle of how the al\u00adgo\u00adrithm works in some blog post\u00ads, but un\u00adder\u00adstand that it is very com\u00adplex.  There\u00adfore, I will prob\u00ada\u00adbly ex\u00adplain it with\u00adout prov\u00ading things.  If you are in\u00adter\u00adest\u00aded in buy\u00ading the book and learn\u00ading the al\u00adgo\u00adrithm rig\u00ador\u00adous\u00adly, the on\u00adly pre\u00adreq\u00adui\u00adsites that I can tell are cal\u00adcu\u00adlus (so you know what an in\u00adte\u00adgral and a de\u00adriv\u00ada\u00adtive are), and a se\u00admes\u00adter of ab\u00adstract al\u00adge\u00adbra (y\u00adou need to know about rings, field\u00ads, ide\u00adal\u00ads, ho\u00admo\u00admor\u00adphism\u00ads, etc., as well as the var\u00adi\u00adous the\u00ado\u00adrems re\u00adlat\u00ading them).    \n In the book, I am still in the part that de\u00advel\u00adops the the\u00ado\u00adry called dif\u00adfer\u00aden\u00adtial al\u00adge\u00adbra nec\u00ades\u00adsary to prove the in\u00adte\u00adgra\u00adtion al\u00adgo\u00adrithm cor\u00adrec\u00adt.  So to be\u00adgin the GSoC pro\u00adgram, I am work\u00ading on learn\u00ading the polys mod\u00adule in sympy.  My method of do\u00ading this is to write doctests for all the func\u00adtions in the mod\u00adule.  It's a daunt\u00ading task, but it's been prob\u00ada\u00adbly the best way of learn\u00ading how a com\u00adput\u00ader mod\u00adule works that I have ev\u00ader tried.  You re\u00adal\u00adly have to un\u00adder\u00adstand all as\u00adpects of a func\u00adtion to write a doctest for it, the types of the pa\u00adram\u00ade\u00adters and re\u00adturn val\u00adue, as well as what the al\u00adgo\u00adrithm is ac\u00adtu\u00adal\u00adly do\u00ading.  It's es\u00adpe\u00adcial\u00adly help\u00adful that the code for the func\u00adtions is right be\u00adlow the doc\u00adstring for each func\u00adtion, so I can see how it re\u00adal\u00adly works on the in\u00adsid\u00ade, re\u00admov\u00ading the mys\u00adtery of the mod\u00adule.  Fur\u00adther\u00admore, it will serve as a ref\u00ader\u00adence for me for the re\u00admain\u00adder of the sum\u00admer, as well for any\u00adone else who wants to learn the polys mod\u00adule, or just needs to de\u00adbug it.  I've al\u00adso ran in\u00adto sev\u00ader\u00adal bugs and in\u00adef\u00adfi\u00adcien\u00adcies in the mod\u00adule that I have tak\u00aden the lib\u00ader\u00adty of fix\u00ading.    \n Well that's it for this post.  If you want to fol\u00adlow my progress on the doctest\u00ads, my branch is  http://github.\u00adcom/as\u00admeur\u00ader/sympy/tree/poly\u00addoc\u00ads-polys9.  Note that the branch will be very un\u00adsta\u00adble un\u00adtil I fin\u00adish at some point at the end of this week or the be\u00adgin\u00adning of the nex\u00adt.", 
      "loc": "/posts/2010/05/26/more-information-on-my-google-summer-of-code-project-this-year/"
    }, 
    {
      "title": "GSoC 2010", 
      "tags": "", 
      "text": "So I ap\u00adplied for Google Sum\u00admer of Code again this year, and I got ac\u00adcept\u00aded!  I will post more here lat\u00ader, but you can read the pro\u00adpos\u00adal ab\u00adstract  here.  The project is to im\u00adprove the in\u00adte\u00adgra\u00adtor in SymPy, mak\u00ading it faster, and able to solve more in\u00adte\u00adgral\u00ads.", 
      "loc": "/posts/2010/04/26/gsoc-2010/"
    }, 
    {
      "title": "Latest SymPy makes it to Fink", 
      "tags": "", 
      "text": "Look at this screen\u00adshot:\n  \n So the lat\u00adest ver\u00adsion of SymPy fi\u00adnal\u00adly made it in\u00adto  fink.  Nor\u00admal\u00adly, this would\u00adn't be that ex\u00adcit\u00ading, but be\u00adfore this, the most re\u00adcent ver\u00adsion in fink was 0.6.4, which was be\u00adfore I ev\u00ader joined the pro\u00adjec\u00adt, with the ex\u00adcep\u00adtion of two com\u00admit\u00ads.  So this is the first ver\u00adsion on fink to in\u00adclude all of my con\u00adtri\u00adbu\u00adtion\u00ads, in\u00adclud\u00ading my 2009 Google Sum\u00admer of Code work.", 
      "loc": "/posts/2010/04/06/latest-sympy-makes-it-to-fink/"
    }, 
    {
      "title": "Automatically Remove Trailing Whitespace in XCode", 
      "tags": "", 
      "text": "I like XCode, and I use it to ed\u00adit all of my source for SymPy.   But, like many ed\u00adi\u00adtors, it likes to au\u00adto-in\u00addent new lines to the lev\u00adel of in\u00adden\u00adta\u00adtion of the pre\u00advi\u00adous line.  This is a use\u00adful fea\u00adture, but it makes for train\u00ading white\u00adspace out the wa\u00adzoo, since blank lines will be in\u00addent\u00aded in.  I am con\u00adstant\u00adly find\u00ading my\u00adself us\u00ading SymPy's strip_whites\u00adpace script to clean up my files.    \n This bugged me enough that I Googled a so\u00adlu\u00adtion, and found  this.  It is a sim\u00adple XCode plug\u00adin that, among oth\u00ader things, adds an op\u00adtion to strip trail\u00ading white\u00adspace on save.  Just in\u00adstall in the Plug\u00adIns fold\u00ader in the XCode pack\u00adage and en\u00adable the op\u00adtion in the new Google pane of the XCode pref\u00ader\u00adences.", 
      "loc": "/posts/2009/12/29/automatically-remove-trailing-whitespace-in-xcode/"
    }, 
    {
      "title": "How to get both 32-bit and 64-bit Python in Snow Leopard", 
      "tags": "", 
      "text": "We had some dis\u00adcus\u00adsion on one of the Python is\u00adsues about whether my Python in Snow Leop\u00adard should be 32-bit or 64-bit.  I orig\u00adi\u00adnal\u00adly thought that it was tied to what the ker\u00adnel was, but I turned out to be wrong.   \n From what I dis\u00adcov\u00adered, the im\u00adpor\u00adtant thing is what the Python was com\u00adpiled as.  You can tell what your Python has been com\u00adpiled as by run\u00adning: \n  \n >>> im\u00adport sys \n >>> from math im\u00adport log \n >>> log(sys.\u00admax\u00adsize, 2) \n  \n If this is just un\u00adder 31, then it is 32 bit.  If it re\u00adturns 63, then it is 64.  An eas\u00adi\u00ader way to tell it to run: \n  \n >>> 2**40 \n  \n If you get 1099511627776L, then you have 32-bit Python, if you get 1099511627776, you have 64-bit Python (no\u00adtice that the num\u00adber is long in 32-bit Python, be\u00adcause it is larg\u00ader than max\u00adin\u00adt).    \n This test won't work in Python 3 be\u00adcause all in\u00adte\u00adgers are \"long\" by de\u00adfault, but the first part will still work.    \n So why does this mat\u00adter, you ask?  Well, aside from the fact that much longer num\u00adbers are not long (any\u00adthing less than 2**63 - 1 = 9223372036854775807), there is the is\u00adsue of hash\u00ading.   \n In 64-bit Python: \n  \n >>> hash('a') \n 12416037344 \n  \n but in 32-bit Python \n  \n >>> hash('a') \n -468864544 \n  \n SymPy us\u00ades hash val\u00adues to or\u00adder ar\u00adgu\u00adments, so of\u00adten it hap\u00adpens that be\u00adhav\u00adior in one ar\u00adchi\u00adtec\u00adture will not show up in the oth\u00ader.  These prob\u00adlems are of\u00adten hard to track and fix, but the worst is when things work fine on the ma\u00adchine you are work\u00ading on.  This ac\u00adtu\u00adal\u00adly hap\u00adpened to me with my GSoC projec\u00adt.  I was renum\u00adber\u00ading the ar\u00adbi\u00adtrary con\u00adstants in the print\u00ading or\u00adder in an ex\u00adpres\u00adsion, but it turned out that the print\u00ading or\u00adder of an ex\u00adpres\u00adsion can be de\u00adpen\u00addent on .args or\u00adder, so I had to mod\u00adi\u00adfy the tests to can\u00adon\u00adize the num\u00adber\u00ading first. \n So here comes the crux of the post.  It turns out that on Mac OS X, if you in\u00adstall the bi\u00adna\u00adry from python.org (Mac In\u00adstall\u00ader Disk Im\u00adage), this in\u00adstalls a 32-bit Python (for com\u00adpat\u00adi\u00adbil\u00adi\u00adty rea\u00adson\u00ads) in /Li\u00adbrary/Frame\u00adwork\u00ads/Python.frame\u00adwork/Ver\u00adsion\u00ads/2.6/bin/python2.6 \n .  How\u00adev\u00ader, if you in\u00adstall Python us\u00ading 64-bit fink in Snow Leop\u00adard, it will com\u00adpile it from source in\u00adto 64-bit, and in\u00adstall it in\u00adto /sw/bin/python2.6.    \n So now I have an easy way to test both ar\u00adchi\u00adtec\u00adtures with\u00adout hav\u00ading to ssh in\u00adto some oth\u00ader ma\u00adchine, which was what I was do\u00ading be\u00adfore.", 
      "loc": "/posts/2009/11/13/how-to-get-both-32-bit/"
    }, 
    {
      "title": "Google Summer of Code 2009 Wrap Up", 
      "tags": "mathjax", 
      "text": "Sor\u00adry about the ex\u00adtreme de\u00adlay with this.  I of course have been busy with class\u00ades. \n Note that this will just be a sum\u00adma\u00adry of the sum\u00admer, with my com\u00adments look\u00ading back on it.  If you want more de\u00adtails on each in\u00addi\u00advid\u00adu\u00adal thing that I im\u00adple\u00adment\u00aded, look back on my pre\u00advi\u00adous blog post\u00ads. \n Let me start from the be\u00adgin\u00adning.  Around late Feb\u00adru\u00adary to ear\u00adly March of this year, I dis\u00adcov\u00adered the ex\u00adis\u00adtence of Google Sum\u00admer of Code.  I knew that I want\u00aded to do some kind of work this sum\u00admer, prefer\u00adably an in\u00adtern\u00adship, so it piqued my in\u00adter\u00adest.  At that time, the men\u00adtor\u00ading or\u00adga\u00adni\u00adza\u00adtions were still ap\u00adply\u00ading for GSoC 2009, so I could on\u00adly look at the ones from 2008.  Most of them were ei\u00adther Lin\u00adux things or Web things, nei\u00adther of which I had any ex\u00adpe\u00adri\u00adence in or am I much in\u00adter\u00adest\u00aded in.  I took a free course in Python at my Uni\u00adver\u00adsi\u00adty the pre\u00advi\u00adous semester, and it was the pro\u00adgram\u00adming lan\u00adguage that I knew best at the time.  I had learned some Ja\u00adva in my first se\u00admes\u00adter CS class (did I men\u00adtion that this was my first year at col\u00adlege?), and I hat\u00aded it, and I was still learn\u00ading C for my sec\u00adond se\u00admes\u00adter CS class.  So I looked at what the Python Foun\u00adda\u00adtion had to of\u00adfer.  I am a dou\u00adble ma\u00adjor in math and com\u00adput\u00ader sci\u00adence, so I looked un\u00adder the math\u00ad/\u00adscience head\u00ading.  That's when I saw SymPy. \n I should not that I have been ahead in Math.  It was my sec\u00adond semester, and I was tak\u00ading Dis\u00adcrete Math\u00ade\u00admat\u00adic\u00ads, Or\u00addi\u00adnary Dif\u00adfer\u00aden\u00adtial Equa\u00adtion\u00ads, Ba\u00adsic Con\u00adcepts of Math, and Vec\u00adtor Anal\u00ady\u00adsis.  So I looked for project ideas on the SymPy page that re\u00adlat\u00aded to what I knew.  The on\u00adly one that I saw, oth\u00ader than core im\u00adprove\u00adments, was to im\u00adprove the ODE solv\u00ading ca\u00adpa\u00adbil\u00adi\u00adties.  I got in\u00adto con\u00adtact with the com\u00admu\u00adni\u00adty and looked at the source, find\u00ading that it was on\u00adly ca\u00adpa\u00adble of solv\u00ading 1st or\u00adder lin\u00adear equa\u00adtions and some spe\u00adcial cas\u00ades of 2nd or\u00adder lin\u00adear ho\u00admo\u00adge\u00adneous equa\u00adtions with con\u00adstant co\u00adef\u00adfi\u00adcients.  I al\u00adready at that point knew sev\u00ader\u00adal meth\u00adods from my ODE course, and I knew much of what I would learn.    \n Ap\u00adpli\u00adca\u00adtion Pe\u00adri\u00adod \n The most dif\u00adfi\u00adcult part of the Google Sum\u00admer of Code, in my opin\u00adion, is the ap\u00adpli\u00adca\u00adtion pe\u00adri\u00adod.  For starter\u00ads, you have to do it while you are still in class\u00ades, so you pret\u00adty much have to do it in your free time.  Al\u00adso, if you have nev\u00ader ap\u00adplied for Google Sum\u00admer of Code be\u00adfore, you do not re\u00adal\u00adly know what a good ap\u00adpli\u00adca\u00adtion should look like.  I have long had my ap\u00adpli\u00adca\u00adtion avail\u00adable on the  SymPy Wi\u00adki, and I will ref\u00ader\u00adence it here a few times.  First of\u00adf, it was rec\u00adom\u00admend\u00aded to me by some of the SymPy de\u00advel\u00adop\u00aders that I put as many po\u00adten\u00adtial things that I could do in the sum\u00admer in my ap\u00adpli\u00adca\u00adtion as I though I could do.  I was still on\u00adly about half way through my ODEs course when I wrote the ap\u00adpli\u00adca\u00adtion, but I had the syl\u00adlabus so I knew the meth\u00adods I would be learn\u00ading at least by name.  So that is ex\u00adact\u00adly what I did:  I packed my ap\u00adpli\u00adca\u00adtion with ev\u00adery pos\u00adsi\u00adble thing that I knew we would be learn\u00ading about in ODEs.    \n Af\u00adter I felt that I had a strong ap\u00adpli\u00adca\u00adtion, and On\u00addrej had proof\u00adread it for me, I sub\u00admit\u00adted it.  There were ac\u00adtu\u00adal\u00adly two iden\u00adti\u00adcal ap\u00adpli\u00adca\u00adtion\u00ads, one for the Python Soft\u00adware Foun\u00adda\u00adtion, and one for Port\u00adland State Uni\u00adver\u00adsi\u00adty.  This is be\u00adcause SymPy was not ac\u00adcept\u00aded as a men\u00adtor\u00ading or\u00adga\u00adni\u00adza\u00adtion di\u00adrect\u00adly, so they had to use those two foun\u00adda\u00adtions as prox\u00adies.  A re\u00adquire\u00adment of ac\u00adcep\u00adtance is to sub\u00admit a patch that pass\u00ades re\u00adview.  I de\u00adcid\u00aded to add a Bernoul\u00adli solver, be\u00adcause Bernoul\u00adli can be solved in the gen\u00ader\u00adal case much like the 1st or\u00adder lin\u00adear ODE, which was al\u00adready im\u00adple\u00adment\u00aded.    \n Af\u00adter I ap\u00adplied, there was an ac\u00adcep\u00adtance pe\u00adri\u00adod.  I used that pe\u00adri\u00adod to be\u00adcome aquat\u00adint\u00aded with the SymPy com\u00admu\u00adni\u00adty and code base.  A good way to do this is to try to fix  EasyToFix is\u00adsues.  I found  is\u00adsue 694, which is to im\u00adple\u00adment a bunch of tests from a pa\u00adper by Michael West\u00ader for test\u00ading com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtem\u00ads.  The tests cov\u00ader ev\u00adery pos\u00adsi\u00adble thing that a full fea\u00adtured CAS could do, so it was a great way to learn SymPy.  The is\u00adsue is still un\u00adfin\u00adished, so work\u00ading on it is still a good way to learn how to use SymPy.    \n Al\u00adso, it was im\u00adpor\u00adtant to learn git, SymPy's ver\u00adsion con\u00adtrol sys\u00adtem.  The learn\u00ading curve it pret\u00adty steep if you have nev\u00ader used ver\u00adsion con\u00adtrol sys\u00adtem be\u00adfore, but once you can use it, it be\u00adcomes a great tool at your dis\u00adpos\u00adal.    \n Ac\u00adcep\u00adtance \n Af\u00adter be\u00ading ac\u00adcept\u00aded, I toned down my work with SymPy to work on fin\u00adish\u00ading up my class\u00ades.  My class\u00ades fin\u00adished a few weeks be\u00adfore the of\u00adfi\u00adcial start, so I used that pe\u00adri\u00adod to get a jump start on my projec\u00adt. \n The GSoC Pe\u00adri\u00adod \n For the start of the pe\u00adri\u00adod, I fol\u00adlowed my time\u00adline.  I im\u00adple\u00adment\u00aded 1st or\u00adder ODEs with ho\u00admo\u00adge\u00adneous co\u00adef\u00adfi\u00adcients and 1st or\u00adder ex\u00adact ODEs.  These were both pret\u00adty sim\u00adple to do, as I ex\u00adpect\u00aded.    \n The next thing I want\u00aded to do was sep\u00ada\u00adra\u00adble.  My goal at this point was to get ev\u00adery rel\u00ade\u00advant ex\u00ader\u00adcise from my text\u00adbook to work with my solver\u00ads.  One of the ex\u00ader\u00adcis\u00ades from my  book  (Pg. 56, No. 21) was $la\u00adtex dy=e{x + y}dx$.  I soon dis\u00adcov\u00adered that it was im\u00adpos\u00adsi\u00adble for SymPy to sep\u00ada\u00adrate $la\u00adtex e{x + y} \\rightar\u00adrow e{x}e{y}$, be\u00adcause the sec\u00adond would be au\u00adto\u00admat\u00adi\u00adcal\u00adly com\u00adbined in the core.  I al\u00adso dis\u00adcov\u00adered that  ex\u00adpand(), which should have been the func\u00adtion to split that, ex\u00adpand\u00aded us\u00ading all pos\u00adsi\u00adble meth\u00adods in\u00addis\u00adcrim\u00adi\u00adnate\u00adly.  Part of my  sep\u00ada\u00adrat\u00ade\u00advars()  func\u00adtion that I was writ\u00ading to sep\u00ada\u00adrate vari\u00adables in ex\u00adpres\u00adsions would be to split things like $la\u00adtex x + yx \\rightar\u00adrow x(1 + y)$ and $la\u00adtex 2 x y + x{2} + y{2} \\rightar\u00adrow (x + y){2}$, but  ex\u00adpand() \n as it was cur\u00adrent\u00adly writ\u00adten would ex\u00adpand those.    \n So I spent a few weeks hack\u00ading on the core to make it not au\u00adto-\u00adcom\u00adbine ex\u00adpo\u00adnents.  I came up with a rule that ex\u00adpo\u00adnents would on\u00adly au\u00adto-\u00adcom\u00adbine if they had the same term mi\u00adnus the co\u00adef\u00adfi\u00adcien\u00adt, the same rule that  Add  us\u00ades to de\u00adter\u00admine what terms should au\u00adto com\u00adbined by ad\u00addi\u00adtion.  So it would com\u00adbine $la\u00adtex e{x}e{x} \\rightar\u00adrow e{2x}$, but $la\u00adtex e{x}e{y}$ would be left alone.  It turns out that some of our al\u00adgo\u00adrithm\u00ads, name\u00adly the Gruntz lim\u00adit al\u00adgo\u00adrith\u00adm, re\u00adlies on au\u00adto-\u00adcom\u00adbin\u00ading.  We al\u00adready had a func\u00adtion that could com\u00adbine ex\u00adpo\u00adnents,  powsim\u00adp(), but it al\u00adso com\u00adbined bases, as in $la\u00adtex xzyz \\rightar\u00adrow (xy)z$, so I had to split the be\u00adhav\u00adior so that it could act on\u00adly as au\u00adto-\u00adcom\u00adbin\u00ading once did (by the way, use  powsim\u00adp(\u00adex\u00adpr, com\u00adbine='\u00adex\u00adp', deep\u00ad=True)  to do this).  Then, af\u00adter some help from On\u00addrej on pin\u00adpoint\u00ading the ex\u00adact lo\u00adca\u00adtion of the bugs, I just ap\u00adplied the func\u00adtion there.  The last thing I did here was to split the be\u00adhav\u00adior of ex\u00adpand, so that you could do  ex\u00adpand(x(y + 1), mul=\u00adFalse)  and it would leave it alone, but  ex\u00adpand(\u00adex\u00adp(x + y), mul=\u00adFalse)  would re\u00adturn  ex\u00adp(x)\u00adex\u00adp(y).  This split be\u00adhav\u00adior turned out to be use\u00adful in more than one place in my code.    \n This was the first non bug fix patch of mine that was pushed in to SymPy, and at the time of this writ\u00ading, it is the last ma\u00adjor one in the lat\u00adest sta\u00adble ver\u00adsion.  It took some ma\u00adjor re\u00adbas\u00ading to get my con\u00advo\u00adlut\u00aded com\u00admit his\u00adto\u00adry ready for sub\u00admis\u00adsion, and it was dur\u00ading this phase that I git fi\u00adnal\u00adly clicked for me, es\u00adpe\u00adcial the  git re\u00adbase  com\u00admand.  This work took a few weeks from my ODEs time, and it be\u00adcame clear that I would not be do\u00ading ev\u00adery pos\u00adsi\u00adble thing from my ap\u00adpli\u00adca\u00adtion.  The rea\u00adson that I in\u00adclud\u00aded so much in my ap\u00adpli\u00adca\u00adtion was that my project was non-atom\u00adic.  I could im\u00adple\u00adment a lit\u00adtle or a lot and still have a work\u00ading  use\u00adful mod\u00adule.    \n If you look at my time\u00adline on my ap\u00adpli\u00adca\u00adtion, you can see that the first half is sym\u00adbol\u00adic meth\u00adod\u00ads, and the sec\u00adond half is oth\u00ader meth\u00adod\u00ads, things like se\u00adries.  It turns out that we did\u00adn't re\u00adal\u00adly learn much about sys\u00adtems of ODEs in my course and we learned very lit\u00adtle about nu\u00admer\u00adi\u00adcal meth\u00adods (and it would take much more to know how to im\u00adple\u00adment them).  We did learn se\u00adries meth\u00adod\u00ads, but they were so an\u00adnoy\u00ading to do that I came to hate them with a pas\u00adsion.  So I de\u00adcid\u00aded to just fo\u00adcus on sym\u00adbol\u00adic meth\u00adod\u00ads, which were my fa\u00advorite any\u00adway.  My goal was to im\u00adple\u00adment as many as I could.    \n Af\u00adter I fin\u00adished up sep\u00ada\u00adra\u00adble equa\u00adtion\u00ads, I came up with an idea that I did not have dur\u00ading the ap\u00adpli\u00adca\u00adtion pe\u00adri\u00adod.  dsolve()  was be\u00adcom\u00ading clut\u00adtered fast with all of my so\u00adlu\u00adtion meth\u00adod\u00ads.  The way that it worked was that it took an ODE and it tried to match meth\u00adods one by one un\u00adtil it found one that worked, which it then used.   This had some draw\u00adback\u00ads.  First, as I men\u00adtioned, the code was very clut\u00adtered.  Sec\u00adond, the ODEs meth\u00adods would have to be ap\u00adplied in a pre\u00adde\u00adter\u00admined or\u00adder.  There are sev\u00ader\u00adal ODEs that match more than one method.  For ex\u00adam\u00adple, $la\u00adtex 2xy + (x2 + y2)\\frac{dy}{dx}=0$ has co\u00adef\u00adfi\u00adcients that are both ho\u00admo\u00adge\u00adneous of or\u00adder 2, and is al\u00adso ex\u00adac\u00adt, so it can be solved by ei\u00adther method.  The two solvers re\u00adturn dif\u00adfer\u00adent\u00adly for\u00admat\u00adted so\u00adlu\u00adtions for each one.  A sim\u00adpler ex\u00adam\u00adple is that 1st or\u00adder ODEs with ho\u00admo\u00adge\u00adneous co\u00adef\u00adfi\u00adcients can be solved in two dif\u00adfer\u00adent ways.  My work\u00ading so\u00adlu\u00adtion was to try them both and then ap\u00adply some heuris\u00adtics to re\u00adturn the sim\u00adplest one.  But some\u00adtimes, one way would cre\u00adate an im\u00adpos\u00adsi\u00adble in\u00adte\u00adgral that would hand the in\u00adte\u00adgra\u00adtion en\u00adgine.  And it made de\u00adbug\u00adging the two solvers more dif\u00adfi\u00adcult be\u00adcause I had to over\u00adride my heuris\u00adtic.  This al\u00adso touch\u00ades on the third point.  Some\u00adtimes the so\u00adlu\u00adtion to an ODE can on\u00adly be rep\u00adre\u00adsent\u00aded in the form of an un\u00adeval\u00adu\u00adat\u00adable in\u00adte\u00adgral. SymPy's  in\u00adte\u00adgrate()  func\u00adtion is sup\u00adposed to re\u00adturn an un\u00adeval\u00adu\u00adat\u00aded  In\u00adte\u00adgral  class if it can\u00adnot do it, but all too of\u00adten it will just hang for\u00adev\u00ader.    \n The so\u00adlu\u00adtion I came up with was to re\u00adwrite dsolve us\u00ading a hints method.  I would cre\u00adate a new func\u00adtion called  clas\u00adsi\u00adfy_ode()  that would do all of the ODE clas\u00adsi\u00adfi\u00adca\u00adtion, re\u00admov\u00ading it from the solv\u00ading code.  By de\u00adfault, dsolve would still use a pre\u00adde\u00adter\u00admined or\u00adder of match\u00ading meth\u00adod\u00ads.  But you could over\u00adride it by pass\u00ading a \"hin\u00adt\" to  dsolve  for any match\u00ading method, and it would ap\u00adply that method.  There would al\u00adso be op\u00adtions to on\u00adly re\u00adturn un\u00adeval\u00adu\u00adat\u00aded in\u00adte\u00adgrals when ap\u00adpli\u00adca\u00adble.    \n I end\u00aded up do\u00ading this and more (see the doc\u00adstrings for  clas\u00adsi\u00adfy_ode()  and  dsolve()  in the cur\u00adrent git mas\u00adter branch), but be\u00adfore I could I need\u00aded to clean up some things.  I need\u00aded to re\u00adwrite all of  dsolve()  and re\u00adlat\u00aded func\u00adtion\u00ads.  Be\u00adfore I start\u00aded the pro\u00adgram, there were some spe\u00adcial cas\u00ades in dsolve for sec\u00adond or\u00adder lin\u00adear ho\u00admo\u00adge\u00adneous ODEs with con\u00adstant co\u00adef\u00adfi\u00adcients and one very spe\u00adcial case ODE for the ex\u00adpand\u00aded form of $la\u00adtex \\frac{d2}{dx2}(x\u00ade{-y}) = 0$.    \n So the first thing I did was im\u00adple\u00adment a solver for the gen\u00ader\u00adal ho\u00admo\u00adge\u00adneous lin\u00adear with con\u00adstant co\u00adef\u00adfi\u00adcients case.  These are rather sim\u00adple to do: you just find the roots of the char\u00adac\u00adter\u00adis\u00adtic poly\u00adno\u00admi\u00adal built off of the co\u00adef\u00adfi\u00adcients, and then put the re\u00adal parts of the roots in front of the ar\u00adgu\u00adment of an ex\u00adpo\u00adnen\u00adtial and the imag\u00adi\u00adnary parts in front of the ar\u00adgu\u00adments of a sine and co\u00adsine (for ex\u00adam\u00adple, $la\u00adtex 3 \\pm 2i$ would give $la\u00adtex C1e{3x}\\s\u00adin{2x} + C2e{3x}\\\u00adcos{2x}$.  The thing was, that if the imag\u00adi\u00adnary part is 0, then you on\u00adly have 1 ar\u00adbi\u00adtrary con\u00adstant on the ex\u00adpo\u00adnen\u00adtial, but if it is non-ze\u00adro, you get 2, one for each trig func\u00adtion.  The rest falls out nice\u00adly if you plug 0 in for $la\u00adtex b$ in\u00adto $e{ax}(C1\\s\u00adin{bx} + C2\\\u00adcos{box})$ be\u00adcause the sine goes to 0 and the co\u00adsine be\u00adcomes 1.  But you would end up with $la\u00adtex C1 + C2$ in\u00adstead of just $la\u00adtex C1$ in that case.  I had al\u00adready planned on do\u00ading ar\u00adbi\u00adtrary con\u00adstant sim\u00adpli\u00adfi\u00adca\u00adtion as part of my pro\u00adjec\u00adt, so I fig\u00adured I would put this on hold and do that first.  Then, once that was done, the ho\u00admo\u00adge\u00adneous case would be re\u00adduced to 1 case in\u00adstead of the usu\u00adal 2 or 3.    \n My orig\u00adi\u00adnal plan was to make an ar\u00adbi\u00adtrary con\u00adstant type that au\u00adto\u00admat\u00adi\u00adcal\u00adly sim\u00adpli\u00adfied it\u00adself.  So, for ex\u00adam\u00adple, if you en\u00adtered  C1 + 2 + x  with  C1  an ar\u00adbi\u00adtrary con\u00adstan\u00adt, it would re\u00adduce to just  C1 + x.  I worked with On\u00addrej, in\u00adclud\u00ading vis\u00adit\u00ading him in Los Alam\u00ados, and we build up a class that worked.  The prob\u00adlem was that, in or\u00adder to have au\u00adto-sim\u00adpli\u00adfi\u00adca\u00adtion, I had to write the sim\u00adpli\u00adfi\u00adca\u00adtion di\u00adrect\u00adly in\u00adto the core.  Nei\u00adther of us liked this, so we worked a lit\u00adtle bit on a ba\u00adsic core that would al\u00adlow au\u00adto-sim\u00adpli\u00adfi\u00adca\u00adtion to be writ\u00adten di\u00adrect\u00adly in the class\u00ades in\u00adstead of in the  Mul.flat\u00adten()  and  Ad\u00add.flat\u00adten()  meth\u00adod\u00ads.  It turns out that my con\u00adstant class is\u00adn't the on\u00adly thing that would ben\u00ade\u00adfit from this.  Things like the or\u00adder class (O(x)) and the in\u00adfin\u00adi\u00adty class (oo) are au\u00adto-sim\u00adpli\u00adfied in the core, and things could be much clean\u00ader if they hap\u00adpened in the class\u00ades them\u00adselves.  Un\u00adfor\u00adtu\u00adnate\u00adly, mod\u00adi\u00adfy\u00ading the core like this is not some\u00adthing that can hap\u00adpen overnight or even in a few week\u00ads.  For one thing, it need\u00aded to wait un\u00adtil we had the new as\u00adsump\u00adtions sys\u00adtem, which was an\u00adoth\u00ader Google Sum\u00admer of Code project run\u00adning par\u00adal\u00adlel to my own.  So we de\u00adcid\u00aded to shelf the idea. \n I still want\u00aded con\u00adstant sim\u00adpli\u00adfi\u00adca\u00adtion, so I set\u00adtled with writ\u00ading a func\u00adtion that could do it in\u00adstead.  There were some down\u00adsides to this.  Mak\u00ading the func\u00adtion as gen\u00ader\u00adal as the class\u00ades might have been would have been far too much work, so I set\u00adtled on mak\u00ading it an in\u00adter\u00adnal-on\u00adly  func\u00adtion that on\u00adly worked on sym\u00adbols named  C1,  C2, etc.  Al\u00adso, un\u00adlike writ\u00ading the sim\u00adpli\u00adfi\u00adca\u00adtion straight in\u00adto  Mul.flat\u00adten()  which was as sim\u00adple as re\u00admov\u00ading any terms that were not de\u00adpen\u00addent on x, writ\u00ading a func\u00adtion that parsed an ex\u00adpres\u00adsion and sim\u00adpli\u00adfied it was con\u00adsid\u00ader\u00adably hard\u00ader to write.  I man\u00adaged to churn out some\u00adthing that worked, and so I was ready to fin\u00adish up the solver I had start\u00aded a few para\u00adgraphs ago.    \n Af\u00adter I fin\u00adished that, I still need\u00aded to main\u00adtain the abil\u00adi\u00adty to solve that spe\u00adcial case ODE.  Ap\u00adpar\u00adent\u00adly, it is an ODE that you would get some\u00adwhere in de\u00adriv\u00ading some\u00adthing about rel\u00ada\u00adtiv\u00adi\u00adty, be\u00adcause it was in the rel\u00ada\u00adtiv\u00adi\u00adty.py ex\u00adam\u00adple file.  I used Maple's ex\u00adcel\u00adlent  ode\u00adanal\u00ady\u00adser()  func\u00adtion (this is where I go the idea for my  clas\u00adsi\u00adfy_ode())to find a sim\u00adple gen\u00ader\u00adal case ODE that it fit (Liou\u00adville ODE).  Af\u00adter I fin\u00adished this, I was ready to start work\u00ading on the hints en\u00adgine.    \n It took me about a week to move all clas\u00adsi\u00adfi\u00adca\u00adtion code in\u00adto  clas\u00adsi\u00adfy_ode(), move all solvers in\u00adto in\u00addi\u00advid\u00adu\u00adal func\u00adtion\u00ads, sep\u00ada\u00adrate sim\u00adpli\u00adfi\u00adca\u00adtion code in\u00adto yet oth\u00ader func\u00adtion\u00ads, and tie it all to\u00adgeth\u00ader in  dsolve().  In the end, the mod\u00adel worked very well.  The mod\u00adu\u00adlar\u00adiza\u00adtion al\u00adlowed me to do some oth\u00ader things that I had not con\u00adsid\u00adered, such as cre\u00adat\u00ading a spe\u00adcial \"best\" hint that used some heuris\u00adtics that I orig\u00adi\u00adnal\u00adly de\u00advel\u00adoped for first or\u00adder ho\u00admo\u00adge\u00adneous which al\u00adways has two pos\u00adsi\u00adble so\u00adlu\u00adtions to try to give the best for\u00admat\u00adted so\u00adlu\u00adtion for any ODE that has more than one pos\u00adsi\u00adble so\u00adlu\u00adtion method.  It al\u00adso made de\u00adbug\u00adging in\u00addi\u00advid\u00adu\u00adal meth\u00adods much eas\u00adier, be\u00adcause I could just use the built in hint calls in  dsolve()  in\u00adstead of com\u00adment\u00ading out lines of code in the source.    \n This was good, be\u00adcause there was one more method that I want\u00aded to im\u00adple\u00admen\u00adt.  I want\u00aded to be able to solve the in\u00adho\u00admo\u00adge\u00adneous case of a nth or\u00adder lin\u00adear ode with con\u00adstant co\u00adef\u00adfi\u00adcients.  This can be done in the gen\u00ader\u00adal case us\u00ading the method of vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads.  It was quite sim\u00adple to set up vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters up in the code.  You on\u00adly have to set up a sys\u00adtem of in\u00adte\u00adgrals us\u00ading the Wron\u00adskian of the gen\u00ader\u00adal so\u00adlu\u00adtion\u00ads.  It would usu\u00adal\u00adly be a very poor choice of a method if you were try\u00ading to solve an ODE by hand be\u00adcause tak\u00ading the Wron\u00adskian and com\u00adput\u00ading n in\u00adte\u00adgrals is a lot of work.  But for a CAS, the work is al\u00adready there.  I just have to set up the in\u00adte\u00adgral\u00ads.    \n It soon be\u00adcame clear that even though, in the\u00ado\u00adry, the method of vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters can solve any ODE of this type, in prac\u00adtice, it does not al\u00adways work so well in SymPy.  This is be\u00adcause SymPy have very poor sim\u00adpli\u00adfi\u00adca\u00adtion, es\u00adpe\u00adcial\u00adly trigono\u00admet\u00adric sim\u00adpli\u00adfi\u00adca\u00adtion, so some\u00adtimes there would be a trigono\u00admet\u00adric Wron\u00adskian that would be iden\u00adti\u00adcal\u00adly equal to some con\u00adstan\u00adt, but it could on\u00adly sim\u00adpli\u00adfy it to some very large ra\u00adtio\u00adnal func\u00adtion of sines and cosines.  When these were passed to the in\u00adte\u00adgral en\u00adgine, it would cause it to fail, be\u00adcause it could not find the in\u00adte\u00adgral for such a seem\u00ading\u00adly com\u00adplex ex\u00adpres\u00adsion.    \n In ad\u00addi\u00adtion, tak\u00ading Wron\u00adskian\u00ads, sim\u00adpli\u00adfy\u00ading them, and then tak\u00ading n in\u00adte\u00adgrals is a lot of work as I said, and even when SymPy could do it, it took a long time.  There is an\u00adoth\u00ader method for solv\u00ading these types of equa\u00adtions called un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients that does not re\u00adquire in\u00adte\u00adgra\u00adtion.  It on\u00adly works on a class of ODEs where the right hand side of the ODE is a sim\u00adple com\u00adbi\u00adna\u00adtion of sines, cosi\u00adnes, ex\u00adpo\u00adnen\u00adtial\u00ads, and poly\u00adno\u00admi\u00adals in x.  It turns out that these kinds of func\u00adtions are com\u00admon any\u00adway, so most ODEs of this type that you would en\u00adcounter could be solved with this method.  Un\u00adlike vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads, un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients re\u00adquires con\u00adsid\u00ader\u00adable se\u00adtup, in\u00adclud\u00ading check\u00ading for dif\u00adfer\u00adent cas\u00ades.  This would be the method that you would want to use if you had to solve the ODE by hand be\u00adcause, even with all the se\u00adtup, it on\u00adly re\u00adquires solv\u00ading a sys\u00adtem of lin\u00adear equa\u00adtions vs. solv\u00ading n in\u00adte\u00adgrals with vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads, but for a CAS, it is the set\u00adup that mat\u00adter\u00ads, so this was a dif\u00adfi\u00adcult prospec\u00adt. \n I spent the last cou\u00adple of weeks writ\u00ading up the nec\u00ades\u00adsary al\u00adgo\u00adrithms to set\u00adup the re\u00adquired sys\u00adtem of lin\u00adear equa\u00adtions and han\u00addling the dif\u00adfer\u00adent cas\u00ades.  Af\u00adter I fi\u00adnal\u00adly worked out all of the bugs, I ran some pro\u00adfil\u00ading against my vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters solver.  It turned out that for ODEs that had trigono\u00admet\u00adric so\u00adlu\u00adtions (which take longer to sim\u00adpli\u00adfy), my un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients solver was an or\u00adder of mag\u00adni\u00adtude faster than the vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters solver (and that is just for the ODEs that the vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters en\u00adgine could even solve at al\u00adl).  For ODEs that on\u00adly had ex\u00adpo\u00adnen\u00adtial\u00ads, it was still 2-4 times faster.    \n I fin\u00adished off the sum\u00admer by writ\u00ading ex\u00adten\u00adsive doc\u00adu\u00admen\u00adta\u00adtion for all of my solvers and func\u00adtion\u00ads.  Hope\u00adful\u00adly some\u00adone who us\u00ades SymPy to solve ODEs can learn some\u00adthing about ODE solv\u00ading meth\u00adods as well as how to use the func\u00adtion I wrote when they read my doc\u00adu\u00admen\u00adta\u00adtion.   \n   Post-G\u00adSoC \n I plan on con\u00adtin\u00adu\u00ading de\u00advel\u00adop\u00adment with SymPy now that the Google Sum\u00admer of Code pe\u00adri\u00adod is over.  SymPy is an amaz\u00ading pro\u00adjec\u00adt, mix\u00ading Python and Com\u00adput\u00ader Al\u00adge\u00adbra, and I want to help it grow.  I may even ap\u00adply again in a fu\u00adture year to im\u00adple\u00adment some oth\u00ader thing in SymPy, or maybe ap\u00adply as a men\u00adtor for SymPy to help some\u00adone else im\u00adprove it.    \n Ad\u00advice \n What fol\u00adlows is some gen\u00ader\u00adal ad\u00advice for some\u00adone who wants to ap\u00adply for Google Sum\u00admer of Code.  Some of the ad\u00advice per\u00adtains specif\u00adi\u00adcal\u00adly to SymPy, and some of it is gen\u00ader\u00adal ad\u00advice that I think would ap\u00adply to any projec\u00adt. \n \n \n Get in\u00ad\u00ad\u00advolved ear\u00ad\u00adly.  As soon as you de\u00ad\u00adcide that you want to par\u00adtic\u00adi\u00ad\u00adpate in Google Sum\u00admer of Code, start get\u00adt\u00ading in\u00ad\u00ad\u00advolved in the pro\u00adjec\u00adt.  Get in\u00ad\u00ad\u00adto con\u00ad\u00adtact with them and dis\u00ad\u00ad\u00adcuss pos\u00adsi\u00adble pro\u00adjec\u00adt\u00ads.  If you are look\u00ading be\u00ad\u00adfore the par\u00adtic\u00adi\u00ad\u00adpat\u00ading or\u00ad\u00adga\u00adni\u00adza\u00ad\u00ad\u00adtions are an\u00ad\u00adnounced, look at the or\u00ad\u00adga\u00adni\u00adza\u00ad\u00ad\u00adtions from pre\u00advi\u00adous years. For some or\u00ad\u00adga\u00adni\u00adza\u00ad\u00ad\u00adtion\u00ads, it will vary; for oth\u00ad\u00aders (like Python), it is al\u00ad\u00admost giv\u00aden that they will be ac\u00ad\u00adcep\u00adt\u00aded ev\u00adery year.       \n   \n  \n Some projects (in\u00ad\u00adclud\u00ading SymPy) re\u00adquire you to send in a patch that pass\u00ades re\u00adview to be ac\u00ad\u00adcep\u00adt\u00aded.  This will give you a change to start fa\u00admil\u00adiar\u00adiz\u00ading your\u00ad\u00adself with the code base.  If you are ap\u00ad\u00adply\u00ading to SymPy, the West\u00ad\u00ader ex\u00adam\u00ad\u00adple I men\u00ad\u00adtioned above is a re\u00adal\u00ad\u00adly good way to learn what SymPy can do and how it work\u00ads.      \n   \n  \n Sub\u00ad\u00adscribe to the mail\u00ading list, and once you are com\u00ad\u00adfort\u00adable with it, par\u00adtic\u00adi\u00ad\u00adpate.  Al\u00ad\u00adso, it is a good idea to idle in IRC (SymPy is on freen\u00adode at #sympy).  This will help you get to know the main con\u00adtrib\u00adu\u00ad\u00adtors for the pro\u00adjec\u00adt.       \n   \n  \n For you ap\u00ad\u00adpli\u00ad\u00adca\u00ad\u00adtion, see if the peo\u00ad\u00adple in the project you are ap\u00ad\u00adply\u00ading for will re\u00adview it. If they like your project idea, they will try to help you write a good ap\u00ad\u00adpli\u00ad\u00adca\u00ad\u00adtion so you can be ac\u00ad\u00adcep\u00adt\u00aded and you can im\u00ad\u00adple\u00ad\u00adment it.  If they don't like your idea, then they will tell you and you should change it, oth\u00ad\u00ader\u00ad\u00adwise you will not be ac\u00ad\u00adcep\u00adt\u00aded, no mat\u00adter how well writ\u00adten your pro\u00ad\u00adpos\u00adal is.  I have my pro\u00ad\u00adpos\u00adal on the wi\u00ad\u00adki (see link above).  I am not say\u00ading that it is nec\u00ades\u00adsar\u00adi\u00ad\u00adly a very good pro\u00ad\u00adpos\u00adal, but it did get ac\u00ad\u00adcep\u00adt\u00aded.  If you are ap\u00ad\u00adply\u00ading to SymPy, On\u00ad\u00addrej will proof\u00adread your ap\u00ad\u00adpli\u00ad\u00adca\u00ad\u00adtions for you.  \n   \n  \n If you are an IRC fan, there is al\u00ad\u00adso #g\u00ad\u00adsoc on freen\u00adode, where you can ask all your GSoC re\u00adlat\u00aded ques\u00ad\u00adtion\u00ads.  Be warned that it does get pret\u00ad\u00adty noisy in the ap\u00ad\u00adpli\u00ad\u00adca\u00ad\u00adtion pe\u00adri\u00adod, es\u00ad\u00adpe\u00ad\u00adcial\u00ad\u00adly right be\u00ad\u00adfore the ap\u00ad\u00adpli\u00ad\u00adca\u00ad\u00adtions are due and right be\u00ad\u00adfore pro\u00ad\u00adpos\u00adals are ac\u00ad\u00adcep\u00adt\u00aded.      \n   \n  \n I can\u00adnot stress this one enough.  If you have nev\u00ader worked with a ver\u00ad\u00adsion con\u00adtrol sys\u00adtem be\u00ad\u00adfore, it is per\u00adhaps more im\u00ad\u00adpor\u00ad\u00adtant to spend your time learn\u00ading it than it is to learn the code base for your pro\u00adjec\u00adt.  These things have a steep learn\u00ading curve if you have nev\u00ader used them be\u00ad\u00adfore.  Once you mas\u00adter them though, they can make your life much eas\u00adi\u00ader.  Al\u00ad\u00adso, the soon\u00ader you learn to use them well, the eas\u00adi\u00ader your life will be lat\u00ader on down the road.  I spent a good part of the last week of GSoC clean\u00ading up my com\u00admit his\u00ad\u00adto\u00adry from the first half of the sum\u00admer when I bad very poor com\u00admit\u00adt\u00ading/log habit\u00ads.  If your project us\u00ades git, such as SymPy does, you might look at   this   tu\u00ad\u00adto\u00adri\u00adal.  If it us\u00ades some\u00adthing else, good luck.  Se\u00adri\u00adous\u00ad\u00adly, git is the on\u00ad\u00adly good ver\u00ad\u00adsion con\u00adtrol sys\u00adtem.  See   this video.  \n   \n  \n Ex\u00adpect to spend on\u00ad\u00adly about half of the sum\u00admer ac\u00ad\u00adtu\u00adal\u00ad\u00adly im\u00ad\u00adple\u00ad\u00admen\u00adt\u00ading stuff.  You may think that you are a good pro\u00ad\u00adgram\u00admer and that your code will not be so bug\u00ad\u00adgy that you will need to spend that much time fix\u00ading bugs, and you may be right.  But the fact is, you will be work\u00ading on code bases writ\u00adten by may pro\u00ad\u00adgram\u00admers that are not so good.  You will need to fix sev\u00ader\u00adal al\u00adready ex\u00adist\u00ading bugs to make your code work, which means that you will need to learn the code base well, learn how to read oth\u00ad\u00ader peo\u00ad\u00adple's code, and how to fix bugs that you had no part in cre\u00adat\u00ading.  You will be glad if a bug is in your code be\u00ad\u00adcause you will usu\u00adal\u00ad\u00adly know im\u00adme\u00addi\u00adate\u00ad\u00adly what caus\u00ades it and how to fix it.  But if a bug is some\u00adwhere else, you will need to find it, fig\u00adure out why it hap\u00adpen\u00ads, what is sup\u00ad\u00adposed to hap\u00adpen, and how to fix it with\u00ad\u00adout break\u00ading any\u00adthing else.  This is al\u00ad\u00adso why it is im\u00ad\u00adpor\u00ad\u00adtant to be ac\u00ad\u00adtive in the de\u00advel\u00adop\u00ader com\u00ad\u00admu\u00adni\u00ad\u00adty.      \n   \n  \n Good luck.", 
      "loc": "/posts/2009/09/07/google-summer-of-code-2009-wrap-up/"
    }, 
    {
      "title": "Undetermined Coefficients", 
      "tags": "mathjax", 
      "text": "[Sorry for the delay in this post.  I was having some difficulties coming up with some of the rationales below. Also, classes have started, which has made me very busy.]\nIf there was one ODE solv\u00ading method that I did not want to im\u00adple\u00adment this sum\u00admer, it was un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients.  I did\u00adn't re\u00adal\u00adly like the method too much when we did it my my ODE class (though it was not as un\u00aden\u00adjoy\u00adable as se\u00adries meth\u00adod\u00ads).  The thing that I nev\u00ader re\u00adal\u00adly un\u00adder\u00adstood very well is to what ex\u00adtent you have to mul\u00adti\u00adply terms in the tri\u00adal func\u00adtion by pow\u00aders of x to make them lin\u00adear\u00adly in\u00adde\u00adpen\u00addent of the so\u00adlu\u00adtion to the gen\u00ader\u00adal equa\u00adtion.  We did our ODEs home\u00adwork in Maple, so I would usu\u00adal\u00adly just keep try\u00ading high\u00ader pow\u00aders of x un\u00adtil I got a so\u00adlu\u00adtion.  But to im\u00adple\u00adment it in SymPy, I had to have a much bet\u00adter un\u00adder\u00adstand\u00ading of the ex\u00adact rules for it. \n From a user's point of view, the method of un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients is much bet\u00adter than the method of vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads.  While it is true that vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters is a gen\u00ader\u00adal method and un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients on\u00adly works on a spe\u00adcial class of func\u00adtion\u00ads, un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients re\u00adquires no in\u00adte\u00adgra\u00adtion or ad\u00advanced sim\u00adpli\u00adfi\u00adca\u00adtion, so it is fast (very fast, as well shall see be\u00adlow).  All that the CAS has to do is fig\u00adure out what a tri\u00adal func\u00adtion looks like, plug it in\u00adto the ODE, and solve for the co\u00adef\u00adfi\u00adcients, which is a sys\u00adtem of lin\u00adear equa\u00adtion\u00ads.    \n On the oth\u00ader hand, from the pro\u00adgram\u00admer's point of view,  vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters  is much bet\u00adter.  All you have to do is take the Wron\u00adskian of the gen\u00ader\u00adal so\u00adlu\u00adtion set and use it to set up some in\u00adte\u00adgral\u00ads.  But the Wron\u00adskian has to be sim\u00adpli\u00adfied, and if the gen\u00ader\u00adal so\u00adlu\u00adtion con\u00adtains sin's and cos's, this re\u00adquires trigono\u00admet\u00adric sim\u00adpli\u00adfi\u00adca\u00adtion not cur\u00adrent\u00adly avail\u00adable in SymPy (although it looks like the  new Polys mod\u00adule  will be mak\u00ading a big leap for\u00adward in this area).  Al\u00adso, in\u00adte\u00adgra\u00adtion is slow, and in SymPy, it of\u00adten fails (hangs forever).    \n Fig\u00adur\u00ading out what the tri\u00adal func\u00adtion should be for un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients is way more dif\u00adfi\u00adcult to pro\u00adgram, but hav\u00ading finnal\u00adly fin\u00adished it, I can say that it is def\u00adi\u00adnite\u00adly worth hav\u00ading in the mod\u00adule.  Prob\u00adlems that it can solve can run or\u00adders of mag\u00adni\u00adtude faster than the vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads, and of\u00adten vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters can't do the in\u00adte\u00adgral or re\u00adturns a less sim\u00adpli\u00adfied re\u00adsult.    \n So what is this un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients?  Well, the idea is this:  if you knew what each lin\u00adear\u00adly in\u00adde\u00adpen\u00addent term of the par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion was, mi\u00adnus the co\u00adef\u00adfi\u00adcients, then you could just set each co\u00adef\u00adfi\u00adcient as an un\u00adknown, plug it in\u00adto the ODE, and solve for them.  It turns out that re\u00adsult\u00ading sys\u00adtem of equa\u00adtions is lin\u00adear, so if you do the first part right, you can al\u00adways get a so\u00adlu\u00adtion.    \n The key thing here is that you know what form the par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion will take.  How\u00adev\u00ader, you don't re\u00adal\u00adly know this ahead of time.  All you have is the lin\u00adear ode $la\u00adtex a_ny{(n)}(x) + \\dots + a_1y'(x) + a_0y(x) = F(x)$ (as far as I can tel\u00adl, this on\u00adly works in the case where the co\u00adef\u00adfi\u00adcients $la\u00adtex a_i$ are con\u00adstant with re\u00adspect to x.  I'd be in\u00adter\u00adest\u00aded to learn that it works for oth\u00ader lin\u00adear ODEs.  At any rate, that is the on\u00adly one that works in my branch right now.).  The so\u00adlu\u00adtion to the ode is $la\u00adtex y(x) = y_g(x) + y_p(x)$, where $la\u00adtex y_g(x)$ is the so\u00adlu\u00adtion to the ho\u00admo\u00adge\u00adneous equa\u00adtion $la\u00adtex f(x) \\e\u00adquiv 0$, and $la\u00adtex y_p(x)$ is the par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion that pro\u00adduces the $la\u00adtex F(x)$ term on the right hand side.  The key here is just that.  If you plug $la\u00adtex y_p(x)$ in\u00adto the left hand side of the ode, you get $la\u00adtex F(x)$.    \n It turns out that this method on\u00adly works if the func\u00adtion $la\u00adtex F(x)$ on\u00adly has a fi\u00adnite num\u00adber of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent de\u00adriv\u00ada\u00adtives (I am un\u00adsure, but this might be able to work in oth\u00ader cas\u00ades, but it would in\u00advolve much more ad\u00advanced math\u00ade\u00admat\u00adic\u00ads).  So what kind of func\u00adtions have a fi\u00adnite num\u00adber of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent so\u00adlu\u00adtion\u00ads?  Ob\u00advi\u00adous\u00adly, poly\u00adno\u00admi\u00adals do.  So does $la\u00adtex ex$, $la\u00adtex \\cos{x}$, and $la\u00adtex \\s\u00adin{x}$.  Al\u00adso, if we mul\u00adti\u00adply two or more of these types to\u00adgeth\u00ader, then we will get a fi\u00adnite num\u00adber of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent so\u00adlu\u00adtions af\u00adter ap\u00adply\u00ading the prod\u00aduct rule.  But is that al\u00adl?  Well, if we take the def\u00adi\u00adni\u00adtion of lin\u00adear in\u00adde\u00adpen\u00addence from lin\u00adear al\u00adge\u00adbra, we know that a set of n vec\u00adtors $la\u00adtex {\\boldsym\u00adbol\u00ad{v_1}, \\boldsym\u00adbol\u00ad{v_2}, \\boldsym\u00adbol\u00ad{v_3}, \\dot\u00ads, \\boldsym\u00adbol\u00ad{v_n}}$, not all ze\u00adro, are lin\u00adear\u00adly in\u00adde\u00adpen\u00addent on\u00adly if $la\u00adtex a_1\\boldsym\u00adbol\u00ad{v_1} + a_2\\boldsym\u00adbol\u00ad{v_2} + a_3\\boldsym\u00adbol\u00ad{v_3} + \\dots + a_n\\boldsym\u00adbol\u00ad{v_n}=0$ holds on\u00adly when $la\u00adtex a_1 \\e\u00adquiv 0, a_2 \\e\u00adquiv 0, a_3 \\e\u00adquiv 0, \\dot\u00ads, a_n \\e\u00adquiv 0$, that is, the on\u00adly so\u00adlu\u00adtion is the triv\u00adial one (re\u00admem\u00adber, this is the  def\u00adi\u00adni\u00adtion  of lin\u00adear in\u00adde\u00adpen\u00addence).  They are lin\u00adear\u00adly de\u00adpen\u00addent if there ex\u00adist weights $la\u00adtex a_1, a_2, a_3, \\dot\u00ads, a_n$, not all 0, such that the equa\u00adtion $la\u00adtex a_1\\boldsym\u00adbol\u00ad{v_1} + a_2\\boldsym\u00adbol\u00ad{v_2} + a_3\\boldsym\u00adbol\u00ad{v_3} + \\dots + a_n\\boldsym\u00adbol\u00ad{v_n}=0$ is sat\u00adis\u00adfied.  Us\u00ading this def\u00adi\u00adni\u00adtion, we can see that a func\u00adtion $la\u00adtex f(x)$ will have a fi\u00adnite num\u00adber of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent de\u00adriv\u00ada\u00adtives if it sat\u00adis\u00adfies $la\u00adtex a_n\u00adf{(n)}(x) + a_{n - 1}f{(n - 1)}(x) + \\dots + a_1f'(x) + a_0f(x) = 0$ for some $la\u00adtex n$ and with $la\u00adtex a_i\\neq 0$ for some $la\u00adtex i$.  But this is just a  ho\u00admo\u00adge\u00adneous lin\u00adear ODE with con\u00adstant co\u00adef\u00adfi\u00adcients, which we know how to solve.    The so\u00adlu\u00adtions are all of the form $la\u00adtex axne{b x}\\\u00adcos{cx}$ or $la\u00adtex axne{b x}\\s\u00adin{cx}$, where a, b, and c are re\u00adal num\u00adbers and n is a non-neg\u00ada\u00adtive in\u00adte\u00adger.  We can set the var\u00adi\u00adous con\u00adstants to 0 to get the type we wan\u00adt.  For ex\u00adam\u00adple, for a poly\u00adno\u00admi\u00adal ter\u00adm, b will be 0 and c will be 0 (use the cos ter\u00adm). \n So this gives us the ex\u00adact form of func\u00adtions that we need to look for to ap\u00adply un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients, based on the as\u00adsump\u00adtion that it on\u00adly works on func\u00adtions with a fi\u00adnite num\u00adber of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent de\u00adriv\u00ada\u00adtives.    \n Well, im\u00adple\u00adment\u00ading it was quite dif\u00adfi\u00adcult.  For ev\u00adery ODE, the first step in im\u00adple\u00admen\u00adta\u00adtion is match\u00ading the ODE, so the solver can know what meth\u00adods it can ap\u00adply to a giv\u00aden ODE.  To match in this case, I had to write a func\u00adtion that de\u00adter\u00admined if the func\u00adtion matched the form giv\u00aden above, which was not too dif\u00adfi\u00adcult, though not as triv\u00adial as just grab\u00adbing the right hand side in vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads.  The next step is to use the match\u00ading to for\u00admat the ODE for the solver.  In this case, it means find\u00ading all of the fi\u00adnite lin\u00adear\u00adly in\u00adde\u00adpen\u00addent de\u00adriv\u00ada\u00adtives of the ODE, so that the solver can just cre\u00adate a lin\u00adear com\u00adbi\u00adna\u00adtion of them solve for the co\u00adef\u00adfi\u00adcients.  This was a lit\u00adtle more dif\u00adfi\u00adcult, and it took some lat\u00ader\u00adal think\u00ading.    \n At this point, there is one more thing that needs to be not\u00aded. Since the tri\u00adal func\u00adtion\u00ads, that is, the lin\u00adear\u00adly in\u00adde\u00adpen\u00addent de\u00adriv\u00ada\u00adtive terms of the right hand side of the ODE, are of the same form as the so\u00adlu\u00adtions to the ho\u00admo\u00adge\u00adneous equa\u00adtion, it is pos\u00adsi\u00adble that one of the tri\u00adal func\u00adtion terms will be a so\u00adlu\u00adtion to the ho\u00admo\u00adge\u00adneous equa\u00adtion.  If this hap\u00adpen\u00ads, plug\u00adging it in\u00adto the ODE will cause it to go to ze\u00adro, which means that we will not be able to solve for a co\u00adef\u00adfi\u00adcient for that ter\u00adm.  In\u00addeed, that term will be of the form $la\u00adtex C1*\\\u00adtex\u00adtr\u00adm{ter\u00adm}$ in the fi\u00adnal so\u00adlu\u00adtion, so even if we had a co\u00adef\u00adfi\u00adcient for it, it would be ab\u00adsorbed in\u00adto this term from the so\u00adlu\u00adtion to the ho\u00admo\u00adge\u00adneous equa\u00adtion.  For ex\u00adam\u00adple, vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters will give a co\u00adef\u00adfi\u00adcient for such terms, even though it is un\u00adnec\u00ades\u00adsary.  This is a clue that Maple us\u00ades vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters for all lin\u00adear con\u00adstant co\u00adef\u00adfi\u00adcient ODE solv\u00ading, be\u00adcause it gives the un\u00adnec\u00ades\u00adsary terms with the co\u00adef\u00adfi\u00adcients that would be giv\u00aden by vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads, in\u00adstead of ab\u00adsorb\u00ading them in\u00adto the ar\u00adbi\u00adtrary con\u00adstants.    \n We can safe\u00adly ig\u00adnore these terms for un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients, be\u00adcause their co\u00adef\u00adfi\u00adcients will not even ap\u00adpear in the sys\u00adtem of lin\u00adear equa\u00adtions of the co\u00adef\u00adfi\u00adcients any\u00adway.  But, with\u00adout these co\u00adef\u00adfi\u00adcients, we will run in\u00adto trou\u00adble.  It turns out that if a term $la\u00adtex xne{ax}\\s\u00adin{bx}$ or $la\u00adtex xne{ax}\\\u00adcos{bx}$ is re\u00adpeat\u00aded so\u00adlu\u00adtion to the ho\u00admo\u00adge\u00adneous equa\u00adtion, and $la\u00adtex x{n + 1}e{ax}\\s\u00adin{bx}$ or $la\u00adtex x{n + 1}e{ax}\\\u00adcos{bx}$ is not, so that $la\u00adtex n$ is the high\u00adest $la\u00adtex x$ pow\u00ader that makes it a so\u00adlu\u00adtion to the ho\u00admo\u00adge\u00adneous equa\u00adtion, and if the tri\u00adal so\u00adlu\u00adtion has $la\u00adtex xme{ax}\\s\u00adin{bx}$ or $la\u00adtex xme{ax}\\\u00adcos{bx}$ terms, but not $la\u00adtex x{m + 1}e{ax}\\s\u00adin{bx}$ or $la\u00adtex x{m + 1}e{ax}\\\u00adcos{bx}$ terms, so that $la\u00adtex m$ is the high\u00adest pow\u00ader of $la\u00adtex x$ in the the tri\u00adal func\u00adtion terms, then we need to mul\u00adti\u00adply these tri\u00adal func\u00adtion terms by $la\u00adtex x{n + m}$ to make them lin\u00adear\u00adly in\u00adde\u00adpen\u00addent with the so\u00adlu\u00adtions of the ho\u00admo\u00adge\u00adneous equa\u00adtion.    \n Most  ref\u00ader\u00adences  sim\u00adply say that you need to mul\u00adti\u00adply the tri\u00adal func\u00adtion terms by \"suf\u00adfi\u00adcient pow\u00aders of x\" to make them lin\u00adear\u00adly in\u00adde\u00adpen\u00addent with the ho\u00admo\u00adge\u00adneous so\u00adlu\u00adtion.  Well, this is just fine if you are do\u00ading it by hand or you are cre\u00adat\u00ading the tri\u00adal func\u00adtion man\u00adu\u00adal\u00adly in Maple and plug\u00adging it in and solv\u00ading for the co\u00adef\u00adfi\u00adcients.  You can just keep up\u00adping the pow\u00aders of x un\u00adtil you get a so\u00adlu\u00adtion for the co\u00adef\u00adfi\u00adcients.  Cre\u00adat\u00ading those tri\u00adal func\u00adtions in Maple, plug\u00adging them in\u00adto the ODE, and solv\u00ading for the co\u00adef\u00adfi\u00adcients is ex\u00adact\u00adly what I had to do for my home\u00adwork when I took ODEs last spring, and this \"up\u00adping pow\u00ader\u00ads\" tri\u00adal and er\u00adror method is ex\u00adact\u00adly the method I used.  But when you are do\u00ading it in SymPy, you need to know ex\u00adact\u00adly what pow\u00ader to mul\u00adti\u00adply it by.  If it is too low, you will not get so\u00adlu\u00adtion to the co\u00adef\u00adfi\u00adcients.  If it is too high, you can ac\u00adtu\u00adal\u00adly end up with too many terms in the fi\u00adnal so\u00adlu\u00adtion, giv\u00ading a wrong an\u00adswer.    \n For\u00adtu\u00adnate\u00adly, my ex\u00adcel\u00adlent  ODEs text\u00adbook  gives the ex\u00adact cas\u00ades to fol\u00adlow, and so I was able to im\u00adple\u00adment it cor\u00adrect\u00adly.  The text\u00adbook al\u00adso gives a whole slew of ex\u00ader\u00adcis\u00ades, all for which the so\u00adlu\u00adtions are giv\u00aden.  As usu\u00adal, this helped me to find the bugs in my very com\u00adplex and dif\u00adfi\u00adcult to write rou\u00adtine.  It al\u00adso helped me to find a  match bug  that would have pre\u00advent\u00aded  dsolve()  from be\u00ading able to match cer\u00adtain types of ODEs.  The bug turned out to be fun\u00adda\u00admen\u00adtal to the way  match()  is writ\u00adten, so I had to write my own cus\u00adtom match\u00ading func\u00adtion for lin\u00adear ODEs.    \n The fi\u00adnal step in solv\u00ading the un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients is of course just cre\u00adat\u00ading a lin\u00adear com\u00adbi\u00adna\u00adtion of the tri\u00adal func\u00adtion terms, plug\u00adging it in\u00adto the orig\u00adi\u00adnal ODE, and set\u00adting the co\u00adef\u00adfi\u00adcients of each term on each side equal to each oth\u00ader, which gives a lin\u00adear sys\u00adtem. SymPy can solve these eas\u00adi\u00adly, and once you have the val\u00adues of the co\u00adef\u00adfi\u00adcients, you can use them to build your par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion, at which point, you are done.    \n The re\u00adsults were as\u00adtound\u00ading.  Vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters would hang on many sim\u00adple in\u00adho\u00admo\u00adge\u00adneous ODEs be\u00adcause of poor trig sim\u00adpli\u00adfi\u00adca\u00adtion of the Wron\u00adsikan, but my un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients method han\u00addles them per\u00adfect\u00adly.  Al\u00adso, there is no need to wor\u00adry about ab\u00adsorb\u00ading su\u00adper\u00adflu\u00adous terms in\u00adto the ar\u00adbi\u00adtrary con\u00adstants as with vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads, be\u00adcause they are re\u00admoved from with\u00adin the un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients al\u00adgo\u00adrith\u00adm. \n But the big\u00adgest thing was speed.  Here are some bench\u00admarks on some ran\u00addom ODEs from the test suit\u00ade. Word\u00adPress code blocks are im\u00adper\u00advi\u00adous to whites\u00adpace, as I have men\u00adtioned be\u00adfore, so no pret\u00adty print\u00ading here.  Al\u00adso, it trun\u00adcates the hints.  The hints used are  'n\u00adth_\u00adlin\u00adear_\u00adcon\u00adstan\u00adt_\u00adco\u00adef\u00adf_un\u00adde\u00adter\u00admined_\u00adco\u00adef\u00adfi\u00adcients'  and  'n\u00adth_\u00adlin\u00adear_\u00adcon\u00adstan\u00adt_\u00adco\u00adef\u00adf_\u00advari\u00ada\u00adtion_of_\u00adpa\u00adram\u00ade\u00adter\u00ads': \n  \n \n\nIn [1]: time dsolve(f(x).diff(x, 2) - 3*f(x).diff(x) - 2*exp(2*x)*sin(x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')\n\nCPU times: user 0.07 s, sys: 0.00 s, total: 0.08 s\n\nWall time: 0.08 s\n\nOut[2]: \n\nf(x) == C1 + (-3*sin(x)/5 - cos(x)/5)*exp(2*x) + C2*exp(3*x)\n\n\n\nIn [3]: time dsolve(f(x).diff(x, 2) - 3*f(x).diff(x) - 2*exp(2*x)*sin(x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')\n\nCPU times: user 0.92 s, sys: 0.01 s, total: 0.93 s\n\nWall time: 0.94 s\n\nOut[4]: \n\nf(x) == C1 + (-3*sin(x)/5 - cos(x)/5)*exp(2*x) + C2*exp(3*x)\n\n\n\nIn [5]: time dsolve(f(x).diff(x, 4) - 2*f(x).diff(x, 2) + f(x) - x + sin(x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')\n\nCPU times: user 0.06 s, sys: 0.00 s, total: 0.06 s\n\nWall time: 0.06 s\n\nOut[6]: \n\nf(x) == x - sin(x)/4 + (C1 + C2*x)*exp(x) + (C3 + C4*x)*exp(-x)\n\n\n\nIn [7]: time dsolve(f(x).diff(x, 4) - 2*f(x).diff(x, 2) + f(x) - x + sin(x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')\n\nCPU times: user 5.43 s, sys: 0.03 s, total: 5.46 s\n\nWall time: 5.52 s\n\nOut[8]: \n\nf(x) == x - sin(x)/4 + (C1 + C2*x)*exp(x) + (C3 + C4*x)*exp(-x)\n\n\n\nIn [9]: time dsolve(f(x).diff(x, 5) + 2*f(x).diff(x, 3) + f(x).diff(x) - 2*x - sin(x) - cos(x), f(x), 'nth_linear_constant_coeff_undetermined_coefficients')\n\nCPU times: user 0.10 s, sys: 0.00 s, total: 0.10 s\n\nWall time: 0.11 s\n\nOut[10]: \n\nf(x) == C1 + (C2 + C3*x - x**2/8)*sin(x) + (C4 + C5*x + x**2/8)*cos(x) + x**2\n\n\n\nIn [11]: time dsolve(f(x).diff(x, 5) + 2*f(x).diff(x, 3) + f(x).diff(x) - 2*x - sin(x) - cos(x), f(x), 'nth_linear_constant_coeff_variation_of_parameters')\n\n\n\n\n\n \n The last one in\u00advolves a par\u00adtic\u00adu\u00adlar\u00adly dif\u00adfi\u00adcult Wron\u00adskian for SymPy (run it with hin\u00adt='n\u00adth_\u00adlin\u00adear_\u00adcon\u00adstan\u00adt_\u00adco\u00adef\u00adf_\u00advari\u00ada\u00adtion_of_\u00adpa\u00adram\u00ade\u00adter\u00ads_In\u00adte\u00adgral', sim\u00adpli\u00adfy=\u00adFalse). \n Wall time com\u00adpar\u00adisons re\u00adveal amaz\u00ading speed dif\u00adfer\u00adences.  We're talk\u00ading or\u00adders of mag\u00adni\u00adtude. \n  \n \n\nIn [13]: 0.94/0.08\n\nOut[13]: 11.75\n\n\n\nIn [14]: 5.52/0.06\n\nOut[14]: 92.0\n\n\n\nIn [15]: oo/0.11\n\nOut[15]: +inf\n\n\n\n \n Of course, vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters has the most dif\u00adfi\u00adcult time when there are sin and cos terms in\u00advolved, be\u00adcause of the poor trig sim\u00adpli\u00adfi\u00adca\u00adtion in SymPy.  So let's see what hap\u00adpens with an ODE that just has ex\u00adpo\u00adnen\u00adtials and poly\u00adno\u00admi\u00adal terms in\u00advolved. \n  \n \n\nIn [16]: time dsolve(f(x).diff(x, 2) + f(x).diff(x) - x**2 - 2*x, f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')\n\nCPU times: user 0.10 s, sys: 0.00 s, total: 0.10 s\n\nWall time: 0.10 s\n\nOut[17]: \n\nf(x) == C1 + x**3/3 + C2*exp(-x)\n\n\n\nIn [18]: time dsolve(f(x).diff(x, 2) + f(x).diff(x) - x**2 - 2*x, f(x), hint='nth_linear_constant_coeff_variation_of_parameters')\n\nCPU times: user 0.19 s, sys: 0.00 s, total: 0.19 s\n\nWall time: 0.20 s\n\nOut[19]: \n\nf(x) == C1 + x**3/3 + C2*exp(-x)\n\n\n\nIn [20]: time dsolve(f(x).diff(x, 3) + 3*f(x).diff(x, 2) + 3*f(x).diff(x) + f(x) - 2*exp(-x) + x**2*exp(-x), f(x), hint='nth_linear_constant_coeff_undetermined_coefficients')\n\nCPU times: user 0.09 s, sys: 0.00 s, total: 0.09 s\n\nWall time: 0.09 s\n\nOut[21]: \n\nf(x) == (C1 + C2*x + C3*x**2 + x**3/3 - x**5/60)*exp(-x)\n\n\n\nIn [22]: time dsolve(f(x).diff(x, 3) + 3*f(x).diff(x, 2) + 3*f(x).diff(x) + f(x) - 2*exp(-x) + x**2*exp(-x), f(x), hint='nth_linear_constant_coeff_variation_of_parameters')\n\nCPU times: user 0.29 s, sys: 0.00 s, total: 0.29 s\n\nWall time: 0.29 s\n\nOut[23]: \n\nf(x) == (C1 + C2*x + C3*x**2 + x**3/3 - x**5/60)*exp(-x)\n\n\n\n\n\n \n The wall time com\u00adpar\u00adisons here are: \n  \n \n\nIn [24]: 0.20/0.10\n\nOut[24]: 2.0\n\n\n\nIn [25]: 0.29/0.09\n\nOut[25]: 3.22222222222\n\n\n\n \n So we don't have or\u00adders of mag\u00adni\u00adtude any\u00admore, but it is still 2 to 3 times faster.  Of course, most ODEs of this form  will  have sin or cos terms in them, so the or\u00adder of mag\u00adni\u00adtude im\u00adprove\u00adment over vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters can prob\u00ada\u00adbly be at\u00adtrib\u00aduted to un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients in gen\u00ader\u00adal.    \n Of course, we know that vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters will still be use\u00adful, be\u00adcause func\u00adtions like $la\u00adtex \\l\u00adn{x}$, $la\u00adtex \\sec{x}$ and $la\u00adtex \\frac{1}{x}$ do not have a fi\u00adnite num\u00adber of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent deriva\u00adtives, and so you can\u00adnot ap\u00adply the method of un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients to them.    \n There is one last thing I want to men\u00adtion.  You can in\u00addeed mul\u00adti\u00adply any poly\u00adno\u00admi\u00adal, ex\u00adpo\u00adnen\u00adtial, sin, or cos func\u00adtions to\u00adgeth\u00ader and still get a func\u00adtion that has a fi\u00adnite num\u00adber of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent so\u00adlu\u00adtion\u00ads, but if you mul\u00adti\u00adply two or more of the trig func\u00adtion\u00ads, you have to ap\u00adply the  pow\u00ader re\u00adduc\u00adtion rules  to the re\u00adsult\u00ading func\u00adtion to get it in terms of sin and cos alone.  Un\u00adfor\u00adtu\u00adnate\u00adly, SymPy does not yet have a  func\u00adtion  that can do this, so to solve such a dif\u00adfer\u00aden\u00adtial equa\u00adtion with un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients (rec\u00adom\u00admend\u00aded, see above), you will have to ap\u00adply them man\u00adu\u00adal\u00adly your\u00adself.  Al\u00adso, just for the record, it does\u00adn't play well with ex\u00adpo\u00adnen\u00adtials in the form of sin's and cos's or the oth\u00ader way around (com\u00adplex co\u00adef\u00adfi\u00adcients on the ar\u00adgu\u00adments), so you should back con\u00advert those first too.    \n Well, this con\u00adcludes the first of two blog posts that I promised.  I al\u00adso promised that I would write about my sum\u00admer of code ex\u00adpe\u00adri\u00adences.  Not on\u00adly is this im\u00adpor\u00adtant to me, but it is a  re\u00adquire\u00adment.  I re\u00adal\u00adly  hope  to get this done soon, but with class\u00ades, who knows.", 
      "loc": "/posts/2009/08/17/undetermined-coefficients/"
    }, 
    {
      "title": "Los Alamos \"Sprint\"", 
      "tags": "", 
      "text": "Last week\u00adend, Luke came to vis\u00adit On\u00addrej in Los Alam\u00ados, so I de\u00adcid\u00aded to drive him up from Al\u00adbu\u00adquerque and vis\u00adit him again.  It was nice meet\u00ading Luke and see\u00ading On\u00addrej again.    \n Aside from cod\u00ading (the main thing that I did was fix an ug\u00adly match bug that was pre\u00advent\u00ading dsolve() from rec\u00adog\u00adniz\u00ading cer\u00adtain ODEs), we vis\u00adit\u00aded the atom\u00adic mu\u00adse\u00adum in Los Alam\u00ados, the  Valles Caldera, and some of the sur\u00adround\u00ading hot springs.    \n Here are some pic\u00adtures that Luke took with his iPhone.  Stupid Word\u00adPress seems to in\u00adsist on flip\u00adping some of them (I can't fix it): \n [gallery] \n This is one of three posts that I plan on do\u00ading this week.  I just fin\u00adished my GSoC project to\u00adday/last night, so I will be blog\u00adging about that.  I plan on do\u00ading a post on the method of Un\u00adde\u00adter\u00admined Co\u00adef\u00adfi\u00adcients, as well as some oth\u00ader things that I man\u00adaged to do.  The oth\u00ader post will be my gen\u00ader\u00adal mus\u00adings/ad\u00advice for GSoC. That will prob\u00ada\u00adbly be my last post here in a while.  I plan on con\u00adtin\u00adu\u00ading work with SymPy, but I get very busy with class\u00ades, so I most like\u00adly won't be do\u00ading much un\u00adtil next sum\u00admer.", 
      "loc": "/posts/2009/08/17/los-alamos-sprint/"
    }, 
    {
      "title": "Testing implicit solutions to ODEs", 
      "tags": "mathjax", 
      "text": "So, the hard dead\u00adline for GSoC it Mon\u00adday, so this will prob\u00ada\u00adbly be my last post un\u00adtil then (I am very busy try\u00ading to fin\u00adish up the ode mod\u00adule by then).  But this is one of those things that you just have to blog about. \n So I have this check\u00adsol func\u00adtion in test_ode.py that at\u00adtempts to check it the so\u00adlu\u00adtions to odes are valid or not.  It was a rel\u00adic of the old ode mod\u00adule.  For that, it would just sub\u00adsti\u00adtute the so\u00adlu\u00adtion in\u00adto the ode and see if it sim\u00adpli\u00adfied to 0.  That is what it still does, if the so\u00adlu\u00adtion is solved for f(x) (the func\u00adtion for all of my ode test\u00ads).  But if the so\u00adlu\u00adtion is im\u00adplic\u00adit in f, ei\u00adther be\u00adcause solve() is not good enough to solve it or be\u00adcause it can\u00adnot be solved, then that method ob\u00advi\u00adous\u00adly does not work.  So what I was try\u00ading to do is what my text\u00adbook sug\u00adgest\u00aded.  Take the de\u00adriv\u00ada\u00adtive of the so\u00adlu\u00adtion im\u00adplic\u00adit\u00adly n times, where n is the or\u00adder of the ode, and see if that is equal to the ode.  Ba\u00adsi\u00adcal\u00adly, I was sub\u00adtract\u00ading the ode from it and see\u00ading if it re\u00adduced to 0. \n How\u00adev\u00ader, it was\u00adn't re\u00adal\u00adly work\u00ading at all for most of my im\u00adplic\u00adit so\u00adlu\u00adtion\u00ads, even the re\u00adal\u00adly sim\u00adple ones.  I end\u00aded up XFAIL\u00ading most of my im\u00adplic\u00adit check\u00adsol test\u00ads.  I think ev\u00adery sin\u00adgle  ho\u00admo\u00adge\u00adneous co\u00adef\u00adfi\u00adcients  had an im\u00adplic\u00adit so\u00adlu\u00adtion, and none of them were work\u00ading with check\u00adsol().    \n So I start\u00aded to ask around on IRC to see if any\u00adone had any bet\u00adter ideas for test\u00ading these.  On\u00addrej could\u00adn't think of any\u00adthing.  Luke and Chris worked on an ex\u00adam\u00adple that I gave them, and it seemed to be that it  was\u00adn't  cor\u00adrect (which I did\u00adn't be\u00adlieve for a sec\u00adond, be\u00adcause the so\u00adlu\u00adtion was straight out of my tex\u00adt, and both ho\u00admo\u00adge\u00adneous co\u00adef\u00adfi\u00adcients in\u00adte\u00adgrals pro\u00adduced that same so\u00adlu\u00adtion).  It turns out that we were mix\u00ading up $la\u00adtex \\log{\\frac{y}{x}}$ and $la\u00adtex \\log{\\frac{x}{y}}$ terms.  One of those ap\u00adpeared in the ode and the oth\u00ader ap\u00adpeared in the so\u00adlu\u00adtion (the ode was $la\u00adtex y dx  + x\\log{\\frac{y}{x}}dy - 2x dy = 0$ and the so\u00adlu\u00adtion is $la\u00adtex \\frac{y}{1 + \\log{\\frac{x}{y}}}=C$,  num\u00adber 9 from my odes tex\u00adt, pg. 61.    \n So Chris had a nov\u00adel idea.  For 1st or\u00adder odes, you can take the de\u00adriv\u00ada\u00adtive of the so\u00adlu\u00adtion and solve for $la\u00adtex \\frac{dy}{dx}$, which will al\u00adways be pos\u00adsi\u00adble, be\u00adcause dif\u00adfer\u00aden\u00adti\u00ada\u00adtion is a lin\u00adear op\u00ader\u00ada\u00adtor.  Then sub\u00adsti\u00adtute that in\u00adto the orig\u00adi\u00adnal ode, and it will re\u00adduce.    \n So we were talk\u00ading about this on IRC lat\u00ader, and I had an epiphany as to why my orig\u00adi\u00adnal method was\u00adn't work\u00ading.  Af\u00adter try\u00ading it man\u00adu\u00adal\u00adly on an ode, I found that I had to mul\u00adti\u00adply through the so\u00adlu\u00adtion's de\u00adriv\u00ada\u00adtive by $la\u00adtex \\frac{x}{f(x)}$ to make it equal to the ode.  Then, that re\u00admind\u00aded me of an im\u00adpor\u00adtant so\u00adlu\u00adtion method that I did\u00adn't have time to im\u00adple\u00adment this sum\u00admer: in\u00adte\u00adgrat\u00ading fac\u00adtors.  I re\u00admem\u00adber that my text\u00adbook had  men\u00adtioned  that there is a the\u00ado\u00adrem that states that ev\u00adery 1st or\u00adder ODE that is lin\u00adear in the de\u00adriv\u00ada\u00adtive has a unique in\u00adte\u00adgrat\u00ading fac\u00adtor that makes it ex\u00adac\u00adt.  And I re\u00adal\u00adized, the de\u00adriv\u00ada\u00adtive of the so\u00adlu\u00adtion will be equal to the ODE if and on\u00adly if the ODE is ex\u00adac\u00adt.  I checked my ex\u00adact tests and ver\u00adi\u00adfied my hunch.  I had to XFAIL all of my im\u00adplic\u00adit ho\u00admo\u00adge\u00adneous co\u00adef\u00adfi\u00adcients so\u00adlu\u00adtion\u00ads, but all of my ex\u00adact check\u00adsols were work\u00ading just fine.    \n So I refac\u00adtored my check\u00adsol func\u00adtion to do this, and it now can check al\u00admost ev\u00adery one of my fail\u00ading check\u00adsol\u00ads.  The ex\u00adcep\u00adtions are some where trigsim\u00adp() can\u00adnot sim\u00adpli\u00adfy the so\u00adlu\u00adtion to 0 (we have a poor trigsim\u00adp), a sec\u00adond or\u00adder so\u00adlu\u00adtion (the above trick on\u00adly works on 1st or\u00adder odes, I be\u00adlieve), and some oth\u00ader sim\u00adpli\u00adfi\u00adca\u00adtion prob\u00adlem\u00ads.   \n The on\u00adly down side to this new rou\u00adtine is that it is kind of slow (be\u00adcause of the sim\u00adpli\u00adfi\u00adca\u00adtion).  I am go\u00ading to have to skip a test of on\u00adly 6 so\u00adlu\u00adtions be\u00adcause it takes 24 sec\u00adonds to com\u00adplete.", 
      "loc": "/posts/2009/08/12/testing-implicit-solutions-to-odes/"
    }, 
    {
      "title": "Homogeneous coefficients corner case", 
      "tags": "mathjax", 
      "text": "Be\u00adfore I start\u00aded the pro\u00adgram, I im\u00adple\u00adment\u00aded Bernoul\u00adli equa\u00adtion\u00ads.  But the gen\u00ader\u00adal so\u00adlu\u00adtion to Bernoul\u00adli equa\u00adtions in\u00advolves rais\u00ading some\u00adthing to the pow\u00ader of $la\u00adtex \\frac{1}{1-n}$, where n is the pow\u00ader of the de\u00adpen\u00addent term (see the  Wikipedia page  for more in\u00adfo).  This works great, as I soon dis\u00adcov\u00adered, un\u00adless n == 1.  Then you get some\u00adthing to the pow\u00ader of $la\u00adtex \\in\u00adfty$.  So I had to go in and re\u00admove the cor\u00adner case. \n So you think that af\u00adter that I would have been more care\u00adful af\u00adter that about check\u00ading that if gen\u00ader\u00adal so\u00adlu\u00adtion that di\u00advides by some\u00adthing I would test to see if that some\u00adthing is not ze\u00adro be\u00adfore re\u00adturn\u00ading it as a so\u00adlu\u00adtion. \n Well, as I was just try\u00ading to im\u00adple\u00adment some sep\u00ada\u00adra\u00adble equa\u00adtion test\u00ads, I was go\u00ading through the ex\u00ader\u00adcis\u00ades of my ode text as I usu\u00adal\u00adly do for test\u00ads, and I came across $la\u00adtex xy' - y = 0$.  If you re\u00adcal\u00adl, this equa\u00adtion al\u00adso has co\u00adef\u00adfi\u00adcients that ho\u00admo\u00adge\u00adneous of the same or\u00adder (1). From the gen\u00ader\u00adal so\u00adlu\u00adtion to ho\u00admo\u00adge\u00adneous co\u00adef\u00adfi\u00adcients, you would plug it in\u00adto $la\u00adtex \\in\u00adt{\\frac{dx}{x}}=\\in\u00adt{\\frac{-Q(1,u)\u00addu}{P(1,u)+uQ(1,u)}}+C$ where $la\u00adtex u = \\frac{y}{x}$ or $la\u00adtex \\in\u00adt{\\frac{dy}{y}}=\\in\u00adt{\\frac{-P(u,1)\u00addu}{uP(u,1)+Q(u,1)}}+C$ where $la\u00adtex u = \\frac{x}{y}$ (here, P and Q are from the gen\u00ader\u00adal form $la\u00adtex P(x,y)dx+Q(x,y)dy=0$).  Well, it turns out that if you plug the co\u00adef\u00adfi\u00adcients from my ex\u00adam\u00adple in\u00adto those equa\u00adtion\u00ads, the de\u00adnom\u00adi\u00adna\u00adtor will be\u00adcome 0 for each one.  So I (ob\u00advi\u00adous\u00adly) need to check for that $la\u00adtex P(1,u)+uQ(1,u)$ and  $la\u00adtex uP\u00ad(u,1)+Q(u,1)$ are not 0 be\u00adfore run\u00adning the ho\u00admo\u00adge\u00adneous co\u00adef\u00adfi\u00adcients solver on a dif\u00adfer\u00aden\u00adtial equa\u00adtion.", 
      "loc": "/posts/2009/08/10/homogeneous-coefficients-corner-case/"
    }, 
    {
      "title": "Variation of Parameters and More", 
      "tags": "mathjax", 
      "text": "Well, the last time I post\u00aded a project up\u00addate, I had re\u00adsigned my\u00adself to writ\u00ading a con\u00adstant sim\u00adpli\u00adfy\u00ading func\u00adtion and putting the Con\u00adstant class on the shelf.  Well, just as I sus\u00adpect\u00aded, it was hell writ\u00ading it, but I even\u00adtu\u00adal\u00adly got it work\u00ading.  Al\u00adready, what I have in dsolve() ben\u00ade\u00adfits from it.  I had many so\u00adlu\u00adtions with things like $la\u00adtex \\frac{x}{C_1}$ or $la\u00adtex -C_1x$ in them, and they are now au\u00adto\u00admat\u00adi\u00adcal\u00adly re\u00adduced to just $la\u00adtex C_1x$.  Of course, the dis\u00adad\u00advan\u00adtage to this, as I men\u00adtioned in the oth\u00ader post, is that it will on\u00adly sim\u00adpli\u00adfy once.  Al\u00adso, I wrote the func\u00adtion very specif\u00adi\u00adcal\u00adly for ex\u00adpres\u00adsions re\u00adturned by dsolve.  It on\u00adly work\u00ads, for ex\u00adam\u00adple, with con\u00adstants named se\u00adquen\u00adtial\u00adly like C1, C2, C3 and so on.  Even with mak\u00ading it spe\u00adcial\u00adized, it was still hell to write.  I was al\u00adso able to get it to renum\u00adber the con\u00adstants, so some\u00adthing like  C2sin(x) + C1cos(x)  would get trans\u00adfered to  C1sin(x) + C2cos(x).  It us\u00ades  Ba\u00adsic._\u00adcom\u00adpare_pret\u00adty()  (thanks to Andy for that tip), so it will al\u00adways num\u00adber the con\u00adstants in the or\u00adder they are print\u00aded.    \n Once I got that work\u00ading, it was just lit\u00adtle work to fin\u00adish up what I had al\u00adready start\u00aded with solv\u00ading gen\u00ader\u00adal lin\u00adear ho\u00admo\u00adge\u00adneous odes ($la\u00adtex a_ny{(n)} + a_{n-1}y{(n-1)} + \\dots + a_2y'' + a_1y' + a_0y = 0$ with $la\u00adtex a_i$ con\u00adstant for all $la\u00adtex i$).  Solv\u00ading these equa\u00adtions is easy.  You just set up a poly\u00adno\u00admi\u00adal of the form $la\u00adtex a_n\u00admn + a_{n-1}m{n-1} + \\c\u00addots + a_2m2 + a_1m + a_0 = 0$ and find the roots of it.  Then you plug the roots in\u00adto an ex\u00adpo\u00adnen\u00adtial times $la\u00adtex xi$ for i from 1 to the mul\u00adti\u00adplic\u00adi\u00adty of the root  (as in $la\u00adtex Cxie{\u00adroot \\c\u00addot x}$).  You usu\u00adal\u00adly ex\u00adpand the re\u00adal and com\u00adplex parts of the root us\u00ading Eu\u00adler's For\u00admu\u00adla, and, once you sim\u00adpli\u00adfy the con\u00adstants, you get some\u00adthing like $la\u00adtex xie{re\u00adal\u00adpart \\c\u00addot x}(C_1\\s\u00adin{(im\u00adpart \\c\u00addot x)} + C_2\\\u00adcos{(im\u00adpart \\c\u00addot x)})$ for each i from 1 to the mul\u00adti\u00adplic\u00adi\u00adty of the root.  Any\u00adway, with the new con\u00adstantsim\u00adp() rou\u00adtine, I was able to set this whole thing up as one step, be\u00adcause if the imag\u00adi\u00adnary part is 0, then the two con\u00adstants will be sim\u00adpli\u00adfied in\u00adto each oth\u00ader.  Al\u00adso, SymPy has some good poly\u00adno\u00admi\u00adal solv\u00ading, so I did\u00adn't have any prob\u00adlems there.  I even made good use of the col\u00adlec\u00adt() func\u00adtion to fac\u00adtor out com\u00admon terms, so you get some\u00adthing like $la\u00adtex (C_1 + C_2x)e{x}$ in\u00adstead of $la\u00adtex C_1e{x} + C_2x\u00ade{x}$, which for larg\u00ader or\u00adder so\u00adlu\u00adtion\u00ads, can make the so\u00adlu\u00adtion much eas\u00adi\u00ader to read (com\u00adpare for ex\u00adam\u00adple, $la\u00adtex ((C_1 + C_2x)\\s\u00adin{x} + (C_3 + C_4x)\\\u00adcos{x})e{x}$ with the ex\u00adpand\u00aded for\u00adm, $la\u00adtex C_1e{x}\\s\u00adin{x} + C_2x\u00ade{x}\\s\u00adin{x} + C_3\\\u00adcos{x}e{x} + C_4x\\\u00adcos{x}{ex}$ as the so\u00adlu\u00adtion to $la\u00adtex {\\frac {d{4}}{d{x}{4}}}f \\left( x \\right) -4\\,{\\frac {d{3}}{d{x}{3}}}f \\left( x \\right) +8\\,{\\frac {d{2}}{d{x}{2}}}f \\left( x \\right) -8\\,{\\frac {d}{dx}}f \\left( x \\right) +4\\,f \\left( x \\right) =0$).    \n I en\u00adtered all 30 ex\u00adam\u00adples from the rel\u00ade\u00advant chap\u00adter of my text (Or\u00addi\u00adnary Dif\u00adfer\u00aden\u00adtial Equa\u00adtions by Mor\u00adris Tenen\u00adbaum and Har\u00adry Pol\u00adlard), and the whole thing runs in un\u00adder 2 sec\u00adonds on my ma\u00adchine.  So it is fast, though that is most\u00adly due to fast poly\u00adno\u00admi\u00adal solv\u00ading in SymPy.    \n So once I got that work\u00ading well, I start\u00aded im\u00adple\u00adment\u00ading vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads, which is a gen\u00ader\u00adal method for solv\u00ading all equa\u00adtions of form $la\u00adtex a_ny{(n)} + a_{n-1}y{(n-1)} + \\dots + a_2y'' + a_1y' + a_0y = F(x)$.  The method will set up an in\u00adte\u00adgral to rep\u00adre\u00adsent the par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion to any equa\u00adtion of this for\u00adm, as\u00adsum\u00ading that you have all $la\u00adtex n$ lin\u00adear\u00adly in\u00adde\u00adpen\u00addent so\u00adlu\u00adtions to the ho\u00admo\u00adge\u00adneous equa\u00adtion $la\u00adtex a_ny{(n)} + a_{n-1}y{(n-1)} + \\dots + a_2y'' + a_1y' + a_0y = 0$.  The co\u00adef\u00adfi\u00adcients $la\u00adtex a_i$ do not even have to be con\u00adstant for this method to work, al\u00adthough they do have to be in my im\u00adplan\u00adta\u00adtion be\u00adcause oth\u00ader\u00adwise it will not be able to find gen\u00ader\u00adal so\u00adlu\u00adtion to the ho\u00admo\u00adge\u00adneous equa\u00adtion.    \n So, aside from do\u00ading my GSoC project this sum\u00admer, I am al\u00adso learn\u00ading Lin\u00adear Al\u00adge\u00adbra, be\u00adcause I could not fit it in to my sched\u00adule next se\u00admes\u00adter and I need to know it for my Knot The\u00ado\u00adry class.  It turns out that it was very use\u00adful in learn\u00ading the method of vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads.  I will ex\u00adplain how the method works be\u00adlow, but first I have a lit\u00adtle rant.    \n Why is the Wikipedia ar\u00adti\u00adcle on  vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters  the on\u00adly web\u00adsite any\u00adwhere that cov\u00aders vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters in the gen\u00ader\u00adal case?  Ev\u00adery oth\u00ader site that I could find on\u00adly cov\u00aders 2nd or\u00adder equa\u00adtion\u00ads, which I un\u00adder\u00adstand is what is taught in most cour\u00adses be\u00adcause ap\u00adply\u00ading it to any\u00adthing high\u00ader can be te\u00addious and de\u00adriv\u00ading the nth or\u00adder case re\u00adquires knowl\u00adedge of Cramer's Rule, which many stu\u00addents may not know.  But you would think that there would at least be sites that dis\u00adcuss what I am about to dis\u00adcuss be\u00adlow, name\u00adly, ap\u00adply\u00ading it to the gen\u00ader\u00adal case of an nth or\u00adder in\u00adho\u00admo\u00adge\u00adneous lin\u00adear ode.  Even the  Wolphram Math\u00adWorld ar\u00adti\u00adcle  on\u00adly ex\u00adplains the deriva\u00adtion for a sec\u00adond or\u00adder lin\u00adear ODE, men\u00adtion\u00ading at the bot\u00adtom that it can be ap\u00adplied to nth or\u00adder lin\u00adear ODEs.  I did find a web\u00adsite called  Plan\u00adet Math  that cov\u00aders the gen\u00ader\u00adal case, but it was\u00adn't on the top of the Google re\u00adsults list and took some dig\u00adging to find.  It al\u00adso has prob\u00adlems of its own, like be\u00ading on a very slow serv\u00ader and some of the La\u00adTeX on the page not ren\u00adder\u00ading among them.   \n This par\u00adtial\u00adly an\u00adnoys me be\u00adcause the Wikipedia ar\u00adti\u00adcle is not very well writ\u00adten.  You have to read through it sev\u00ader\u00adal times to un\u00adder\u00adstand the deriva\u00adtion (I will try to be bet\u00adter be\u00adlow).  The Plan\u00adet Math site is a lit\u00adtle bet\u00adter, but like I said, it took some dig\u00adging to find, and I ac\u00adtu\u00adal\u00adly found it af\u00adter I had writ\u00adten up half of this post al\u00adready.    \n But it is al\u00adso part of a larg\u00ader at\u00adti\u00adtude that I am find\u00ading more and more of where any\u00adthing that is not like\u00adly to be di\u00adrect\u00adly ap\u00adplied is not worth know\u00ading and thus not worth teach\u00ading.  Sure, it is not like\u00adly that any per\u00adson do\u00ading hand cal\u00adcu\u00adla\u00adtions will ev\u00ader at\u00adtempt vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters on an ode of or\u00adder high\u00ader than 2 or 3, but that is what com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtems like SymPy are for.  Un\u00adfor\u00adtu\u00adnate\u00adly, it seems that they are al\u00adso in a large part for al\u00adlow\u00ading you to not know how or why some\u00adthing math\u00ade\u00admat\u00adi\u00adcal\u00adly is true.  What dif\u00adfer\u00adence does it make if vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters can be ap\u00adplied to a 5th or\u00adder ODE if I have to use Maple to do ac\u00adtu\u00adal\u00adly do it any\u00adway.  As long as the mak\u00aders of Maple know how to ap\u00adply vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters to a nth or\u00adder ODE, I can get along just fine.  At least with SymPy, the source is freely avail\u00adable, so any\u00adone who does de\u00adsire to know how things are work\u00ading can eas\u00adi\u00adly see.  Any\u00adway, I am done rant\u00ading now, so if you were skip\u00adping that part, this would be the point to start read\u00ading again. \n So you have your lin\u00adear in\u00adho\u00admo\u00adge\u00adneous ODE: $la\u00adtex a_ny{(n)} + a_{n-1}y{(n-1)} + \\dots + a_2y'' + a_1y' + a_0y = F(x)$.  $la\u00adtex a_n$ can\u00adnot be ze\u00adro (other\u00adwise it would be a n-1 or\u00adder ODE), so we can and should di\u00advide through by it.  Lets pre\u00adtend that we al\u00adready did that, and just use the same let\u00adter\u00ads.  Al\u00adso, I will re\u00adwrite $la\u00adtex a_n$ as $la\u00adtex a_n(x)$ to em\u00adpha\u00adsize that the co\u00adef\u00adfi\u00adcients do not have to be con\u00adstants for this to work.  So you have your lin\u00adear in\u00adho\u00admo\u00adge\u00adneous ODE: $la\u00adtex y{(n)} + a_{n-1}(x)y{(n-1)} + \\dots + a_2(x)y'' + a_1(x)y' + a_0(x)y = F(x)$.  So, as I men\u00adtioned above, we need n lin\u00adear\u00adly in\u00adde\u00adpen\u00addent so\u00adlu\u00adtions to the ho\u00admo\u00adge\u00adneous equa\u00adtion $la\u00adtex y{(n)} + a_{n-1}(x)y{(n-1)} + \\dots + a_2(x)y'' + a_1(x)y' + a_0(x)y = 0$ to use this method.  Let us call those so\u00adlu\u00adtions $la\u00adtex y_1(x), y_2(x), \\dot\u00ads, y_n(x)$.  Now let us write our par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion as $la\u00adtex y_p(x) = c_1(x)y_1(x) + c_2(x)y_2(x) + \\dots + c_n(x)y_n(x)$.  Now, if we sub\u00adsti\u00adtute our par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion in to the left hand side of our ODE, we should get $la\u00adtex F(x)$ back.  So we have $la\u00adtex (y_p){(n)} + a_{n-1}(x)(y_p){(n-1)} + \\dots + a_2(x)y_p'' + a_1(x)y_p' + a_0(x)y_p =$ $la\u00adtex F(x)$.  Now, let me re\u00adwrite $la\u00adtex y_p$ as a sum\u00adma\u00adtion to help keep things from get\u00adting too messy.  I am al\u00adso go\u00ading to write $la\u00adtex c_i$ in\u00adstead of $la\u00adtex c_i(x)$ on terms for ad\u00addi\u00adtion\u00adal san\u00adi\u00adty.  Ev\u00adery vari\u00adable is a func\u00adtion of x.  $la\u00adtex y_p(x) = \\sum_{i=1}{n} c_i y_i$.  The par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion should sat\u00adis\u00adfy the con\u00addi\u00adtion of the ODE, so \n $la\u00adtex y_p{(n)} + a_{n-1}y_p{(n-1)} + \\dots + a_2y_p'' + a_1y_p' + a_0y_p = F(x)$. \n $la\u00adtex (\\\u00adsum_{i=1}{n} c_i y_i){(n)} + a_{n-1}(\\\u00adsum_{i=1}{n} c_i y_i){(n-1)} + \\dots + a_2(\\\u00adsum_{i=1}{n} c_i y_i){(2)} + $ \n $la\u00adtex a_1(\\\u00adsum_{i=1}{n} c_i y_i){(1)} + a_0\\\u00adsum_{i=1}{n} c_i y_i = F(x)$. \n Now, if we ap\u00adply the prod\u00aduct rule to this, things will get ug\u00adly re\u00adal\u00adly fast, be\u00adcause we have to ap\u00adply the prod\u00aduct rule on each term as many times as the or\u00adder of that term (the first term would have to be ap\u00adplied n times, the sec\u00adond, n-1 times, and so on).  But there is a trick that we can use.  In the ho\u00admo\u00adge\u00adneous case, there is no par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion, so in that case the $la\u00adtex c_i$ terms must all van\u00adish iden\u00adti\u00adcal\u00adly be\u00adcause the so\u00adlu\u00adtions are lin\u00adear\u00adly in\u00adde\u00adpen\u00addent of one an\u00adoth\u00ader.  Thus, if we plug the par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion in\u00adto the ho\u00admo\u00adge\u00adneous case, we get \n $la\u00adtex (\\\u00adsum_{i=1}{n} c_i y_i){(n)} + a_{n-1}(\\\u00adsum_{i=1}{n} c_i y_i){(n-1)} + \\dots + a_2(\\\u00adsum_{i=1}{n} c_i y_i){(2)} + $ \n $la\u00adtex a_1(\\\u00adsum_{i=1}{n} c_i y_i){(1)} + a_0\\\u00adsum_{i=1}{n} c_i y_i = 0$. \n We al\u00adready know that if we plug the $la\u00adtex y_i$ terms in in\u00addi\u00advid\u00adu\u00adal\u00adly of the $la\u00adtex c_i$ terms, that the ex\u00adpres\u00adsion will van\u00adish iden\u00adti\u00adcal\u00adly be\u00adcause the $la\u00adtex y_i$ terms are so\u00adlu\u00adtions to the ho\u00admo\u00adge\u00adneous equa\u00adtion.  The prod\u00aduct rule on each term will be eval\u00adu\u00adat\u00aded ac\u00adcord\u00ading to the  Leib\u00adniz Rule, which is that $la\u00adtex (c_i \\c\u00addot f_i){(n)}=\\\u00adsum_{k=0}n {n \\choose k} c_i{(k)} y_i(x){(n-k)}$.  Now the $la\u00adtex c_i y_i{(n)}$ terms will van\u00adish be\u00adcause we can fac\u00adtor out a $la\u00adtex c_i$ and they will be ex\u00adact\u00adly the ho\u00admo\u00adge\u00adneous so\u00adlu\u00adtion.  Be\u00adcause the ex\u00adpres\u00adsion is iden\u00adti\u00adcal\u00adly equal to ze\u00adro, the re\u00admain\u00ading terms must van\u00adish as well.  If we as\u00adsume that each $la\u00adtex \\sum_{i=1}n c_i' y_i{(j)}=0$ for each j from 0 to n-2, then this will take care of this; the terms with high\u00ader de\u00adriv\u00ada\u00adtives on $la\u00adtex c_i$ will al\u00adso be 0, if this is true, then we do not need them for our deriva\u00adtion.  In oth\u00ader word\u00ads,   \n $la\u00adtex  c_1' y_1  + c_2' y_2 + \\c\u00addots + c_n' y_n = 0 $ \n $la\u00adtex c_n' y_1' + c_n' y_2' + \\c\u00addots + c_n' y_n' = 0 $ \n $la\u00adtex \\v\u00addots $ \n $la\u00adtex c_n' y_1{(n-2)} + c_n' y_2{(n-2)} + \\c\u00addots + c_n' y_n{(n-2)} = 0$. \n So, turn\u00ading back to our orig\u00adi\u00adnal ODE with the par\u00adtic\u00adu\u00adlar so\u00adlu\u00adtion sub\u00adsti\u00adtut\u00aded in, we have \n $la\u00adtex (\\\u00adsum_{i=1}{n} c_i y_i){(n)} + a_{n-1}(\\\u00adsum_{i=1}{n} c_i y_i){(n-1)} + \\dots + a_2(\\\u00adsum_{i=1}{n} c_i y_i){(2)} + $ \n $la\u00adtex a_1(\\\u00adsum_{i=1}{n} c_i y_i){(1)} + a_0\\\u00adsum_{i=1}{n} c_i y_i = F(x)$. \n But we know that most of the terms of this will van\u00adish, from our as\u00adsump\u00adtion above.  If we re\u00admove those terms, what re\u00admains is $la\u00adtex \\sum_{i=1}{n} c_i' y_i{(n-1)} = F(x)$.  So this is where it is nice that I learned  Cramer's Rule  lit\u00ader\u00adal\u00adly days be\u00adfore learn\u00ading how to do Vari\u00ada\u00adtion of Pa\u00adram\u00ade\u00adters in the gen\u00ader\u00adal case.  We have a sys\u00adtem of n equa\u00adtions (the n-1 from above, plus the one we just de\u00adrived), of n un\u00adknowns (the $la\u00adtex c_i$ terms).  The de\u00adter\u00admi\u00adnant that we use here is used of\u00adten enough to war\u00adrant a name: the  Wron\u00adskian.  We have that $la\u00adtex c_i' = \\frac{W_i(x)}{W(x)}$, or $la\u00adtex c_i = \\int \\frac{W_i(x)}{W(x)}$, where $la\u00adtex W_i(x)$ is the Wron\u00adskian of the fun\u00adda\u00admen\u00adtal sys\u00adtem with the ith col\u00adumn re\u00adplaced with $la\u00adtex \\be\u00adgin{b\u00adma\u00adtrix} 0 \\ 0 \\ \\v\u00addots \\ 0 \\ F(x) \\end{b\u00adma\u00adtrix}$.  So we fi\u00adnal\u00adly have $la\u00adtex y_p = \\sum_{i=1}n \\int \\frac{W_i(x)}{W(x)} y_i$.    \n Well, that's the the\u00ado\u00adry, but as al\u00adways here, that is on\u00adly half of the sto\u00adry.  A Wron\u00adskian func\u00adtion is al\u00adready im\u00adple\u00adment\u00aded in SymPy, and find\u00ading $la\u00adtex W_i(x)$ sim\u00adply amounts to $la\u00adtex F(x)$ times the Wron\u00adskian of the sys\u00adtem with\u00adout the ith equa\u00adtion, all times $la\u00adtex (-1)i$.  So im\u00adple\u00adment\u00ading it was easy enough.  But it soon be\u00adcame clear that there would be some prob\u00adlems with this method.  Some\u00adtimes, the SymPy would re\u00adturn a re\u00adal\u00adly sim\u00adple Wron\u00adskian, some\u00adthing like $la\u00adtex -4e{2x}$, but oth\u00ader times, it would re\u00adturn some\u00adthing crazy.  For ex\u00adam\u00adple, con\u00adsid\u00ader the ex\u00adpres\u00adsion that I re\u00adport\u00aded in  SymPy is\u00adsue 1562.  The ex\u00adpres\u00adsion is (thanks to SymPy's  la\u00adtex()  com\u00admand, no thanks to Word\u00adPress's stupid au\u00adto line breaks that have forced me to up\u00adload my own im\u00adage.  If it was\u00adn't such a pain, I would do it for ev\u00adery equa\u00adtion, be\u00adcause it looks much nicer.): \n . \n This is the Wron\u00adskian, as cal\u00adcu\u00adlat\u00aded by SymPy's  wron\u00adskian()  func\u00adtion, of   \n $la\u00adtex \\be\u00adgin{b\u00adma\u00adtrix}x \\s\u00adin{x}, & \\s\u00adin{x}, & 1, & x \\cos{x}, & \\cos{x}\\end{b\u00adma\u00adtrix}$, which is the set of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent so\u00adlu\u00adtions to the ODE $la\u00adtex {\\frac {d{5}}{d{x}{5}}}f \\left( x \\right) +2\\,{\\frac {d{3}}{d{x}{3}}}f \\left( x \\right) +{\\frac {d}{dx}}f \\left( x \\right) -1$.  Well, the prob\u00adlem here is that, as ver\u00adi\u00adfied by Maple, that com\u00adplex Wron\u00adskian above is iden\u00adti\u00adcal\u00adly equal to $la\u00adtex -4$.  SymPy's  sim\u00adpli\u00adfy()  and  trigsim\u00adp()  func\u00adtions are not ad\u00advanced enough to han\u00addle it.  It turns out that in this case, the prob\u00adlem is that SymPy's  can\u00adcel()  and  fac\u00adtor()  rou\u00adtines do not work un\u00adless the ex\u00adpres\u00adsion has on\u00adly sym\u00adbols in it, and that ex\u00adpres\u00adsion re\u00adquires you to can\u00adcel and fac\u00adtor to find the $la\u00adtex \\cos2{x} + \\s\u00adin2{x}$ (see the is\u00adsue page for more in\u00adfor\u00adma\u00adtion on this).  Un\u00adfor\u00adtu\u00adnate\u00adly, SymPy's  in\u00adte\u00adgrate()  can\u00adnot han\u00addle that un\u00adsim\u00adpli\u00adfied ex\u00adpres\u00adsion in the de\u00adnom\u00adi\u00adna\u00adtor of some\u00adthing, as you could imag\u00adine, and it seems like al\u00admost ev\u00adery time that sin's and cos's are part of the so\u00adlu\u00adtion to the ho\u00admo\u00adge\u00adneous equa\u00adtion, the Wron\u00adskian be\u00adcomes too dif\u00adfi\u00adcult for SymPy to sim\u00adpli\u00adfy.  So, while I was hop\u00ading to slip along with on\u00adly vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads, which tech\u00adni\u00adcal\u00adly solves ev\u00adery lin\u00adear in\u00adho\u00admo\u00adge\u00adneous ODE, it looks like I am go\u00ading to have to im\u00adple\u00adment the method of un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients.  Vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters will still be use\u00adful, as un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients on\u00adly works if the ex\u00adpres\u00adsion on the right hand side of the equa\u00adtion, $la\u00adtex F(x)$ has a fi\u00adnite set of lin\u00adear\u00adly in\u00adde\u00adpen\u00addent de\u00adriv\u00ada\u00adtives (such as sin, cos, ex\u00adp, poly\u00adno\u00admi\u00adal terms, and com\u00adbi\u00adna\u00adtions of them (I'll talk more about this when\u00adev\u00ader I im\u00adple\u00adment it).    \n The good news here is that I dis\u00adcov\u00adered that I was wrong.  I had pre\u00advi\u00adous\u00adly be\u00adlieved that among the sec\u00adond or\u00adder spe\u00adcial cas\u00ades were cas\u00ades that could on\u00adly be han\u00addled by vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters or un\u00adde\u00adter\u00admined co\u00adef\u00adfi\u00adcients, but it turns out I was wrong.  All that was im\u00adple\u00adment\u00aded were the ho\u00admo\u00adge\u00adneous cas\u00ades for sec\u00adond or\u00adder lin\u00adear with con\u00adstant co\u00adef\u00adfi\u00adcients.  In ad\u00addi\u00adtion to this, there was one very spe\u00adcial case ODE that On\u00addrej had im\u00adple\u00adment\u00aded for an ex\u00adam\u00adple (ex\u00adam\u00adples/ad\u00advanced/rel\u00ada\u00adtiv\u00adi\u00adty.py).  The ODE is \n $la\u00adtex -2({\\frac{d}{dx}}f(x)){e{-f(x)}}+x({\\frac{d}{dx}}f(x)){2}{e{-f(x)}}-x({\\frac{d{2}}{d{x}{2}}}f(x)){e{-f(x)}}$, which is the sec\u00adond de\u00adriv\u00ada\u00adtive of $la\u00adtex xe{-f(x)}$ with re\u00adspect to x.  Ac\u00adcord\u00ading to the ex\u00adam\u00adple file, it is know as Ein\u00adstein's equa\u00adtion\u00ads.  Maple has a nice  odead\u00advi\u00adsor()  func\u00adtion sim\u00adi\u00adlar to the  clas\u00adsi\u00adfy_ode()  func\u00adtion I am writ\u00ading for SymPy that tells you all of the dif\u00adfer\u00adent ways that an ODE can be solved. So, I plugged that ODE in\u00adto it and got a few pos\u00adsi\u00adble meth\u00adods out that I could po\u00adten\u00adtial\u00adly im\u00adple\u00adment in SymPy to main\u00adtain com\u00adpat\u00adi\u00adbil\u00adi\u00adty with the ex\u00adam\u00adple equa\u00adtion.  The chief one is that the low\u00adest or\u00adder of f in the ODE is 1 (as\u00adsum\u00ading you di\u00advide out the $la\u00adtex e{-f(x)}$ ter\u00adm, which is per\u00adfect\u00adly rea\u00adson\u00adable as that term will nev\u00ader be 0. You can then make the sub\u00adsti\u00adtu\u00adtion $la\u00adtex u = f'(x)$, and you will re\u00adduce the or\u00adder of the ODE to first or\u00adder, which in this case would be a Bernoul\u00adli equa\u00adtion, the first thing that I ev\u00ader im\u00adple\u00adment\u00aded in SymPy.    \n But I did\u00adn't do that.  Re\u00adduc\u00adtion of or\u00adder meth\u00adods would be great to have for  dsolve(), but that is a project for an\u00adoth\u00ader sum\u00admer.  Aside from that method, Maple's  odead\u00advi\u00adsor()  al\u00adso told me that it was a Li\u00adou\u00adville ODE.  I had nev\u00ader heard of that method, and nei\u00adther it seems has Wikipedia or \"Un\u00adcle Google\" (as On\u00addrej calls it).  For\u00adtu\u00adnate\u00adly, Maple's Doc\u00adu\u00admen\u00adta\u00adtion has a nice page for each type of ODE re\u00adturned by  odead\u00advi\u00adsor(), so I was able to learn the method. The method re\u00adlies on Lie Sym\u00adme\u00adtries and ex\u00adact sec\u00adond or\u00adder equa\u00adtion\u00ads, nei\u00adther of which I am ac\u00adtu\u00adal\u00adly fa\u00admil\u00adiar with, so I will not at\u00adtempt to prove any\u00adthing here.  Suf\u00adfice it to say that if an ODE has the form   \n $la\u00adtex {\\frac{d{2}}{d{x}{2}}}y(x)+g(y(x))({\\frac{d}{dx}}y(x)){2}+f(x){\\frac{d}{dx}}y(x)=0$, then the so\u00adlu\u00adtion to the ODE is \n $la\u00adtex \\in\u00adt{y(x)}{e{\\int g(a){\u00adda}}}{\u00adda}+C1\\in\u00adt{e{-\\int f(x){dx}}}{dx}+C2=0$ \n You could prob\u00ada\u00adbly ver\u00adi\u00adfy this by sub\u00adsti\u00adtut\u00ading the so\u00adlu\u00adtion in\u00adto the orig\u00adi\u00adnal ODE.  See the  Maple Doc\u00adu\u00admen\u00adta\u00adtion page on Li\u00adou\u00adville ODEs, as well as the  pa\u00adper they ref\u00ader\u00adence  (Gold\u00adstein and Braun, \"Ad\u00advanced Meth\u00adods for the So\u00adlu\u00adtion of Dif\u00adfer\u00aden\u00adtial Equa\u00adtion\u00ads\", see pg. 98).    \n The so\u00adlu\u00adtion is very straight for\u00adward--as much so as first or\u00adder lin\u00adear or Bernoul\u00adli equa\u00adtion\u00ads, so it was a cinch to im\u00adple\u00adment it.  It looks like quite a few dif\u00adfer\u00aden\u00adtial equa\u00adtions gen\u00ader\u00adat\u00aded by do\u00ading $la\u00adtex F''(y(x), x)$ for some func\u00adtion or x and y $la\u00adtex F(y(x), x)$ gen\u00ader\u00adates equa\u00adtions of that type, so it could be ac\u00adtu\u00adal\u00adly use\u00adful for solv\u00ading oth\u00ader things.    \n Be\u00adfore I sign of\u00adf, I just want to men\u00adtion one oth\u00ader thing that I im\u00adple\u00adment\u00aded.  I want\u00aded my lin\u00adear ho\u00admo\u00adge\u00adneous con\u00adstant co\u00adef\u00adfi\u00adcient ODE solver to be able to han\u00addle ODEs for which SymPy can't solve the char\u00adac\u00adter\u00adis\u00adtic equa\u00adtion, for what\u00adev\u00ader rea\u00adson.  SymPy has  RootOf()  ob\u00adjects sim\u00adi\u00adlar to Maple that let you rep\u00adre\u00adsent the roots of a poly\u00adno\u00admi\u00adal with\u00adout ac\u00adtu\u00adal\u00adly solv\u00ading it, or even be\u00ading able to solve it, but a you can on\u00adly use RootOf's if you know that none of the roots are re\u00adpeat\u00aded.  Oth\u00ader\u00adwise, you would have to know which terms re\u00adquire an ad\u00addi\u00adtion\u00adal $la\u00adtex xi$ to pre\u00adserve lin\u00adear in\u00adde\u00adpen\u00addence.  Well, it turns out that there is a way to tell if a poly\u00adno\u00admi\u00adal has re\u00adpeat\u00aded roots with\u00adout solv\u00ading for them.  There is a num\u00adber as\u00adso\u00adci\u00adat\u00aded with ev\u00adery poly\u00adno\u00admi\u00adal of one vari\u00adable called the  dis\u00adcrim\u00adi\u00adnant.  For ex\u00adam\u00adple, the dis\u00adcrim\u00adi\u00adnant of the com\u00admon qua\u00addrat\u00adic poly\u00adno\u00admi\u00adal $la\u00adtex ax2 + bx + c$ is the term un\u00adder the square root of the fa\u00admous so\u00adlu\u00adtion $la\u00adtex b2 - 4ac$.  It is clear that a qua\u00addrat\u00adic has re\u00adpeat\u00aded roots if and on\u00adly if the dis\u00adcrim\u00adi\u00adnant is 0.  Well, the same is true for the dis\u00adcrim\u00adi\u00adnant of any poly\u00adno\u00admi\u00adal.  I am not high\u00adly fa\u00admil\u00adiar with this (ask me again af\u00adter I have tak\u00aden my ab\u00adstract al\u00adge\u00adbra class next semester), but ap\u00adpar\u00adent\u00adly there is some\u00adthing called the re\u00adsul\u00adtan\u00adt, which is the prod\u00aduct of the dif\u00adfer\u00adences of roots be\u00adtween two poly\u00adno\u00admi\u00adals and which can al\u00adso be cal\u00adcu\u00adlat\u00aded with\u00adout ex\u00adplic\u00adit\u00adly find\u00ading the roots of the poly\u00adno\u00admi\u00adal\u00ads.  Clear\u00adly, this will be 0 if and on\u00adly if the two poly\u00adno\u00admi\u00adals share a root.  So the dis\u00adcrim\u00adi\u00adnant is built from the fact that a poly\u00adno\u00admi\u00adal has a re\u00adpeat\u00aded root iff it shares a root with its re\u00adsul\u00adtan\u00adt.  So it is ba\u00adsi\u00adcal\u00adly the re\u00adsul\u00adtant of a poly\u00adno\u00admi\u00adal and its de\u00adr\u00ada\u00adti\u00advave, times an ex\u00adtra fac\u00adtor.  It is 0 if and on\u00adly if the poly\u00adno\u00admi\u00adal has a re\u00adpeat\u00aded root.    \n For\u00adtu\u00adnate\u00adly, SymPy's ex\u00adce\u00adlent Polys mod\u00adule al\u00adready had re\u00adsul\u00adtants im\u00adple\u00adment\u00aded (quite ef\u00adfi\u00adcient\u00adly too, I might ad\u00add), so it was easy to im\u00adple\u00adment the dis\u00adcrim\u00adi\u00adnan\u00adt.  I added it as  is\u00adsue 1555.  If you are a SymPy de\u00advel\u00adop\u00ader and you have some\u00adhow man\u00adaged to make your\u00adself read this far (b\u00adless your heart), please re\u00adview that patch.    \n Well, this has turned out to be one hel\u00adla long blog post.  But what can I say.  You don't have to read this thing (ex\u00adcept for pos\u00adsi\u00adbly my men\u00adtor.  Sor\u00adry Andy).  And I haven't been quite up\u00addat\u00ading week\u00adly like I am sup\u00adposed to be, so this com\u00adpen\u00adsates.  If you hap\u00adpened up\u00adon this blog post be\u00adcause, like me, you were look\u00ading for a gen\u00ader\u00adal treat\u00adment of vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads, I hope you found my lit\u00adtle write up help\u00adful.  And if you did, and you now un\u00adder\u00adstand it, could you go ahead and im\u00adprove the Wikipedia ar\u00adti\u00adcle.  I'm not up to it?", 
      "loc": "/posts/2009/08/01/variation-of-parameters-and-more/"
    }, 
    {
      "title": "Modifying a list while looping through it in Python", 
      "tags": "", 
      "text": "Here is an in\u00adter\u00adest\u00ading thing that I found.   x  is a SymPy Sym\u00adbol\u00ad:\n  \n I would have ex\u00adpect\u00aded to get  a = [], but it on\u00adly re\u00admoves the first item.  And yes,  x + 1  pass\u00ades the con\u00addi\u00adtion: \n  \n >>> (x + 1).has(x) \n True \n  \n Clear\u00adly, it is a bad idea to mod\u00adi\u00adfy a list while I am loop\u00ading through it. I should in\u00adstead be do\u00ading some\u00adthing like this: \n  \n But I am in\u00adtrigued as to why ex\u00adact\u00adly this fail\u00ads.  If any of the read\u00aders of the blog thinks that he know, please post in the com\u00adments.  Or, if I fig\u00adure it out, I will post an up\u00addate.  Al\u00adso, here is a sim\u00adi\u00adlar ex\u00adam\u00adple, with a strange re\u00adsult: \n  \n (Sor\u00adry for the im\u00adages by the way.  Word\u00adPress's so called \"code\" blocks are im\u00adper\u00advi\u00adous to in\u00adden\u00adta\u00adtion.) \n UP\u00adDATE (a few min\u00adutes lat\u00ader): \n Well, I fig\u00adured it would come to me as to why this was hap\u00adpen\u00ading, and it did\u00adn't take long.  While I haven't read the ac\u00adtu\u00adal  Python Lan\u00adguage Ref\u00ader\u00adence, this is what I am as\u00adsum\u00ading is hap\u00adpen\u00ading.  This is all just my guess\u00ading on how Python is im\u00adple\u00adment\u00aded.  Please cor\u00adrect me if I am wrong. \n So, ob\u00advi\u00adous\u00adly, a Python list is just a C ar\u00adray.  It is prob\u00ada\u00adbly an ar\u00adray of point\u00ader\u00ads, which is the on\u00adly way I can see that would let it be mu\u00adta\u00adble with dif\u00adfer\u00adent ob\u00adjects (this is how com\u00adpiled lan\u00adguages with dy\u00adnam\u00adic typ\u00ading like  Ob\u00adjec\u00adtive-C  more or less pull it of\u00adf).  Now C does not have the  for i in list  syn\u00adtax that Python has (nor does any oth\u00ader lan\u00adguage that I know of.  That is one of the rea\u00adsons that Python is so awe\u00adsome!), so if you want to re\u00adcurse a list (C ar\u00adray), you have to do the usu\u00adal  for (i=0; i<=len(list); i++) {  from C (or it prob\u00ada\u00adbly us\u00ades a while loop, which would al\u00adlow for things like it\u00ader\u00ada\u00adtors, but a for loop in C is lit\u00ader\u00adal\u00adly just a wrap\u00adper around a while loop any\u00adway).  Then of course, in\u00adside of the loop, you just have  list[i]  block\u00ads.  So when I was go\u00ading through my list, for ex\u00adam\u00adple, the list of num\u00adbers in the last ex\u00adam\u00adple, it would hit item 0 (the first item), re\u00admove it, which would amount to re\u00adbuild\u00ading the list as  [2, 3, 4, 5], then it would hit item 1, which is now 3, re\u00admove it, re\u00adbuild\u00ading the list, and so on.  So the even num\u00adbered el\u00ade\u00adments re\u00admain be\u00adcause it skips ev\u00adery el\u00ade\u00adment af\u00adter one that it re\u00admoves. CPython must have good er\u00adror han\u00addling, be\u00adcause even\u00adtu\u00adal\u00adly this would cause the in\u00addices to go be\u00adyond the length of the list.  It seems to me that this be\u00adhav\u00adior is not very well de\u00adfined.  Per\u00adson\u00adal\u00adly, I think that what\u00adev\u00ader you are loop\u00ading through in a for loop should be\u00adcome im\u00admutable with\u00adin the loop block.  I checked Python 3.1, and the be\u00adhav\u00adior is ex\u00adact\u00adly the same. \n Based on this,  .re\u00admove()  re\u00adbuilds the list each time.  I would have thought it would just set the val\u00adue in the ar\u00adray to Nul\u00adl, but I guess that would make it more dif\u00adfi\u00adcult to test equal\u00adi\u00adty with an equiv\u00ada\u00adlent list that does\u00adn't have Null val\u00adues.  It is good to know that  .re\u00admove()  does that, be\u00adcause it means that can be an ex\u00adpen\u00adsive op\u00ader\u00ada\u00adtion.", 
      "loc": "/posts/2009/07/20/modifying-a-list-while-looping-through-it-in-python/"
    }, 
    {
      "title": "Constant stuff", 
      "tags": "", 
      "text": "So I was able to get a work\u00ading ver\u00adsion of the Con\u00adstant class, but be\u00adcause the code clut\u00adtered up the in\u00adter\u00adnal Add and Mul class\u00ades too much, On\u00addrej con\u00advinced me that to make a func\u00adtion that does the sim\u00adpli\u00adfi\u00adca\u00adtion in\u00adstead, and I re\u00adluc\u00adtant\u00adly agreed.  Af\u00adter be\u00adgin\u00ading work on it, I re\u00adal\u00adized that it will be much eas\u00adi\u00ader to make it just an in\u00adter\u00adnal func\u00adtion that han\u00addles the spe\u00adcial cas\u00ades pre\u00adsent\u00aded by  dsolve().  That means that it will on\u00adly han\u00addle ar\u00adbi\u00adtrary con\u00adstants that are in\u00adde\u00adpen\u00addent of one vari\u00adable, and it will on\u00adly work with con\u00adstants that are named as \"C1\", \"C2\", and so on.    \n If we ev\u00ader get the sympyx core that On\u00addrej and I worked on when I was in Los Alam\u00ados in, it will be easy for my to use a Con\u00adstant class, be\u00adcause it will have han\u00addler log\u00adic that will al\u00adlow for the Con\u00adstant class to ex\u00adist in\u00adde\u00adpen\u00addent of Add and Mul. It al\u00adready can ex\u00adist in\u00adde\u00adpen\u00addent of Pow with a mi\u00adnor code ad\u00addi\u00adtion, but sim\u00adpli\u00adfy\u00ading pow\u00aders is eas\u00adi\u00ader than sim\u00adpli\u00adfy\u00ading ad\u00addi\u00adtion and mul\u00adti\u00adplca\u00adtion be\u00adcause ex\u00adpo\u00adnen\u00adti\u00ada\u00adtion is nei\u00adther com\u00admu\u00adta\u00adtive nor as\u00adso\u00adcia\u00adtive, mean\u00ading that you don't have to wor\u00adry about ab\u00adsorb\u00ading stuff on the oth\u00ader side of some\u00adthing, like  2 + x + C.    \n See my  con\u00adstan\u00adt-\u00adMul branch for my work\u00ading ver\u00adsion of a Con\u00adstant class the im\u00adple\u00adments in Mul and Ad\u00add.  See my  con\u00adstan\u00adt-\u00adfunc\u00adtion  branch for my work on the in\u00adter\u00adnal func\u00adtion. \n Be\u00adcause I have de\u00adcid\u00aded to make thing sim\u00adple and make the func\u00adtion in\u00adter\u00adnal on\u00adly, I should have things up and run\u00adning soon.  Then, it will be sim\u00adple to fix up my nth or\u00adder ho\u00admo\u00adge\u00adneous stuff that I al\u00adready have so that it work\u00ads, and then to im\u00adple\u00adment vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads!", 
      "loc": "/posts/2009/07/16/constant-stuff/"
    }, 
    {
      "title": "Meeting Ondrej in Los Alamos", 
      "tags": "", 
      "text": "So On\u00addrej was kind enough to have me over to his house in Los Alam\u00ados for Fri\u00adday and Sat\u00adur\u00adday.  We spent a lot of time cod\u00ading to\u00adgeth\u00ader.  While we worked on some oth\u00ader things too, we main\u00adly worked on my con\u00adstant class.  On\u00addrej and I came up with an idea for re\u00adstruc\u00adtured Mul and Add class\u00ades that would al\u00adlow dif\u00adfer\u00adent ob\u00adjects in them to han\u00addle the oth\u00ader ob\u00adjects in them.  The way it is now, if I want my Con\u00adstant ob\u00adject to ab\u00adsorb oth\u00ader ob\u00adject\u00ads, like  2aCx => Cx, I have to hard\u00adcode it in\u00adto Mul.  The same is true with Ad\u00add.  This makes the Mul and Add class\u00ades mud\u00addy.  Right now, there is al\u00adready spe\u00adcial han\u00addling for oth\u00ader such dy\u00adnam\u00adic ob\u00adjects such as Or\u00adder class\u00ades (e.g.,  O(x)), and In\u00adfin\u00adi\u00adty class.  See the  Ad\u00add.flat\u00adten()  and  Mul.flat\u00adten()  meth\u00adods in sympy/\u00adcore/ad\u00add.py and sympy.\u00adcore/\u00admul.py to see what I mean.    \n We came up with a sys\u00adtem where sym\u00adbols and num\u00adbers are han\u00addled the same way, be\u00adcause we need them to be fast, but if an ex\u00adpres\u00adsion has an ob\u00adject that has a  han\u00addle_\u00admul()  method, it will call that method with the oth\u00ader ob\u00adjects in the ex\u00adpres\u00adsion in the Mul/Add and the ob\u00adject will take care of the spe\u00adcial han\u00addling.  On\u00addrej was able to get most of it work\u00ading in his ex\u00adper\u00adi\u00admen\u00adtal core that does\u00adn't use as\u00adsump\u00adtions  here.  We will hope\u00adful\u00adly end up us\u00ading it, but we need to wait un\u00adtil we merge the new as\u00adsump\u00adtions sys\u00adtem.   \n So in the mean while, I have a work\u00ading Con\u00adstant class that mod\u00adi\u00adfies Mul and Add  here.  Since it will take a while un\u00adtil the new as\u00adsump\u00adtions sys\u00adtem is done (Fabi\u00adan Seoane  is do\u00ading it for his Google Sum\u00admer of Code pro\u00adjec\u00adt), we may end up tem\u00adpo\u00adrar\u00adily adding in my Con\u00adstant branch.  Once I have a work\u00ading Con\u00adstant class, I can solve  ho\u00admo\u00adge\u00adneous dif\u00adfer\u00aden\u00adtial equa\u00adtions  (not to be con\u00adfused with  first or\u00adder dif\u00adfer\u00aden\u00adtial equa\u00adtions with ho\u00admo\u00adge\u00adneous co\u00adef\u00adfi\u00adcients)  with one case (there are sev\u00ader\u00adal cas\u00ades de\u00adpend\u00ading on whether the roots of the so called char\u00adac\u00adter\u00adis\u00adtic equa\u00adtion are re\u00adal, imag\u00adi\u00adnary, or com\u00adplex, but we can ac\u00adtu\u00adal\u00adly han\u00addle them in one case if we have con\u00adstants that com\u00adbine in\u00adto each oth\u00ader.  More on this in a lat\u00ader post).  Once I have that (which I have ev\u00adery\u00adthing al\u00adready ex\u00adcept for the ar\u00adbi\u00adtrary con\u00adstants), I can then im\u00adple\u00adment  vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adters, which, along with sep\u00ada\u00adra\u00adble, will prob\u00ada\u00adbly be the most used solver of the ones that I will im\u00adple\u00adment this sum\u00admer.    \n Once I get those, I can clean up a lot of the 2nd or\u00adder dif\u00adfer\u00aden\u00adtial equa\u00adtion code in dsolve (cur\u00adrent\u00adly it is just a hack with a bunch of spe\u00adcial cas\u00ades all cov\u00adered by vari\u00ada\u00adtion of pa\u00adram\u00ade\u00adter\u00ads).  With that code cleaned up, I can refac\u00adtor dsolve to use my pro\u00adposed hints en\u00adgine, which will al\u00adlow the us\u00ader to choose which meth\u00adods they want to use to solve an equa\u00adtion (more on that in a lat\u00ader post too).", 
      "loc": "/posts/2009/07/13/meeting-ondrej-in-los-alamos/"
    }, 
    {
      "title": "Update", 
      "tags": "mathjax", 
      "text": "It's been a while since I've post\u00aded here, so I fig\u00adured an up\u00addate was in or\u00adder.  Here is a list of stuff that I have done since my last post. \n \n \n I re\u00ad\u00adcov\u00ad\u00adered my da\u00ad\u00adta from my Ter\u00admi\u00ad\u00adnal his\u00ad\u00adto\u00adry.  This was\u00adn't too dif\u00ad\u00adfi\u00adcult as I pre\u00ad\u00addic\u00adt\u00aded.  I just had to do some mi\u00adnor for\u00ad\u00admat\u00adt\u00ading on the   git com\u00admit --in\u00adter\u00adac\u00ad\u00adtive   da\u00ad\u00adta to make it a valid git patch file.  For what\u00adev\u00ader rea\u00ad\u00adson, a hand\u00ad\u00adful of the changes would\u00adn't ap\u00ad\u00adply be\u00ad\u00adcause git could\u00adn't find where changed lines were, even though they were iden\u00adti\u00ad\u00adcal to what was in the patch.    git ap\u00ad\u00adply   does\u00adn't seem to have a merge op\u00ad\u00adtion, but even\u00ad\u00adtu\u00adal\u00ad\u00adly I found the   --re\u00ad\u00adject   op\u00ad\u00adtion, which puts failed patch\u00ades in .rej files, in\u00ad\u00adstead of just fail\u00ading the whole ap\u00ad\u00adply.  \n   \n  \n I got sep\u00ada\u00adra\u00adble equa\u00ad\u00adtions im\u00ad\u00adple\u00ad\u00admen\u00adt\u00aded in dsolve.  I ac\u00ad\u00adtu\u00adal\u00ad\u00adly did this on the road be\u00ad\u00adfore I lost my data, but I failed to men\u00ad\u00adtion it be\u00ad\u00adfore, so here it is.  The hard\u00adest part with that was cre\u00adat\u00ading a de\u00ad\u00adcent   sep\u00ada\u00adrat\u00ade\u00ad\u00advars()   func\u00ad\u00adtion that could sep\u00ada\u00adrate just about any fun\u00adci\u00ad\u00adton. As I men\u00ad\u00adtioned in an   ear\u00adli\u00ader post, this in\u00ad\u00ad\u00advolved chang\u00ading the way that SymPy han\u00ad\u00addles au\u00ad\u00adto\u00ad\u00admat\u00adic com\u00adbin\u00ading of ex\u00adpo\u00ad\u00adnents in the core, as well as refac\u00ad\u00adtor\u00ading ex\u00ad\u00adpand. I al\u00ad\u00adso had to make the func\u00ad\u00adtion com\u00ad\u00adplete\u00ad\u00adly in\u00ad\u00adde\u00adpen\u00ad\u00addent of   match, be\u00ad\u00adcause   match   is too bug\u00ad\u00adgy to work cor\u00adrec\u00adt\u00ad\u00adly for sep\u00ada\u00adra\u00adble equa\u00ad\u00adtion\u00ads.      \n   \n  \n Speak\u00ading of refac\u00ad\u00adtor\u00ading   ex\u00ad\u00adpand   and com\u00adbin\u00ading ex\u00adpo\u00ad\u00adnents, that work made it in!  It is the first ma\u00adjor thing that I have done that has ac\u00ad\u00adtu\u00adal\u00ad\u00adly made it in\u00ad\u00ad\u00adto the main SymPy re\u00adpo.  It got in just be\u00ad\u00adfore the re\u00adlease of SymPy 0.6.5-\u00adbe\u00ad\u00adta2, so it should be in the fi\u00ad\u00adnal re\u00adlease of SymPy 0.6.5.  Most like\u00ad\u00adly, none of my ODE stuff will make it in un\u00adtil 0.7.      \n   \n  \n I start\u00aded to work on   Var\u00adi\u00ada\u00ad\u00adtion of Pa\u00adram\u00ade\u00adters, but be\u00ad\u00adfore I could ac\u00ad\u00adtu\u00adal\u00ad\u00adly get to the var\u00adi\u00ada\u00ad\u00adtion of pa\u00adram\u00ade\u00adters part, I need\u00aded to be able to solve a ho\u00ad\u00admo\u00adge\u00ad\u00adneous equa\u00ad\u00adtion $la\u00ad\u00adtex a_ny{(n)}+a_{n-1}y{(n-1)}+\\\u00ad\u00addot\u00ads+a_1y'+a_0y=0$ ($la\u00ad\u00adtex a_i$ con\u00ads\u00adtant for all $la\u00ad\u00adtex i$).  If you know how that work\u00ads, it in\u00ad\u00ad\u00advolves find\u00ad\u00ading the roots of the poly\u00adno\u00admi\u00adal giv\u00aden by $la\u00ad\u00adtex a_n\u00adrn+a_{n-1}r{n-1}+\\\u00ad\u00addot\u00ads+a_1r+a_0=0$.  De\u00adpend\u00ading on whether these roots are re\u00adal, imag\u00adi\u00ad\u00adnary, or com\u00ad\u00adplex, you have dif\u00adfer\u00ad\u00adent so\u00adlu\u00ad\u00adtions with ex\u00adpo\u00ad\u00adnen\u00ad\u00adtials or sin's and cos's.  I had no trou\u00adble get\u00adt\u00ading the ex\u00adpo\u00ad\u00adnen\u00ad\u00adtials and the sin's and cos's to work cor\u00adrec\u00adt\u00ad\u00adly (SymPy al\u00adready has a root find\u00ad\u00ader that I put to work), but I did have a prob\u00adlem get\u00adt\u00ading the ar\u00adbi\u00ad\u00adtrary con\u00ads\u00adtants to work cor\u00adrec\u00ad\u00adty.  It turns out that the code for that would be much sim\u00ad\u00adpler if I had an ar\u00adbi\u00ad\u00adtrary con\u00ads\u00adtant type that au\u00ad\u00adto\u00ad\u00admat\u00adi\u00ad\u00adcal\u00ad\u00adly \"ab\u00ad\u00adsorbed\" oth\u00ad\u00ader con\u00ads\u00adtants.  Since I had planned on do\u00ading that any\u00adway, I de\u00ad\u00adcid\u00aded to put the rest of var\u00adi\u00ada\u00ad\u00adtion of pa\u00adram\u00ade\u00adters on hold and be\u00ad\u00adgin work on that.  \n   \n  \n We had a Doc\u00adu\u00ad\u00admen\u00ad\u00adta\u00ad\u00adtion day on June 30, and I de\u00ad\u00adcid\u00aded to write up a doc\u00adu\u00ad\u00adment that would help peo\u00ad\u00adple new to SymPy and Python with some of the gotchas and pit\u00ad\u00adfal\u00adl\u00ads.  For ex\u00adam\u00ad\u00adple, un\u00ad\u00adlike most oth\u00ad\u00ader in\u00ad\u00adde\u00adpen\u00ad\u00addent CAS's like Maple, you can't just type   1/2   in SymPy to get $la\u00ad\u00adtex \\frac{1}{2}$.  That is be\u00ad\u00adcause Python eval\u00adu\u00adates it nu\u00admer\u00adi\u00ad\u00adcal\u00ad\u00adly.  You have to do   S(1)/2   or   Ra\u00ad\u00adtio\u00ad\u00adnal(1,2)   to get the Ra\u00ad\u00adtio\u00ad\u00adnal class.  It's all things like that.  It's tak\u00aden me a while to get it to\u00adgeth\u00ad\u00ader, not be\u00ad\u00adcause it took me long to write it, but be\u00ad\u00adcause it has to be in the Sphinx doc\u00adu\u00ad\u00admen\u00ad\u00adta\u00ad\u00adtion for\u00ad\u00admat, which I have had to learn.  I am just fin\u00adish\u00ading it up now.  \n   \n  \n I met with On\u00ad\u00addrej on Sat\u00adur\u00ad\u00adday.  He went down from Los Alam\u00ados to Carl\u00ads\u00adbad with a friend to see the cav\u00adern\u00ads, and they stopped here in Al\u00adbu\u00ad\u00adquerque on the way back up.  He came just in time to see the fire\u00ad\u00adwork\u00ads, and af\u00adter that got some din\u00adn\u00ader.  We weren't able to do any cod\u00ading, but hope\u00ad\u00adful\u00ad\u00adly we will be able to meet up again lat\u00ader this sum\u00admer to do some of that.", 
      "loc": "/posts/2009/07/06/update/"
    }, 
    {
      "title": "How to permanently lose data with git (and then retrieve it again)", 
      "tags": "", 
      "text": "So I pushed some changes to github so On\u00addrej could help me de\u00adbug the nseries test\u00ads, when I no\u00adticed that the changes that I pushed had some bad com\u00adments.  So I de\u00adcid\u00aded to re\u00adbase.  But git re\u00adbase -i told me that there was al\u00adready a re\u00adbase in progress.  I fig\u00adured that I must have done it a long time ago and for\u00adgot to abort, so I ran git re\u00adbase --abort.    \n DON'T DO THAT. \n I no\u00adticed my ed\u00adi\u00adtor was telling me that an open file had changed.  Then, I no\u00adticed that ALL of my un\u00adcom\u00admit\u00aded changes were gone!  And, be\u00ading un\u00adcom\u00admit\u00aded changes, git did not have them saved any\u00adwhere! \n So now I start\u00aded to pan\u00adic.  I had done a lot of work on dsolve that I had\u00adn't com\u00admit\u00aded yet. Nor\u00admal\u00adly, I have hourly back\u00adups run by  Time Ma\u00adchine, but I am on va\u00adca\u00adtion and my back\u00adup drive is at home.  So I start\u00aded to see if I could re\u00adtrieve it some\u00adwhere.  grep quick\u00adly told me that it was\u00adn't in the hid\u00adden git di\u00adrec\u00adto\u00adry, but it was still in my .pyc files.  But a Google search told me that re\u00adtriev\u00ading from that is not so easy, if not im\u00adpos\u00adsi\u00adble with Python 2.6.  So then, I de\u00adcid\u00aded to see if there was any lin\u00adger\u00ading stuff in my vir\u00adtu\u00adal mem\u00ado\u00adry from my ed\u00adi\u00adtor.  So I ran grep on my hard\u00addrive and wait\u00aded.    \n While I was wait\u00ading, though, I no\u00adticed when I scrolled up in my com\u00admand his\u00adto\u00adry that my lost changes were in my Ter\u00admi\u00adnal.  It turns out that I had just run git com\u00admit --in\u00adter\u00adac\u00adtive and had used * on my patch\u00ades, so it gave me ev\u00adery\u00adthing!    \n So I copied my Ter\u00admi\u00adnal his\u00adto\u00adry and will work on putting ev\u00adery\u00adthing back to\u00admor\u00adrow.  It should be easy, as\u00adsum\u00ading that git ap\u00adply works for the for\u00admat that git gives in com\u00admit --in\u00adter\u00adac\u00adtive.    \n So the lessons are: Don't abort a re\u00adbase with\u00adout com\u00admit\u00ading.  Don't start a re\u00adbase and then leave it there.  Look in your Ter\u00admi\u00adnal his\u00adto\u00adry if you loose stuff.  And it might be a good idea to make man\u00adu\u00adal back\u00adups if you are away from your back\u00adup drive for a while. \n This al\u00adso high\u00adlights why it is im\u00adpor\u00adtant to try to re\u00adcov\u00ader da\u00adta im\u00adme\u00addi\u00adate\u00adly af\u00adter re\u00adal\u00adiz\u00ading that it is gone.  If I had closed my Ter\u00admi\u00adnal ses\u00adsion or filled it past the max\u00adi\u00admum num\u00adber of lines, my da\u00adta would be gone.  Even if it were in my vir\u00adtu\u00adal mem\u00ado\u00adry, that would\u00adn't last for\u00adev\u00ader ei\u00adther.", 
      "loc": "/posts/2009/06/22/how-to-permanently-lose-data-with-git-and-then-retrieve-it-again/"
    }, 
    {
      "title": "Refactoring Expand", 
      "tags": "mathjax", 
      "text": "So I have spent the past week refac\u00adtor\u00ading ex\u00adpand so that you can have more con\u00adtrol over what ex\u00adpan\u00adsion meth\u00adods you use.  With the present method, ex\u00adpand takes in hints which de\u00adfaults to ba\u00adsic.  ba\u00adsic dis\u00adtrib\u00aduted mul\u00adti\u00adpli\u00adca\u00adtion over ad\u00addi\u00adtion ($la\u00adtex x(y+z) \\rightar\u00adrow xy+xz$), ex\u00adpand\u00aded multi\u00adno\u00admi\u00adal ex\u00adpres\u00adsions ($la\u00adtex (x+y)2 \\rightar\u00adrow x2+2xy+y2$), ex\u00adpand\u00aded log\u00ada\u00adrithms ($la\u00adtex \\log{x2} \\rightar\u00adrow 2\\log{x}$ and $la\u00adtex \\log{xy} \\rightar\u00adrow \\log{x}+\\log{y}$), and ex\u00adpand\u00aded pow\u00aders ($la\u00adtex (xy)n \\rightar\u00adrow xnyn$ and $la\u00adtex e{x+y} \\rightar\u00adrow e{x}e{y}$).    \n If you want\u00aded to do any of these things, you had to use ex\u00adpand_ba\u00adsic, which did all of them.  Al\u00adso, you had no con\u00adtrol on how deep the ex\u00adpan\u00adsion wen\u00adt.  It went all they way down in re\u00adcur\u00adsion, so if you on\u00adly want\u00aded, for ex\u00adam\u00adple, to dis\u00adtrib\u00adute mul\u00adti\u00adpli\u00adca\u00adtion  on the top lev\u00adel, it was im\u00adpos\u00adsi\u00adble.    \n So I de\u00adcid\u00aded to start and fix  is\u00adsue 1455.  I now have a branch ready in my github ac\u00adcount (see  here).    \n With my patch, you can now choose to ex\u00adpand us\u00ading each of the above in\u00addi\u00advid\u00adu\u00adal\u00adly with the log, mul, multi\u00adno\u00admi\u00adal, pow\u00ader_\u00adex\u00adp, pow\u00ader_base.  In ad\u00addi\u00adtion to this, you al\u00adso now have com\u00adplete con\u00adtrol of how deep the ex\u00adpres\u00adsion re\u00adcurs\u00ades in the ex\u00adpand.  Pre\u00advi\u00adous\u00adly, you could\u00adn't, for ex\u00adam\u00adple, ex\u00adpand $la\u00adtex x(y+e{x(y+z)})$ to $la\u00adtex xy+x\u00ade{x(y+z)}$. (It would al\u00adso dis\u00adtrib\u00adute the ex\u00adpo\u00adnen\u00adt, then ex\u00adpand to $la\u00adtex e{xy}e{xz}$).  Now, you can choose to on\u00adly dis\u00adtrib\u00adute mul\u00adti\u00adpli\u00adca\u00adtion over ad\u00addi\u00adtion, and to on\u00adly do it on the top lev\u00adel.    \n Au\u00adto\u00admat\u00adic ex\u00adpan\u00adsion of ex\u00adpo\u00adnents \n I men\u00adtioned above that ex\u00adpand would ex\u00adpand $la\u00adtex e{xy+xz}$ to $la\u00adtex e{xy}e{xz}$. Ac\u00adtu\u00adal\u00adly, in the cur\u00adrent ver\u00adsion of SymPy, this would not hap\u00adpen be\u00adcause it au\u00adto\u00admat\u00adi\u00adcal\u00adly com\u00adbines ex\u00adpo\u00adnents like $la\u00adtex e{xy}e{xz}$ to $la\u00adtex e{xy+xz}$.    \n I have been work\u00ading for the past few weeks chang\u00ading this as per  is\u00adsue 252.   I have been most\u00adly suc\u00adcess\u00adful, ex\u00adcept there are two nseries tests that I can\u00adnot fig\u00adure out how to fix.  If you think you know why nseries would fail with\u00adout au\u00adto\u00admat\u00adic com\u00adbin\u00ading of ex\u00adpo\u00adnents, please let me know.  The ex\u00adpand branch in my GitHub re\u00adpo al\u00adso has the ex\u00adpo\u00adnent patch\u00ades in it, if you want to see what I mean.    \n Be\u00adcause some things, like the gruntz al\u00adgo\u00adrith\u00adm, re\u00adly on au\u00adto\u00admat\u00adic com\u00adbin\u00ading of ex\u00adpo\u00adnents, so I had to re\u00adwork powsim\u00adp, which com\u00adbined ex\u00adpo\u00adnents but al\u00adso com\u00adbined bases ($la\u00adtex xaya$ to $la\u00adtex (xy)a$) so that it could on\u00adly com\u00adbine ex\u00adpo\u00adnents.  That way, I could use it to get the old be\u00adhav\u00adior where I need\u00aded it.  Use  powsim\u00adp(\u00adex\u00adpr, deep\u00ad=True, com\u00adbine='\u00adex\u00adp')  in my branch to get the old au\u00adto\u00admat\u00adic be\u00adhav\u00adior.    \n So what does this have to do with ODEs? \n When I start\u00aded work\u00ading on sep\u00ada\u00adra\u00adble equa\u00adtion\u00ads, I want\u00aded to be able to sep\u00ada\u00adrate things like $la\u00adtex e{x+y}$ in\u00adto $la\u00adtex ex\u00adey$, which is sep\u00ada\u00adra\u00adble in $la\u00adtex x$ and $la\u00adtex y$.  So that is why I need\u00aded to refac\u00adtor ex\u00adpand (I don't, for ex\u00adam\u00adple, want to change $la\u00adtex x(y+1)$ to $la\u00adtex xy+x$ be\u00adcause the lat\u00ader is not eas\u00adi\u00adly rec\u00adog\u00adniz\u00adable as sep\u00ada\u00adrate.  Do\u00ading this or course re\u00adquired that SymPy did\u00adn't au\u00adto\u00admat\u00adi\u00adcal\u00adly put back to\u00adgeth\u00ader $la\u00adtex ex\u00adey$ in\u00adto $la\u00adtex e{x+y}$, so I had to fix that is\u00adsue as well.    \n I am al\u00admost fin\u00adished im\u00adple\u00adment\u00ading sep\u00ada\u00adra\u00adble (there are some match is\u00adsues that I will blog about lat\u00ader when\u00adev\u00ader I get them straight\u00adened out\u00ad), and the on\u00adly thing that is hold\u00ading all of this back is those nseries test\u00ads.  If any\u00adone is fa\u00admil\u00adiar with how those al\u00adgo\u00adrithms work and which parts re\u00adquire au\u00adto\u00admat\u00adic com\u00adbin\u00ading of ex\u00adpo\u00adnents, that would be great.", 
      "loc": "/posts/2009/06/21/refactoring-expand/"
    }, 
    {
      "title": "Vacation", 
      "tags": "", 
      "text": "I am on va\u00adca\u00adtion now.  I am vis\u00adit\u00ading the Grand Canyon, Hoover Dam, Yel\u00adlow\u00adstone, and oth\u00ader places.  I will be able to do some cod\u00ading on the road, but not as much as when I am home.  The va\u00adca\u00adtion will last about a week.  Hope\u00adful\u00adly I will be able to get a blog post about what I have been do\u00ading in SymPy writ\u00adten up in the next few days.", 
      "loc": "/posts/2009/06/13/vacation/"
    }, 
    {
      "title": "git stash", 
      "tags": "", 
      "text": "I've al\u00adways won\u00addered what the com\u00admand is that lets you do stuff like change branch\u00ades and check\u00adout to old\u00ader states with\u00adout com\u00admit\u00ading, since git won't let you do any\u00adthing if you haven't com\u00admit\u00aded.    \n Well, I found the an\u00adswer.  It's  git stash.  I think I will be us\u00ading this a lot, con\u00adsid\u00ader\u00ading how of\u00adten my work\u00adflow gets in\u00adter\u00adrupt\u00aded.  I wish I knew about it be\u00adfore I start\u00aded work\u00ading on this ex\u00adpo\u00adnen\u00adti\u00ada\u00adtion mess (more on that lat\u00ader).    \n It is al\u00adso nicer to test if my code breaks an old fea\u00adture to stash in\u00adstead of test\u00ading in sympy 0.6.4 in\u00adstalled on my sys\u00adtem.    \n UP\u00adDATE: No won\u00adder I did\u00adn't find this ear\u00adli\u00ader.   stash  is\u00adn't list\u00aded in  git --help.", 
      "loc": "/posts/2009/06/05/git-stash/"
    }, 
    {
      "title": "Separable next", 
      "tags": "mathjax", 
      "text": "So the next thing on my  list  is seper\u00ada\u00adble dif\u00adfer\u00aden\u00adtial equa\u00adtion\u00ads.  As I pre\u00addict\u00aded in my pro\u00adpos\u00adal, I am go\u00ading to have to do some work to get SymPy to rec\u00adog\u00adnize all equa\u00adtions that are sep\u00ada\u00adra\u00adble.  Cur\u00adrent\u00adly, it can match ex\u00adpres\u00adsions that are ex\u00adact\u00adly writ\u00adten as $la\u00adtex a(x)b(y)\\frac{dy}{dx}+c(x)d(y)=0$, such as $la\u00adtex x2(y+2)\\frac{dy}{dx}-y3=0$ but the match\u00ading en\u00adgine can\u00adnot get things like $la\u00adtex (x2y+2x2)\\frac{dy}{dx}+-y3=0$, be\u00adcause it does\u00adn't know how to fac\u00adtor out the $la\u00adtex x2$.  There is a func\u00adtion, col\u00adlec\u00adt, that can fac\u00adtor out ex\u00adpres\u00adsions if you give them to it ex\u00adpli\u00adci\u00adly with \n col\u00adlec\u00adt(x2*y+x2,x**2) \n but it does\u00adn't know yet how to sep\u00ada\u00adrate vari\u00adables in gen\u00ader\u00adal.  So I will be work\u00ading on it this week.  Once it can prop\u00ader\u00adly sep\u00ada\u00adrate sep\u00ada\u00adra\u00adble ex\u00adpres\u00adsion\u00ads, im\u00adple\u00adment\u00ading it in dsolve will be cake.    \n Al\u00adso, it needs to learn how to do $la\u00adtex e{x+y}\\rightar\u00adrow e{x}e{y}$ and $la\u00adtex 1+x+y+xy \\rightar\u00adrow (1+x)(1+y)$.", 
      "loc": "/posts/2009/05/31/separable-next/"
    }, 
    {
      "title": "First Order Differential Equations with Homogeneous Coefficients", 
      "tags": "mathjax", 
      "text": "So here is what I have done. \u00a0Ho\u00admo\u00adge\u00adneous has  sev\u00ader\u00adal mean\u00adings, but when I use it in this post, I will mean  ho\u00admo\u00adge\u00adneous func\u00adtions. \u00a0We on\u00adly care about func\u00adtions of two vari\u00adables, so I will al\u00adso on\u00adly talk about them. \u00a0A func\u00adtion $la\u00adtex F(x,y) $\u00a0is called ho\u00admo\u00adge\u00adneous of or\u00adder $la\u00adtex n$ if $la\u00adtex F(tx,\u00adty)=tn\u00adF(x,y)$\u00a0\u00adfor some $la\u00adtex n$. \u00a0Al\u00adso, if we \"pul\u00adl\" an $la\u00adtex x$\u00a0out, we get $la\u00adtex F(x,y)=xn\u00adF(1,\\frac{x}{y})=xnG(\\frac{y}{x})$, which is why the def\u00adi\u00adni\u00adtion is of\u00adten stat\u00aded that the func\u00adtion can be writ\u00adten as a func\u00adtion of $la\u00adtex \\frac{y}{x} $. \u00a0Of course, we could do the same with $la\u00adtex y$\u00a0and get a func\u00adtion of $la\u00adtex \\frac{x}{y}$. \u00a0Here is an ex\u00adam\u00adple of a ho\u00admo\u00adge\u00adneous\u00a0\u00adfunc\u00adtion: $la\u00adtex x2+y\\sqrt{x2+y2}\\s\u00adin{\\frac{x}{y}}$. \u00a0Y\u00adou can see that $la\u00adtex (x\u00adt)2+yt\\sqrt{(x\u00adt)2+(yt)2}\\s\u00adin{\\frac{x\u00adt}{yt}}=t2\\left\u00ad(x2+y\\sqrt{x2+y2}\\s\u00adin{\\frac{x}{y}}\\right)$.   \n Now, if the co\u00adef\u00adfi\u00adcients $la\u00adtex P$\u00a0and $la\u00adtex Q$\u00a0in the\u00a0\u00adfirst or\u00adder dif\u00adfer\u00aden\u00adtial equa\u00adtion $la\u00adtex P(x,y)dx+Q(x,y)dy=0$\u00a0are both ho\u00admo\u00adge\u00adneous func\u00adtions of the same or\u00adder, then the sub\u00adsti\u00adtu\u00adtion $la\u00adtex x=uy$\u00a0or $la\u00adtex y=ux$\u00a0will make the equa\u00adtion\u00a0sep\u00ada\u00adra\u00adble. \u00a0I will show how to do it for $la\u00adtex y=ux$. \u00a0We have $la\u00adtex dy=xdy+udx$\u00a0\u00adby the prod\u00aduct rule. \u00a0We al\u00adso have $la\u00adtex P(x,y)=P(x,x\u00adu)$ and $la\u00adtex Q(x,y)=Q(x,x\u00adu)$. \u00a0Be\u00adcause these func\u00adtions are ho\u00admo\u00adge\u00adneous, we can \"pull out\" an $la\u00adtex xn$\u00a0from each, giv\u00ading us $la\u00adtex xn\u00adP(1,u)dx+xn\u00adQ(1,u)(x\u00addu+udx)=0$. \u00a0Be\u00adcause we made the sub\u00adsti\u00adtu\u00adtion $la\u00adtex u=\\frac{y}{x}$, we al\u00adready have had to as\u00adsume $la\u00adtex x\\neq0$. \u00a0Thus, we can di\u00advide the whole thing by $la\u00adtex xn$. \u00a0Do\u00ading this, and ex\u00adpand\u00ading the re\u00admain\u00ading terms, we get $la\u00adtex P(1,u)dx+xQ(1,u)\u00addu+uQ(1,u)dx=0$. \u00a0Refac\u00adtor\u00ading the $la\u00adtex dx$ and $la\u00adtex dy$ terms, we get $la\u00adtex (P(1,u)+uQ(1,u))dx=-xQ(1,u)\u00addu$. \u00a0The equa\u00adtion is\u00a0sep\u00ada\u00adra\u00adble! \u00a0Sep\u00ada\u00adrat\u00ading\u00a0\u00advari\u00adables and in\u00adte\u00adgrat\u00ading, we get\u00a0$la\u00adtex \\in\u00adt{\\frac{dx}{x}}=\\in\u00adt{\\frac{-Q(1,u)\u00addu}{P(1,u)+uQ(1,u)}}+C$. \u00a0If we had used $la\u00adtex x=uy$ in\u00adstead, we would have got\u00adten $la\u00adtex \\in\u00adt{\\frac{dy}{y}}=\\in\u00adt{\\frac{-P(u,1)\u00addu}{uP(u,1)+Q(u,1)}}+C$. \u00a0This is ex\u00adact\u00adly how I was able to solve these equa\u00adtions in SymPy. \u00a0Each ho\u00admo\u00adge\u00adneous equa\u00adtion has two pos\u00adsi\u00adble in\u00adte\u00adgral\u00ads, and of\u00adten the right hand side of one equa\u00adtion is a much hard\u00ader in\u00adte\u00adgral than the right hand side of the oth\u00ader. \u00a0There\u00adfore, I did them both, and ap\u00adplied a lit\u00adtle\u00a0heuris\u00adtic\u00a0on which one to re\u00adturn. \u00a0It prefers ex\u00adpres\u00adsions that can be solved for y (f(x) in the case of SymPy),\u00a0\u00adex\u00adpres\u00adsion\u00ads\u00a0that have eval\u00adu\u00adat\u00aded in\u00adte\u00adgral\u00ads, and if nei\u00adther of them are solv\u00adable, the short\u00adest one, which tends to be the sim\u00adplest.   \n Here is an ex\u00adam\u00adple from my text book. \u00a0$la\u00adtex 2xy\u00addx+(x2+y2)dy=0$. \u00a0As\u00adtute read\u00aders of this blog may have no\u00adticed that this equa\u00adtion is  ex\u00adact. \u00a0It is eas\u00adi\u00ader to solve that way, but we will try us\u00ading the meth\u00adods out\u00adlined above. \u00a0First, we no\u00adtice that the co\u00ade\u00adfi\u00adcients of $la\u00adtex dx$ and $la\u00adtex dy$ are both ho\u00admo\u00adge\u00adneous of or\u00adder 2, so we can make the sub\u00adsti\u00adtu\u00adtion $la\u00adtex x=uy$ or $la\u00adtex u=yx$ and the equa\u00adtion would be\u00adcome seper\u00ada\u00adble. \u00a0If I were do\u00ading this by hand or for a home\u00adwork as\u00adsign\u00admen\u00adt, I would make one of those sub\u00adsti\u00adtu\u00adtions and work it through, but we have the ex\u00adact form above, so let's use it just like SymPy would. \u00a0$la\u00adtex P(x,y)=2xy $ and $la\u00adtex Q(x,y)=x2+y2$. \u00a0So we get $la\u00adtex \\in\u00adt{\\frac{dx}{x}}=\\in\u00adt{\\frac{-(1+u2)\u00addu}{2u+u(1+u2)}}+C$ with $la\u00adtex u=\\frac{y}{x}$ and $la\u00adtex \\in\u00adt{\\frac{dy}{y}}=\\in\u00adt{\\frac{-2udu}{u(2u)+(1+u2)}}+C$ with $la\u00adtex u=\\frac{x}{y}$ (here and for the re\u00admain\u00adder of this deriva\u00adtion, the ar\u00adbi\u00adtrary con\u00adstants in the two equa\u00adtions do not nec\u00ades\u00adsar\u00adi\u00adly equal each oth\u00ader un\u00adtil the last step). \u00a0Both in\u00adte\u00adgrals can be solved \u00a0with a\u00a0\u00adsub\u00adsti\u00adtu\u00adtion\u00a0of the de\u00adnom\u00adi\u00adna\u00adtor, giv\u00ading, with $la\u00adtex u$ back sub\u00adsti\u00adtut\u00aded, $la\u00adtex \\l\u00adn{x}=\\frac{-\\l\u00adn{(\\frac{y3}{x3}+\\frac{3y}{x})}}{3}+C$ and $la\u00adtex \\l\u00adn{y}=\\frac{-\\l\u00adn{(\\frac{3x3}{y3}+1)}}{3}+C$. \u00a0If we make $la\u00adtex C=l\u00adn(C_1)$, and pull the con\u00adstants in front of the logs on the right hand sides in as pow\u00ader\u00ads, we can com\u00adbine ev\u00adery\u00adthing in\u00adto log\u00ada\u00adrithm\u00ads. \u00a0After do\u00ading that, we then take the an\u00adtilog of both sides and get $la\u00adtex x=C_1{(\\frac{y3}{x3}+\\frac{3y}{x})}{-\\frac{1}{3}}$ and $la\u00adtex y=C_1{(\\frac{3x3}{y3}+1)}{-\\frac{1}{3}}$. \u00a0We then raise the whole equa\u00adtion to the $la\u00adtex -3$ pow\u00ader and make $la\u00adtex C_1{-3}=A$. \u00a0We get \n $la\u00adtex \\frac{1}{x3}=A(\\frac{y3}{x3}+3\\frac{y}{x})$ \n $la\u00adtex \\frac{1}{x3}=A\\frac{y3+3x2y}{x3}$ \n $la\u00adtex K=y3+3x2y$   \n and   \n $la\u00adtex \\frac{1}{y3}=A(\\frac{3x2}{y2}+1)$ \n $la\u00adtex \\frac{1}{y}=A(3x2y+y2)$ \n $la\u00adtex K=y3+3x2y$, \n where $la\u00adtex K=\\frac{1}{A}$ \n Ver\u00adi\u00adfy as an ex\u00ader\u00adcise that you get the same so\u00adlu\u00adtion by the ex\u00adact dif\u00adfer\u00aden\u00adtial equa\u00adtion meth\u00adods (or  don't... you know, de\u00adpend\u00ading on which you'd rather do). \n Of course, if that was all there was to it, I would have fin\u00adished in a day. \u00a0There was more. \u00a0First, I had to write a func\u00adtion that de\u00adter\u00admines if an ex\u00adpres\u00adsion is ho\u00admo\u00adge\u00adneous and what or\u00adder if it is.  That was about 150 lines of code right there plus tests (150 lines is a lot in Python).     \n I al\u00adso want\u00aded it to rec\u00adog\u00adnize that $la\u00adtex \\l\u00adn{x}-\\l\u00adn{y}$ is ho\u00admo\u00adge\u00adneous be\u00adcause $la\u00adtex \\l\u00adn{x}-\\l\u00adn{y}=\\l\u00adn{\\frac{x}{y}}$.  SymPy was in\u00adca\u00adpable of com\u00adbin\u00ading log\u00ada\u00adrithms like this, so I had to write a log\u00adcom\u00adbine func\u00adtion, which was an\u00adoth\u00ader 100 lines of code plus test\u00ads.  This came in handy, be\u00adcause I was al\u00adso able to use it in the part above where I com\u00adbined the log\u00ada\u00adrithms of my an\u00adswer to elim\u00adi\u00adnate all of them.    \n Last\u00adly, you may have no\u00adticed that my math looks much nicer in this post.  It turns out that Word\u00adPress sup\u00adports math us\u00ading $la\u00adtex  <math>$.  Un\u00adfor\u00adtu\u00adnate\u00adly, I did not dis\u00adcov\u00ader this un\u00adtil I had al\u00adready up\u00adload\u00aded im\u00adages of al\u00admost all the math ex\u00adpres\u00adsions in the post, so I had to go back and fix them.    \n Al\u00adso, I was hav\u00ading a prob\u00adlem where the math would\u00adn't ren\u00adder, but it turns out that this was an is\u00adsue with me copy\u00ading and past\u00ading \"$la\u00adtex\" and the ex\u00adpres\u00adsions in\u00adto the Word\u00adPress rich text ed\u00adi\u00adtor.  I changed my ed\u00adi\u00adtor set\u00adtings to plain tex\u00adt.  I'm sor\u00adry, but web rich text ed\u00adi\u00adtors do not work.  And I've grown ac\u00adcus\u00adtomed to see\u00ading the source of stuff that I write hav\u00ading done ev\u00adery\u00adthing in $la\u00adtex \\La\u00adTeX$ for a year and hav\u00ading edit\u00aded Wikipedia for a while.   \n I wish there were a free blog\u00adging site like Word\u00adPress or Blog\u00adger that used Me\u00addi\u00adaWi\u00adki or $la\u00adtex \\La\u00adTeX$ as its ren\u00adder\u00ading en\u00adgine.  It would look nice, the for\u00admat\u00adting would be a stan\u00addard thing that is\u00adn't con\u00adfus\u00ading htm\u00adl, and $la\u00adtex \\La\u00adTeX$ math would come out much nicer.", 
      "loc": "/posts/2009/05/31/first-order-differential-equations-with-homogeneous-coefficients/"
    }, 
    {
      "title": "Just finished a new bit.", 
      "tags": "", 
      "text": "I just fin\u00adished first or\u00adder ho\u00admo\u00adge\u00adneous equa\u00adtion\u00ads, as well as my log\u00adcom\u00adbine func\u00adtion, and I have pushed them to  http://github.\u00adcom/as\u00admeur\u00ader/sympy/tree/odes-stable. \u00a0So ex\u00adpect a ma\u00adjor blog post\u00ading about them both soon (it is mid\u00adnight right now, so bed\u00adtime, maybe to\u00admor\u00adrow). \n If you are a mem\u00adber of the SymPy project read\u00ading this,  please, re\u00adview my patch\u00ades. \u00a0I have al\u00adready sub\u00admit\u00adted ex\u00adact equa\u00adtions and the log\u00adcom\u00adbine\u00a0\u00adfunc\u00adtion, and nei\u00adther of them have made it in. \u00a0And the more re\u00adview\u00ading that there is, the bet\u00adter for my code.", 
      "loc": "/posts/2009/05/30/just-finished-a-new-bit/"
    }, 
    {
      "title": "One problem solved", 
      "tags": "", 
      "text": "Well, I fig\u00adured out why my patch files are\u00a0ap\u00adpear\u00ading\u00a0\u00adcor\u00adrupt\u00aded to ev\u00adery\u00adone. \u00a0It is close to what I ex\u00adpect\u00aded. \u00a0The files had a Mac\u00adin\u00adtosh char\u00adac\u00adter en\u00adcod\u00ading, when ev\u00adery\u00adone was ex\u00adpect\u00ading UT\u00adF-8. \u00a0Chang\u00ading the en\u00adcod\u00ading with Tex\u00adtWran\u00adgler was easy enough, but now the ques\u00adtion is, how do I make git use this en\u00adcod\u00ading by de\u00adfault?", 
      "loc": "/posts/2009/05/25/one-problem-solved/"
    }, 
    {
      "title": "Patch Problems and Updates", 
      "tags": "", 
      "text": "So the GSoC pro\u00adgram of\u00adfi\u00adcial\u00adly start\u00aded Sat\u00adur\u00adday. \u00a0I have al\u00admost fin\u00adished ev\u00adery\u00adthing on the time\u00adline for the first week al\u00adready, ex\u00adcept for ini\u00adtial con\u00addi\u00adtion\u00ads, which I am putting off un\u00adtil On\u00addrej re\u00adcodes solve so that it re\u00adturns a RootOf in\u00adstance when it can\u00adnot solve the equa\u00adtion. \u00a0See this  post. \n In or\u00adder to solve ho\u00admo\u00adge\u00adneous equa\u00adtion\u00ads, I had to de\u00adter\u00admine if an equa\u00adtion is ho\u00admo\u00adge\u00adneous. \u00a0I will post what all this mean\u00ads, when I fin\u00adish ev\u00adery\u00adthing up. \u00a0Right now, I just need to write a few more tests and make sure that they work. \u00a0So I wrote the func\u00adtion, which is very com\u00adpli\u00adcat\u00aded, be\u00adcause it has to take any ex\u00adpres\u00adsion and break it up re\u00adcur\u00adsive\u00adly. \u00a0One thing that I want\u00aded for it to do is to re\u00adal\u00adize that log(x)-log(y) == log(x/y) (no La\u00adTeX to\u00adday, I am too tired). \u00a0This is ba\u00adsi\u00adcal\u00adly be\u00adcause just log(x) or log(y) will make it non-ho\u00admo\u00adge\u00adneous, but log(x/y) will make is ho\u00admo\u00adge\u00adneous (a\u00adgain, more on what this all means lat\u00ader). \u00a0It turns out SymPy could not re\u00adal\u00adly do this sim\u00adpli\u00adfi\u00adca\u00adtion, so I had to go in and write a log\u00adcom\u00adbine func\u00adtion that did that. \u00a0The func\u00adtion works quite well (at least from my test\u00ads), but it is al\u00adso a beefy piece or re\u00adcur\u00adsive work. \n So here is the part where I am now. \u00a0I want\u00aded to sub\u00admit the log\u00adcom\u00adbine func\u00adtion as a reg\u00adu\u00adlar patch, be\u00adcause strict\u00adly speak\u00ading it is not re\u00adlat\u00aded to my GSoC projec\u00adt. \u00a0So I used 'git for\u00admat-\u00adpatch' and git 'send-e\u00admail' as usu\u00adal. \u00a0But then, yes\u00adter\u00adday, I be\u00adgan to won\u00adder why no one had re\u00adviewed or even re\u00adspond\u00aded to my patch\u00ades. \u00a0I checked that patch list, and found to my dis\u00admay that none of the emails made it through. \u00a0I sus\u00adpect that git is the prob\u00adlem, so I send the patch\u00ades man\u00adu\u00adal\u00adly with my email clien\u00adt. \n Which led to an\u00adoth\u00ader prob\u00adlem: the re\u00adview\u00aders are claim\u00ading that my files are\u00a0\u00adcor\u00adrup\u00adt. \u00a0These are ma\u00adjor prob\u00adlem\u00ads. \u00a0I can\u00adnot re\u00adli\u00adably send patch emails through git, and when I send them man\u00adu\u00adal\u00adly, the files are messed up. \n Can any\u00adone read\u00ading this blog (does any\u00adone ac\u00adtu\u00adal\u00adly read this blog?) give me some ad\u00advice here? \u00a0I think the cor\u00adrup\u00adtion of the patch files  may  have some\u00adthing to do with the fact that I am us\u00ading Mac OS X, which I know likes to put nasty things like re\u00adsource forks in files which screws them up when they are sent to non-\u00adMac\u00ads. \n Of course, this does not ex\u00adplain why git will not send email\u00ads. \u00a0It has sent them  be\u00adfore, though I think I have had this prob\u00adlem since the  be\u00adgin\u00adning. \n And an\u00adoth\u00ader ques\u00adtion to you git ge\u00adnius\u00ades out there: how do I change branch\u00ades with\u00adout\u00a0\u00adcom\u00admit\u00adting\u00a0changes? \u00a0Some\u00adtimes, I am in the mid\u00addle of two things, and I fin\u00adish one and I want to push it to its own branch, but I can\u00adnot do this with\u00adout\u00a0\u00adcom\u00admit\u00adting\u00a0the changes on the oth\u00ader thing, which I am not ready to do be\u00adcause I am not done with it yet.", 
      "loc": "/posts/2009/05/25/patch-problems-and-updates/"
    }, 
    {
      "title": "Work started -- Exact Differential Equations", 
      "tags": "", 
      "text": "I have de\u00adcid\u00aded to start work\u00ading on my pro\u00adjec\u00adt, even though it is a week ear\u00adly, since I am fin\u00adished with school and have noth\u00ading bet\u00adter to do. \u00a0I al\u00adso like the idea of get\u00adting ahead. \u00a0I am push\u00ading ev\u00adery\u00adthing to my\u00a0 github ac\u00adcount. \u00a0So far, I have im\u00adple\u00adment\u00aded\u00a0 ex\u00adact dif\u00adfer\u00aden\u00adtial equa\u00adtions, which are cake (i.e., they took me about an hour to code up\u00ad). \u00a0These are equa\u00adtions of the type,where. \u00a0If this con\u00addi\u00adtion hold\u00ads, then there ex\u00adists a func\u00adtion, of\u00adten called a 'po\u00adten\u00adtial func\u00adtion' be\u00adcause of some ap\u00adpli\u00adca\u00adtions of the\u00adses equa\u00adtions to physic\u00ads, such thatand. \u00a0This is be\u00adcause mixed par\u00adtials are equal for con\u00adtin\u00adu\u00adous func\u00adtion\u00ads. \u00a0The so\u00adlu\u00adtion will then just be. \u00a0The tricky part is find\u00ading the po\u00adten\u00adtial func\u00adtion, but it turns out to be eas\u00adi\u00ader than you would think. \u00a0Be\u00adcause of the fun\u00adda\u00admen\u00adtal the\u00ado\u00adrem of cal\u00adcu\u00adlus, the po\u00adten\u00adtial func\u00adtion is just. \u00a0There is a re\u00adstric\u00adtion where the rec\u00adtan\u00adgle con\u00adnect\u00ading,,, andhas to lie en\u00adtire\u00adly in the do\u00admain of    and, but if we let, then this is not re\u00adal\u00adly a prob\u00adlem for func\u00adtions that SymPy will en\u00adcounter. \u00a0UP\u00adDATE: It turns out this is a prob\u00adlem if the equa\u00adtion has sin\u00adgu\u00adlar\u00adi\u00adties in it. \u00a0For\u00adtu\u00adnate\u00adly, I was able to code up a work\u00adaround that usu\u00adal\u00adly work\u00ads. \n So you can see that this is easy to im\u00adple\u00adment in SymPy if you know the above fac\u00adt. \u00a0It turns out that most so\u00adlu\u00adtion meth\u00adods for ODEs are like this. \u00a0They can be solved in the gen\u00ader\u00adal case, al\u00adthough usu\u00adal\u00adly stu\u00addents are on\u00adly taught tricks be\u00adcause they are much eas\u00adi\u00ader to re\u00admem\u00adber than gen\u00ader\u00adal\u00adly solved for\u00admu\u00adlas. \u00a0For ex\u00adam\u00adple, to solve an ex\u00adact dif\u00adfer\u00aden\u00adtial equa\u00adtion, stu\u00addents are of\u00adten taught to just in\u00adte\u00adgratewith re\u00adspect toandwith re\u00adspect to. \u00a0It is much sim\u00adpler for a hu\u00adman be\u00ading to do that than the above in\u00adte\u00adgral, be\u00adcause the in\u00adte\u00adgral in\u00advolves eval\u00adu\u00adat\u00ading lim\u00adits and so on, but for a com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtem, the above in\u00adte\u00adgral is a one-\u00adlin\u00ader. \n By the way, if you want to test my code, you should clone my github repos\u00adi\u00adto\u00adry and switch to the odes branch. \u00a0Y\u00adou can do this by typ\u00ading 'git clone git://github.\u00adcom/as\u00admeur\u00ader/sympy.git' and then 'git check\u00adout odes' in a Ter\u00admi\u00adnal that is cd'd to the di\u00adrec\u00adto\u00adry you want to clone to (of course, you will need git in\u00adstalled first!). \u00a0Then type 'cd sympy' and './bin/isympy', which will start SymPy. \u00a0Then from there, you can do stuff like 'd\u00adsolve(s\u00adin(x)cos(f(x))+\u00adcos(x)sin(f(x))f(x).d\u00adif\u00adf(x),f(x)' (this is ex\u00adac\u00adt). \u00a0It's easy to gen\u00ader\u00adate an ex\u00adact dif\u00adfer\u00aden\u00adtial equa\u00adtion. \u00a0Just start with a ran\u00addom func\u00adtion of x and y, then take the\u00a0deriva\u00adtive\u00a0of it with re\u00adspect to x and y each, and do a sub\u00ads(y,f(x)) on each term (SymPy wants func\u00adtions for the de\u00adpen\u00addent vari\u00adable, so we have to use f(x)). \u00a0Then do dsolve(<the de\u00adriv\u00ada\u00adtive with\u00ad\u00a0re\u00adspec\u00adt\u00a0\u00adto x>+<the de\u00adriv\u00ada\u00adtive with re\u00adspect to y>f(x).d\u00adif\u00adf(x),f(x)). \u00a0Y\u00adou should get your orig\u00adi\u00adnal func\u00adtion equals an ar\u00adbi\u00adtrary con\u00adstant C1. \u00a0By the way, dif\u00adf(<\u00adfunc\u00adtion>,x) will take the\u00a0deriva\u00adtive of <func\u00adtion> with re\u00adspect to x. \n Up nex\u00adt: Ini\u00adtial con\u00addi\u00adtion\u00ads, and then first or\u00adder ho\u00admo\u00adge\u00adneous dif\u00adfer\u00aden\u00adtial equa\u00adtion\u00ads.", 
      "loc": "/posts/2009/05/16/work-started-exact-differential-equations/"
    }, 
    {
      "title": "My GSoC Proposal", 
      "tags": "", 
      "text": "I have copied my pro\u00adpos\u00adals over to the SymPy Wi\u00adki and for\u00admat\u00adted them so that they look nice (in\u00adclud\u00ading La\u00adTeX for the for\u00admu\u00adlas). \u00a0I in\u00adclud\u00aded both the Port\u00adland State Uni\u00adver\u00adsi\u00adty pro\u00adpos\u00adal, which was ac\u00adcept\u00aded (at the top), and the Python Soft\u00adware Foun\u00adda\u00adtion pro\u00adpos\u00adal, which was near\u00adly iden\u00adti\u00adcal, but was not ac\u00adcept\u00aded. \u00a0I did this main\u00adly for my\u00adself so I can eas\u00adi\u00adly find my time\u00adline dur\u00ading the sum\u00admer, but if any\u00adone wants to see what my pro\u00adpos\u00adal looked like, here it is. \u00a0Note that I am pret\u00adty sure that the time\u00adline on the pro\u00adpos\u00adal will not be the same as what I will ac\u00adtu\u00adal\u00adly do (e.g., I have learned much less about sys\u00adtems of ODEs (0), than I ex\u00adpect\u00aded, and I have learned about a cou\u00adple new sym\u00adbol\u00adic meth\u00adod\u00ads). \n The link is  here.", 
      "loc": "/posts/2009/05/08/my-gsoc-proposal/"
    }, 
    {
      "title": "Git Tutorial", 
      "tags": "", 
      "text": "So I was brows\u00ading the  Google Open Source Blog, when I found a link to this  Git Tu\u00adto\u00adri\u00adal. \u00a0I wish I had found this a month ago when I start\u00aded learn\u00ading Git. \u00a0SymPy on\u00adly has a very ba\u00adsic tu\u00adto\u00adri\u00adal for Git. \u00a0Their main tu\u00adto\u00adri\u00adal is still writ\u00adten for Mer\u00adcu\u00adri\u00adal, which they used un\u00adtil re\u00adcent\u00adly. \n Any\u00adway, I have been read\u00ading the tu\u00adto\u00adri\u00adal, and so far it is awe\u00adsome, so I thought it would make a good post here.", 
      "loc": "/posts/2009/04/26/git-tutorial/"
    }, 
    {
      "title": "About", 
      "tags": "", 
      "text": "I am a grad\u00adu\u00adate stu\u00addent in Math\u00ade\u00admat\u00adics New Mex\u00adi\u00adco State Uni\u00adver\u00adsi\u00adty at Las Cruces, NM, though I re\u00adside in Al\u00adbu\u00adquerque, NM for the sum\u00admer time.", 
      "loc": "/stories/about/"
    }, 
    {
      "title": "First Post!", 
      "tags": "", 
      "text": "Well, I got ac\u00adcept\u00aded in\u00adto the Google Sum\u00admer of Code pro\u00adgram for 2009. I will be work\u00ading on\u00a0 SymPy, a com\u00adput\u00ader al\u00adge\u00adbra sys\u00adtem writ\u00adten and run in Python. I will be work\u00ading on build\u00ading an or\u00addi\u00adnary dif\u00adfer\u00aden\u00adtial equa\u00adtion en\u00adgine for it, as its present ca\u00adpa\u00adbil\u00adi\u00adties are very lim\u00adit\u00aded. You can look at my ap\u00adpli\u00adca\u00adtion\u00a0 ab\u00adstract. SymPy re\u00adquires that I blog about my work at least once a week, so here it is. More will be post\u00aded here lat\u00ader.\n Originally I started this blog on blogger, but I think WordPress will be a little better. \u00a0Name\u00adly, it seems to sup\u00adport  plug\u00adins, so I can in\u00adsert La\u00adTeX code much eas\u00adi\u00ader.  It would seem that on\u00adly blogs not host\u00aded at word\u00adpress.\u00adcom sup\u00adport plug\u00adins.\nSo I think I will \u00a0just use LaTeXiT and do it manually. \u00a0Oh well. \u00a0Anyway, here is the Divergence Theorem, which nicely shows both mathematical beauty and LaTeX beauty.", 
      "loc": "/posts/2009/04/22/first-post/"
    }
  ]
}