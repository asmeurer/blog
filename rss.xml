<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aaron Meurer's Blog</title><link>https://asmeurer.com/blog/</link><description>My blog</description><atom:link href="https://asmeurer.com/blog/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 27 Dec 2022 22:34:22 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>The SymPy/HackerRank DMCA Incident</title><link>https://asmeurer.com/blog/posts/the-sympy-hackerrank-dmca-incident/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;&lt;em&gt;Thank you to Ondřej Čertík, Oscar Benjamin, Travis Oliphant, and Pamela Chestek for reviewing this blog post. Any errors in the post are my own.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;On April 19, 2022, for approximately 11.5 hours, the &lt;a href="https://docs.sympy.org/"&gt;documentation website&lt;/a&gt; for the open source &lt;a href="https://www.sympy.org/"&gt;SymPy&lt;/a&gt; project and the &lt;a href="https://github.com/sympy/sympy_doc"&gt;corresponding GitHub repository&lt;/a&gt; were taken down as a result of a &lt;a href="https://github.com/github/dmca/blob/master/2022/04/2022-04-15-hackerrank.md"&gt;DMCA takedown notice&lt;/a&gt; submitted by WorthIT Solutions on behalf of HackerRank. In this post, I’d like to explain what the DMCA is and how it works, detail exactly what happened with this incident, and go over my views on the incident and some of the lessons we’ve learned as a result.&lt;/p&gt;
&lt;h2&gt;What is the DMCA?&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;The information in this section has been drawn from various sources, including:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href="https://assets.fenwick.com/legacy/FenwickDocuments/DMCA-QA.pdf"&gt;“Your DMCA Safe Harbor Questions Answered”&lt;/a&gt; Mitchell Zimmerman (2017)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;The EFF’s &lt;a href="https://www.eff.org/wp/unintended-consequences-16-years-under-dmca"&gt;Unintended Consequences - 16 Years Under the DMCA&lt;/a&gt; (2014)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;GitHub’s &lt;a href="https://docs.github.com/en/site-policy/content-removal-policies/dmca-takedown-policy"&gt;DMCA Takedown Policy&lt;/a&gt; page&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Digital Millennium Copyright Act (DMCA) is a US law that was passed in 1998. It has laid the groundwork for how copyright is enforced in the age of the internet. One of the DMCA provisions that is important to understand is the so-called “safe harbor” provision. The safe harbor provision, roughly speaking, makes it so that websites can avoid liability because they are simply hosting or transmitting copyrighted content on behalf of their end-users.&lt;/p&gt;
&lt;p&gt;The safe harbor provision has been absolutely essential to the modern internet. Without it, a website like GitHub could not exist. Imagine if every time someone found their copyrighted content had been uploaded to GitHub without their permission, that they could sue GitHub for damages. If this were the case, GitHub could never operate. The way GitHub works today, it cannot possibly know if every single thing that is uploaded to it is done so legally. The safe harbor provision also makes modern social media websites like Facebook, Twitter, and YouTube possible.&lt;/p&gt;
&lt;p&gt;However, in order for a website to have and maintain safe harbor status, it must follow certain practices as outlined by the DMCA. In particular, sites must manage the “notice-and-take-down process”. GitHub’s notice-and-take-down process is described in its &lt;a href="https://docs.github.com/en/site-policy/content-removal-policies/dmca-takedown-policy"&gt;DMCA takedown policy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The notice-and-take-down process works like this: a provider (like GitHub) has a means for a copyright holder to submit a notice. In GitHub’s case, they provide an online &lt;a href="https://github.com/contact/dmca"&gt;form&lt;/a&gt;. This notice must include certain information, including the name and address of the submitter, identification of the copyrighted work, the material on the site that is infringing copyright, and a statement of good faith, signed under penalty of perjury, that the person submitting the notice owns the copyright and believes their rights have been infringed upon. GitHub’s form also requires the submitter to assert that they have taken &lt;a href="https://www.lumendatabase.org/topics/22"&gt;fair use&lt;/a&gt; into consideration.&lt;/p&gt;
&lt;p&gt;Once the notice is submitted and once the provider confirms that the above things are done, they must “expeditiously” remove public access to the content. The DMCA does not define “expeditiously”.&lt;/p&gt;
&lt;p&gt;The owner of the accused content then has the opportunity to file a counter-notice.  GitHub’s counter notice procedure is described in its &lt;a href="https://docs.github.com/en/site-policy/content-removal-policies/guide-to-submitting-a-dmca-counter-notice"&gt;guide to submitting a DMCA counter notice&lt;/a&gt;. This gives the person whose content has been removed recourse if they believe the original notice was invalid. A counter notice contains a statement by the user that the content was removed “as a result of mistake or misidentification”, signed under penalty of perjury. When a provider receives a counter notice, they must forward it to the original complainant, and restore the challenged material after 10-14 business days. At this point, if the complainant wishes to keep the material down, they must file a lawsuit against the alleged infringer.&lt;/p&gt;
&lt;p&gt;By following these procedures as outlined by the DMCA, GitHub avoids liability to either party.&lt;/p&gt;
&lt;p&gt;GitHub goes beyond what the DMCA law requires. All notices and counter notices that have ever been submitted to GitHub are published publicly in the &lt;a href="https://github.com/github/dmca"&gt;github/dmca repository&lt;/a&gt; (with personal information redacted). GitHub has also historically sided with developers in high profile infringement cases, such as the &lt;a href="https://github.blog/2020-11-16-standing-up-for-developers-youtube-dl-is-back/"&gt;youtube-dl incident in 2020&lt;/a&gt; (this incident involved a takedown relating to copyright circumvention, which is a different part of the DMCA law that I haven’t discussed here because it isn’t relevant to the notice that was sent to SymPy).&lt;/p&gt;
&lt;p&gt;It’s important to understand, however, that GitHub’s hands are tied in many ways here. If they do not follow the notice and counter notice procedures exactly as outlined in the DMCA law, they risk losing their safe harbor status with the US Copyright Office. Were this to happen, it would be completely disastrous to GitHub as a business. Without safe harbor protection, GitHub could be liable for any copyrighted content that someone uploaded to its platform.&lt;/p&gt;
&lt;p&gt;Finally, a technical note: when someone submits a takedown notice on a single part of a GitHub repository, GitHub’s response is to take down the entire repository. This is because it is technically impossible to remove only part of a repository due to the way git works. Completely scrubbing data from git history is possible, but it’s a destructive process that’s very disruptive to developers. Instead, GitHub requires the repository owners to &lt;a href="https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/removing-sensitive-data-from-a-repository"&gt;scrub the data themselves&lt;/a&gt;, if they choose to, within one business day. Otherwise, they will take the entire repository down.&lt;/p&gt;
&lt;h2&gt;What happened&lt;/h2&gt;
&lt;p&gt;Below I provide a quick timeline of what happened. Times are in Mountain Daylight Time, which is where I live.&lt;/p&gt;
&lt;p&gt;First, for background, the SymPy documentation website &lt;a href="https://docs.sympy.org/"&gt;https://docs.sympy.org/&lt;/a&gt; is hosted on &lt;a href="https://pages.github.com/"&gt;GitHub Pages&lt;/a&gt; and mirrors the repository &lt;a href="https://github.com/sympy/sympy_doc"&gt;https://github.com/sympy/sympy_doc&lt;/a&gt;. It is common for websites to be hosted on GitHub Pages because it’s completely free and easy to set up for someone who is already used to using git and GitHub. This &lt;a href="https://github.com/asmeurer/blog"&gt;blog itself&lt;/a&gt; is hosted on GitHub Pages. The sympy_doc repository only contains the pre-built HTML of SymPy’s documentation. The actual source code lives in &lt;a href="https://github.com/sympy/sympy"&gt;the main SymPy repository&lt;/a&gt;. However, the DMCA claims were only ever made against the website, so the main SymPy source code repository was unaffected.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Friday, Apr 15, 4:26 PM&lt;/strong&gt;: Admins of the sympy/sympy_doc GitHub repository (myself, Ondřej Čertík, and Oscar Benjamin) received an automated email from &lt;a href="mailto:support@githubsupport.com"&gt;support@githubsupport.com&lt;/a&gt; informing us that a DMCA takedown notice was filed against the SymPy documentation. Specifically, the claim, which can now be found on &lt;a href="https://github.com/github/dmca/blob/master/2022/04/2022-04-15-hackerrank.md"&gt;the github/dmca repository&lt;/a&gt;, claimed that “Someone has illegally copied our client's technical exams questions and answers from their official website https://www.hackerrank.com/ and uploaded them on their platform without permission.” It specifically referenced the page &lt;a href="https://docs.sympy.org/latest/modules/solvers/solvers.html"&gt;https://docs.sympy.org/latest/modules/solvers/solvers.html&lt;/a&gt;. The notice was made on behalf of HackerRank by an individual from “WorthIT Solutions Pvt. Ltd.” The notice also stated “the infringing website is not willing to remove our client's work”, which came as a surprise to us since, at no point in time prior to receiving this notice had we received any communications from HackerRank or WorthIT Solutions.&lt;/p&gt;
&lt;p&gt;The support email stated that if we do not remove the offending content within one business day, the repository, and consequently the docs website, will be taken down.&lt;/p&gt;
&lt;p&gt;While it is not relevant to the legality of the situation, it is worth noting that this was on Good Friday and the upcoming Sunday, April 17, was Easter Sunday, which limited our ability to effectively respond over the weekend.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Friday, April 15 - Tuesday, April 19&lt;/strong&gt;: At first, we were not sure if the support email was legitimate or if it was just convincing spam. One thing that confused us was that the support email came from a domain, &lt;a href="https://githubsupport.com/"&gt;githubsupport.com&lt;/a&gt;, which did not appear to exist. Another issue is that although GitHub’s policy was to post all DMCA claims to &lt;a href="https://github.com/github/dmca"&gt;the github/dmca repository&lt;/a&gt;, this particular claim had not yet been uploaded there. We reached out to GitHub support to ask if the email was legitimate, and they responded Monday, April 18, 3:18 PM that the email was indeed a legitimate email from GitHub Trust &amp;amp; Safety.&lt;/p&gt;
&lt;p&gt;I had already reached out on Friday to &lt;a href="https://numfocus.org/"&gt;NumFOCUS&lt;/a&gt; for assistance. NumFOCUS is a 501(c)(3) non-profit organization that represents many open source scientific projects including SymPy. However, due to the limited time frame of the notice and the fact that it occurred over a holiday weekend, NumFOCUS was not able to connect us with legal counsel until Tuesday.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tuesday, April 19, 12:21 PM&lt;/strong&gt;: We received notice from GitHub that the &lt;a href="https://github.com/sympy/sympy_doc"&gt;sympy/sympy_doc&lt;/a&gt; repository has been taken offline. The sympy/sympy_doc repository was replaced with a notice that the documentation was taken down by the DMCA notice with a link to the notice, which had been posted to the public github/dmca repository, and the documentation website itself started to 404. Since this was now public knowledge, we publicly announced this on the &lt;a href="https://groups.google.com/g/sympy/c/yuJXymiJqws"&gt;SymPy mailing list&lt;/a&gt; and &lt;a href="https://twitter.com/SymPy/status/1516534649970851841"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We also worked with NumFOCUS and the legal counsel to send a counter notice to GitHub, since we believed that the notice was mistaken and that the claimed infringement, the code and mathematical examples on the docs page, were likely not even copyrightable.&lt;/p&gt;
&lt;p&gt;Not long after the takedown occurred, someone posted it &lt;a href="https://news.ycombinator.com/item?id=31087175"&gt;to Hacker News&lt;/a&gt;. The Hacker News posting eventually made its way to the front page and by the end of the day it had made its way to &lt;a href="https://upvotetracker.com/post/hn/31087175"&gt;rank 3&lt;/a&gt; on the site, where it received hundreds of upvotes and comments. The story also generated a lot of &lt;a href="https://twitter.com/search?q=hackerrank%20since%3A2022-04-19%20until%3A2022-04-20"&gt;buzz on Twitter&lt;/a&gt; at this time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tuesday, April 19, 6:40 PM&lt;/strong&gt;: Vivek Ravisankar, the CEO of HackerRank, &lt;a href="https://news.ycombinator.com/item?id=31091354"&gt;posted a public apology on the Hacker News thread&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-markdown"&gt;Hello, I'm Vivek, founder/CEO of HackerRank. Our intention with this initiative is to takedown plagiarized code snippets or solutions to company assessments. This was definitely an unintended consequence. We are looking into it ASAP and also going to do an RCA to ensure this doesn't happen again.

Sorry, everyone!
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tuesday, April 19, 8:26 PM&lt;/strong&gt;: Vivek posted a &lt;a href="https://news.ycombinator.com/item?id=31092085"&gt;followup comment on Hacker News&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-markdown"&gt;Hello again, Vivek, founder/CEO here. In the interest of moving swiftly, here are the actions we are going to take:
(1) We have withdrawn the DMCA notice for sympy; Sent a note to senior leadership in Github to act on this quickly.

(2) We have stopped the whole DMCA process for now and working on internal guidelines of what constitutes a real violation so that these kind of incidents don't happen. We are going to do this in-house

(3) We are going to donate $25k to the sympy project.

As a company we take a lot of pride in helping developers and it sucks to see this. I'm extremely sorry for what happened here.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;HackerRank did follow through with the $25k donation to SymPy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wednesday, April 20, 12:00 AM (approximately)&lt;/strong&gt;: The SymPy documentation website and the sympy/sympy_doc repository went back online.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Wednesday, April 20, 2022, 10:11 AM&lt;/strong&gt;: We received an email notice from GitHub that the DMCA claim against our repository has been retracted. The &lt;a href="https://github.com/github/dmca/blob/master/2022/04/2022-04-19-hackerrank-retraction.md"&gt;retraction is made available online&lt;/a&gt; on the github/dmca repository.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;My Views&lt;/h2&gt;
&lt;p&gt;Now that I’ve stated the facts, let me take a moment to give my own thoughts on this whole thing. My belief is that the DMCA claim that was made against the SymPy repository was completely baseless and without merit. Not only is no part of the SymPy documentation, to my knowledge, taken illegally from HackerRank or any other copyrighted source, but the claim itself was completely unspecific about which parts of the documentation were supposedly infringing. This made it impossible for us to comply even if the complaint was legitimate. In addition, it is questionable whether the supposed parts of the documentation that were taken from HackerRank, the mathematical and code examples, are even copyrightable. While this may not have been an actively targeted attack against SymPy, as a community run open source project, it served as one in practice.&lt;/p&gt;
&lt;p&gt;We have never learned any more about which parts of the SymPy documentation were supposedly infringing on HackerRank’s copyright, and I expect we never will. Some people online have speculated that HackerRank actually took examples from the SymPy documentation, not the other way around, but I do not know if this is the case or not. It seems likely, given the large number of other &lt;a href="https://github.com/github/dmca/search?q=worthit"&gt;takedown notices WorthIT has made to GitHub on HackerRank’s behalf&lt;/a&gt;, that they were using some sort of automated or semi-automated detection system, which somehow detected what it thought was infringing content on our website. I have personally never used the HackerRank platform, so I only know what sorts of things are on it from second-hand accounts.&lt;/p&gt;
&lt;p&gt;Firstly let me say that if anyone or anything is to be blamed for this, my personal belief is that the blame should primarily lie on the DMCA law itself. While the “safe harbor” provisions of the law have been critical to the development of the modern internet, allowing social websites such as GitHub to exist without the burden of legal liability for user contributed content, other provisions are hostile to those same users, even those who are operating in a completely legal manner. The DMCA works in a “guilty until proven innocent” way, and the very operation of the takedown notice policy implicitly assumes that those making claims are not abusing the system as bad actors. It also incentivizes platforms such as GitHub to step aside and not take sides in claims, even claims such as this one, which refer to likely uncopyrightable material or are too unspecific to reasonably address even if they are legitimate.&lt;/p&gt;
&lt;p&gt;The DMCA also has had further chilling effects due to its anti-circumvention provisions. The &lt;a href="https://www.eff.org/wp/unintended-consequences-16-years-under-dmca"&gt;EFF has written&lt;/a&gt; extensively about these. While something as radical as &lt;a href="https://en.wikipedia.org/wiki/Copyright_abolition"&gt;abolishing copyright&lt;/a&gt; may be considered to be practically untenable, I believe that laws like the DMCA can be rewritten so that they still serve their intended function of protecting copyright owners and providing “safe harbor” to websites like GitHub, while also protecting the rights of those accused of infringing copyright.&lt;/p&gt;
&lt;p&gt;With that being said, I think some blame does need to lie on HackerRank and WorthIT Solutions for abusing the DMCA system and filing claims like this. They also lied in their claim when they said “the infringing website is not willing to remove our client's work.” At no point were we contacted by HackerRank or WorthIT Solutions about any copyright infringement. If we were, we would have been happy to work with them to determine whether any content in SymPy is infringing on copyright and remove it if it was. Even if it were the case that SymPy’s documentation infringed on HackerRank’s copyright, the immediate escalation to a DMCA takedown notice, which legally forced GitHub to completely disable the entire SymPy documentation, was completely inappropriate. Even submitting a counter notice is risky, because by doing so it increases the likelihood that the complaining party will bring an infringement lawsuit. Many DMCA’d repositories do not submit a counter notice for this reason, and we were only able to do so comfortably because we were able to do so via NumFOCUS. Had HackerRank not retracted the notice, we would have had to wait for our counter notice to take effect, meaning our docs website would have remained unavailable for 10-14 days. And had they instead taken down the main SymPy repository instead of the sympy_doc repo where the docs are hosted, this would have been a major disruption for our entire development workflow.&lt;/p&gt;
&lt;p&gt;I do want to thank Vivek for quickly retracting the notice once this came to his attention, and I hope that he will be rethinking their DMCA policies at HackerRank, and for their donation to support SymPy and NumFOCUS.&lt;/p&gt;
&lt;p&gt;Finally, while many have blamed GitHub, I believe that for the most part, they have acted as they are effectively required to by law. It is important to understand that any similar website based in the US would have likely treated this claim in a similar way. For instance, here is &lt;a href="https://about.gitlab.com/handbook/dmca/"&gt;GitLab’s DMCA policy&lt;/a&gt;, which you can see is very similar to GitHub’s. By all accounts, GitHub is an industry leader here, by posting all notices and counter notices &lt;a href="https://github.com/github/dmca"&gt;online&lt;/a&gt;, which they are not required to do, and by being very open about their DMCA policies (&lt;a href="https://docs.github.com/en/site-policy/content-removal-policies/dmca-takedown-policy"&gt;[1]&lt;/a&gt;, &lt;a href="https://docs.github.com/en/site-policy/content-removal-policies/guide-to-submitting-a-dmca-counter-notice"&gt;[2]&lt;/a&gt;, &lt;a href="https://docs.github.com/en/site-policy/content-removal-policies/guide-to-submitting-a-dmca-takedown-notice"&gt;[3]&lt;/a&gt;). With that being said, there are ways that GitHub’s processes could be improved here. The one business day that we were given to respond is actually standard in the industry, and ultimately comes from the “expeditiously” wording of the DMCA. But even so, if we were given more time than this, it would have made things much easier. It may have even been possible for us to reach out to HackerRank and resolve the situation before any actual takedown occurred. It also would be helpful if GitHub, while staying within the DMCA provisions, had a higher standard of legitimacy for takedown notices such as the one we received. As I have noted, the request we received was not nearly specific enough for us to effectively act on it, which should have been apparent to GitHub, since the only information WorthIT provided was a link to the HackerRank home page. Finally, I have two small technical requests from GitHub: first is to make &lt;a href="https://githubsupport.com/"&gt;githubsupport.com&lt;/a&gt; a real website so that support emails appear more legitimate, and second is to post DMCA notices to the DMCA repository right away rather than only after the repository is taken down, to make it clearer that the notices are in fact legitimate.&lt;/p&gt;
&lt;p&gt;Open source communities such as SymPy are under-resourced and typically ill equipped to handle situations like these, which inherently puts them in an inferior position. This is despite the fact that open source software serves a global commons that benefits all. I have estimated that SymPy itself is used by hundreds of thousands of people, and the broader scientific Python ecosystem that it is part of is used by millions of people. Abuses of copyright law against these communities are harmful to society as a whole.&lt;/p&gt;
&lt;h2&gt;Lessons Learned&lt;/h2&gt;
&lt;p&gt;I’d like to end with a few lessons that I’ve learned from this whole process.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Take DMCA takedown notices seriously.&lt;/strong&gt; If you ever receive a DMCA takedown notice from GitHub or any other website, you need to take it seriously. The website is required by law to remove your content after they receive such a notice. You can submit a counter notice, but this increases the likelihood of being sued.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;NumFOCUS fiscal sponsorship is invaluable.&lt;/strong&gt; Our NumFOCUS fiscal sponsorship was invaluable here. Thanks to NumFOCUS, we were able to immediately access high quality legal advice on how to proceed here. Had HackerRank not retracted their notice, or even, heaven forbid, decided to sue, we would have had significant assistance and support from NumFOCUS. If you are part of an open source project that doesn’t have fiscal sponsorship, I would recommend looking into NumFOCUS, or other similar organizations. And if you want to &lt;a href="https://numfocus.org/support"&gt;support NumFOCUS&lt;/a&gt;, I encourage you to do so.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Make backups of your online data.&lt;/strong&gt; While the source code of any GitHub repository is effectively backed up onto every computer that has a git clone. Other data such as issues and pull request comments are not. We were lucky that the DMCA notice was sent against our documentation repository instead of our main repository. If our main repository were taken down instead, we would have lost access to all GitHub issue and pull request history. I have been looking into effective ways to backup this data. If anyone has any suggestions here, please let me know in the comments.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I do feel that being on a site like GitHub is still preferable to something like self-hosting. If you self-host, you become responsible for a ton of things which GitHub does for you, like making sure everything stays online, handling servers, and managing spam. Also, self-hosting does not magically shield you from legal threats. If you self-host content that infringes on someone’s copyright, you are still legally liable for hosting that content.&lt;/p&gt;
&lt;p&gt;Finally, I want to thank everyone who supported SymPy during this incident. Even if you just talked about this on social media or upvoted the Hacker News story, that helped us get this into the public eye, which led to a much faster resolution than we expected. I especially want to thank Leah Silen and Arliss Collins from NumFOCUS; Ondřej Čertík, Oscar Benjamin, and other SymPy community members; Pamela Chestek, the NumFOCUS legal counsel; and Travis Oliphant for the help they provided to us. Thank you to Thomas Dohmke, GitHub’s CEO, who we have reached out to privately, and who has promised to improve GitHub’s DMCA policies. I also want to thank Vivek Ravisankar from HackerRank for retracting the DMCA claim, and for the generous donation to SymPy.&lt;/p&gt;
&lt;p&gt;Now that this incident is over, I’m hopeful we in the SymPy community can all go back to building software.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you wish to donate to support SymPy, you may do so &lt;a href="https://www.sympy.org/en/donate.html"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description><guid>https://asmeurer.com/blog/posts/the-sympy-hackerrank-dmca-incident/</guid><pubDate>Wed, 27 Apr 2022 20:00:00 GMT</pubDate></item><item><title>Switching to Utterances Comments</title><link>https://asmeurer.com/blog/posts/switching-to-utterances-comments/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;I've ditched Disqus as the comment system on this blog. I am now using
&lt;a href="https://utteranc.es/"&gt;Utterances&lt;/a&gt;. Utterances is an open source comment
system that is backed by GitHub issues. Basically, every post has a
corresponding issue opened on GitHub, and the comments on the post are the
comments on the issue. Utterances automatically places the comments at the
bottom of the post. For example,
&lt;a href="https://github.com/asmeurer/blog/issues/18"&gt;here&lt;/a&gt; is the issue corresponding
to this post.&lt;/p&gt;
&lt;p&gt;I didn't like Disqus mostly because it serves ads and tracking. Even though I
had opted out from as much of it as I could in the Disqus settings, it still
loads tracking scripts on every page. I run &lt;a href="https://github.com/gorhill/uBlock"&gt;uBlock
Origin&lt;/a&gt; always, and it's a bit hypocritical
if my own side has things that are blocked by it. In some cases I can't avoid
it (as far as I know), like when I embed a YouTube video, but it definitely
shouldn't be on every post.&lt;/p&gt;
&lt;p&gt;Utterances is a very nice alternative. I has lots of advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Comments are not self-hosted. GitHub hosts them. Since you need a GitHub
account to comment, this should make comment spam a non-issue.&lt;/li&gt;
&lt;li&gt;Comments support full Markdown.&lt;/li&gt;
&lt;li&gt;Users can edit their comments.&lt;/li&gt;
&lt;li&gt;I can edit and fully moderate all comments.&lt;/li&gt;
&lt;li&gt;Users log in with a federated system that proves their identity.&lt;/li&gt;
&lt;li&gt;Email subscription to posts.&lt;/li&gt;
&lt;li&gt;No ads or tracking.&lt;/li&gt;
&lt;li&gt;It's completely open source and free to use.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you use &lt;a href="https://getnikola.com/"&gt;Nikola&lt;/a&gt; like I do, it &lt;a href="https://getnikola.com/handbook.html#comments"&gt;natively supports
Utterances&lt;/a&gt; (a feature which I
added). Otherwise, go to the &lt;a href="https://utteranc.es/"&gt;Utterances&lt;/a&gt; and paste the
script tag generated at the bottom into your blog template. Then install the
&lt;a href="https://github.com/apps/utterances"&gt;Utterances app&lt;/a&gt; in your repo, and you are
done.&lt;/p&gt;
&lt;h3&gt;Exporting Disqus Comments&lt;/h3&gt;
&lt;p&gt;Some of my old posts had Disqus comments, which I wanted to preserve somehow.
Here is guide on how I did that, since it wasn't as straightforward as I would
have hoped.&lt;/p&gt;
&lt;p&gt;The first step is to export your Disqus comments. It's very difficult to
actually find the place in the Disqus site where you do this, but I finally
found the &lt;a href="https://disqus.com/admin/discussions/export/"&gt;URL&lt;/a&gt;. The export takes
some time to complete (for me it took about half an hour). When it finished,
Disqus will email you an XML file with all your comments. Note that the file
contains all comments for all sites you have ever set up with Disqus. For me,
it also included all the comments on my old &lt;a href="http://asmeurersympy.wordpress.com/"&gt;Wordpress
blog&lt;/a&gt;, as well as posts for draft blog
posts that I never ended up publishing. It also contained all comments that
were marked as spam, so you will need to remember to filter those.&lt;/p&gt;
&lt;p&gt;I decided that since I only have a handful of posts with Disqus comments, I
would just write a script to process them all and manually print them out,
which I will then manually enter in to the Utterances comment system for those
posts.&lt;/p&gt;
&lt;p&gt;I wrote a script to process the comments, which you can find
&lt;a href="https://github.com/asmeurer/blog/blob/master/disqus-comments/export_disqus_comments.py"&gt;here&lt;/a&gt;.
Disqus does provides an &lt;a href="https://disqus.com/api/schemas/1.0/disqus.xsd"&gt;XML
schema&lt;/a&gt; for the XML. I used a
library called &lt;a href="https://xsdata.readthedocs.io/en/latest/index.html"&gt;xsData&lt;/a&gt;,
which lets you take an XML scheme and generate Python dataclasses
corresponding to it, which make manipulating the parsed XML much easier than
the standard library xml library. The script outputs text like&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-markdown"&gt;========== Comments from https://asmeurer.github.io/blog/posts/what-happens-when-you-mess-with-hashing-in-python/ ==========

These are the original comments on this post that were made when this blog used the [Disqus blog system](https://www.asmeurer.com/blog/posts/switching-to-utterances-comments/).

&amp;gt;**Comment from bjd2385 on 2016-08-28 12:33:12+00:00:**

&amp;gt;&amp;lt;p&amp;gt;Very interesting post. I was just looking into hash functions (I've never formally learned what the topic entails), and since I'm most familiar with Python this post explained quite a bit, especially your early mathematical points.&amp;lt;/p&amp;gt;

&amp;gt;**Comment from Mark Lawrence on 2016-10-03 20:26:54+00:00:**

&amp;gt;&amp;lt;p&amp;gt;At what point does Python 3 force the override of __hash__ if you've defined __eq__?  E.g when would your&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;AlwaysEqual class fail?&amp;lt;/p&amp;gt;

&amp;gt;**Replies:**

&amp;gt;&amp;gt;**Comment from asmeurer on 2016-10-03 20:38:13+00:00:**

&amp;gt;&amp;gt;&amp;lt;p&amp;gt;That's a good catch. I originally wrote this post in Python 2. The example does indeed fail in Python 3. More specifically, if you override __eq__, Python 3 automatically sets __hash__ to None. I'll update the post to make this more clear.&amp;lt;/p&amp;gt;

&amp;gt;**Comment from Erick Mendonça on 2017-07-30 03:23:55+00:00:**

&amp;gt;&amp;lt;p&amp;gt;Great article! We must really pay attention to these details when implementing custom hashes.&amp;lt;/p&amp;gt;

&amp;gt;**Comment from Ignacio on 2017-10-07 22:31:56+00:00:**

&amp;gt;&amp;lt;p&amp;gt;Thanks a lot for this post! Clarified a lot of concepts.&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which I then manually copied to each post's Utterances page on GitHub.&lt;/p&gt;
&lt;p&gt;Feel free to adapt &lt;a href="https://github.com/asmeurer/blog/blob/master/disqus-comments/export_disqus_comments.py"&gt;my
script&lt;/a&gt;
if you find yourself in a similar situation.&lt;/p&gt;
&lt;h3&gt;Utterances Comments&lt;/h3&gt;
&lt;p&gt;Feel free to use the comments on this page to play around with the commenting
system.&lt;/p&gt;
&lt;p&gt;Note that to comment, there are two options. You can log in on this page,
which will let you type your comment in the box below. This requires giving
the Utterances bot access to your GitHub account. Alternately, if you don't
want to give a bot access, you can just go directly to the GitHub issue page
and comment there. I am currently in the process of figuring out how to add
some boilerplate to each page that makes this clear (see &lt;a href="https://github.com/utterance/utterances/issues/355"&gt;this Utterances
issue&lt;/a&gt;). If anyone has any
suggestions on how to do this, let me know. For now, I am just going to
manually add a statement about this as the first comment on each post.&lt;/p&gt;</description><guid>https://asmeurer.com/blog/posts/switching-to-utterances-comments/</guid><pubDate>Thu, 03 Jun 2021 03:57:49 GMT</pubDate></item><item><title>Verifying the Riemann Hypothesis with SymPy and mpmath</title><link>https://asmeurer.com/blog/posts/verifying-the-riemann-hypothesis-with-sympy-and-mpmath/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;Like most people, I've had a lot of free time recently, and I've spent some of
it watching various YouTube videos about the &lt;a href="https://en.wikipedia.org/wiki/Riemann_hypothesis"&gt;Riemann
Hypothesis&lt;/a&gt;. I've collected
the videos I've watched into &lt;a href="https://www.youtube.com/playlist?list=PLrFrByaoJbcqKjzgJvLs2-spSmzP7jolT"&gt;YouTube
playlist&lt;/a&gt;.
The playlist is sorted with the most mathematically approachable videos first,
so even if you haven't studied complex analysis before, you can watch the
first few. If you have studied complex analysis, all the videos will be within
your reach (none of them are highly technical with proofs). Each video
contains parts that aren't in any of the other videos, so you will get
something out of watching each of them.&lt;/p&gt;
&lt;p&gt;One of the &lt;a href="https://www.youtube.com/watch?v=lyf9W2PWm40&amp;amp;list=PLrFrByaoJbcqKjzgJvLs2-spSmzP7jolT&amp;amp;index=8"&gt;videos near the end of the
playlist&lt;/a&gt;
is a lecture by Keith Conrad. In it, he mentioned a method by which one could
go about verifying the Riemann Hypothesis with a computer. I wanted to see if
I could do this with SymPy and mpmath. It turns out you can.&lt;/p&gt;
&lt;h2&gt;Background Mathematics&lt;/h2&gt;
&lt;h3&gt;Euler's Product Formula&lt;/h3&gt;
&lt;p&gt;Before we get to the computations, let's go over some mathematical background.
As you may know, the Riemann Hypothesis is one of the 7 &lt;a href="https://en.wikipedia.org/wiki/Millennium_Prize_Problems"&gt;Millennium Prize
Problems&lt;/a&gt; outlined by
the Clay Mathematics Institute in 2000. The problems have gained some fame
because each problem comes with a $1,000,000 prize if solved. One problem, the
&lt;a href="https://en.wikipedia.org/wiki/Poincar%C3%A9_conjecture"&gt;Poincaré conjecture&lt;/a&gt;,
has already been solved (Grigori Perelman who solved it turned down the 1
million dollar prize). The remainder remain unsolved.&lt;/p&gt;
&lt;p&gt;The Riemann Hypothesis is one of the most famous of these problems. The reason
for this is that the problem is central many open questions in number theory.
There are hundreds of theorems which are only known to be true contingent on
the Riemann Hypothesis, meaning that if the Riemann Hypothesis were proven,
immediately hundreds of theorems would be proven as well. Also, unlike some
other Millennium Prize problems, like P=NP, the Riemann Hypothesis is almost
universally believed to be true by mathematicians. So it's not a question of
whether or not it is true, just one of how to actually prove it. The problem
has been open for over 160 years, and while many advances have been made, no
one has yet come up with a proof of it (crackpot proofs aside).&lt;/p&gt;
&lt;p&gt;To understand the statement of the hypothesis, we must first define the zeta
function. Let&lt;/p&gt;
&lt;p&gt;$$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}$$&lt;/p&gt;
&lt;p&gt;(that squiggle $\zeta$ is the lowercase Greek letter zeta). This expression
makes sense if $s$ is an integer greater than or equal to 2, $s=2, 3, 4, \ldots$,
since we know from simple arguments from calculus that the summation converges
in those cases (it isn't important for us what those values are, only that the
summation converges). The story begins with Euler, who in 1740 considered the
following infinite product:&lt;/p&gt;
&lt;p&gt;$$\prod_{\text{$p$ prime}}\frac{1}{1 -
\frac{1}{p^s}}.$$&lt;/p&gt;
&lt;p&gt;The product ranges over all prime numbers, i.e., it is
$$\left(\frac{1}{1 - \frac{1}{2^s}}\right)\cdot\left(\frac{1}{1 -
\frac{1}{3^s}}\right)\cdot\left(\frac{1}{1 - \frac{1}{5^s}}\right)\cdots.$$
The fraction $\frac{1}{1 - \frac{1}{p}}$ may seem odd at first, but consider
the famous geometric series formula, $$\sum_{k=0}^\infty r^k = \frac{1}{1 -
r},$$ which is true for $|r| &amp;lt; 1$. Our fraction is exactly of this form, with
$r = \frac{1}{p^s}$. So substituting, we have&lt;/p&gt;
&lt;p&gt;$$\prod_{\text{$p$ prime}}\frac{1}{1 - \frac{1}{p^s}} =
\prod_{\text{$p$ prime}}\sum_{k=0}^\infty \left(\frac{1}{p^s}\right)^k =
\prod_{\text{$p$ prime}}\sum_{k=0}^\infty \left(\frac{1}{p^k}\right)^s.$$&lt;/p&gt;
&lt;p&gt;Let's take a closer look at what this is. It is&lt;/p&gt;
&lt;p&gt;$$\left(1 + \frac{1}{p_1^s} + \frac{1}{p_1^{2s}} + \frac{1}{p_1^{3s}} +
\cdots\right)\cdot\left(1 + \frac{1}{p_2^s} + \frac{1}{p_2^{2s}} +
\frac{1}{p_2^{3s}} + \cdots\right)\cdot\left(1 + \frac{1}{p_3^s} + \frac{1}{p_3^{2s}} +
\frac{1}{p_3^{3s}} + \cdots\right)\cdots,$$&lt;/p&gt;
&lt;p&gt;where $p_1$ is the first prime, $p_2$ is the second prime, and so on. Now
think about how to expand finite products of finite sums, for instance,
$$(x_1 + x_2 + x_3)(y_1 + y_2 + y_3)(z_1 + z_2 + z_3).$$ To expand the above,
you would take a sum of every combination where you pick one $x$ term, one $y$
term, and one $z$ term, giving&lt;/p&gt;
&lt;p&gt;$$x_1y_1z_1 + x_1y_1z_2 + \cdots + x_2y_1z_3 + \cdots + x_3y_2z_1 + \cdots + x_3y_3z_3.$$&lt;/p&gt;
&lt;p&gt;So to expand the infinite product, we do the same thing. We take every
combination of picking $1/p_i^{ks}$, with one $k$ for each $i$. If we pick
infinitely many non-$1$ powers, the product will be zero, so we only need to
consider terms where there are finitely many primes. The resulting sum will be
something like&lt;/p&gt;
&lt;p&gt;$$\frac{1}{1^s} + \frac{1}{p_1^s} + \frac{1}{p_2^s} + \frac{1}{\left(p_1^2\right)^s} +
\frac{1}{p_3^s} + \frac{1}{\left(p_1p_2\right)^s} + \cdots,$$&lt;/p&gt;
&lt;p&gt;where each prime power combination is picked exactly once. However, we know by
the &lt;a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic"&gt;Fundamental Theorem of
Arithmetic&lt;/a&gt;
that when you take all combinations of products of primes that you get each
positive integer exactly once. So the above sum is just&lt;/p&gt;
&lt;p&gt;$$\frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \cdots,$$ which is just
$\zeta(s)$ as we defined it above.&lt;/p&gt;
&lt;p&gt;In other words,&lt;/p&gt;
&lt;p&gt;$$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s} = \prod_{\text{$p$
prime}}\frac{1}{1 - \frac{1}{p^s}},$$ for $s = 2, 3, 4, \ldots$. This is known
as Euler's product formula for the zeta function. Euler's product formula
gives us our first clue as to why the zeta function can give us insights into
prime numbers.&lt;/p&gt;
&lt;h3&gt;Analytic Continuation&lt;/h3&gt;
&lt;p&gt;In 1859, Bernhard Riemann wrote a &lt;a href="https://en.wikipedia.org/wiki/On_the_Number_of_Primes_Less_Than_a_Given_Magnitude"&gt;short 9 page paper on number theory and the
zeta
function&lt;/a&gt;.
It was the only paper Riemann ever wrote on the subject of number theory, but
it is undoubtedly one of the most important papers every written on the
subject.&lt;/p&gt;
&lt;p&gt;In the paper, Riemann considered that the zeta function summation,&lt;/p&gt;
&lt;p&gt;$$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s},$$&lt;/p&gt;
&lt;p&gt;makes sense not just for integers $s = 2, 3, 4, \ldots$, but for any real
number $s &amp;gt; 1$ (if $s = 1$, the summation is the &lt;a href="https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)"&gt;harmonic
series&lt;/a&gt;, which
famously diverges). In fact, it is not hard to see that for complex $s$, the
summation makes sense so long as $\mathrm{Re}(s) &amp;gt; 1$ (for more about what it
even means for $s$ to be complex in that formula, and the basic ideas of
analytic continuation, I recommend &lt;a href="https://www.youtube.com/watch?v=sD0NjbwqlYw&amp;amp;list=PLrFrByaoJbcqKjzgJvLs2-spSmzP7jolT&amp;amp;index=3"&gt;3Blue1Brown's
video&lt;/a&gt;
from my YouTube playlist).&lt;/p&gt;
&lt;p&gt;Riemann wanted to extend this function to the entire complex plane, not just
$\mathrm{Re}(s) &amp;gt; 1$. The process of doing this is called &lt;a href="https://en.wikipedia.org/wiki/Analytic_continuation"&gt;analytic
continuation&lt;/a&gt;. The theory
of complex analysis tells us that if we can find an extension of $\zeta(s)$ to
the whole complex plan that remains differentiable, then that extension is
unique, and we can reasonably say that that &lt;em&gt;is&lt;/em&gt; the definition of the
function everywhere.&lt;/p&gt;
&lt;p&gt;Riemann used the following approach. Consider what we might call the
"completed zeta function"&lt;/p&gt;
&lt;p&gt;$$Z(s) = \pi^{-\frac{s}{2}}\Gamma\left(\frac{s}{2}\right)\zeta(s).$$&lt;/p&gt;
&lt;p&gt;Using Fourier analysis, Riemann gave a formula for $Z(s)$ that is defined
everywhere, allowing us to use it to define $\zeta(s)$ to the left of 1. I
won't repeat Riemann's formula for $Z(s)$ as the exact formula isn't
important, but from it one could also see&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;$Z(s)$ is defined everywhere in the complex plane, except for simple poles at 0
and 1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$Z(s) = Z(1 - s).$ This means if we have a value for $s$ that is right of
the line $\mathrm{Re}(z) = \frac{1}{2},$ we can get a value to the left of
it by reflecting it over the real-axis and the line at $\frac{1}{2}$ (to
see this, note that the average of $s$ and $1 - s$ is $1/2$, so the
midpoint of a line connecting the two should always go through the point
$1/2$).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;img src="https://asmeurer.com/blog/s-and-1-s.svg" alt="Reflection of s and 1 - s" width="608"&gt;
&lt;p&gt;(Reflection of $s$ and $1 - s$. Created with
&lt;a href="https://www.geogebra.org/graphing/c9rzy9hj"&gt;Geogebra&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;Zeros&lt;/h3&gt;
&lt;p&gt;Looking at $Z(s)$, it is a product of three parts. So the zeros and poles of
$Z(s)$ correspond to the zeros and poles of these parts, unless they cancel.
$\pi^{-\frac{s}{2}}$ is the easiest: it has no zeros and no poles. The second
part is the &lt;a href="https://en.wikipedia.org/wiki/Gamma_function"&gt;gamma function&lt;/a&gt;.
$\Gamma(z)$ has no zeros and has simple poles at nonpositive integers $z=0,
-1, -2, \ldots$.&lt;/p&gt;
&lt;p&gt;So taking this, along with the fact that $Z(s)$ is entire except for simple
poles at 0 and 1, we get from $$\zeta(s) =
\frac{Z(s)}{\pi^{-\frac{s}{2}}\Gamma\left(\frac{s}{2}\right)}$$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$Z(s)$ has a simple pole at 1, which means that $\zeta(s)$ does as well.
This is not surprising, since we already know the summation formula from
above diverges as $s$ approaches 1.&lt;/li&gt;
&lt;li&gt;$Z(s)$ has a simple pole at 0. Since $\Gamma\left(\frac{s}{2}\right)$ also
has a simple pole at 0, they must cancel and $\zeta(s)$ must have neither a
zero nor a pole at 0 (in fact, $\zeta(0) = -1/2$).&lt;/li&gt;
&lt;li&gt;Since $\Gamma\left(\frac{s}{2}\right)$ has no zeros, there are no further
poles of $\zeta(s)$. Thus, $\zeta(s)$ is entire everywhere except for a
simple pole at $s=1$.&lt;/li&gt;
&lt;li&gt;$\Gamma\left(\frac{s}{2}\right)$ has poles at the remaining negative even
integers. Since $Z(s)$ has no poles there, these must correspond to zeros
of $\zeta(s)$. These are the so-called "trivial" zeros of the zeta
function, at $s=-2, -4, -6, \ldots$. The term "trivial" here is a relative
one. They are trivial to see from the above formula, whereas other zeros of
$\zeta(s)$ are much harder to find.&lt;/li&gt;
&lt;li&gt;$\zeta(s) \neq 0$ if $\mathrm{Re}(s) &amp;gt; 1$. One way to see this is from the
Euler product formula. Since each term in the product is not zero, the
function itself cannot be zero (this is a bit hand-wavy, but it can be made
rigorous). This implies that $Z(s) \neq 0$ in this region as well. We can
reflect $\mathrm{Re}(s) &amp;gt; 1$ over the line at $\frac{1}{2}$ by considering
$\zeta(1 - s)$. Using the above formula and the fact that $Z(s) = Z(1 -
s)$, we see that $\zeta(s)$ cannot be zero for $\mathrm{Re}(s) &amp;lt; 0$ either,
with the exception of the aforementioned trivial zeros at $s=-2, -4, -6,
\ldots$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Thus, any non-trivial zeros of $\zeta(s)$ must have real part between 0 and 1.
This is the so-called "critical strip". Riemann hypothesized that these zeros
are not only between 0 and 1, but are in fact on the line dividing the strip
at real part equal to $1/2$. This line is called the "critical line". This is
Riemann's famous hypothesis: that all the non-trivial zeros of $\zeta(s)$ have
real part equal to $1/2$.&lt;/p&gt;
&lt;h3&gt;Computational Verification&lt;/h3&gt;
&lt;p&gt;Whenever you have a mathematical hypothesis, it is good to check if it is true
numerically. Riemann himself used some methods (not the same ones we use here)
to numerically estimate the first few non-trivial zeros of $\zeta(s)$, and
found that they lied on the critical line, hence the motivation for his
hypothesis. Here is an &lt;a href="https://www.maths.tcd.ie/pub/HistMath/People/Riemann/Zeta/EZeta.pdf"&gt;English
translation&lt;/a&gt;
of his original paper if you are interested.&lt;/p&gt;
&lt;p&gt;If we verified that all the zeros in the critical strip from, say,
$\mathrm{Im}(s) = 0$ to $\mathrm{Im}(s) = N$ are in fact on the critical line
for some large $N$, then it would give evidence that the Riemann Hypothesis is
true. However, to be sure, this would not constitute a proof.
&lt;a href="https://en.wikipedia.org/wiki/G._H._Hardy"&gt;Hardy&lt;/a&gt; showed in 1914 that
$\zeta(s)$ has infinitely many zeros on the critical strip, so only finding
finitely many of them would not suffice as a proof. (Although if we were to
find a counter-example, a zero &lt;em&gt;not&lt;/em&gt; on the critical line, that WOULD
constitute a proof that the Hypothesis is false. However, there are strong
reasons to believe that the hypothesis is not false, so this would be unlikely
to happen.)&lt;/p&gt;
&lt;p&gt;How would we verify that the zeros are all on the line $1/2$. We can find
zeros of $\zeta(s)$ numerically, but how would we know if the real part is
really exactly 0.5 and not 0.500000000000000000000000000000000001? And more
importantly, just because we find some zeros, it doesn't mean that we have all
of them. Maybe we can find a bunch of zeros on the critical line, but how
would we be sure that there aren't other zeros lurking around elsewhere on the
critical strip?&lt;/p&gt;
&lt;p&gt;We want to find rigorous answers to these two questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;How can we count the number of zeros between $\mathrm{Im}(s) = 0$ and
$\mathrm{Im}(s) = N$ of $\zeta(s)$?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How can we verify that all those zeros lie on the critical line, that is,
they have real part equal to exactly $1/2$?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Counting Zeros Part 1&lt;/h4&gt;
&lt;p&gt;To answer the first question, we can make use of a powerful theorem from
complex analysis called the &lt;a href="https://en.wikipedia.org/wiki/Argument_principle#Generalized_argument_principle"&gt;argument
principle&lt;/a&gt;.
The argument principle says that if $f$ is a meromorphic function on some
closed contour $C$, and does not have any zeros or poles on $C$ itself, then&lt;/p&gt;
&lt;p&gt;$$\frac{1}{2\pi i}\oint_C \frac{f'(z)}{f(z)}\,dz = \#\left\{\text{zeros of $f$
inside of C}\right\} - \#\left\{\text{poles of $f$
inside of C}\right\},$$ where all zeros and poles are counted with
multiplicity.&lt;/p&gt;
&lt;p&gt;In other words, the integral on the left-hand side counts the number of zeros
of $f$ minus the number of poles of $f$ in a region. The argument principle is
quite easy to show given the Cauchy residue theorem (see the above linked
Wikipedia article for a proof). The expression $f'(z)/f(z)$ is called the
"&lt;a href="https://en.wikipedia.org/wiki/Logarithmic_derivative"&gt;logarithmic
derivative&lt;/a&gt; of $f$",
because it equals $\frac{d}{dz} \log(f(z))$ (although it makes sense even without
defining what "$\log$" means).&lt;/p&gt;
&lt;p&gt;One should take a moment to appreciate the beauty of this result. The
left-hand side is an integral, something we generally think of as being a
continuous quantity. But it is always exactly equal to an integer. Results
such as these give us a further glimpse at how analytic functions and complex
analysis can produce theorems about number theory, a field which one would
naively think can only be studied via discrete means. In fact, these methods
are far more powerful than discrete methods. For many results in number
theory, we only know how to prove them using complex analytic means. So-called
&lt;a href="https://en.wikipedia.org/wiki/Elementary_proof"&gt;"elementary" proofs&lt;/a&gt; for
these results, or proofs that only use discrete methods and do not use complex
analysis, have not yet been found.&lt;/p&gt;
&lt;p&gt;Practically speaking, the fact that the above integral is exactly an integer
means that if we compute it numerically and it comes out to something like
0.9999999, we know that it must in fact equal exactly 1. So as long as we get
a result that is near an integer, we can round it to the exact answer.&lt;/p&gt;
&lt;p&gt;We can integrate a contour along the critical strip up to some $\mathrm{Im}(s)
= N$ to count the number of zeros up to $N$ (we have to make sure to account
for the poles. I go into more details about this when I actually compute the
integral below).&lt;/p&gt;
&lt;h4&gt;Counting Zeros Part 2&lt;/h4&gt;
&lt;p&gt;So using the argument principle, we can count the number of zeros in a region.
Now how can we verify that they all lie on the critical line? The answer lies
in the $Z(s)$ function defined above. By the points outlined in the previous
section, we can see that $Z(s)$ is zero exactly where $\zeta(s)$ is zero on
the critical strip, and it is not zero anywhere else. In other words,&lt;/p&gt;
&lt;div style="text-align:center"&gt; &lt;b&gt;the zeros of $Z(s)$ are exactly the non-trivial zeros of $\zeta(s)$.&lt;/b&gt;&lt;/div&gt;
&lt;p&gt;This helps us because $Z(s)$ has a nice property on the critical line. First
we note that $Z(s)$ commutes with conjugation, that is $\overline{Z(s)} =
Z(\overline{s})$ (this isn't obvious from what I have shown, but it is true).
On the critical line $\frac{1}{2} + it$, we have&lt;/p&gt;
&lt;p&gt;$$\overline{Z\left(\frac{1}{2} + it\right)} = Z\left(\overline{\frac{1}{2} +
it}\right) = Z\left(\frac{1}{2} - it\right).$$&lt;/p&gt;
&lt;p&gt;However, $Z(s) = Z(1 - s)$, and $1 - \left(\frac{1}{2} - it\right) =
\frac{1}{2} + it$, so&lt;/p&gt;
&lt;p&gt;$$\overline{Z\left(\frac{1}{2} + it\right)} = Z\left(\frac{1}{2} +
it\right),$$&lt;/p&gt;
&lt;p&gt;which means that $Z\left(\frac{1}{2} + it\right)$ is real valued for real $t$.&lt;/p&gt;
&lt;p&gt;This simplifies things a lot, because it is much easier to find zeros of a real
function. In fact, we don't even care about finding the zeros, only counting
them. Since $Z(s)$ is continuous, we can use a simple method: counting sign
changes. If a continuous real function changes signs from negative to positive or from
positive to negative n times in an interval, then it must have at least n
zeros in that interval. It may have more, for instance, if some zeros are
clustered close together, or if a zero has a multiplicity greater than 1, but
we know that there must be at least n.&lt;/p&gt;
&lt;p&gt;So our approach to verifying the Riemann Hypothesis is as such:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Integrate $\frac{1}{2\pi i}\oint_C Z'(s)/Z(s)\,ds$ along a contour $C$
that runs along the critical strip up to some $\mathrm{Im}(s) = N$. The
integral will tell us there are exactly $n$ zeros in the contour, counting
multiplicity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Try to find $n$ sign changes of $Z(1/2 + it)$ for $t\in [0, N]$. If we can
find $n$ of them, we are done. We have confirmed all the zeros are on the
critical line.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Step 2 would fail if the Riemann Hypothesis is false, in which case a zero
wouldn't be on the critical line. But it would also fail if a zero has a
multiplicity greater than 1, since the integral would count it more times than
the sign changes. Fortunately, as it turns out, the Riemann Hypothesis has
been verified up to N = 10000000000000, and no one has yet found a zero of the
zeta function yet that has a multiplicity greater than 1, so we should not
expect that to happen (no one has yet found a counterexample to the Riemann
Hypothesis either).&lt;/p&gt;
&lt;h2&gt;Verification with SymPy and mpmath&lt;/h2&gt;
&lt;p&gt;We now use SymPy and mpmath to compute the above quantities. We use
&lt;a href="https://www.sympy.org/"&gt;SymPy&lt;/a&gt; to do symbolic manipulation for us, but the
heavy work is done by &lt;a href="http://mpmath.org/doc/current/index.html"&gt;mpmath&lt;/a&gt;.
mpmath is a pure Python library for arbitrary precision numerics. It is used
by SymPy under the hood, but it will be easier for us to use it directly. It
can do, among other things, numeric integration. When I first tried to do
this, I tried using the &lt;a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.zeta.html"&gt;&lt;code&gt;scipy.special&lt;/code&gt; zeta
function&lt;/a&gt;,
but unfortunately, it does not support complex arguments.&lt;/p&gt;
&lt;p&gt;First we do some basic imports&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; from sympy import *
&amp;gt;&amp;gt;&amp;gt; import mpmath
&amp;gt;&amp;gt;&amp;gt; import numpy as np
&amp;gt;&amp;gt;&amp;gt; import matplotlib.pyplot as plt
&amp;gt;&amp;gt;&amp;gt; s = symbols('s')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Define the completed zeta function $Z = \pi^{-s/2}\Gamma(s/2)\zeta(s)$.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; Z = pi**(-s/2)*gamma(s/2)*zeta(s)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can verify that Z is indeed real for $s = \frac{1}{2} + it.$&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; Z.subs(s, 1/2 + 0.5j).evalf()
-1.97702795164031 + 5.49690501450151e-17*I
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We get a small imaginary part due to the way floating point arithmetic works.
Since it is below &lt;code&gt;1e-15&lt;/code&gt;, we can safely ignore it.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;D&lt;/code&gt; will be the logarithmic derivative of &lt;code&gt;Z&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; D = simplify(Z.diff(s)/Z)
&amp;gt;&amp;gt;&amp;gt; D
polygamma(0, s/2)/2 - log(pi)/2 + Derivative(zeta(s), s)/zeta(s)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is $$\frac{\operatorname{polygamma}{\left(0,\frac{s}{2} \right)}}{2} -
\frac{\log{\left(\pi \right)}}{2} + \frac{
\zeta'\left(s\right)}{\zeta\left(s\right)}.$$&lt;/p&gt;
&lt;p&gt;Note that logarithmic derivatives behave similar to logarithms. The
logarithmic derivative of a product is the sum of logarithmic derivatives (the
$\operatorname{polygamma}$ function is the derivative of $\Gamma$).&lt;/p&gt;
&lt;p&gt;We now use
&lt;a href="https://docs.sympy.org/latest/modules/utilities/lambdify.html#sympy.utilities.lambdify.lambdify"&gt;&lt;code&gt;lambdify&lt;/code&gt;&lt;/a&gt;
to convert the SymPy expressions &lt;code&gt;Z&lt;/code&gt; and &lt;code&gt;D&lt;/code&gt; into functions that are evaluated
using mpmath. A technical difficulty here is that the derivative of the zeta
function $\zeta'(s)$ does not have a closed-form expression. &lt;a href="http://mpmath.org/doc/current/functions/zeta.html?highlight=zeta#mpmath.zeta"&gt;mpmath's &lt;code&gt;zeta&lt;/code&gt;
can evaluate
$\zeta'$&lt;/a&gt;
but it doesn't yet work with &lt;code&gt;sympy.lambdify&lt;/code&gt; (see &lt;a href="https://github.com/sympy/sympy/issues/11802"&gt;SymPy issue
11802&lt;/a&gt;). So we have to manually
define &lt;code&gt;"Derivative"&lt;/code&gt; in lambdify, knowing that it will be the derivative of
&lt;code&gt;zeta&lt;/code&gt; when it is called. Beware that this is only correct for this specific
expression where we know that &lt;code&gt;Derivative&lt;/code&gt; will be &lt;code&gt;Derivative(zeta(s), s)&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; Z_func = lambdify(s, Z, 'mpmath')
&amp;gt;&amp;gt;&amp;gt; D_func = lambdify(s, D, modules=['mpmath',
...     {'Derivative': lambda expr, z: mpmath.zeta(z, derivative=1)}])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now define a function to use the argument principle to count the number of
zeros up to $Ni$. Due to the symmetry $Z(s) = Z(1 - s)$, it is only necessary
to count zeros in the top half-plane.&lt;/p&gt;
&lt;p&gt;We have to be careful about the poles of $Z(s)$ at 0 and 1. We can either
integrate right above them, or expand the contour to include them. I chose to
do the former, starting at $0.1i$. It is known that there $\zeta(s)$ has no
zeros near the real axis on the critical strip. I could have also expanded the
contour to go around 0 and 1, and offset the result by 2 to account for the
integral counting those points as poles.&lt;/p&gt;
&lt;p&gt;It has also been shown that there are no zeros on the lines $\mathrm{Re}(s) =
0$ or $\mathrm{Re}(s) = 1$, so we do not need to worry about that. If the
upper point of our contour happens to have zeros exactly on it, we would be
very unlucky, but even if this were to happen we could just adjust it up a
little bit.&lt;/p&gt;
&lt;img src="https://asmeurer.com/blog/contour-c.svg" alt="Our contour" width="608"&gt;
&lt;p&gt;(Our contour with $N=10$. Created with &lt;a href="https://www.geogebra.org/graphing/nmnsaywd"&gt;Geogebra&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;a href="http://mpmath.org/doc/current/calculus/integration.html#mpmath.quad"&gt;&lt;code&gt;mpmath.quad&lt;/code&gt;&lt;/a&gt;
can take a list of points to compute a contour. The &lt;code&gt;maxdegree&lt;/code&gt; parameter
allows us to increase the degree of the quadrature if it becomes necessary to
get an accurate result.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def argument_count(func, N, maxdegree=6):
...     return 1/(2*mpmath.pi*1j)*(mpmath.quad(func,
...         [1 + 0.1j, 1 + N*1j, 0 + N*1j, 0 + 0.1j,  1 + 0.1j],
...         maxdegree=maxdegree))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let's test it. Lets count the zeros of $$s^2 - s + 1/2$$ in the box
bounded by the above rectangle ($N = 10$).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; expr = s**2 - s + S(1)/2
&amp;gt;&amp;gt;&amp;gt; argument_count(lambdify(s, expr.diff(s)/expr), 10)
mpc(real='1.0', imag='3.4287545414000525e-24')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The integral is 1. We can confirm there is indeed one
zero in this box, at $\frac{1}{2} + \frac{i}{2}$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; solve(s**2 - s + S(1)/2)
[1/2 - I/2, 1/2 + I/2]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now compute points of $Z$ along the critical line so we can count the sign
changes. We also make provisions in case we have to increase the precision of
mpmath to get correct results here. &lt;code&gt;dps&lt;/code&gt; is the number of digits of precision
the values are computed to. The default is 15, but mpmath can compute values
to any number of digits.
&lt;a href="http://mpmath.org/doc/current/general.html#chop"&gt;&lt;code&gt;mpmath.chop&lt;/code&gt;&lt;/a&gt; zeros out
values that are close to &lt;code&gt;0&lt;/code&gt;, which removes any numerically insignificant
imaginary parts that arise from the floating point evaluation.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def compute_points(Z_func, N, npoints=10000, dps=15):
...     import warnings
...     old_dps = mpmath.mp.dps
...     points = np.linspace(0, N, npoints)
...     try:
...         mpmath.mp.dps = dps
...         L = [mpmath.chop(Z_func(i)) for i in 1/2 + points*1j]
...     finally:
...         mpmath.mp.dps = old_dps
...     if L[-1] == 0:
...         # mpmath will give 0 if the precision is not high enough, since Z
...         # decays rapidly on the critical line.
...         warnings.warn("You may need to increase the precision")
...     return L
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next define a function to count the number of sign changes in a list of real
values.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def sign_changes(L):
...     """
...     Count the number of sign changes in L
...
...     Values of L should all be real.
...     """
...     changes = 0
...     assert im(L[0]) == 0, L[0]
...     s = sign(L[0])
...     for i in L[1:]:
...         assert im(i) == 0, i
...         s_ = sign(i)
...         if s_ == 0:
...             # Assume these got chopped to 0
...             continue
...         if s_ != s:
...             changes += 1
...         s = s_
...     return changes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, for $\sin(s)$ from -10 to 10, there are 7 zeros ($3\pi\approx
9.42$).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; sign_changes(lambdify(s, sin(s))(np.linspace(-10, 10)))
7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can check how many zeros of $Z(s)$ (and hence non-trivial zeros of
$\zeta(s)$) we can find. According to
&lt;a href="https://en.wikipedia.org/wiki/Riemann_hypothesis"&gt;Wikipedia&lt;/a&gt;, the first few
non-trivial zeros of $\zeta(s)$ in the upper half-plane are 14.135, 21.022,
and 25.011.&lt;/p&gt;
&lt;p&gt;First try up to $N=20$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 20)
mpc(real='0.99999931531867581', imag='-3.2332902529067346e-24')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mathematically, the above value &lt;em&gt;must&lt;/em&gt; be an integer, so we know it is 1.&lt;/p&gt;
&lt;p&gt;Now check the number of sign changes of $Z(s)$ from $\frac{1}{2} + 0i$ to
$\frac{1}{2} + 20i$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 20)
&amp;gt;&amp;gt;&amp;gt; sign_changes(L)
1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So it checks out. There is one zero between $0$ and $20i$ on the critical
strip, and it is in fact on the critical line, as expected!&lt;/p&gt;
&lt;p&gt;Now let's verify the other two zeros from Wikipedia.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 25)
mpc(real='1.9961479945577916', imag='-3.2332902529067346e-24')
&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 25)
&amp;gt;&amp;gt;&amp;gt; sign_changes(L)
2
&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 30)
mpc(real='2.9997317058520916', imag='-3.2332902529067346e-24')
&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 30)
&amp;gt;&amp;gt;&amp;gt; sign_changes(L)
3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both check out as well.&lt;/p&gt;
&lt;p&gt;Since we are computing the points, we can go ahead and make a plot as well.
However, there is a technical difficulty. If you naively try to plot $Z(1/2 +
it)$, you will find that it decays rapidly, so fast that you cannot really
tell where it crosses 0:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def plot_points_bad(L, N):
...     npoints = len(L)
...     points = np.linspace(0, N, npoints)
...     plt.figure()
...     plt.plot(points, L)
...     plt.plot(points, [0]*npoints, linestyle=':')
&amp;gt;&amp;gt;&amp;gt; plot_points_bad(L, 30)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src="https://asmeurer.com/blog/riemann-bad.svg" width="608"&gt;
&lt;p&gt;So instead of plotting $Z(1/2 + it)$, we plot $\log(|Z(1/2 + it)|)$. The
logarithm will make the zeros go to $-\infty$, but these will be easy to see.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; def plot_points(L, N):
...     npoints = len(L)
...     points = np.linspace(0, N, npoints)
...     p = [mpmath.log(abs(i)) for i in L]
...     plt.figure()
...     plt.plot(points, p)
...     plt.plot(points, [0]*npoints, linestyle=':')
&amp;gt;&amp;gt;&amp;gt; plot_points(L, 30)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src="https://asmeurer.com/blog/riemann-30.svg" width="608"&gt;
&lt;p&gt;The spikes downward are the zeros.&lt;/p&gt;
&lt;p&gt;Finally, let's check up to N=100. &lt;a href="https://oeis.org/A072080"&gt;OEIS A072080&lt;/a&gt;
gives the number of zeros of $\zeta(s)$ in upper half-plane up to $10^ni$.
According to it, we should get 29 zeros between $0$ and $100i$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 100)
mpc(real='28.248036536895913', imag='-3.2332902529067346e-24')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is not near an integer. This means we need to increase the precision of
the quadrature (the &lt;code&gt;maxdegree&lt;/code&gt; argument).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; argument_count(D_func, 100, maxdegree=9)
mpc(real='29.000000005970151', imag='-3.2332902529067346e-24')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the sign changes...&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 100)
__main__:11: UserWarning: You may need to increase the precision
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our guard against the precision being too low was triggered. Try raising it
(the default dps is 15).&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; L = compute_points(Z_func, 100, dps=50)
&amp;gt;&amp;gt;&amp;gt; sign_changes(L)
29
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They both give 29. So we have verified the Riemann Hypothesis up to $100i$!&lt;/p&gt;
&lt;p&gt;Here is a plot of these 29 zeros.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; plot_points(L, 100)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src="https://asmeurer.com/blog/riemann-100.svg" width="608"&gt;
&lt;p&gt;(remember that the spikes downward are the zeros)&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;$N=100$ takes a few minutes to compute, and I imagine larger and larger values
would require increasing the precision more, slowing it down even further, so
I didn't go higher than this. But it is clear that this method works.&lt;/p&gt;
&lt;p&gt;This was just me playing around with SymPy and mpmath, but if I wanted to
actually verify the Riemann Hypothesis, I would try to find a more efficient
method of computing the above quantities. For the sake of simplicity, I used
$Z(s)$ for both the argument principle and sign changes computations, but it
would have been more efficient to use $\zeta(s)$ for the argument principle
integral, since it has a simpler formula. It would also be useful if there
were a formula with similar properties to $Z(s)$ (real on the critical line
with the same zeros as $\zeta(s)$), but that did not decay as rapidly.&lt;/p&gt;
&lt;p&gt;Furthermore, for the argument principle integral, I would like to see precise
error estimates for the integral. We saw above with $N=100$ with the default
quadrature that we got a value of 28.248, which is not close to an integer.
This tipped us off that we should increase the quadrature, which ended up
giving us the right answer, but if the original number happened to be close to
an integer, we might have been fooled. Ideally, one would like know the exact
quadrature degree needed. If you can get error estimates guaranteeing the
error for the integral will be less than 0.5, you can always round the answer
to the nearest integer. For the sign changes, you don't need to be as
rigorous, because simply seeing as many sign changes as you have zeros is
sufficient. However, one could certainly be more efficient in computing the
values along the interval, rather than just naively computing 10000 points and
raising the precision until it works, as I have done.&lt;/p&gt;
&lt;p&gt;One would also probably want to use a faster integrator than mpmath (like one
written in C), and perhaps also find a faster to evaluate expression than the
one I used for $Z(s)$. It is also possible that one could special-case the
quadrature algorithm knowing that it will be computed on $\zeta'(s)/\zeta(s)$.&lt;/p&gt;
&lt;p&gt;In this post I described the Riemann zeta function and the Riemann Hypothesis,
and showed how to computationally verify it. But I didn't really go over the
details of why the Riemann Hypothesis matters. I encourage you to watch the
videos in my &lt;a href="https://www.youtube.com/playlist?list=PLrFrByaoJbcqKjzgJvLs2-spSmzP7jolT"&gt;YouTube
playlist&lt;/a&gt;
if you want to know this. Among other things, the truth of the Riemann
Hypothesis would give a very precise bound on the distribution of prime
numbers. Also, the non-trivial zeros of $\zeta(s)$ are, in some sense, the
"spectrum" of the prime numbers, meaning they exactly encode the position of
every prime on the number line.&lt;/p&gt;</description><guid>https://asmeurer.com/blog/posts/verifying-the-riemann-hypothesis-with-sympy-and-mpmath/</guid><pubDate>Tue, 31 Mar 2020 21:12:54 GMT</pubDate></item><item><title>Quansight Labs Work Update for September, 2019</title><link>https://asmeurer.com/blog/posts/quansight-labs-work-update-for-september-2019/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;&lt;em&gt;This post has been cross-posted on the &lt;a href="https://labs.quansight.org/blog/2019/10/quansight-labs-work-update-for-september-2019/"&gt;Quansight Labs
Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As of November, 2018, I have been working at
&lt;a href="https://www.quansight.com/"&gt;Quansight&lt;/a&gt;. Quansight is a new startup founded by
the same people who started Anaconda, which aims to connect companies and open
source communities, and offers consulting, training, support and mentoring
services. I work under the heading of &lt;a href="https://www.quansight.com/labs"&gt;Quansight
Labs&lt;/a&gt;. Quansight Labs is a public-benefit
division of Quansight. It provides a home for a "PyData Core Team" which
consists of developers, community managers, designers, and documentation
writers who build open-source technology and grow open-source communities
around all aspects of the AI and Data Science workflow.&lt;/p&gt;
&lt;p&gt;My work at Quansight is split between doing open source consulting for various
companies, and working on SymPy.
&lt;a href="https://www.sympy.org/en/index.html"&gt;SymPy&lt;/a&gt;, for those who do not know, is a
symbolic mathematics library written in pure Python. I am the lead maintainer
of SymPy.&lt;/p&gt;
&lt;p&gt;In this post, I will detail some of the open source work that I have done
recently, both as part of my open source consulting, and as part of my work on
SymPy for Quansight Labs.&lt;/p&gt;
&lt;h3&gt;Bounds Checking in Numba&lt;/h3&gt;
&lt;p&gt;As part of work on a client project, I have been working on contributing code
to the &lt;a href="https://numba.pydata.org"&gt;numba&lt;/a&gt; project. Numba is a just-in-time
compiler for Python. It lets you write native Python code and with the use of
a simple &lt;code&gt;@jit&lt;/code&gt; decorator, the code will be automatically sped up using LLVM.
This can result in code that is up to 1000x faster in some cases:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
In [1]: import numba

In [2]: import numpy

In [3]: def test(x):
   ...:     A = 0
   ...:     for i in range(len(x)):
   ...:         A += i*x[i]
   ...:     return A
   ...:

In [4]: @numba.njit
   ...: def test_jit(x):
   ...:     A = 0
   ...:     for i in range(len(x)):
   ...:         A += i*x[i]
   ...:     return A
   ...:

In [5]: x = numpy.arange(1000)

In [6]: %timeit test(x)
249 µs ± 5.77 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)

In [7]: %timeit test_jit(x)
336 ns ± 0.638 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)

In [8]: 249/.336
Out[8]: 741.0714285714286
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Numba only works for a subset of Python code, and primarily targets code that
uses NumPy arrays.&lt;/p&gt;
&lt;p&gt;Numba, with the help of LLVM, achieves this level of performance through many
optimizations. One thing that it does to improve performance is to remove all
bounds checking from array indexing. This means that if an array index is out
of bounds, instead of receiving an &lt;code&gt;IndexError&lt;/code&gt;, you will get garbage, or
possibly a segmentation fault.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import numpy as np
&amp;gt;&amp;gt;&amp;gt; from numba import njit
&amp;gt;&amp;gt;&amp;gt; def outtabounds(x):
...     A = 0
...     for i in range(1000):
...         A += x[i]
...     return A
&amp;gt;&amp;gt;&amp;gt; x = np.arange(100)
&amp;gt;&amp;gt;&amp;gt; outtabounds(x) # pure Python/NumPy behavior
Traceback (most recent call last):
  File "&amp;lt;stdin&amp;gt;", line 1, in &amp;lt;module&amp;gt;
  File "&amp;lt;stdin&amp;gt;", line 4, in outtabounds
IndexError: index 100 is out of bounds for axis 0 with size 100
&amp;gt;&amp;gt;&amp;gt; njit(outtabounds)(x) # the default numba behavior
-8557904790533229732
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In numba pull request &lt;a href="https://github.com/numba/numba/pull/4432"&gt;#4432&lt;/a&gt;, I am
working on adding a flag to &lt;code&gt;@njit&lt;/code&gt; that will enable bounds checks for array
indexing. This will remain disabled by default for performance purposes. But
you will be able to enable it by passing &lt;code&gt;boundscheck=True&lt;/code&gt; to &lt;code&gt;@njit&lt;/code&gt;, or by
setting the &lt;code&gt;NUMBA_BOUNDSCHECK=1&lt;/code&gt; environment variable. This will make it
easier to detect out of bounds issues like the one above. It will work like&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-pycon"&gt;&amp;gt;&amp;gt;&amp;gt; @njit(boundscheck=True)
... def outtabounds(x):
...     A = 0
...     for i in range(1000):
...         A += x[i]
...     return A
&amp;gt;&amp;gt;&amp;gt; x = np.arange(100)
&amp;gt;&amp;gt;&amp;gt; outtabounds(x) # numba behavior in my pull request #4432
Traceback (most recent call last):
  File "&amp;lt;stdin&amp;gt;", line 1, in &amp;lt;module&amp;gt;
IndexError: index is out of bounds
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pull request is still in progress, and many things such as the quality of
the error message reporting will need to be improved. This should make
debugging issues easier for people who write numba code once it is merged.&lt;/p&gt;
&lt;h3&gt;removestar&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.asmeurer.com/removestar/"&gt;removestar&lt;/a&gt; is a new tool I wrote to
automatically replace &lt;code&gt;import *&lt;/code&gt; in Python modules with explicit imports.&lt;/p&gt;
&lt;p&gt;For those who don't know, Python's &lt;code&gt;import&lt;/code&gt; statement supports so-called
"wildcard" or "star" imports, like&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;from sympy import *
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will import every public name from the &lt;code&gt;sympy&lt;/code&gt; module into the current
namespace. This is often useful because it saves on typing every name that is
used in the import line. This is especially useful when working interactively,
where you just want to import every name and minimize typing.&lt;/p&gt;
&lt;p&gt;However, doing &lt;code&gt;from module import *&lt;/code&gt; is generally frowned upon in Python. It is
considered acceptable when working interactively at a &lt;code&gt;python&lt;/code&gt; prompt, or in
&lt;code&gt;__init__.py&lt;/code&gt; files (removestar skips &lt;code&gt;__init__.py&lt;/code&gt; files by default).&lt;/p&gt;
&lt;p&gt;Some reasons why &lt;code&gt;import *&lt;/code&gt; is bad:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It hides which names are actually imported.&lt;/li&gt;
&lt;li&gt;It is difficult both for human readers and static analyzers such as
pyflakes to tell where a given name comes from when &lt;code&gt;import *&lt;/code&gt; is used. For
example, pyflakes cannot detect unused names (for instance, from typos) in
the presence of &lt;code&gt;import *&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If there are multiple &lt;code&gt;import *&lt;/code&gt; statements, it may not be clear which names
come from which module. In some cases, both modules may have a given name,
but only the second import will end up being used. This can break people's
intuition that the order of imports in a Python file generally does not
matter.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;import *&lt;/code&gt; often imports more names than you would expect. Unless the module
you import defines &lt;code&gt;__all__&lt;/code&gt; or carefully &lt;code&gt;del&lt;/code&gt;s unused names at the module
level, &lt;code&gt;import *&lt;/code&gt; will import every public (doesn't start with an
underscore) name defined in the module file. This can often include things
like standard library imports or loop variables defined at the top-level of
the file. For imports from modules (from &lt;code&gt;__init__.py&lt;/code&gt;), &lt;code&gt;from module import *&lt;/code&gt; will include every submodule defined in that module. Using &lt;code&gt;__all__&lt;/code&gt; in
modules and &lt;code&gt;__init__.py&lt;/code&gt; files is also good practice, as these things are
also often confusing even for interactive use where &lt;code&gt;import *&lt;/code&gt; is
acceptable.&lt;/li&gt;
&lt;li&gt;In Python 3, &lt;code&gt;import *&lt;/code&gt; is syntactically not allowed inside of a function
definition.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are some official Python references stating not to use &lt;code&gt;import *&lt;/code&gt; in
files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://docs.python.org/3/faq/programming.html?highlight=faq#what-are-the-best-practices-for-using-import-in-a-module"&gt;The official Python
FAQ&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In general, don’t use &lt;code&gt;from modulename import *&lt;/code&gt;. Doing so clutters the
importer’s namespace, and makes it much harder for linters to detect
undefined names.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.python.org/dev/peps/pep-0008/#imports"&gt;PEP 8&lt;/a&gt; (the official
Python style guide):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Wildcard imports (&lt;code&gt;from &amp;lt;module&amp;gt; import *&lt;/code&gt;) should be avoided, as they
make it unclear which names are present in the namespace, confusing both
readers and many automated tools.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Unfortunately, if you come across a file in the wild that uses &lt;code&gt;import *&lt;/code&gt;, it
can be hard to fix it, because you need to find every name in the file that is
imported from the &lt;code&gt;*&lt;/code&gt; and manually add an import for it. Removestar makes this
easy by finding which names come from &lt;code&gt;*&lt;/code&gt; imports and replacing the import
lines in the file automatically.&lt;/p&gt;
&lt;p&gt;As an example, suppose you have a module &lt;code&gt;mymod&lt;/code&gt; like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mymod/
  | __init__.py
  | a.py
  | b.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;# mymod/a.py
from .b import *

def func(x):
    return x + y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;# mymod/b.py
x = 1
y = 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then &lt;code&gt;removestar&lt;/code&gt; works like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ removestar -i mymod/
$ cat mymod/a.py
# mymod/a.py
from .b import y

def func(x):
    return x + y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;-i&lt;/code&gt; flag causes it to edit &lt;code&gt;a.py&lt;/code&gt; in-place. Without it, it would just
print a diff to the terminal.&lt;/p&gt;
&lt;p&gt;For implicit star imports and explicit star imports from the same module,
&lt;code&gt;removestar&lt;/code&gt; works statically, making use of
&lt;a href="https://github.com/PyCQA/pyflakes"&gt;pyflakes&lt;/a&gt;. This means none of the code is
actually executed. For external imports, it is not possible to work statically
as external imports may include C extension modules, so in that case, it
imports the names dynamically.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;removestar&lt;/code&gt; can be installed with pip or conda:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install removestar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or if you use conda&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge removestar
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;sphinx-math-dollar&lt;/h3&gt;
&lt;p&gt;In SymPy, we make heavy use of LaTeX math in our documentation. For example,
in our &lt;a href="https://docs.sympy.org/dev/modules/functions/special.html#sympy.functions.special.hyper.hyper"&gt;special functions
documentation&lt;/a&gt;,
most special functions are defined using a LaTeX formula, like &lt;img src="https://asmeurer.com/blog/besselj_docs.png" alt="The docs for besselj"&gt;&lt;/p&gt;
&lt;p&gt;(from &lt;a href="https://docs.sympy.org/dev/modules/functions/special.html#sympy.functions.special.bessel.besselj"&gt;https://docs.sympy.org/dev/modules/functions/special.html#sympy.functions.special.bessel.besselj&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;However, the source for this math in the docstring of the function uses RST
syntax:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;class besselj(BesselBase):
    """
    Bessel function of the first kind.

    The Bessel `J` function of order `\nu` is defined to be the function
    satisfying Bessel's differential equation

    .. math ::
        z^2 \frac{\mathrm{d}^2 w}{\mathrm{d}z^2}
        + z \frac{\mathrm{d}w}{\mathrm{d}z} + (z^2 - \nu^2) w = 0,

    with Laurent expansion

    .. math ::
        J_\nu(z) = z^\nu \left(\frac{1}{\Gamma(\nu + 1) 2^\nu} + O(z^2) \right),

    if :math:`\nu` is not a negative integer. If :math:`\nu=-n \in \mathbb{Z}_{&amp;lt;0}`
    *is* a negative integer, then the definition is

    .. math ::
        J_{-n}(z) = (-1)^n J_n(z).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Furthermore, in SymPy's documentation we have configured it so that text
between `single backticks` is rendered as math. This was originally done for
convenience, as the alternative way is to write &lt;code&gt;:math:`\nu`&lt;/code&gt; every
time you want to use inline math. But this has lead to many people being
confused, as they are used to Markdown where `single backticks` produce
&lt;code&gt;code&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A better way to write this would be if we could delimit math with dollar
signs, like &lt;code&gt;$\nu$&lt;/code&gt;. This is how things are done in LaTeX documents, as well
as in things like the Jupyter notebook.&lt;/p&gt;
&lt;p&gt;With the new &lt;a href="https://www.sympy.org/sphinx-math-dollar/"&gt;sphinx-math-dollar&lt;/a&gt;
Sphinx extension, this is now possible. Writing &lt;code&gt;$\nu$&lt;/code&gt; produces $\nu$, and
the above docstring can now be written as&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;class besselj(BesselBase):
    """
    Bessel function of the first kind.

    The Bessel $J$ function of order $\nu$ is defined to be the function
    satisfying Bessel's differential equation

    .. math ::
        z^2 \frac{\mathrm{d}^2 w}{\mathrm{d}z^2}
        + z \frac{\mathrm{d}w}{\mathrm{d}z} + (z^2 - \nu^2) w = 0,

    with Laurent expansion

    .. math ::
        J_\nu(z) = z^\nu \left(\frac{1}{\Gamma(\nu + 1) 2^\nu} + O(z^2) \right),

    if $\nu$ is not a negative integer. If $\nu=-n \in \mathbb{Z}_{&amp;lt;0}$
    *is* a negative integer, then the definition is

    .. math ::
        J_{-n}(z) = (-1)^n J_n(z).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also plan to add support for &lt;code&gt;$$double dollars$$&lt;/code&gt; for display math so that &lt;code&gt;.. math ::&lt;/code&gt; is no longer needed either .&lt;/p&gt;
&lt;p&gt;For end users, the documentation on &lt;a href="https://docs.sympy.org"&gt;docs.sympy.org&lt;/a&gt;
will continue to render exactly the same, but for developers, it is much
easier to read and write.&lt;/p&gt;
&lt;p&gt;This extension can be easily used in any Sphinx project. Simply install it
with pip or conda:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install sphinx-math-dollar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge sphinx-math-dollar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then enable it in your &lt;code&gt;conf.py&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;extensions = ['sphinx_math_dollar', 'sphinx.ext.mathjax']
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Google Season of Docs&lt;/h3&gt;
&lt;p&gt;The above work on sphinx-math-dollar is part of work I have been doing to
improve the tooling around SymPy's documentation. This has been to assist our
technical writer Lauren Glattly, who is working with SymPy for the next three
months as part of the new &lt;a href="https://developers.google.com/season-of-docs/"&gt;Google Season of
Docs&lt;/a&gt; program. Lauren's project
is to improve the consistency of our docstrings in SymPy. She has already
identified many key ways our docstring documentation can be improved, and is
currently working on a style guide for writing docstrings. Some of the issues
that Lauren has identified require improved tooling around the way the HTML
documentation is built to fix. So some other SymPy developers and I have been
working on improving this, so that she can focus on the technical writing
aspects of our documentation.&lt;/p&gt;
&lt;p&gt;Lauren has created a draft style guide for documentation at
&lt;a href="https://github.com/sympy/sympy/wiki/SymPy-Documentation-Style-Guide"&gt;https://github.com/sympy/sympy/wiki/SymPy-Documentation-Style-Guide&lt;/a&gt;. Please
take a moment to look at it and if you have any feedback on it, comment below
or write to the SymPy mailing list.&lt;/p&gt;</description><guid>https://asmeurer.com/blog/posts/quansight-labs-work-update-for-september-2019/</guid><pubDate>Mon, 07 Oct 2019 05:00:00 GMT</pubDate></item><item><title>What's New in SymPy 1.4</title><link>https://asmeurer.com/blog/posts/whats-new-in-sympy-14/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;&lt;em&gt;This post has been cross-posted on the &lt;a href="https://labs.quansight.org/blog/2019/04/whats-new-in-sympy-14/"&gt;Quansight Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As of November, 2018, I have been working at
&lt;a href="https://www.quansight.com/"&gt;Quansight&lt;/a&gt;. Quansight is a new startup founded by
the same people who started Anaconda, which aims to connect companies and open
source communities, and offers consulting, training, support and mentoring
services. I work under the heading of &lt;a href="https://www.quansight.com/labs"&gt;Quansight
Labs&lt;/a&gt;. Quansight Labs is a public-benefit
division of Quansight. It provides a home for a "PyData Core Team" which
consists of developers, community managers, designers, and documentation
writers who build open-source technology and grow open-source communities
around all aspects of the AI and Data Science workflow. As a part of this, I
am able to spend a fraction of my time working on SymPy.
&lt;a href="https://www.sympy.org/en/index.html"&gt;SymPy&lt;/a&gt;, for those who do not know, is a
symbolic mathematics library written in pure Python. I am the lead maintainer
of SymPy.&lt;/p&gt;
&lt;p&gt;SymPy 1.4 was released on April 9, 2019. In this post, I'd like to go over
some of the highlights for this release. The full release notes for the
release can be found on the &lt;a href="https://github.com/sympy/sympy/wiki/Release-Notes-for-1.4"&gt;SymPy
wiki&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To update to SymPy 1.4, use&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;conda install sympy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or if you prefer to use pip&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U sympy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The SymPy 1.4 release contains over &lt;a href="https://github.com/sympy/sympy/wiki/Release-Notes-for-1.4#authors"&gt;500 changes from 38 different
submodules&lt;/a&gt;,
so I will not be going over every change, but only a few of the main
highlights. A &lt;a href="https://github.com/sympy/sympy/wiki/Release-Notes-for-1.4#authors"&gt;total of 104
people&lt;/a&gt;
contributed to this release, of whom 66 contributed for the first time for
this release.&lt;/p&gt;
&lt;p&gt;While I did not personally work on any of the changes listed below (my work
for this release tended to be more invisible, behind the scenes fixes), I did
do the release itself.&lt;/p&gt;
&lt;h2&gt;Automatic LaTeX rendering in the Jupyter notebook&lt;/h2&gt;
&lt;p&gt;Prior to SymPy 1.4, SymPy expressions in the notebook rendered by default with their
string representation. To get &lt;code&gt;LaTeX&lt;/code&gt; output, you had to call &lt;code&gt;init_printing()&lt;/code&gt;:&lt;/p&gt;
&lt;img src="https://asmeurer.com/blog/sympy-1.3-notebook.png" alt="SymPy 1.3 rendering in the Jupyter lab notebook"&gt;
&lt;p&gt;In SymPy 1.4, SymPy expressions now automatically render as LaTeX in the notebook:&lt;/p&gt;
&lt;img src="https://asmeurer.com/blog/sympy-1.4-notebook.png" alt="SymPy 1.4 rendering in the Jupyter lab notebook"&gt;
&lt;p&gt;However, this only applies automatically if the type of an object is a SymPy
expression. For built-in types such as lists or ints, &lt;code&gt;init_printing()&lt;/code&gt; is
still required to get LaTeX printing. For example, &lt;code&gt;solve()&lt;/code&gt; returns a list,
so does not render as LaTeX unless &lt;code&gt;init_printing()&lt;/code&gt; is called:&lt;/p&gt;
&lt;img src="https://asmeurer.com/blog/sympy-1.4-notebook-2.png" alt="SymPy 1.4 rendering in the Jupyter lab notebook with init_printing()"&gt;
&lt;p&gt;&lt;code&gt;init_printing()&lt;/code&gt; is also still needed if you want to change any of the
printing settings, for instance, passing flags to the &lt;code&gt;latex()&lt;/code&gt; printer or
selecting a different printer.&lt;/p&gt;
&lt;p&gt;If you want the string form of an expression for copy-pasting, you can use
&lt;code&gt;print&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Improved simplification of relational expressions&lt;/h2&gt;
&lt;p&gt;Simplification of relational and piecewise expressions has been improved:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; x, y, z, w = symbols('x y z w')
&amp;gt;&amp;gt;&amp;gt; init_printing()
&amp;gt;&amp;gt;&amp;gt; expr = And(Eq(x,y), x &amp;gt;= y, w &amp;lt; y, y &amp;gt;= z, z &amp;lt; y)
&amp;gt;&amp;gt;&amp;gt; expr
x = y ∧ x ≥ y ∧ y ≥ z ∧ w &amp;lt; y ∧ z &amp;lt; y
&amp;gt;&amp;gt;&amp;gt; simplify(expr)
x = y ∧ y &amp;gt; Max(w, z)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; expr = Piecewise((x*y, And(x &amp;gt;= y, Eq(y, 0))), (x - 1, Eq(x, 1)), (0, True))
&amp;gt;&amp;gt;&amp;gt; expr
⎧ x⋅y   for y = 0 ∧ x ≥ y
⎪
⎨x - 1      for x = 1
⎪
⎩  0        otherwise
&amp;gt;&amp;gt;&amp;gt; simplify(expr)
0
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Improved MathML printing&lt;/h2&gt;
&lt;p&gt;The MathML presentation printer has been greatly improved, putting it on par
with the existing Unicode and LaTeX pretty printers.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; mathml(Integral(exp(-x**2), (x, -oo, oo)), 'presentation')
&amp;lt;mrow&amp;gt;&amp;lt;msubsup&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;#x222B;&amp;lt;/mo&amp;gt;&amp;lt;mrow&amp;gt;&amp;lt;mo&amp;gt;-&amp;lt;/mo&amp;gt;&amp;lt;mi&amp;gt;&amp;amp;#x221E;&amp;lt;/mi&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;mi&amp;gt;&amp;amp;#x221E;&amp;lt;/mi&amp;gt;&amp;lt;/msubsup&amp;gt;&amp;lt;msup&amp;gt;&amp;lt;mi&amp;gt;&amp;amp;ExponentialE;&amp;lt;/mi&amp;gt;&amp;lt;mrow&amp;gt;&amp;lt;mo&amp;gt;-&amp;lt;/mo&amp;gt;&amp;lt;msup&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;mn&amp;gt;2&amp;lt;/mn&amp;gt;&amp;lt;/msup&amp;gt;&amp;lt;/mrow&amp;gt;&amp;lt;/msup&amp;gt;&amp;lt;mo&amp;gt;&amp;amp;dd;&amp;lt;/mo&amp;gt;&amp;lt;mi&amp;gt;x&amp;lt;/mi&amp;gt;&amp;lt;/mrow&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If your &lt;a href="https://caniuse.com/#feat=mathml"&gt;browser supports MathML&lt;/a&gt; (at the
time of writing, only Firefox and Safari), you should see the above
presentation form for &lt;code&gt;Integral(exp(-x**2), (x, -oo, oo))&lt;/code&gt; below:&lt;/p&gt;
&lt;p&gt;&lt;math style="display: block;"&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mo&gt;∫&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;mi&gt;∞&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;∞&lt;/mi&gt;&lt;/msubsup&gt;&lt;msup&gt;&lt;mi&gt;ⅇ&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo&gt;ⅆ&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;&lt;/p&gt;
&lt;h2&gt;Improvements to solvers&lt;/h2&gt;
&lt;p&gt;Several improvements have been made to the solvers.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; eq = Eq((x**2 - 7*x + 11)**(x**2 - 13*x + 42), 1)
&amp;gt;&amp;gt;&amp;gt; eq
                2
               x  - 13⋅x + 42
⎛ 2           ⎞
⎝x  - 7⋅x + 11⎠               = 1
&amp;gt;&amp;gt;&amp;gt; solve(eq, x) # In SymPy 1.3, this only gave the partial solution [2, 5, 6, 7]
[2, 3, 4, 5, 6, 7]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ODE solver, &lt;code&gt;dsolve&lt;/code&gt;, has also seen some improvements. Two new hints have
been added.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;'nth_algebraic'&lt;/code&gt; solves ODEs using &lt;code&gt;solve&lt;/code&gt; by inverting the derivatives
algebraically:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; f = Function('f')
&amp;gt;&amp;gt;&amp;gt; eq = Eq(f(x) * (f(x).diff(x)**2 - 1), 0)
&amp;gt;&amp;gt;&amp;gt; eq
⎛          2    ⎞
⎜⎛d       ⎞     ⎟
⎜⎜──(f(x))⎟  - 1⎟⋅f(x) = 0
⎝⎝dx      ⎠     ⎠
&amp;gt;&amp;gt;&amp;gt; dsolve(eq, f(x)) # In SymPy 1.3, this only gave the solution f(x) = C1 - x
[f(x) = 0, f(x) = C₁ - x, f(x) = C₁ + x]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;'nth_order_reducible'&lt;/code&gt; solves ODEs that only involve derivatives of &lt;code&gt;f(x)&lt;/code&gt;,
via the substitution $g(x)=f^{(n)}(x)$.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-py"&gt;&amp;gt;&amp;gt;&amp;gt; eq = Eq(Derivative(f(x), (x, 2)) + x*Derivative(f(x), x), x)
&amp;gt;&amp;gt;&amp;gt; eq
               2
  d           d
x⋅──(f(x)) + ───(f(x)) = x
  dx           2
             dx
&amp;gt;&amp;gt;&amp;gt; dsolve(eq, f(x))
                  ⎛√2⋅x⎞
f(x) = C₁ + C₂⋅erf⎜────⎟ + x
                  ⎝ 2  ⎠
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Dropping Python 3.4 support&lt;/h2&gt;
&lt;p&gt;This is the last release of SymPy to support Python 3.4. SymPy 1.4 supports
Python 2.7, 3.4, 3.5, 3.6, 3.7, and PyPy. What's perhaps more exciting is that
the next release of SymPy, 1.5, which will be released later this year, will
be the last version to support Python 2.7.&lt;/p&gt;
&lt;p&gt;Our
&lt;a href="https://github.com/sympy/sympy/wiki/Python-version-support-policy"&gt;policy&lt;/a&gt; is
to drop support for major Python versions when they reach their &lt;a href="https://devguide.python.org/#status-of-python-branches"&gt;End of
Life&lt;/a&gt;. In other words,
they receive no further support from the core Python team. Python 3.4 reached
its end of life on May 19 of this year, and Python 2.7 will reach its end of
life on January 1, 2020.&lt;/p&gt;
&lt;p&gt;I have &lt;a href="https://www.asmeurer.com/blog/posts/moving-away-from-python-2/"&gt;blogged in the
past&lt;/a&gt; on why I
believe it is important for library authors to be proactive in dropping Python
2 support, and since then &lt;a href="https://python3statement.org"&gt;a large number of Python
libraries&lt;/a&gt; have either dropped support or
announced their plans to by 2020.&lt;/p&gt;
&lt;p&gt;Having Python 2 support removed will not only allow us to remove a &lt;a href="https://github.com/sympy/sympy/blob/sympy-1.4/sympy/core/compatibility.py"&gt;large
amount of compatibility
cruft&lt;/a&gt;
from our codebase, it will also allow us to use some Python 3-only features
that will clean up our API, such as &lt;a href="https://python-3-for-scientists.readthedocs.io/en/latest/python3_advanced.html#keyword-only-arguments"&gt;keyword-only
arguments&lt;/a&gt;,
&lt;a href="https://python-3-for-scientists.readthedocs.io/en/latest/python3_features.html#function-annotations"&gt;type
hints&lt;/a&gt;,
and &lt;a href="https://python-3-for-scientists.readthedocs.io/en/latest/python3_features.html#unicode-variable-names"&gt;Unicode variable
names&lt;/a&gt;.
It will also enable &lt;a href="https://github.com/sympy/sympy/issues?q=is%3Aissue+is%3Aopen+label%3A%22Dropping+Python+2%22"&gt;several internal
changes&lt;/a&gt;
that will not be visible to end-users, but which will result in a much cleaner
and more maintainable codebase.&lt;/p&gt;
&lt;p&gt;If you are still using Python 2, I strongly recommend switching to Python 3,
as otherwise the entire ecosystem of Python libraries is soon going to stop
improving for you. Python 3 is already highly recommended for SymPy usage due
to several key improvements. In particular, in Python 3, division of two
Python &lt;code&gt;int&lt;/code&gt;s like &lt;code&gt;1/2&lt;/code&gt; produces the float &lt;code&gt;0.5&lt;/code&gt;. In Python 2, it does
integer division (producing &lt;code&gt;1/2 == 0&lt;/code&gt;). The Python 2 integer division
behavior can lead to very surprising results when using SymPy (imagine writing
&lt;code&gt;x**2 + 1/2*x + 2&lt;/code&gt; and having the &lt;code&gt;x&lt;/code&gt; term "disappear"). When using SymPy, we
&lt;a href="https://docs.sympy.org/latest/tutorial/gotchas.html#two-final-notes-and"&gt;recommend&lt;/a&gt;
using rational numbers (like &lt;code&gt;Rational(1, 2)&lt;/code&gt;) and avoiding &lt;code&gt;int/int&lt;/code&gt;, but the
Python 3 behavior will at least maintain a mathematically correct result if
you do not do this. SymPy is also &lt;a href="https://speed.python.org/comparison/?exe=12%2BL%2Bmaster%2C12%2BL%2B3.5%2C12%2BL%2B3.6%2C12%2BL%2B2.7&amp;amp;ben=666%2C667%2C669%2C668&amp;amp;env=1%2C2&amp;amp;hor=false&amp;amp;bas=none&amp;amp;chart=normal+bars"&gt;already faster in Python
3&lt;/a&gt;
due to things like &lt;code&gt;math.gcd&lt;/code&gt; and &lt;code&gt;functools.lru_cache&lt;/code&gt; being written in C,
and general performance improvements in the interpreter itself.&lt;/p&gt;
&lt;h2&gt;And much more&lt;/h2&gt;
&lt;p&gt;These are only a few of the highlights of the hundreds of changes in this
release. The full release notes can be found on &lt;a href="https://github.com/sympy/sympy/wiki/Release-Notes-for-1.4"&gt;our
wiki&lt;/a&gt;. The wiki
also has the in progress changes for our next release, &lt;a href="https://github.com/sympy/sympy/wiki/Release-Notes-for-1.5"&gt;SymPy
1.5&lt;/a&gt;, which will be
released later this year. Our &lt;a href="https://github.com/sympy/sympy-bot"&gt;bot&lt;/a&gt;
automatically collects release notes from every pull request, meaning SymPy
releases have very comprehensive and readable release notes pages. If you see
any mistakes on either page, feel free to edit the wiki and fix them.&lt;/p&gt;</description><guid>https://asmeurer.com/blog/posts/whats-new-in-sympy-14/</guid><pubDate>Thu, 02 May 2019 05:00:00 GMT</pubDate></item><item><title>GitHub Cuts</title><link>https://asmeurer.com/blog/posts/github-cuts/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;GitHub recently announced its &lt;a href="https://blog.github.com/2018-08-28-announcing-paper-cuts/"&gt;paper cuts
initiative&lt;/a&gt; to fix
minor issues that make things more difficult for GitHub users. As someone who
spends most of his day on &lt;a href="https://github.com"&gt;github.com&lt;/a&gt;, this initiative is
great, as these small cuts can quickly add up to a painful experience.&lt;/p&gt;
&lt;p&gt;The initiative has already made some great fixes, such as &lt;a href="https://blog.github.com/changelog/2018-07-31-unselectable-diff-markers/"&gt;making the diff
markers
unselectable&lt;/a&gt;
and
&lt;a href="https://blog.github.com/changelog/2018-10-08-issue-and-pull-request-hovercards/"&gt;hovercards&lt;/a&gt;.
Small changes like these are usually quite easy for GitHub to do, but they
make a huge difference to those of use who use GitHub every day.&lt;/p&gt;
&lt;p&gt;I &lt;a href="https://twitter.com/asmeurer/status/1034528642389266432"&gt;recently asked&lt;/a&gt;
how these cuts could be reported to GitHub for fixing, but got no response. So
I am writing this blog post.&lt;/p&gt;
&lt;p&gt;To be very clear: I think that on the whole GitHub is great and they are doing
a great job. And it's still better than the alternatives (to put things in
perspective, I recently spent &lt;a href="https://twitter.com/asmeurer/status/1029158262069899266"&gt;half an
hour&lt;/a&gt; trying to
figure out how to change my password in BitBucket, and GitLab can't even keep
me logged in between sessions). GitHub has and continues to revolutionize the
open source ecosystem, and is still the best place to host an open source
project.&lt;/p&gt;
&lt;p&gt;But since GitHub did
&lt;a href="https://blog.github.com/2018-08-28-announcing-paper-cuts/"&gt;ask&lt;/a&gt; what sorts of
changes they want to see, I'm providing a list. In this post I'm trying to
only ask about things that are small changes (though I realize many won't be
as easy to fix as they may appear from the outside, and I readily admit that I
am not a web developer).&lt;/p&gt;
&lt;p&gt;These are just the things that have bothered me, personally. Other people use
GitHub differently and no doubt have their own pain points. For instance, I
have no suggestions about the project boards feature of GitHub because I don't
use it. If you are also a GitHub user and have your own pain points feel free
to use the comment box below (though I have no idea if GitHub will actually
see them).&lt;/p&gt;
&lt;p&gt;If you work for GitHub and have any questions, feel free to comment below, or
&lt;a href="mailto:asmeurer@gmail.com"&gt;email me&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In no particular order:&lt;/p&gt;
&lt;h3&gt;Issues&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow anyone to add labels to issues.&lt;/strong&gt; At the very least, allow the
person who opened the issue to add labels.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new issue transfer ability is great, but please &lt;strong&gt;make it require only
push access, not admin access.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Remove the automatic hiding of comments when there are too many.&lt;/strong&gt; I
understand this is done for technical reasons, but it breaks
Cmd-F/scrolling through the page to find comments. Often I go to an issue
trying to find an old comment and can't because buried in the comments is a
button I have to press to actually show the comment (it's even worse when
you have to find and press the button multiple times).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Better indication for cross-referenced pull requests.&lt;/strong&gt; I really don't
know how to fix this, only that it is a problem. It happens all the time
that a new contributor comes to a SymPy issue and asks if it has been
worked on yet. They generally do not seem to notice the cross-referenced
pull requests in the list.
&lt;a href="https://github.com/sympy/sympy/issues/14943"&gt;Here&lt;/a&gt; is an example of what
I'm talking about.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Indicate better if a cross-referenced pull request would close an
issue.&lt;/strong&gt; Preferably with text, not just an icon.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HTML pull request/issue templates.&lt;/strong&gt; I don't know if this counts as a
"cut", as it isn't a simple fix. Right now, many projects use pull
requests/new issue templates, but it is not very user friendly. The problem
is that the whole thing is done in plain text, often with the template text
as an HTML comment to prevent it from appearing in the final issue text.
Even for me, I often find this quite difficult to read through, but for new
contributors, we often find that they don't read it at all. Sure there's no
way to force people to read, but if we could instead create a very simple
HTML form for people to fill out, it would be much more friendly, even to
experienced people like myself.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Fix the back button in Chrome.&lt;/strong&gt; I don't know if this is something that
GitHub can fix, and I also do not know how things work in other browsers. I
use Chrome on macOS. Often, when I click the "back" button and it takes me
back to an issue page, the contents of the page are out-of-date (the newest
comments or commits do not appear). It's often even more out-of-date than
it was when I left the page. I have to reload the page to get the latest
content.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow Markdown formatting in issue titles.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Show people's names next to comments as "Real Name (@username)".&lt;/strong&gt; In
general, GitHub should be emphasizing people's display names rather than
their usernames.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Remember my selection for the "sort" setting in the issues list.&lt;/strong&gt; I'd
love to have issues/pull requests sort by "most recently updated" by
default, so that I don't miss updates to old issues/pull requests.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Make advanced search filters more accessible.&lt;/strong&gt; They should autofill,
similar to how Gmail or even GitLab search works (yes, please steal all
the good ideas from GitLab; they already stole all their good ideas from
you).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tone down the reaction emojis.&lt;/strong&gt; Maybe this ship has sailed, but
reaction emojis are way too unprofessional for some projects.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Copy/paste text as Markdown.&lt;/strong&gt; For example, copying "&lt;strong&gt;bold&lt;/strong&gt;" and
pasting it into the comment box would paste &lt;code&gt;**bold**&lt;/code&gt;. Another idea that
you can steal from GitLab.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Strike out #12345 issue links when the issue/PR is closed/merged&lt;/strong&gt;
(like &lt;strike&gt;#12345&lt;/strike&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Pull requests&lt;/h3&gt;
&lt;ol start="15"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add a button that automatically merges a pull request as soon as all the
CI checks pass.&lt;/strong&gt; Any additional commits pushed to the branch in the
interim would cancel it, and it should also be cancellable by someone else
with push access or the PR author.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add some way to disable the automatic hiding of large diffs.&lt;/strong&gt; This
breaks Cmd-F on the page, and makes it harder to scroll through the pull
request to find what you are looking for (typically the most important
changes are the ones that are hidden!).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Include all issue/PR authors in the authors search on the pull request
list page.&lt;/strong&gt; Right now it only lists people with push access. But I
generally can't remember people's GitHub usernames, and autofilling based
on all authors would be very helpful.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Better contextual guesses for issue autofilling (after typing &lt;code&gt;#&lt;/code&gt;).&lt;/strong&gt;
For instance, if an issue has already been referenced or cross-referenced,
it should appear near the top of the list. We have almost &lt;a href="https://github.com/sympy/sympy/issues"&gt;3000 open
issues&lt;/a&gt; in SymPy, and the current
issue numbers are 5-digits long, so referencing an issue purely by number
is very error prone.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Auto-update edited comments.&lt;/strong&gt; Context: SymPy uses a
&lt;a href="https://github.com/sympy/sympy-bot"&gt;bot&lt;/a&gt; that comments on every pull
request, requiring a release notes entry to be added to the description.
This works quite well, but to prevent the bot from spamming, we have it
comment only once, and edit its comment on any further checks. However,
these edits do not automatically update, so people have to manually reload
the page to see them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Don't hide full commit messages by default in the commits view.&lt;/strong&gt; It
would be better to encourage people to write good commit messages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Make issue cross-references in pull request titles work.&lt;/strong&gt; I'd rather
people didn't put issue numbers in pull request titles but they do it
anyway, so it would be nice if they actually worked as links.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow me to comment on lines that aren't visible by default.&lt;/strong&gt; That is,
lines that you have to click the "expand" icon above or below the line
numbers to access. As an example, this can be useful to point out a line
that should have been changed but wasn't.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Copying code from a diff that includes lines that aren't visible by
default includes an extra space to the left for those lines.&lt;/strong&gt; This is a
straight up bug. Probably fixing the previous point would also fix this :)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Make searches include text from the pull request diff.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;When a diff indents a line color the whitespace to the left of the
line.&lt;/strong&gt; (see
&lt;a href="https://twitter.com/asmeurer/status/740611970714480640"&gt;this&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pull requests can show commits that are already in master.&lt;/strong&gt; For
example, if someone makes pull request B based off of pull request A and
then A gets merged, B will still show the commits from A. This has been a
bug forever.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Make the "jump to file or symbol" popdown collapsible.&lt;/strong&gt; Specifically
what I mean is I want to be able to show just the files, without any
symbols. For large pull requests, it is very difficult to use this popdown
if there are hundreds of symbols. I typically want to just jump to a
specific file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The status check on the favicon goes away when you switch to the diff
tab.&lt;/strong&gt; Kudos to Marius Gedminas for &lt;a href="https://twitter.com/mgedmin/status/1058381090694553601"&gt;pointing this
out&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/sympy/sympy/pull/15280#issuecomment-426795606"&gt;Apparently&lt;/a&gt;
status checks that use the GitHub Apps API are forced to link into the
checks tab.&lt;/strong&gt; The checks tab is useless if no information is actually
published to it. It would be better if it could link straight to the
external site, like is done with oauth integrations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Make it easier to copy someone's username from the pull request page.&lt;/strong&gt;
I generally do this to &lt;code&gt;git remote add&lt;/code&gt; them (using
&lt;a href="https://github.com/github/hub"&gt;hub&lt;/a&gt;). If I try to select their username
from a comment, it's a link, which makes it hard to select. I generally
copy it from the blue text at the top "&lt;em&gt;user&lt;/em&gt; wants to merge &lt;em&gt;n&lt;/em&gt; commits
from &lt;code&gt;sympy:master&lt;/code&gt; from &lt;code&gt;user:branch&lt;/code&gt;". If it were easier to select
"user" or "branch" from that box (say, by double clicking), that would be
helpful.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Change the "resolve conversation" UI.&lt;/strong&gt; I keep pressing it on accident
because it's where I expect the "new comment" button to be.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Reviews&lt;/h3&gt;
&lt;p&gt;I wrote a &lt;a href="https://www.asmeurer.com/blog/posts/github-reviews-gripes/"&gt;whole
post&lt;/a&gt; about the
reviews feature when it came out. Not much has changed since then (actually,
it has gotten worse). In short, the feature doesn't work like I would like it
too, and I find the default behavior of deferred comments to be extremely
detrimental. If there were a way to completely disable reviews (for myself, I
don't care about other people using the feature), I would.&lt;/p&gt;
&lt;p&gt;See my blog post for full details on why I think the reviews feature is broken
and actually makes things worse, not better than before. I've summarized a few
things that could change below.&lt;/p&gt;
&lt;ol start="32"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Make reviews non-deferred by default.&lt;/strong&gt; This is the biggest thing. If I
had to pick only a single item on this page to be changed, it would be
this. The issue is if I start a review and walk away from it, but forget
to "finalize" it with a review status, the review is never actually seen
by anyone. The simplest way to fix this would be to simply make partial
reviews public.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Make Cmd-Enter default to immediate comment.&lt;/strong&gt; Barring the above change,
Cmd-Enter on a pull request line comment should default to immediate
comment, not deferred (review) comment. The problem with the
Cmd-Shift-Enter shortcut is that it is inconsistent: on a normal comment,
it closes the pull request, and on a reply comment, it does nothing. I
shouldn't have to check what "comment context" I am in to figure out what
keyboard shortcut to use. The worst part is if you accidentally start a
review, it's a pain in the ass to undo that and just post a normal
comment. The simplest way to fix this would be to swap the current meaning
of Cmd-Enter and Cmd-Shift-Enter for line comments (and no, this wouldn't
be a backwards incompatible change, it would be a regression fix;
Cmd-Enter &lt;em&gt;used&lt;/em&gt; to do the right thing).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow reviewing your own pull request.&lt;/strong&gt; There's no reason to disallow
this, and it would often be quite useful to, for instance, mark a work in
progress PR as such with a "request changes" review. Obviously
self-reviews would be excluded from any required reviews.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Unhide the reviews box.&lt;/strong&gt; It should just be the same box as the comment
box, unstead of buried on the diff tab (see my &lt;a href="https://www.asmeurer.com/blog/posts/github-reviews-gripes/"&gt;blog
post&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Show review status in the pull request list as a red X or green check.&lt;/strong&gt;
This would make it easier to see which pull requests have reviews.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow new commits to invalidate reviews.&lt;/strong&gt; That way they work the same
way as any other status check. (I see that this is now an option for
required reviews, which is new since my original blog post, but it still
doesn't affect the status as reported on the pull requests list).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow requiring zero negative reviews to merge (but not necessarily any
positive reviews)&lt;/strong&gt;. Requiring a positive review is pointless. The person
merging can just add one real quick before they merge, but it is
unnecessary extra work. On the other hand allowing people with push access
to block a merge with a negative review would be very useful.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Web editor&lt;/h3&gt;
&lt;ol start="39"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The web editor seems to have a search function, but I can't get it to
actually work.&lt;/strong&gt; Half the time Cmd-F pops open the browser search, which
doesn't find text that isn't on screen. And when I press Cmd-G to actually
do the search, it doesn't work (and there are no buttons to perform the
search either).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add basic syntax testing in the web editor for common languages to catch
basic mistakes.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Mobile site&lt;/h3&gt;
&lt;ol start="41"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Please make the mobile site work with iOS 10.&lt;/strong&gt; I don't see any reason
why simple things like buttons (like the merge button or the comment
button) shouldn't work on a slightly older browser. No, I am not a web
developer, but I do use my phone a lot and I've noticed that literally
every other website works just fine on it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add a way to disable the mobile site permanently.&lt;/strong&gt; For the most part,
the mobile site is useless (see below). If you aren't going to put full
development effort into it, allow me to disable it permanently so that
every time I visit &lt;a href="https://github.com"&gt;github.com&lt;/a&gt; on my phone it goes to
the desktop site.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Seeing as how the site (mobile or not) is almost completely unusable on every
mobile device I own, it's hard to list other things here, but based on back
when it actually worked, these are some of the things that annoyed me the
most. Basically, I have found that virtually every time I go to GitHub to do
anything on mobile, I have to switch to desktop mode to actually do what I
want.&lt;/p&gt;
&lt;p&gt;My apologies if any of these actually work now: as I said,
&lt;a href="https://github.com"&gt;github.com&lt;/a&gt; doesn't actually work at all on my phone.&lt;/p&gt;
&lt;ol start="43"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cannot search issues on mobile.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cannot make a line comment that &lt;em&gt;isn't&lt;/em&gt; a review on mobile.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Cannot view lines beyond the default diff in pull requests on mobile.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Show more than 2 lines of the README and 0 lines of the code by default
on project pages.&lt;/strong&gt; Yes mobile screens are small but it's also not hard to
scroll on them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Support Jupyter notebook rendering on mobile.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Files view&lt;/h3&gt;
&lt;ol start="48"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;GitHub needs a better default color theme for syntax highlighting.&lt;/strong&gt;
Most of the colors are very similar to one another and hard to
differentiate. Also things like strings are black, even though one of the
most useful aspects of syntax highlighting generally is to indicate
whether something is in a string or not.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add MathJax support to markdown files.&lt;/strong&gt; This would be amazingly useful
for SymPy, as well as many scientific software projects. Right now if you
want this you have to use a Jupyter notebook. MathJax support in
issue/pull request comments would be awesome as well, though I'm not
holding out for that.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add "display source" button for markdown, ReST, etc.&lt;/strong&gt; I mean the button
that is already there for Jupyter notebooks. Right now you have to view
markdown and ReST files "raw" or edit the file to see their source.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add a link to the pull request in the blame view.&lt;/strong&gt; Usually I want to
find the pull request that produced a change, not just the commit.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Wiki&lt;/h3&gt;
&lt;ol start="52"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The wikis used to support LaTeX math with MathJax. It would be great if
this were re-added.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The ability to set push permissions for the wiki separately from the
repo it is attached to, or otherwise create an oauth token that can only
push to the wiki would be useful.&lt;/strong&gt; Context: for SymPy, we use a
&lt;a href="https://github.com/sympy/sympy-bot"&gt;bot&lt;/a&gt; that automatically updates our
&lt;a href="https://github.com/sympy/sympy/wiki/Release-Notes"&gt;release notes&lt;/a&gt; on our
wiki. It works quite well, but the only way it can push to the wiki is if
we give it push access to the full repo.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Notification emails&lt;/h3&gt;
&lt;ol start="54"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Don't clobber special emails/email headers.&lt;/strong&gt; GitHub adds special emails
like &lt;a href="mailto:author@noreply.github.com"&gt;author@noreply.github.com&lt;/a&gt; and
&lt;a href="mailto:mention@noreply.github.com"&gt;mention@noreply.github.com&lt;/a&gt; to email
notifications based on how the notification was triggered. This is useful,
as I can create an email filter for
&lt;a href="mailto:author@noreply.github.com"&gt;author@noreply.github.com&lt;/a&gt; for
notifications on issues and pull requests created by me. The bad news is,
&lt;a href="mailto:mention@noreply.github.com"&gt;mention@noreply.github.com&lt;/a&gt;, which is
added when I am @mentioned, clobbers
&lt;a href="mailto:author@noreply.github.com"&gt;author@noreply.github.com&lt;/a&gt;, so that it
doesn't appear anymore. In other words, as soon as someone @mentions me in
one of my issues, I become &lt;em&gt;less&lt;/em&gt; likely to see it, because it no longer
gets my label (I get @mentioned on &lt;em&gt;a lot&lt;/em&gt; of issues and don't have the
ability to read all of my notification emails). Ditto for the
&lt;code&gt;X-GitHub-Reason&lt;/code&gt; email headers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Readd the "view issue" links in Gmail.&lt;/strong&gt; (I forgot what these are
called). GitHub notification emails used to have these useful "view issue"
buttons that showed up on the right in the email list in Gmail, but they
were removed for some reason.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;API&lt;/h3&gt;
&lt;ol start="56"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Make the requests in the API docs actually return what they show in the
docs.&lt;/strong&gt; This means the &lt;a href="https://github.com/octocat/Hello-World/"&gt;example
repo&lt;/a&gt; should have actual example
issues corresponding to what is shown in the docs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow giving deploy key access to just one branch.&lt;/strong&gt; That way I can have
a deploy key for &lt;code&gt;gh-pages&lt;/code&gt; and minimize the attack surface that the
existence of that key produces. I think everyone would agree that more
fine-grained permissions throughout the API would be nice, but this is one
that would benefit me personally, specifically for my project
&lt;a href="https://drdoctr.github.io/"&gt;doctr&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;GitHub Pages&lt;/h3&gt;
&lt;p&gt;GitHub pages is one of the best features of GitHub, and in fact, this very
blog is hosted on it. Very few complaints here, because for the most part, it
"just works".&lt;/p&gt;
&lt;ol start="58"&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://twitter.com/asmeurer/status/831962312122761216"&gt;&lt;strong&gt;Moar themes.&lt;/strong&gt;&lt;/a&gt;
Also it's awesome that you can use any GitHub repo as a theme now, but it
turns out most random themes you find around GitHub don't actually work
very well.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The steps to add HTTPS to an existing GitHub pages custom domain are a
bit confusing.&lt;/strong&gt;. This took us a while to figure out for
&lt;a href="https://sympy.org"&gt;sympy.org&lt;/a&gt;. To get things to work, you have to trigger
GitHub to issue a cert for the domain. But the UI to issue the cert is to
paste the domain into the box. So if the domain is already there but it
doesn't work, you have to re-enter it. Also if you want both www and the
apex domain to be HTTPS you have to enter them both in the box to trigger
GitHub to issue a cert. This is primarily a UX issue. See
&lt;a href="https://github.com/sympy/sympy.github.com/issues/105#issuecomment-415899934"&gt;https://github.com/sympy/sympy.github.com/issues/105#issuecomment-415899934&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Settings&lt;/h3&gt;
&lt;ol start="60"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Automatically protected branches make the branch difficult to delete
when you are done with it.&lt;/strong&gt; My use-case is to create a branch for a
release, which I want to protect, but I also want to delete the branch
once it is merged. I can protect the branch automatically pretty easily,
but then I have to go and delete the protection rule when it's merged to
delete it. There are several ways this could be fixed. For instance, you
could add a rule to allow protected branches to be deleted if they are
up-to-date with default branch.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Add a way to disable the ability for non-admins to create new branches
on a repo.&lt;/strong&gt; We want all of our pull requests to come from forks. Branches
in the repo just create confusion, for instance, they appear whenever
someone clones the repository.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Related to the previous point, make pull request reverts come from
forks.&lt;/strong&gt; Right now when someone uses the revert pull request button, it
creates a new branch in the same repo, but it would be better if the
branch were made in the person's fork.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow me to enable branch protection by default for new repos.&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow me to enable branch protection by default on new branches.&lt;/strong&gt; This
is more important than the previous one because of the feature that lets
people push to your branch on a pull request (which is a great feature by
the way).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Clicking a team name in the settings should default to the "members"
tab.&lt;/strong&gt; I don't understand why GitHub has a non-open "discussions" feature,
but I find it to be completely useless, and generally see such things as
harmful for open source.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Suggest people to add push access to.&lt;/strong&gt; I don't necessarily mean
passively (though that could be interesting too), but I mean in the page
to add someone, it would be nice if the popup suggested or indicated which
people had contributed the project before, since just searching for a name
searches all of GitHub, and I don't want to accidentally give access to
the wrong person.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Profiles&lt;/h3&gt;
&lt;ol start="67"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stop trying to make profile pages look "cute" with randomly highlighted
pull requests.&lt;/strong&gt; GitHub should have learned by now that profile pages
matter a lot (whether people want them to or not), and there can be
unintended consequences to the things that are put on them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Explain what the axes actually mean in the new "activity overview".&lt;/strong&gt;
I'm referring to
&lt;a href="https://twitter.com/asmeurer/status/1033141923630874624"&gt;this&lt;/a&gt; (it's
still in beta and you have to manually enable it on your profile page).
Personally I'm leaving the feature off because I don't like being
metricized/gamified, but if you're going to have it, at least include some
transparency.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Releases&lt;/h3&gt;
&lt;ol start="69"&gt;
&lt;li&gt;&lt;strong&gt;Allow hiding the "source code (zip)" and "source code (tar.gz)" files in
a release.&lt;/strong&gt; We upload our actual release files (generated by &lt;code&gt;setup.py&lt;/code&gt;)
to the GitHub release. We want people to download those, not snapshots of
the repo.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Miscellaneous&lt;/h3&gt;
&lt;ol start="70"&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The repository search function doesn't support partial matches.&lt;/strong&gt; This
is annoying for &lt;a href="https://github.com/conda-forge/"&gt;conda-forge&lt;/a&gt;. For
instance, if I &lt;a href="https://github.com/conda-forge/?utf8=%E2%9C%93&amp;amp;q=png&amp;amp;type=&amp;amp;language="&gt;search for
"png"&lt;/a&gt;
it doesn't show the
&lt;a href="https://github.com/conda-forge/libpng-feedstock"&gt;libpng-feedstock&lt;/a&gt; repo.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Show commit history as a graph.&lt;/strong&gt; Like &lt;code&gt;git log --graph&lt;/code&gt;. This would go
a &lt;em&gt;long&lt;/em&gt; way to helping new users understand git. When I first started
with git, understanding the history as a graph was a major part of me
finally grokking how it worked.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bring back the old "fork" UI.&lt;/strong&gt; The one that just had icons for all the
repos, and the icons didn't go away or become harder to find if you
already had a fork. Some of us use the "fork" button to go to our
pre-existing forks, not just to perform a fork action. This was recently
changed and now it's better than it was, but I still don't see why
existing forks need to be harder to find, visually, than nonexisting ones.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Provide a more official way to request fixes to these cuts.&lt;/strong&gt; I often
ask on Twitter, but get no response. Preferably something public so that
others could vote on them (but I understand if you don't want too much
bikeshedding).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description><guid>https://asmeurer.com/blog/posts/github-cuts/</guid><pubDate>Tue, 06 Nov 2018 22:54:21 GMT</pubDate></item><item><title>Automatically deploying this blog to GitHub Pages with Travis CI</title><link>https://asmeurer.com/blog/posts/automatically-deploying-this-blog-to-github-pages-with-travis-ci/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;This blog is now &lt;a href="http://travis-ci.org/asmeurer/blog"&gt;deployed to GitHub pages automatically&lt;/a&gt; from Travis CI.&lt;/p&gt;
&lt;p&gt;As I've outlined in the &lt;a href="https://asmeurer.com/blog/posts/automatically-deploying-this-blog-to-github-pages-with-travis-ci/moving-to-github-pages-with-nikola/"&gt;past&lt;/a&gt;, this
website is built with the &lt;a href="https://getnikola.com/"&gt;Nikola&lt;/a&gt; static blogging
engine. I really like Nikola because it uses Python, has lots of nice
extensions, and
is
&lt;a href="https://github.com/getnikola/nikola/blob/master/LICENSE.txt"&gt;sanely licensed&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most importantly, it is a static site generator, meaning I write my posts in
Markdown, and Nikola generates the site as static web content ("static" means no web server
is required to run the site). This means that the site can be hosted for free
on &lt;a href="https://pages.github.com/"&gt;GitHub pages&lt;/a&gt;. This is how this site has been
hosted since I started it. I have
a &lt;a href="http://github.com/asmeurer/blog"&gt;GitHub repo&lt;/a&gt; for the site, and the content
itself is deployed to
the &lt;a href="https://github.com/asmeurer/blog/tree/gh-pages"&gt;gh-pages&lt;/a&gt; branch of the
repo. But until now, the deployment has happened only manually with the
&lt;code&gt;nikola github_deploy&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;A much better way is to deploy automatically using Travis CI. That way, I do
not need to run any software on my computer to deploy the blog.&lt;/p&gt;
&lt;p&gt;The steps outlined here will work for any static site generator. They assume
you already have one set up and hosted on GitHub.&lt;/p&gt;
&lt;h3&gt;Step 1: Create a .travis.yml file&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Create a &lt;code&gt;.travis.yml&lt;/code&gt; file like the one below&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;sudo: false
language: python

python:
  - 3.6

install:
  - pip install "Nikola[extras]" doctr

script:
  - set -e
  - nikola build
  - doctr deploy . --built-docs output/
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;If you use a different static site generator, replace &lt;code&gt;nikola&lt;/code&gt; with that
site generator's command.&lt;/li&gt;
&lt;li&gt;If you have Nikola configured to output to a different directory, or use a
different static site generator, replace &lt;code&gt;--built-docs output/&lt;/code&gt; with the
directory where the site is built.&lt;/li&gt;
&lt;li&gt;Add any extra packages you need to build your site to the &lt;code&gt;pip install&lt;/code&gt;
command. For instance, I use the &lt;code&gt;commonmark&lt;/code&gt; extension for Nikola, so I
need to install &lt;code&gt;commonmark&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;set -e&lt;/code&gt; line is important. It will prevent the blog from being deployed
if the build fails.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Then go to &lt;a href="http://www.asmeurer.com/blog/"&gt;https://travis-ci.org/profile/&lt;/a&gt; and enable Travis for your blog
repo.&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;Step 2: Run doctr&lt;/h3&gt;
&lt;p&gt;The key here is &lt;a href="https://drdoctr.github.io/doctr/"&gt;doctr&lt;/a&gt;, a tool I wrote with
&lt;a href="https://github.com/gforsyth"&gt;Gil Forsyth&lt;/a&gt; that makes deploying anything from
Travis CI to GitHub Pages a breeze. It automatically handles creating and
encrypting a deploy SSH key for GitHub, and the syncing of files to the
&lt;code&gt;gh-pages&lt;/code&gt; branch.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;First install doctr.&lt;/strong&gt; &lt;code&gt;doctr&lt;/code&gt; requires
Python 3.5+, so you'll need that. You can install it with conda:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;conda install -c conda-forge doctr
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or if you don't use conda, with pip&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install doctr
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Then run this command in your blog repo:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;doctr configure
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will ask you for your GitHub username and password,
and for the name of the repo you are deploying from and to (for instance, for
my blog, I entered &lt;code&gt;asmeurer/blog&lt;/code&gt;). The output will look something like this:&lt;/p&gt;
&lt;!-- http seems to give the least amount of highlighting. text is --&gt;
&lt;!-- supposed to work, but doesn't render correctly. --&gt;
&lt;pre&gt;&lt;code class="language-http"&gt;$ doctr configure
What is your GitHub username? asmeurer
Enter the GitHub password for asmeurer:
A two-factor authentication code is required: app
Authentication code: 911451
What repo do you want to build the docs for (org/reponame, like 'drdoctr/doctr')? asmeurer/blog
What repo do you want to deploy the docs to? [asmeurer/blog] asmeurer/blog
Generating public/private rsa key pair.
Your identification has been saved in github_deploy_key.
Your public key has been saved in github_deploy_key.pub.
The key fingerprint is:
SHA256:4cscEfJCy9DTUb3DnPNfvbBHod2bqH7LEqz4BvBEkqc doctr deploy key for asmeurer/blog
The key's randomart image is:
+---[RSA 4096]----+
|    ..+.oo..     |
|     *o*..  .    |
|      O.+  o o   |
|     E + o  B  . |
|      + S .  +o +|
|       = o o o.o+|
|        * . . =.=|
|       . o ..+ =.|
|        o..o+oo  |
+----[SHA256]-----+

The deploy key has been added for asmeurer/blog.

You can go to https://github.com/asmeurer/blog/settings/keys to revoke the deploy key.

================== You should now do the following ==================

1. Commit the file github_deploy_key.enc.

2. Add

    script:
      - set -e
      - # Command to build your docs
      - pip install doctr
      - doctr deploy &amp;lt;deploy_directory&amp;gt;

to the docs build of your .travis.yml.  The 'set -e' prevents doctr from
running when the docs build fails. Use the 'script' section so that if
doctr fails it causes the build to fail.

3. Put

    env:
      global:
        - secure: "Kf8DlqFuQz9ekJXpd3Q9sW5cs+CvaHpsXPSz0QmSZ01HlA4iOtdWVvUttDNb6VGyR6DcAkXlADRf/KzvAJvaqUVotETJ1LD2SegnPzgdz4t8zK21DhKt29PtqndeUocTBA6B3x6KnACdBx4enmZMTafTNRX82RMppwqxSMqO8mA="

in your .travis.yml.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Follow the steps at the end of the command:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Commit the file &lt;code&gt;github_deploy_key.enc&lt;/code&gt;.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;You already have &lt;code&gt;doctr deploy&lt;/code&gt; in your &lt;code&gt;.travis.yml&lt;/code&gt; from step 1 above.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Add the &lt;code&gt;env&lt;/code&gt; block to your &lt;code&gt;.travis.yml&lt;/code&gt;.&lt;/strong&gt; This will let Travis CI decrypt
the SSH key used to deploy to &lt;code&gt;gh-pages&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;That's it&lt;/h3&gt;
&lt;p&gt;Doctr will now deploy your blog automatically. You may want to look at the
Travis build to make sure everything works. Note that &lt;code&gt;doctr&lt;/code&gt; only deploys
from &lt;code&gt;master&lt;/code&gt; by default (see below). You may also want to look at the
other
&lt;a href="https://drdoctr.github.io/doctr/commandline.html#doctr-deploy"&gt;command line flags&lt;/a&gt; for
&lt;code&gt;doctr deploy&lt;/code&gt;, which let you do things such as to deploy to &lt;code&gt;gh-pages&lt;/code&gt; for a
different repo than the one your blog is hosted on.&lt;/p&gt;
&lt;p&gt;I recommend these steps over the ones in
the
&lt;a href="https://getnikola.com/blog/automating-nikola-rebuilds-with-travis-ci.html"&gt;Nikola manual&lt;/a&gt; because
doctr handles the SSH key generation for you, making things more secure. I
also found that the &lt;code&gt;nikola github_deploy&lt;/code&gt; command
was &lt;a href="https://github.com/getnikola/nikola/issues/2847"&gt;doing too much&lt;/a&gt;, and
&lt;code&gt;doctr&lt;/code&gt; handles syncing the built pages already anyway. Using &lt;code&gt;doctr&lt;/code&gt; is much
simpler.&lt;/p&gt;
&lt;h3&gt;Extra stuff&lt;/h3&gt;
&lt;h4&gt;Reverting a build&lt;/h4&gt;
&lt;p&gt;If a build goes wrong and you need to revert it, you'll need to use git to
revert the commit on your &lt;code&gt;gh-pages&lt;/code&gt; branch. Unfortunately, GitHub doesn't
seem to have a way to revert commits in their web interface, so it has to be
done from the command line.&lt;/p&gt;
&lt;h4&gt;Revoking the deploy key&lt;/h4&gt;
&lt;p&gt;To revoke the deploy key generated by doctr, go your repo in GitHub, click on
"settings" and then "deploy keys". Do this if you decide to stop using this,
or if you feel the key may have been compromised. If you do this, the
deployment will stop until you run step 2 again to create a new key.&lt;/p&gt;
&lt;h4&gt;Building the blog from branches&lt;/h4&gt;
&lt;p&gt;You can also build your blog from branches, e.g., if you want to test things
out without deploying to the final repo.&lt;/p&gt;
&lt;p&gt;We will use the steps
outlined
&lt;a href="https://drdoctr.github.io/doctr/recipes.html#deploy-docs-from-any-branch"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Replace the line&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;  - doctr deploy . --built-docs output/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in your &lt;code&gt;.travis.yml&lt;/code&gt; with something like&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-yaml"&gt;  - if [[ "${TRAVIS_BRANCH}" == "master" ]]; then
      doctr deploy . --built-docs output/;
    else
      doctr deploy "branch-$TRAVIS_BRANCH" --built-docs output/ --no-require-master;
    fi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will deploy your blog as normal from &lt;code&gt;master&lt;/code&gt;, but from a branch it will
deploy to the &lt;code&gt;branch-&amp;lt;branchname&amp;gt;&lt;/code&gt; subdir. For instance, my blog is at
&lt;a href="http://www.asmeurer.com/blog/"&gt;http://www.asmeurer.com/blog/&lt;/a&gt;, and if I had a branch called &lt;code&gt;test&lt;/code&gt;, it would
deploy it to &lt;a href="https://asmeurer.com/blog/posts/automatically-deploying-this-blog-to-github-pages-with-travis-ci/"&gt;http://www.asmeurer.com/blog/branch-test/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note that it will not delete old branches for you from &lt;code&gt;gh-pages&lt;/code&gt;. You'll need
to do that manually once they are merged.&lt;/p&gt;
&lt;p&gt;This only works for branches in the same repo. It is not possible to deploy
from a branch from pull request from a fork, for security purposes.&lt;/p&gt;
&lt;h4&gt;Enable build cancellation in Travis&lt;/h4&gt;
&lt;p&gt;If you go the Travis page for your blog and choose "settings" from the
hamburger menu, you can enable auto cancellation for branch builds. This will
make it so that if you push many changes in succession, only the most recent
one will get built. This makes the changes get built faster, and lets you
revert mistakes or typos without them ever actually being deployed.&lt;/p&gt;</description><guid>https://asmeurer.com/blog/posts/automatically-deploying-this-blog-to-github-pages-with-travis-ci/</guid><pubDate>Mon, 19 Jun 2017 19:21:32 GMT</pubDate></item><item><title>GitHub Reviews Gripes</title><link>https://asmeurer.com/blog/posts/github-reviews-gripes/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;&lt;em&gt;Update: I want to keep the original post intact, but I'll post any feature
updates that GitHub makes here as they are released.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;You can now &lt;a href="https://github.com/blog/2265-dismissing-reviews-on-pull-requests"&gt;dismiss a review&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;You can
now
&lt;a href="https://github.com/blog/2306-filter-pull-request-reviews-and-review-requests"&gt;filter the pull request list by review&lt;/a&gt;.
The review status of a PR also appears in the pull request list (albeit in
very tiny and easy to miss text).&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;You can
now
&lt;a href="https://github.com/blog/2330-restrict-review-dismissals-with-protected-branches"&gt;restrict review dismissals&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;GitHub
&lt;a href="https://github.com/blog/2256-a-whole-new-github-universe-announcing-new-tools-forums-and-features"&gt;recently&lt;/a&gt; rolled
out a new feature on their pull requests called "Reviews". The feature is (in
theory), something that I've
been
&lt;a href="https://groups.google.com/d/msg/sympy/KJwDwT_P6Lw/27ha6ipuBwAJ"&gt;asking for&lt;/a&gt;.
However, it really falls short in a big way, and I wanted to write down my
gripes with it, in the hopes that it spurs someone at GitHub to fix it.&lt;/p&gt;
&lt;p&gt;If you don't know, GitHub has had, for some time, a feature called "pull
requests" ("PRs"), which lets you quite nicely show the diff and commit
differences between two branches before merging them. People can comment on
pull requests, or on individual lines in the diff. Once an administrator feels
that the pull request is "ready", they can click a button and have the branch
automatically merged.&lt;/p&gt;
&lt;p&gt;The concept seems super simple
in &lt;a href="https://en.wikipedia.org/wiki/Hindsight_bias"&gt;retrospect&lt;/a&gt;, but this
feature completely revolutionized open source software development. It really
is the bread and butter of GitHub. I would argue that this one single feature
has made GitHub the (&lt;em&gt;the&lt;/em&gt;) primary hosting site for open source software.&lt;/p&gt;
&lt;p&gt;Aside from being an awesome idea, GitHub's trademark with pull requests, along
with their other features, has been absolute simplicity in implementation.
GitHub Reviews marks, by my estimation, the first major feature released by
GitHub that completely and utterly lacks in this execution of simplicity.&lt;/p&gt;
&lt;p&gt;Let's look at what Reviews is. When the feature first came out, I had a hard
time figuring out how it even worked (the
poor
&lt;a href="https://twitter.com/asmeurer/status/776125249712717824"&gt;release date docs&lt;/a&gt;
didn't help here either).&lt;/p&gt;
&lt;p&gt;Basically, at the bottom of a pull request, you now see this&lt;/p&gt;
&lt;img src="https://asmeurer.com/blog/reviews1.png" width="788"&gt;
&lt;p&gt;Clicking the "Add your review" button takes you to the diff page (first gripe:
why does it move you to the diff page?), and opens this dialog&lt;/p&gt;
&lt;img src="https://asmeurer.com/blog/reviews2.png" width="1020"&gt;
&lt;p&gt;"OK", you might think, "this is simple enough. A review is just a special
comment box where I can approve or reject a pull request." (This is basically
the feature that I've been wanting, the ability to approve or reject pull
requests.) And if you thought that, you'd be wrong.&lt;/p&gt;
&lt;p&gt;The simplest way I can describe a review, having played with it, is that it is
a distinct method of commenting on pull requests and on lines of diffs of pull
requests. Distinct, that is, from the methods that &lt;strong&gt;already exist&lt;/strong&gt; in the
GitHub pull requests feature. That's right. There are now two ways to comment
on a pull request (or on a line in a pull request). There's the old way, which
involves typing text into the box at the bottom of the main pull request page
(or on a line, and then pressing "Add a single comment"), and the new way,
which involves clicking a special button at the top of the diff view (and the
diff view only) (or by clicking a line in the diff and
clicking "Start a review").&lt;/p&gt;
&lt;p&gt;How do these two ways of the extremely simple task of commenting differ from
one another? Two ways. One, with the old way, when you comment on a PR (or
line), the comment is made immediately. It's saved instantly to the GitHub
database, and a notification email is sent to everyone subscribed to the PR.
With the new way, the comment is &lt;strong&gt;not&lt;/strong&gt; made immediately.  Instead, you start
a "review", which postpones all comments from being published until you scroll
to the top and press a button ("Review changes"). &lt;strong&gt;Did you forget to scroll
to the top and press that button? Oh well, your comments never got sent to
anyone.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now, I've been told by some people that delayed commenting is a feature that
they like. I can see how fewer total emails could be nice. &lt;strong&gt;But if you just
want a way to delay comments, why do you need distinct commenting UIs?&lt;/strong&gt;
Couldn't the same thing be achieved via a user setting (I highly suspect that
any given person will either like or dislike delayed commenting universally)?
Or with a checkbox next to the comment button, like "delay notifications for
this comment"? You can probably guess by now which of the two commenting
systems I prefer. But guess what happens when I press the "Cmd-Enter" keyboard
shortcut that's been hard-wired into my brain to submit a comment? I'll give
you a hint: the
result
&lt;a href="https://twitter.com/asmeurer/status/781949163562999808"&gt;does not make me happy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The second distinction between normal, old-fashioned commenting and the
new-fangled reviews system is that when you finalize a review, you can elect
to "approve" or "reject" the pull request. This approval or rejection gets set
as a special status on the pull request. This status, for me personally, is
the only feature here that I've been wanting. It turns out, however, that it's
completely broken, and useless.&lt;/p&gt;
&lt;p&gt;Here's my problem. We have, at the time of
writing, &lt;a href="https://github.com/sympy/sympy/pulls"&gt;382 open pull requests&lt;/a&gt; in
SymPy. A lot of these are old, and need to be triaged. But the problem from my
point of view is the new ones. When I look through the list of pull requests,
I want to be able to know, at a glance, which ones are "reviewable". For me,
this means two things&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The tests pass.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;No other reviewer (myself included) has already requested changes, which
still need to be made by the PR author.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Point 1 is really easy to see. In the pull request list, there is a nice green
checkmark if Travis passed and a red X if it failed.&lt;/p&gt;
&lt;img src="https://asmeurer.com/blog/prlist.png" width="608"&gt;
&lt;p&gt;The second point is a disaster. Unfortunately, there's no simple way to do
this. You might suggest adding a special label, like "Needs changes", to pull
requests that have been reviewed. The problem with this is that the label
won't go away when the changes have been made. And to worsen things, people
who don't have push access (in the list above, only two PR authors have push
access, and one of them is me), cannot add or remove labels on pull requests.&lt;/p&gt;
&lt;p&gt;Another thing
that
&lt;a href="https://twitter.com/asmeurer/status/771393023389339649"&gt;has been suggested to me&lt;/a&gt; is
an external "review" service that sets a status for a review. The problem with
this (aside from the fact that I couldn't find one that actually did the very
simple thing that I wanted), is that you now have to teach all your pull
request reviewers to use this service. You might as well forget about it.&lt;/p&gt;
&lt;p&gt;Having a first-class way in GitHub for reviewers to say "I approve these
changes" or "I don't approve these changes" would be a huge boon, because then
everyone would use it.&lt;/p&gt;
&lt;p&gt;So great right, this new Reviews feature is exactly what you want, you say.
You can now approve or reject pull requests.&lt;/p&gt;
&lt;p&gt;Well no, because GitHub managed to overengineer this feature to the point of
making it useless. This completely simple feature. All they had to do was
extend the status UI and add a simple "I approve/I reject" button. If they did
that, it would have worked perfectly.&lt;/p&gt;
&lt;p&gt;Here are the problems. First, the pull request list has no indication of
review status. Guess which pull requests in the above screenshot have reviews
(and which are positive and which are negative). You can't tell (for example,
the last one in the list has a negative review). If they were actually treated
like statuses, like the UI suggests that they would, you would at least see an
X on the ones that have negative reviews (positive reviews I'm much less
worried about; most people who review PRs have merge access, so if they like
the PR they can just merge it). I would suggest to GitHub to add, next to the
status checkbox, a picture of everyone who's made a review on the PR, with a
green checkmark or red X to indicate the type of review. Also, add buttons
(&lt;strong&gt;buttons&lt;/strong&gt;, not just buried advanced search options) to filter by reviews.&lt;/p&gt;
&lt;p&gt;OK, so that's a minor UI annoyance, but it gets worse. Next on the docket, &lt;strong&gt;you
can't review your own pull requests.&lt;/strong&gt; It's not allowed for some reason.&lt;/p&gt;
&lt;img src="https://asmeurer.com/blog/reviews3.png" width="411"&gt;
&lt;p&gt;Now why would you want to review your own pull request, you might ask? Aren't
you always going to "approve" your own PR? Well, first off, no. There is such
a thing as
a &lt;a href="http://ben.balter.com/2015/12/08/types-of-pull-requests/"&gt;WIP PR&lt;/a&gt;. The
author setting a negative review on his own PR would be a great way to
indicate WIP status (especially given the way reviews work, see my next
gripe). Secondly, the "author" of a pull request is just the person who
clicked the "New pull request" button. That's not necessarily the only person
who has changes in the pull request. Thanks to the magic of how git works,
it's quite easy to have a pull request with commits from many people. Multiple
people pushing to a shared branch, with a matching pull request for discussion
(and easy viewing of new commits and diff) is a valid and useful workflow
(it's the only one I know of that works for writing collaborative prose). For
the &lt;a href="https://github.com/sympy/sympy-paper"&gt;SymPy paper&lt;/a&gt;, I wanted to use
GitHub Reviews to sign off on a common branch, but since I'm the one who
started the pull request, I couldn't do it.&lt;/p&gt;
&lt;p&gt;Next gripe, and this, I want to stress, makes the whole feature completely
useless for my needs: &lt;strong&gt;reviews do not reset when new commits are pushed&lt;/strong&gt;.
Now, I just outlined above two use-cases where you might want to do a review
that doesn't reset (marking WIP, and marking approval, although the second is
debatable), but both of those can easily be done by other means, like editing
the title of the PR, or old-fashioned commenting. The whole point of Reviews
(especially negative reviews), you'd think, would be to indicate to people
that the pull request, as it currently stands, needs new changes. A negative
review is like failing your "human" test suite.&lt;/p&gt;
&lt;p&gt;But unlike your automated test suite, which reset and get a new go every time
you push a change (because hey, who knows, maybe the change ACTUALLY FIXED THE
ISSUE), reviews do not reset, unless the original reviewers explicitly change
them. So my dream of being able to glance at the pull request list and see
which PRs need changes has officially
been &lt;a href="https://en.wiktionary.org/wiki/pipe_dream"&gt;piped&lt;/a&gt;. Even if the list
actually showed what PRs have been reviewed, it would be a lie, because as
soon as the PR author pushes a change, the review status becomes potentially
outdated.&lt;/p&gt;
&lt;p&gt;Now, given the rocky start that this whole feature has had, I figured that
this was probably just a simple bug. But after I reported it to GitHub,
they've informed me that this is in fact &lt;em&gt;intended behavior&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To make things worse, GitHub has another feature with Reviews,
called
&lt;a href="https://help.github.com/articles/approving-a-pull-request-with-required-reviews/"&gt;required reviews&lt;/a&gt;.
You can make it so that every pull request must receive at least one positive
review and zero negative reviews before it can be merged (go to the branch
settings for your repository). This works similar to required status checks,
which make it so that your tests must pass before a PR can be merged. In
practice, this means you need zero negative reviews, since anyone with push
access could just do a positive review before merging (although annoyingly,
you have to actually manually do it; IMHO, just requiring zero negative
reviews should be sufficient, since merging is implicitly a positive review).&lt;/p&gt;
&lt;p&gt;Now, you can see that the above "feature" of reviews not resetting breaks the
whole thing. If someone negative reviews a PR, that one person has to go in
and change their review before it can be merged. And even if the author pushes
new changes to fix the issues outlined in the review, the PR cannot be merged
until the reviewer resets it. So this actually makes the reviewing situation
&lt;em&gt;worse&lt;/em&gt;, because now anyone who reviews a pull request at any point in time
has to go through with it all the way to the merge. I can't go to a PR that
someone requested changes for, which were later made by the author, and merge
it. I have to ping the reviewer and get them to change their review first.
Needless to say, we do not have this feature enabled for SymPy's repo.&lt;/p&gt;
&lt;p&gt;I think I maybe see the intended use-case here. You want to make it so that
people's reviews are not forgotten or ignored. But that's completely foreign
to my own problems. I trust the SymPy community, and the people who have push
access to do due diligence before merging a pull request. And if a bad change
gets in, we can revert it. Maybe this feature matters more for projects that
continuously deploy. Likely most of the code internal at GitHub works like
that. But guess what GitHub, most of the code &lt;em&gt;on&lt;/em&gt; GitHub does &lt;em&gt;not&lt;/em&gt; work like
that. You need to rethink this feature to support more than just your
use-cases.&lt;/p&gt;
&lt;p&gt;I think starting simple, say, just a simple "approve/reject" button on each
PR, which just adds an icon, and that's it, would have been a better approach.
Then they could have listened to the feedback on what sorts of things people
wanted it to be able to do (like setting a status, or showing up in the search
list, or "delayed commenting" if that's really what people want). This is how
GitHub used to do things. It's frustrating to see a feature implemented that
doesn't (yet) do quite what you want, but it's even more frustrating to see a
feature implemented that does all the things that you don't want.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Yes, I'm a little mad here. I hope you enjoyed my rant. Here are what I see as
the problems with the "Reviews" feature. I don't know how to fix these
problems (I'm not a UI/UX guy. GitHub supposedly hires them, though).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There are now two distinct ways to comment on a PR (delayed and non-delayed).
There should be one (say, with a checkbox to delay commenting).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you insist on keeping delayed commenting, let me turn it off by default
(default = the Cmd-Enter keyboard shortcut).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The reviews button is buried on the diff page. I would put it under the
main PR comment box, and just reuse the same comment box.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reviews should show up in the pull request list. They should be filterable
with a nice UI.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let me review my own pull requests. These can be excluded from required
reviews (that makes sense to me). Beyond that, there's no reason this
shouldn't be allowed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Don't require a positive review for required reviews, only zero negative
reviews. Merging a PR is implicitly positively reviewing it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Allow reviews to reset when new commits are pushed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I get that the last point may not be what everyone wants. But GitHub needs to
think about UI, and defaults here. Right now, the UI looks like reviews are
like statuses, but they actually aren't because of this.&lt;/p&gt;
&lt;p&gt;I am dispirited to see GitHub release such a broken feature, but even the best
trip up sometimes. I'm not yet calling "doom" on GitHub. Everyone has
their &lt;a href="https://en.wikipedia.org/wiki/Apple_USB_Mouse"&gt;hockey puck mice&lt;/a&gt;. I'm
actually hopeful that they can fix these issues, and implement a feature that
makes real headway into helping me solve one of my biggest problems on GitHub
right now, the reviewing of pull requests.&lt;/p&gt;</description><guid>https://asmeurer.com/blog/posts/github-reviews-gripes/</guid><pubDate>Thu, 06 Oct 2016 00:12:16 GMT</pubDate></item><item><title>Tuples</title><link>https://asmeurer.com/blog/posts/tuples/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;Today, David Beazley made some tweets:&lt;/p&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;At the bookstore. I'll admit I judge Python books by their tuple description. "Read only list?"  Back on the shelf.  Nope.&lt;/p&gt;— David Beazley (@dabeaz) &lt;a href="https://twitter.com/dabeaz/status/778634205395845120"&gt;September 21, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Usually there's a sentence nearby "sometimes you need a read only list." No. No, I haven't. Not in 20 years. Not even once. Sorry.&lt;/p&gt;— David Beazley (@dabeaz) &lt;a href="https://twitter.com/dabeaz/status/778635637457088512"&gt;September 21, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;My main objection is that "read only list" is a lazy description lacking thought. A red flag for every other topic that might be covered.&lt;/p&gt;— David Beazley (@dabeaz) &lt;a href="https://twitter.com/dabeaz/status/778639979052498944"&gt;September 21, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;There are quite a few good responses to these tweets, both from David and from
others (and from yours truly). I recommend reading the the thread (click on
the &lt;a href="https://twitter.com/dabeaz/status/778634205395845120"&gt;first tweet&lt;/a&gt; above).&lt;/p&gt;
&lt;p&gt;Now to start off, I want to say that I respect the hell out of David Beazley.
The guy literally &lt;a href="http://www.dabeaz.com/cookbook.html"&gt;wrote the book&lt;/a&gt; on
Python, and he knows way more about Python than I ever will. He's also one of
the most entertaining Python people you can
&lt;a href="https://twitter.com/dabeaz"&gt;follow on Twitter&lt;/a&gt;. But hey, that doesn't mean I
can't disagree sometimes.&lt;/p&gt;
&lt;h2&gt;List vs. Tuple. Fight!&lt;/h2&gt;
&lt;p&gt;As you probably know, there are two "array" datatypes in Python, &lt;code&gt;list&lt;/code&gt; and
&lt;code&gt;tuple&lt;/code&gt;.&lt;sup id="fnref:list"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/tuples/#fn:list"&gt;1&lt;/a&gt;&lt;/sup&gt; The primary difference between the two is that lists are &lt;em&gt;mutable&lt;/em&gt;,
that is you can change their entries and length after they are created, with
methods like &lt;code&gt;.append&lt;/code&gt; or &lt;code&gt;+=&lt;/code&gt;. Tuples, on the other hand, are &lt;em&gt;immutable&lt;/em&gt;.
Once you create one, you cannot change it. This makes the implementation
simpler (and hence faster, although don't let anyone tell you you should use a
tuple just because it's faster). This, as
&lt;a href="http://nedbatchelder.com/blog/201608/lists_vs_tuples.html"&gt;Ned Batchelder&lt;/a&gt;
points out, is the only technical difference between the two.&lt;/p&gt;
&lt;p&gt;The the idea that particularly bugs me here is that tuples are primarily
useful as "record" datatypes.&lt;/p&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;&lt;a href="https://twitter.com/AllenDowney"&gt;@AllenDowney&lt;/a&gt; Better than "read-only-list." ;-).   Mainly looking for the tuple-as-record description. That's often what's missing.&lt;/p&gt;— David Beazley (@dabeaz) &lt;a href="https://twitter.com/dabeaz/status/778685294593716224"&gt;September 21, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;Tuples are awesome for records. This is both by design—since they have a
fixed shape, the positions in a tuple can be "fixed" values, and by convention—if a
Python programmer sees parentheses instead of square brackets, he is more
likely to see the object as "record-like". The &lt;code&gt;namedtuple&lt;/code&gt; object in the standard library
takes the record idea further by letting you actually name the fields:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;namedtuple&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;person&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;namedtuple&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Person'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'name, age'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;person&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Aaron'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Person&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Aaron'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;But is that really the &lt;em&gt;only&lt;/em&gt; place you'd want to use a tuple over a list?&lt;/p&gt;
&lt;p&gt;Consider five other places you might encounter a tuple in Python, courtesy of
Allen Downey:&lt;/p&gt;
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;&lt;a href="https://twitter.com/dabeaz"&gt;@dabeaz&lt;/a&gt; (1) tuple assignment (2) multiple return values (3) *args (4) output from zip, enumerate, etc (5) key in dictionary&lt;/p&gt;— Allen Downey (@AllenDowney) &lt;a href="https://twitter.com/AllenDowney/status/778691102094176257"&gt;September 21, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;In code these look like:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multiple assignments:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&amp;gt;&amp;gt;&amp;gt; (a, b) = 1, 2
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;(yes, the parentheses are optional here, as they are in many places where a
tuple can be used, but this is still a tuple, or at least it looks like one ;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Multiple return values:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For example,
&lt;a href="https://docs.python.org/3/library/os.html#os.walk"&gt;&lt;code&gt;os.walk&lt;/code&gt;&lt;/a&gt;. This is
for the most part a special case of using tuples as records.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;*args&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&amp;gt;&amp;gt;&amp;gt; def f(*args):
...     print(type(args), args)
...
&amp;gt;&amp;gt;&amp;gt; f(1, 2, 3)
&amp;lt;class 'tuple'&amp;gt; (1, 2, 3)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Arbitrary positional function arguments are always stored as a &lt;code&gt;tuple&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Return value from builtins &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;enumerate&lt;/code&gt;, etc.:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'abc'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'a'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'b'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'c'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'abc'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'a'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'b'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'c'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This also applies to the combinatoric generators in
&lt;a href="https://docs.python.org/3.6/library/itertools.html"&gt;itertools&lt;/a&gt; (like
&lt;code&gt;product&lt;/code&gt;, &lt;code&gt;combinations&lt;/code&gt;, etc.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Dictionary keys:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&amp;gt;&amp;gt;&amp;gt; {
...     (0, 0): '.',
...     (0, 1): ' ',
...     (1, 0): '.',
...     (1, 1): ' ',
... }
{(0, 1): ' ', (1, 0): '.', (0, 0): '.', (1, 1): ' '}
&lt;/pre&gt;&lt;/div&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This last one I find to be very important. You could arguably use a list for
the first four of Allen Downey's points&lt;sup id="fnref:assign"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/tuples/#fn:assign"&gt;2&lt;/a&gt;&lt;/sup&gt; (or Python could have, if it wanted to). But it
is
&lt;a href="https://asmeurer.github.io/blog/posts/what-happens-when-you-mess-with-hashing-in-python/"&gt;impossible&lt;/a&gt;
to meaningfully hash a mutable data structure in Python, and hashability is a
requirement for dictionary keys.&lt;/p&gt;
&lt;p&gt;However, be careful. Not all tuples are hashable. Tuples can contain
anything, but only tuples of immutable values are hashable. Consider&lt;sup id="fnref:TypeError"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/tuples/#fn:TypeError"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Such tuples are not hashable, and cannot be used as dictionary keys.&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Traceback&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;most&lt;/span&gt; &lt;span class="n"&gt;recent&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s2"&gt;"&amp;lt;ipython-input-39-36822ba665ca&amp;gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nb"&gt;hash&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="ne"&gt;TypeError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;unhashable&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'list'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Why is &lt;code&gt;list&lt;/code&gt; the Default?&lt;/h2&gt;
&lt;p&gt;My second gripe here is this notion that your default ordered collection
object in Python should be &lt;code&gt;list&lt;/code&gt;. &lt;code&gt;tuples&lt;/code&gt; are only to be used as "records",
or if you suspect &lt;em&gt;might&lt;/em&gt; want to use it as a dictionary key. First off, you
never know when you'll want something to be hashable. Both dictionary keys and
&lt;code&gt;sets&lt;/code&gt; require hashability. Suppose you want to de-duplicate a collection of
sequences. If you represent the sequences with &lt;code&gt;list&lt;/code&gt;, you'll either have to
write a custom loop that checks for duplicates, or manually convert them to
&lt;code&gt;tuple&lt;/code&gt; and throw them in a &lt;code&gt;set&lt;/code&gt;. If you start with &lt;code&gt;tuple&lt;/code&gt;, you don't have
to worry about it (again, assuming the entries of the tuples are all hashable
as well).&lt;/p&gt;
&lt;p&gt;Consider another usage of tuples, which I consider to be
important, namely tree structures. Say you wanted a simple representation of a
Python syntax tree. You might represent &lt;code&gt;1 - 2*(-3 + 4)&lt;/code&gt; as&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'*'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'+'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This isn't really a record. The meaning of the entries in the tuples is
determined by the first value of the tuple, not position. In this example, the length
of the tuple also signifies meaning (binary vs. unary &lt;code&gt;-&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;If this looks familiar to you, it's because this is how the language Lisp
represents all programs. This is a common pattern.
&lt;a href="http://dask.pydata.org/en/latest/graphs.html"&gt;Dask graphs&lt;/a&gt; use tuples and
dictionaries to represent computations.
&lt;a href="http://docs.sympy.org/latest/tutorial/manipulation.html"&gt;SymPy expression trees&lt;/a&gt;
use tuples and Python classes to represent symbolic mathematical expressions.&lt;/p&gt;
&lt;p&gt;But why use tuples over lists here? Suppose you had an object like the one
above, but using lists: &lt;code&gt;['-', 1, ['*', 2, ['+', ['-', 3], 4]]]&lt;/code&gt;. If you
discover you need to use this as a dictionary key, or want to put it in a
&lt;code&gt;set&lt;/code&gt;, you would need to convert this to a hashable object. To do this you
need to write a function that recursively converts each &lt;code&gt;list&lt;/code&gt; to a &lt;code&gt;tuple&lt;/code&gt;.
See how long it takes you to write that function correctly.&lt;/p&gt;
&lt;h2&gt;Mutability is Bad&lt;/h2&gt;
&lt;p&gt;More to the point, however, mutability is bad. I counted 12 distinct methods
on &lt;code&gt;list&lt;/code&gt; that mutate it (how many can you remember off the top of your
head?&lt;sup id="fnref:mutate"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/tuples/#fn:mutate"&gt;3&lt;/a&gt;&lt;/sup&gt;). &lt;em&gt;Any&lt;/em&gt; function that gets access to a list can mutate it,
using any one of these methods. All it takes is for someone to forget that
&lt;code&gt;+=&lt;/code&gt; mutates a list (and that they should copy it first) for code completely
distant from the origin definition to cause issues. The hardest bug I ever
debugged had a three character
&lt;a href="https://github.com/inducer/pudb/commit/b979fc5909c8d731eb907fc25f4e97904fb7cbbd"&gt;fix&lt;/a&gt;,
adding &lt;code&gt;[:]&lt;/code&gt; to copy a global list that I was (accidentally) mutating. It took
me a several hour airplane ride and some deep dark magic that I'll leave for
another blog post to discover the source of my problems (the problems I was
having appeared to be quite distant from the actual source).&lt;/p&gt;
&lt;h2&gt;A Better "Default"&lt;/h2&gt;
&lt;p&gt;I propose that Python code in general would be vastly improved if people used
&lt;code&gt;tuple&lt;/code&gt; as the default ordered collection, and only switched to &lt;code&gt;list&lt;/code&gt; if
mutation was necessary (it's less necessary than you think; you can always
copy a tuple instead of mutating it). I agree with David Beazley that you
don't "sometimes need a read only list". Rather, you "sometimes need a
writable tuple".&lt;/p&gt;
&lt;p&gt;This makes more sense than defaulting to &lt;code&gt;list&lt;/code&gt;, and only switching to &lt;code&gt;tuple&lt;/code&gt;
when hashability is needed, or when some weird "rule of thumb" applies that
says that you should use &lt;code&gt;tuple&lt;/code&gt; if you have a "record". Maybe there's a good
reason that &lt;code&gt;*args&lt;/code&gt; and almost all builtin and standard library functions
return tuples instead of lists. It's harder to accidentally break someone
else's code, or have someone else accidentally break your code, when your data
structures are immutable.&lt;/p&gt;
&lt;h2&gt;Footnotes&lt;/h2&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:list"&gt;
&lt;p&gt;I want to avoid saying "a tuple is an immutable list", since "list"
can be interpreted in two ways, as an English word meaning "ordered
collection" (in
which case, the statement is true), or as the Python type &lt;code&gt;list&lt;/code&gt; (in which
case, the statement is false—&lt;code&gt;tuple&lt;/code&gt; is not a subclass of &lt;code&gt;list&lt;/code&gt;). &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/tuples/#fnref:list" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:assign"&gt;
&lt;p&gt;Yes,&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&amp;gt;&amp;gt;&amp;gt; [a, b] = 1, 2
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;works. &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/tuples/#fnref:assign" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:mutate"&gt;
&lt;p&gt;&lt;/p&gt;&lt;div id="spoiler" style="display:none"&gt;
&lt;code&gt;__delitem__&lt;/code&gt;, &lt;code&gt;__iadd__&lt;/code&gt;, &lt;code&gt;__imul__&lt;/code&gt;, &lt;code&gt;__setitem__&lt;/code&gt;, &lt;code&gt;append&lt;/code&gt;, &lt;code&gt;clear&lt;/code&gt;, &lt;code&gt;extend&lt;/code&gt;, &lt;code&gt;insert&lt;/code&gt;,
&lt;code&gt;pop&lt;/code&gt;, &lt;code&gt;remove&lt;/code&gt;, &lt;code&gt;reverse&lt;/code&gt;, and &lt;code&gt;sort&lt;/code&gt;.
&lt;/div&gt;
&lt;button title="Click to show/hide content" type="button" onclick="if(document.getElementById('spoiler') .style.display=='none')
{document.getElementById('spoiler')
.style.display=''}else{document.getElementById('spoiler')
.style.display='none'}"&gt;Show/hide answer&lt;/button&gt; &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/tuples/#fnref:mutate" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;
&lt;/li&gt;
&lt;li id="fn:TypeError"&gt;
&lt;p&gt;One of the tweets from the conversation:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;&lt;a href="https://twitter.com/asmeurer"&gt;@asmeurer&lt;/a&gt; &lt;a href="https://twitter.com/AllenDowney"&gt;@AllenDowney&lt;/a&gt; As yes:&lt;br&gt;&lt;br&gt;t = (1,2, [3, 4])&lt;br&gt;t[2] += [5,6]&lt;br&gt;&lt;br&gt;;-)&lt;/p&gt;— David Beazley (@dabeaz) &lt;a href="https://twitter.com/dabeaz/status/778697399975813120"&gt;September 21, 2016&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
&lt;p&gt;This is similar to this example. But
it turns out this one doesn't work:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mh"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mh"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;4&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mh"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mh"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mh"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Traceback&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;most&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recent&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;File&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"&amp;lt;stdin&amp;gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;module&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;TypeError:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;'&lt;/span&gt;&lt;span class="n"&gt;tuple&lt;/span&gt;&lt;span class="p"&gt;'&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;object&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;does&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;support&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;assignment&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I have no idea why. It seems to me that it should work. &lt;code&gt;t[2]&lt;/code&gt; is a list
and &lt;code&gt;list&lt;/code&gt; has &lt;code&gt;__iadd__&lt;/code&gt; defined. It seems that Python gets kind of weird
about things on the left-hand side of an assignment. &lt;strong&gt;EDIT:
&lt;a href="http://stackoverflow.com/a/29747466/161801"&gt;Here's&lt;/a&gt; why.&lt;/strong&gt; &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/tuples/#fnref:TypeError" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><guid>https://asmeurer.com/blog/posts/tuples/</guid><pubDate>Thu, 22 Sep 2016 02:33:14 GMT</pubDate></item><item><title>Moving Away from Python 2</title><link>https://asmeurer.com/blog/posts/moving-away-from-python-2/</link><dc:creator>Aaron Meurer</dc:creator><description>&lt;p&gt;About a month ago I tweeted this:&lt;/p&gt;
&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Thought: get the maintainers of a bunch of big Python libraries to sign something saying that they WILL drop Python 2.7 support in 2020.&lt;/p&gt;— Aaron Meurer (@asmeurer) &lt;a href="https://twitter.com/asmeurer/status/712304912428875776"&gt;March 22, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;EDIT: Some people have started working on making this happen. See
&lt;a href="https://python3statement.github.io/"&gt;https://python3statement.github.io/&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For those of you who don't know, Python 2.7 is
&lt;a href="https://docs.python.org/devguide/#status-of-python-branches"&gt;slated&lt;/a&gt; to reach
end-of-life in 2020 (originally, it was slated to end in 2015, but it was
extended in 2014, due to the extraordinary difficulty of moving to a newer
version). "End-of-life" means absolutely no more support from the core Python
team, even for security updates.&lt;/p&gt;
&lt;p&gt;I'm writing this post because I want to clarify why I think this should be
done, and to clear up some misconceptions, the primary one being that this
represents library developers being antagonistic against those who want or
have to use Python 2.&lt;/p&gt;
&lt;p&gt;I'm writing this from my perspective as a library developer. I'm the lead
developer of &lt;a href="http://www.sympy.org/"&gt;SymPy&lt;/a&gt;, and I have sympathies for
developers of other libraries.&lt;sup id="fnref:sympy"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fn:sympy"&gt;1&lt;/a&gt;&lt;/sup&gt; I say this because my idea may seem a bit
in tension with "users" (even though I hate the "developer/user" distinction).&lt;/p&gt;
&lt;h3&gt;Python 2&lt;/h3&gt;
&lt;p&gt;There are a few reasons why I think libraries should drop (and announce that
they will drop) Python 2 support by 2020 (actually earlier, say 2018 or 2019,
depending on how core the library is).&lt;/p&gt;
&lt;p&gt;First, library developers have to be the leaders here. This is apparent from
the historical move to Python 3 up to this point. Consider the three (not
necessarily disjoint) classes of people: CPython core developers, library
developers, and users. The core developers were the first to move to Python 3,
since they were the ones who wrote it. They were also the ones who provided
the messaging around Python 3, which has varied over time. In my opinion, it
should have been and should be more forceful.&lt;sup id="fnref:core"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fn:core"&gt;2&lt;/a&gt;&lt;/sup&gt; Then you have the library
developers and the users. A chief difference here is that users are probably
going to be using only one version of Python. In order for them to switch that
version to Python 3, all the libraries that they use need to support it. This
took some time, since library developers saw little impetus to support Python
3 when no one was using it (Catch 22), and to worsen the situation, versions
of Python older than 2.6 made
&lt;a href="https://asmeurersympy.wordpress.com/2013/08/22/python-3-single-codebase-vs-2to3/"&gt;single codebase compatibility&lt;/a&gt;
almost impossible.&lt;/p&gt;
&lt;p&gt;Today, though, &lt;a href="http://py3readiness.org/"&gt;almost all libraries&lt;/a&gt; support Python
3, and we're reaching a point where those that don't have
forks that do.&lt;/p&gt;
&lt;p&gt;But it only happened &lt;em&gt;after&lt;/em&gt; the library developers transitioned. I believe
libraries need to be the leaders in moving away from Python 2 as well. It's
important to do this for a few reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Python 2.7 support ends in 2020. That means all updates, including security
  updates. For all intents and purposes, Python 2.7 becomes an insecure
  language to use at that point in time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Supporting two major versions of Python is technical debt for every project
  that does it. While writing cross compatible code is
  &lt;a href="http://python-future.org/"&gt;easier than ever&lt;/a&gt;, it still remains true that
  you have to remember to add &lt;code&gt;__future__&lt;/code&gt; imports to the top of every file,
  to import all relevant builtins from your compatibility file or library, and
  to run all your tests in both Python 2 and 3. Supporting both versions is a
  major cognitive burden to library developers, as they always have to be
  aware of important differences in the two languages. Developers on any
  library that does anything with strings will need to understand how things
  work in both Python 2 and 3, and the often obscure workarounds required for
  things to work in both (pop quiz: how do you write Unicode characters to a
  file in a Python 2/3 compatible way?).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Some of Python 3's
  &lt;a href="https://asmeurer.github.io/python3-presentation/slides.html"&gt;new syntax features&lt;/a&gt;
  (i.e., features that are impossible to use in Python 2) only matter for
  library developers. A great example of this is
  &lt;a href="https://www.python.org/dev/peps/pep-3102/"&gt;keyword-only arguments&lt;/a&gt;. From an
  API standpoint, almost every instance of keyword arguments should be
  implemented as keyword-only arguments. This avoids mistakes that come from
  the antipattern of passing keyword arguments without naming the keyword, and
  allows the argspec of the function to be expanded in the future without
  breaking API.&lt;sup id="fnref:swift"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fn:swift"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second reason I think library developers should agree to drop Python 2
support by 2020 is completely selfish. A response that I heard on that tweet
(as well as elsewhere), was that libraries should provide carrots, not sticks.
In other words, instead of forcing people off of Python 2, we should make them
want to come to Python 3. There are some issues with this argument. First,
Python 3 already has
&lt;a href="https://asmeurer.github.io/python3-presentation/slides.html"&gt;tons of carrots&lt;/a&gt;.
Honestly, not being terrible at Unicode ought to be a carrot in its own right.&lt;sup id="fnref:unicode"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fn:unicode"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;If you don't deal with strings, or do but don't care about those silly
foreigners with weird accents in their names, there are other major carrots as
well. For SymPy, the fact that 1/2 gives 0 in Python 2 has historically been a
major source of frustration for new users. Imagine writing out &lt;code&gt;1/2*x +
x**(1/2)*y*z - 3*z**2&lt;/code&gt; and wondering why half of what you wrote just
"disappeared" (granted, this was worse before we
&lt;a href="https://asmeurersympy.wordpress.com/2011/08/18/sqrtx-now-prints-as-sqrtx/"&gt;fixed the printers&lt;/a&gt;).
While &lt;code&gt;integer/integer&lt;/code&gt; not giving a rational number is a major
&lt;a href="http://docs.sympy.org/latest/tutorial/gotchas.html#two-final-notes-and"&gt;gotcha&lt;/a&gt;
for SymPy, giving a float is infinitely better than giving what is effectively
the wrong answer. Don't use strings or integers?
&lt;a href="https://asmeurer.github.io/python3-presentation/slides.html"&gt;I've got more&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Frankly, if these "carrots" haven't convinced you yet, then I'll wager you're
not really the sort of person who is persuaded by carrots.&lt;/p&gt;
&lt;p&gt;Second, some "carrots" are impossible unless they are implemented in
libraries. While some features can be implemented in 2/3 compatible code and
only work in Python 3 (such as &lt;code&gt;@&lt;/code&gt; matrix multiplication), others, such as
keyword-only arguments, can only be implemented in code that does not support
Python 2. Supporting them in Python 2 would be a net deficit of technical debt
(one can imagine, for instance, trying to support keyword-only arguments
manually using &lt;code&gt;**kwargs&lt;/code&gt;, or by using some monstrous meta-programming).&lt;/p&gt;
&lt;p&gt;Third, as I said, I'm selfish. Python 3 &lt;em&gt;does&lt;/em&gt; have carrots, and I want them.
As long as I have to support Python 2 in my code, I can't use keyword-only
arguments, or extended argument unpacking, or async/await, or any of the
dozens of features that can't be used in cross compatible code.&lt;/p&gt;
&lt;p&gt;A counterargument might be that instead of blocking users of existing
libraries, developers should create new libraries which are Python 3-only and
make use of new exciting features of Python 3 there. I agree we should do
that, but existing libraries are good too. I don't see why developers should
throw out all of a well-developed library just so they can use some Python
features that they are excited about.&lt;/p&gt;
&lt;h3&gt;Legacy Python&lt;/h3&gt;
&lt;p&gt;A lot of people have taken to calling Python 2
"&lt;a href="https://twitter.com/RipLegacyPython"&gt;legacy Python&lt;/a&gt;". This phrase is often
used condescendingly and
&lt;a href="https://twitter.com/stephtdouglas/status/713433933040340993"&gt;angers a lot of people&lt;/a&gt;
(and indeed, this blog post is the first time I've used it myself). However, I
think Python 2 really should be seen this way, as a "legacy" system. If you
want to use it, for whatever your reasons, that's fine, but just as you
shouldn't expect to get any of the newest features of Python, you shouldn't
expect to be able to use the newest versions of your libraries. Those
libraries that have a lot of development resources may choose to support older
Python 2-compatible versions with bug and/or security fixes. Python 2 itself
will be supported for these until 2020. Those without resources probably won't
(keep in mind that you're using open source libraries without paying money for
them).&lt;/p&gt;
&lt;p&gt;I get that some people have to use Python 2, for whatever reasons. But using
outdated software comes at a cost. Libraries have borne this technical debt
for the most part thus far, but they shouldn't be expected to bear it forever.
The debt will only increase, especially as the technical opportunity cost, if
you will, of not being able to use newer and shinier versions of Python 3
grows. The burden will have to shift at some point. Those with the financial
resources may choose to offload this debt to others,&lt;sup id="fnref:continuum"&gt;&lt;a class="footnote-ref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fn:continuum"&gt;5&lt;/a&gt;&lt;/sup&gt; say, by
backporting features or bugfixes to older library versions that support Python
2 (or by helping to move code to Python 3).&lt;/p&gt;
&lt;p&gt;I want to end by pointing out that if you are, for whatever reason, still
using Python 2, you may be worried that if libraries become Python 3-only and
start using Python 3 features, won't that break your code? The answer is no.
Assuming package maintainers mark the metadata on their packages correctly,
tools like pip and conda will not install non-Python 2 compatible versions
into Python 2.&lt;/p&gt;
&lt;p&gt;If you haven't transitioned yet, and want to know more, a good place to start
is the &lt;a href="https://docs.python.org/3/howto/pyporting.html"&gt;official docs&lt;/a&gt;. I also
highly recommend using &lt;a href="http://conda.pydata.org/docs/"&gt;conda&lt;/a&gt; environments, as
it will make it easy to separate your Python 2 code from your Python 3 code.&lt;/p&gt;
&lt;h4&gt;Footnotes&lt;/h4&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:sympy"&gt;
&lt;p&gt;With that being said, the opinions here are entirely my own, and are
    don't necessarily represent those of other people, nor do they
    represent official SymPy policy (no decisions have been made by the
    community about this at this time). &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fnref:sympy" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:core"&gt;
&lt;p&gt;It often feels like core Python itself doesn't really want people to
    use Python 3. It's little things, like
    &lt;a href="https://docs.python.org/library/"&gt;docs links&lt;/a&gt; that redirect to Python
    2, or &lt;a href="https://www.python.org/dev/peps/pep-0394/"&gt;PEP 394&lt;/a&gt;, which
    still says that the &lt;code&gt;python&lt;/code&gt; should always point to Python 2. &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fnref:core" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:swift"&gt;
&lt;p&gt;In Swift, Apple's new language for iOS and OS X, function parameter
    names are effectively "keyword-only"
    &lt;a href="https://developer.apple.com/library/ios/documentation/Swift/Conceptual/Swift_Programming_Language/Functions.html"&gt;by default&lt;/a&gt;. &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fnref:swift" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:unicode"&gt;
&lt;p&gt;As an example of this, in conda, if you use Python 2 in the root
    environment, then installing into a path with non-ASCII characters is
    unsupported. This is common on Windows, because Windows by default
    uses the user's full name as the username, and the default conda
    install path is in the user directory.&lt;/p&gt;
&lt;p&gt;This is unsupported except in Python 3, because to fix the issue,
every single place in conda where a string appears would have to be
changed to use a &lt;code&gt;unicode&lt;/code&gt; string in Python 2. The basic issue is that
things like &lt;code&gt;'π' + u'i'&lt;/code&gt; raise &lt;code&gt;UnicodeDecodeError&lt;/code&gt; in Python 2 (even
though &lt;code&gt;'π' + 'i'&lt;/code&gt;, &lt;code&gt;u'π' + 'i'&lt;/code&gt;, and &lt;code&gt;u'π' + u'i'&lt;/code&gt; all work fine).
You can read a more in-depth description of the problem
&lt;a href="https://github.com/sympy/sympy/pull/9692#issuecomment-126162173"&gt;here&lt;/a&gt;.
Incidentally, this is also why you should never use &lt;code&gt;from __future__
import unicode_literals&lt;/code&gt; in Python 2, in my opinion.&lt;/p&gt;
&lt;p&gt;I no longer work on conda, but as far as I know, the
&lt;a href="https://github.com/conda/conda/issues/1180"&gt;issue&lt;/a&gt; remains unfixed.
Of course, this whole thing works just fine if conda is run in Python
3. &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fnref:unicode" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:continuum"&gt;
&lt;p&gt;If that legitimately interests you, I
    &lt;a href="https://twitter.com/pwang/status/712780279211884546"&gt;hear Continuum&lt;/a&gt;
    may be able to help you. &lt;a class="footnote-backref" href="https://asmeurer.com/blog/posts/moving-away-from-python-2/#fnref:continuum" title="Jump back to footnote 5 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><guid>https://asmeurer.com/blog/posts/moving-away-from-python-2/</guid><pubDate>Thu, 19 May 2016 18:00:00 GMT</pubDate></item></channel></rss>