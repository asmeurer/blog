<!DOCTYPE html>
<html prefix="
        og: http://ogp.me/ns#
        article: http://ogp.me/ns/article#
    " lang="en">
    <head>
    <meta charset="utf-8">
    <meta name="description" content="My blog on my work on SymPy and other fun stuff.">
    <meta name="viewport" content="width=device-width">
    <title>Aaron Meurer's SymPy Blog (old posts, page 4) | Aaron Meurer's SymPy Blog</title>

    
            <link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">

    
            <link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">

      <link rel="canonical" href="http://asmeurersympy.wordpress.com/index-4.html">



    
        <!--[if lt IE 9]><script src="/assets/js/html5.js"></script><![endif]-->

    




</head>
<body>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container-fluid">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://asmeurersympy.wordpress.com/">Aaron Meurer's SymPy Blog</a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                
                <li>
<a href="archive.html">Archives</a>
                </li>
<li>
<a href="categories/index.html">Tags</a>
                </li>
<li>
<a href="rss.xml">RSS</a>

            </li>
</ul>

            <ul class="nav navbar-nav navbar-right">
                
                
                    
            </ul>
        </div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container-fluid -->
</nav>

<!-- End of Menubar -->

<div class="container">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
<div class="postindex">
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/08/05/prototype-risch_integrate-function-ready-for-testing.html" class="u-url">Prototype risch_integrate() function ready for testing!</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/08/05/prototype-risch_integrate-function-ready-for-testing.html" rel="bookmark"><time class="published dt-published" datetime="2010-08-05T22:30:00+00:00" itemprop="datePublished" title="Publication date">2010-08-05 22:30</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/08/05/prototype-risch_integrate-function-ready-for-testing.html#disqus_thread" data-disqus-identifier="cache/posts/2010/08/05/prototype-risch_integrate-function-ready-for-testing.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>So today I finally finished up the prototype function I talked about <a href="http://asmeurersympy.wordpress.com/2010/07/31/integration-of-primitive-functions/">last week</a>.  The function is called <code>risch_integrate()</code> and is available at my <a href="http://github.com/asmeurer/sympy/tree/integration3">integration3</a> branch.  Unlike the inner level functions I have showcased in <a href="http://asmeurersympy.wordpress.com/2010/07/31/integration-of-primitive-functions/">previous</a> <a href="http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/">blog posts</a>, this function does not require you to do substitution for dummy variables and manually create a list of derivatives, etc.  All you have to do is pass it a function and the integration variable, and it will return the result, just like normal <code>integrate()</code>. I have spent the past few days working on a monster of a function called <code>build_extension()</code> that does this preparsing work for you.  The reason that the function was so hard to write is that the transcendental Risch Algorithm is very picky.  <em>Every</em> differential extension has to be transcendental over the previous extensions.  This means that if you have a function like $latex e^x + e^{\frac{x}{2}}$, you cannot write this as $latex t_0 + t_1$ with $latex t_0=e^x$ and $latex t_1=e^{\frac{x}{2}}$ because $latex t_0$ and $latex t_1$ will each be algebraic over the other ($latex t_0=t_1^2$).  You also cannot let $latex t_0=e^{x}$ and rewrite the whole integral in terms of $latex t_0$ because you will get $latex t_0 + \sqrt{t_0}$, which is an algebraic function.  The only way that you can do it is to let $latex t_0=e^{\frac{x}{2}}$, and then your function will be $latex t_0^2 + t_0$.  </p>
<p>Now, fortunately, there is an algorithm that provides necessary and sufficient conditions for determining if an extension is algebraic over the previous ones.  It's called the Risch Structure Theorems.  My first order of business this week was to finish implementing these.  This is actually the reason that I we had to wait until now to get this prototype function.  The Structure Theorems are at the very end of Bronstein's book, and the integration algorithm is not correct without them (namely, it is not correct if you add an algebraic extension).  I just recently got to them in my reading.  Actually, I skipped some work on tangent integration so I could get to them first.  I hope to talk a little about them in a future "Risch Integration" blog post, though be aware that they require some extremely intense algebraic machinery to prove, so I won't be giving any proofs.</p>
<p>Even though these algorithms can tell me, for example, that I shouldn't have added $latex t_0=e^x$ above because it makes $latex e^{\frac{x}{2}}=\sqrt{t_0}$, that means that I have to go back and restart my search for an extension so that I can try to get $latex t_0=e^{\frac{x}{2}}$ instead.  So I wrote a simple function that takes the arguments of the exponentials and determines the lowest common factor.  This heuristic saves a lot of time.  </p>
<p>I also noticed (actually, Chris Smith inadvertently pointed it out to me; super thanks to him), that the Structure Theorem algorithms only tell you if the terms are the same as monomials.  It would tell you that $latex e^x = e^{x + 1}$ because both satisfy $latex Dt=t$.  Therefore, I had to also modify the structure theorem algorithms to pull out any constant term.  </p>
<p>It can still be necessary to restart building the extension even with the above heuristic.  For example, if you have $latex e^x + e^{x^2} + e^{\frac{x}{2} + x^2}$, and start with $latex t_0=e^x$ and $latex t_1=e^{x^2}$, then the structure theorems will tell you that $latex e^{x/2 + x^2} = \sqrt{t_0}t_1$, which we cannot use because of the radical.  The solution it uses is to split it up as $latex e^x + e^{x^2} + e^{\frac{x}{2}}e^{x^2}$ (the structure theorems tell you exactly how to do this so you are splitting in terms of the other exponentials) and then restart the extension building entirely.  This can be an expensive operation, because you have to rebuild $latex t_0$ and $latex t_1$, but this time, the heuristic function I wrote from above handles the $latex e^{\frac{x}{2}}$ correctly, making $latex t_0=e^{\frac{x}{2}}$, with the final answer $latex t_0^2 + t_1 + t_0t_1$.  I could have probably made it smarter by only going back to before the conflicting extensions, but this was quite a bit more work, and adds more difficulties such as non-trivial relationships, so I just took the lazy way and restarted completely.  It doesn't take <em>that</em> much time.  </p>
<p>Of course, sometimes, you cannot add a new exponential, no matter how you add the extensions.  The classic example is $latex e^{\frac{\log{(x)}}{2}}$, which you can see is actually equal to $latex \sqrt{x}$, an algebraic function.  Therefore, I had to implement some tricky logic to keep the <code>build_extension()</code> function from trying again infinitely.  I hope I did it right, so that it never infinite loops, and never fails when it really can be done.  Only time and testing will tell.</p>
<p>It is exactly the same for logarithms, except in that case, when a new logarithm is algebraic in terms of old ones, it can be written as a linear combination of them.  This means that there are never any radicals to worry about, though you do also have to worry about constants.  For example, $latex \log{(x)}$ looks the same as $latex \log{(2x)}$ because they both satisfy $latex Dt=\frac{1}{x}$.  An example of a logarithm that is algebraic over old ones is $latex \log{(x^2 - 1)}$ over $latex \log{(x + 1)}$ and $latex \log{(x - 1)}$, because $latex \log{(x^2 - 1)}=\log{((x + 1)(x - 1))}=\log{(x + 1)} + \log{(x - 1)}$.  </p>
<p>The parallels between exponentials and logarithms are amazing.  For the structure theorems, the exponential case is exactly the same as the logarithmic case except replacing addition with multiplication and multiplication with exponentiation.  For the exponential case, you need the arguments of the already added logarithms to find the algebraic dependence, and the arguments of the already added exponentials to find the constant term.  For the logarithmic case, you need the arguments of the already added exponentials to find the algebraic dependence, and the arguments of the already added logarithms to find the content term. Everything else is exactly the same, except for the shift in operators.  Of course, I realize why these things are, mathematically, but the symmetry still amazing to me.  I will hopefully explain in more detail in my future Structure Theorems post.  </p>
<p>So onto the <code>risch_integrate()</code> function.  Here is the text that I have basically put in my <a href="http://github.com/asmeurer/sympy/commit/e3cd5f18f86fd6377836f33f726182c8bd4dc1a0">commit message</a>, the <a href="http://code.google.com/p/sympy/issues/detail?q=2010">aptly numbered issue</a> that I have created for it, and the <a href="http://groups.google.com/group/sympy/browse_thread/thread/2464fa764f6f47aa">post to the mailing list</a> (it's not so much that I am lazy as that I was really excited to get this out there).</p>
<p></p>
<blockquote>
<p>I have ready in my integration3 branch a prototype risch_integrate() function that is a user-level function for the full Risch Algorithm I have been implementing this summer.  Pull from h<a href="//github.com/asmeurer/sympy/tree/integration3">ttp://github.com/asmeurer/sympy/tree/integration3</a>.</p>
<p>This is NOT ready to go in.  It is a prototype function that I am making available so people can try out the new algorithm and hopefully help me to find the bugs in it.  Please pass it your favorite non-elementary integrals and see if it can determine that they are not elementary.  If you try to pass it a very crazy function at random, the chances are pretty high that it will not be elementary.  So a better way to test it is to come up with a crazy function, then differentiate it. Then pass the derivative and see if it can give you your original function back.  Note that it will probably not look exactly the same as your original function, and may differ by a constant.  You should verify by differentiating the result you get and calling cancel() (or simplify(), but usually cancel() is enough) on the difference.</p>
<p>So you can review the code too, if you like, but just know that things are not stable yet, and this isn't strictly a branch for review.  </p>
<p>So far, this function only supports exponentials and logarithms.</p>
<p>Support for trigonometric functions is planned.  Algebraic functions are</p>
<p>not supported. If the function returns an unevaluated Integral, it means</p>
<p>that it has proven the integral to be non-elementary.  Note that several</p>
<p>cases are still not implemented, so you may get NotImplementedError</p>
<p>instead. Eventually, these will all be eliminated, and the only</p>
<p>NotImplementedError you should see from this function is</p>
<p>NotImplementedError("Algebraic extensions are not supported.")</p>
<p>This function has not been integrated in any way with the already</p>
<p>existing integrate() yet, and you can use it to compare.</p>
<p>Examples:</p>
<p>[code language="py"]</p>
<p>In [1]: risch_integrate(exp(x**2), x)</p>
<p>Out[1]:</p>
<p>⌠</p>
<p>⎮  ⎛ 2⎞</p>
<p>⎮  ⎝x ⎠</p>
<p>⎮ ℯ     dx</p>
<p>⌡</p>
<p>In [2]: risch_integrate(x*<em>100</em>exp(x), x).diff(x)</p>
<p>Out[2]:
 100  x
x   ⋅ℯ</p>
<p>In [3]: %timeit risch_integrate(x*<em>100</em>exp(x), x).diff(x)</p>
<p>1 loops, best of 3: 270 ms per loop</p>
<p>In [4]: integrate(x*<em>100</em>exp(x), x)</p>
<p>... hangs ...</p>
<p>In [5]: risch_integrate(x/log(x), x)</p>
<p>Out[5]:</p>
<p>⌠</p>
<p>⎮   x</p>
<p>⎮ ────── dx</p>
<p>⎮ log(x)</p>
<p>⌡</p>
<p>In [6]: risch_integrate(log(x)**10, x).diff(x)</p>
<p>Out[6]:
   10
log  (x)</p>
<p>In [7]: integrate(log(x)**10, x).diff(x)</p>
<p>Out[7]:
   10
log  (x)</p>
<p>In [8]: %timeit risch_integrate(log(x)**10, x).diff(x)</p>
<p>10 loops, best of 3: 159 ms per loop</p>
<p>In [9]: %timeit integrate(log(x)**10, x).diff(x)</p>
<p>1 loops, best of 3: 2.35 s per loop</p>
<p>[/code]</p>
<p>Be warned that things are still very buggy and you should always verify</p>
<p>results by differentiating.  Usually, cancel(diff(result, x) - result)</p>
<p>should be enough.  This should go to 0.</p>
<p>So please, please, PLEASE, try out this function and report any bugs that you find.  It is not necessary to report NotImplementedError bugs, because I already know about those (I put them in there), and as I mentioned above, they are all planned to disappear.  Also, I am continually updating my branch with fixes, so you should do a "git pull" and try again before you report anything.</p>
<p>Also, I am aware that there are test failures.  This is because I had to hack exp._eval_subs() to only do exact substitution (no algebraic substitution).  It's just a quick hack workaround, and I should eventually get a real fix.  </p>
<p>Finally, I'm thinking there needs to be a way to differentiate between an unevaluated Integral because the integrator failed and an unevaluated Integral because it has proven the integral to be non-elementary.  Any ideas?</p>
</blockquote>

<p>Also, looking at the integral from the previous blog post, you can get the different results by using the <code>handle_log</code> argument to <code>risch_integrate()</code>:</p>
<p>If <code>handle_first == 'log'</code> (the default right now), then it will gather all logarithms first, and then exponentials (insomuch as it can do it in that order).  If <code>handle_first='exp'</code>, it gathers exponentials first.  The difference is that the Risch Algorithm integrates recursively, one extension at a time, starting with the outer-most one. So if you have an expression with both logarithms and exponentials, such that they do not depend on each other, <code>handle_first == 'log'</code> will integrate the exponentials first, because they will be gathered last (be at the top of the tower of extensions), and <code>handle_first == 'exp'</code> will integrate the logarithms first.  Right now, I have defaulted to 'log' because the exponential integration algorithm is slightly more complete.  If you get <code>NotImplementedError</code> with one, it is possible (though I don't know for sure yet) that you might get an answer with the other.  </p>
<p>Also, they can give different looking results, and at different speeds.  For example:</p>
<p><strong>Hover over the code and click on the left-most, "view source" icon (a paper icon with <tt>&lt; &gt;</tt> over it) to view without breaks.  Opens in a new window.</strong></p>
<p>[code language="py"]</p>
<p>In [1]: f = (x<em>(x + 1)</em>((x<strong>2<em>exp(2</em>x</strong>2) - log(x + 1)<strong>2)</strong>2 +
   ...: 2<em>x</em>exp(3<em>x<strong>2)<em>(x - (2</em>x</strong>3 + 2</em>x<strong>2 + x + 1)<em>log(x + 1))))/((x +
   ...: 1)</em>log(x + 1)</strong>2 - (x<strong>3 + x</strong>2)<em>exp(2</em>x<strong>2))</strong>2</p>
<p>In [2]: f</p>
<p>Out[2]: 
          ⎛                          2                                                   ⎞
          ⎜⎛                       2⎞                                                   2⎟
          ⎜⎜     2           2  2⋅x ⎟        ⎛    ⎛           2      3⎞           ⎞  3⋅x ⎟
x⋅(1 + x)⋅⎝⎝- log (1 + x) + x ⋅ℯ    ⎠  + 2⋅x⋅⎝x - ⎝1 + x + 2⋅x  + 2⋅x ⎠⋅log(1 + x)⎠⋅ℯ    ⎠</p>
<p>──────────────────────────────────────────────────────────────────────────────────────────
                                                                2                       <br>
                         ⎛                                    2⎞                        <br>
                         ⎜   2                  ⎛ 2    3⎞  2⋅x ⎟                        <br>
                         ⎝log (1 + x)⋅(1 + x) - ⎝x  + x ⎠⋅ℯ    ⎠                          </p>
<p>In [3]: risch_integrate(f, x, handle_first='log')</p>
<p>Out[3]: 
       ⎛              ⎛ 2⎞⎞                   ⎛                ⎛ 2⎞⎞                           <br>
       ⎜log(1 + x)    ⎝x ⎠⎟                   ⎜  log(1 + x)    ⎝x ⎠⎟          ⎛ 2⎞             <br>
    log⎜────────── + ℯ    ⎟                log⎜- ────────── + ℯ    ⎟       2  ⎝x ⎠             <br>
       ⎝    x             ⎠                   ⎝      x             ⎠      x ⋅ℯ    ⋅log(1 + x)  <br>
x + ─────────────────────── - log(1 + x) - ───────────────────────── + ──────────────────────────
               2                                       2                                        2
                                                                              2           3  2⋅x 
                                                                       - x⋅log (1 + x) + x ⋅ℯ    </p>
<p>In [4]: risch_integrate(f, x, handle_first='exp')</p>
<p>Out[4]: 
       ⎛                ⎛ 2⎞⎞                   ⎛                ⎛ 2⎞⎞        ⎛ 2⎞           <br>
       ⎜                ⎝x ⎠⎟                   ⎜                ⎝x ⎠⎟        ⎝x ⎠           <br>
    log⎝log(1 + x) + x⋅ℯ    ⎠                log⎝log(1 + x) - x⋅ℯ    ⎠     x⋅ℯ    ⋅log(1 + x)<br>
x + ───────────────────────── - log(1 + x) - ───────────────────────── - ──────────────────────
                2                                        2                                    2
                                                                            2           2  2⋅x 
                                                                         log (1 + x) - x ⋅ℯ    </p>
<p>In [5]: %timeit risch_integrate(f, x, handle_first='log')</p>
<p>1 loops, best of 3: 1.49 s per loop</p>
<p>In [6]: %timeit risch_integrate(f, x, handle_first='exp')</p>
<p>1 loops, best of 3: 1.21 s per loop</p>
<p>In [7]: cancel(risch_integrate(f, x, handle_first='log').diff(x) - f)</p>
<p>Out[7]: 0</p>
<p>In [8]: cancel(risch_integrate(f, x, handle_first='exp').diff(x) - f)</p>
<p>Out[8]: 0</p>
<p>[/code]</p>
<p>So go now, and pull my <a href="//github.com/asmeurer/sympy/tree/integration3">branch</a>, and try this function out.  And report any problems that you have back to me, either through the mailing list, IRC, issue 2010, or as a comment to this blog post (I don't really care how).</p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/07/31/integration-of-primitive-functions.html" class="u-url">Integration of primitive functions</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/07/31/integration-of-primitive-functions.html" rel="bookmark"><time class="published dt-published" datetime="2010-07-31T06:44:31+00:00" itemprop="datePublished" title="Publication date">2010-07-31 06:44</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/07/31/integration-of-primitive-functions.html#disqus_thread" data-disqus-identifier="cache/posts/2010/07/31/integration-of-primitive-functions.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<strong>Integration of Primitive Functions</strong>
<p>So this past week, I had another break through in my project.  The <a href="http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/">first break through</a>, as you may recall, was the completion of the <code>integrate_hyperexponential()</code> function, which allowed for the integration in hyperexponential extensions, including proving the nonexistence of elementary integrals.  Now I have worked my way up to this level on the other major half of the integration algorithm (actually, major third; more on that later): integration of primitive elements.  </p>
<p>This time, I can refer you to my <a href="http://asmeurersympy.wordpress.com/2010/07/24/the-risch-algorithm-part-2-elementary-functions/">previous blog post</a> for definitions.  The chief thing here is that there is now a function in my <tt>integration3</tt> branch called <code>integrate_primitive()</code>, and it is used primarily for integrating functions with logarithms.</p>
<p>So, how about some examples?  The first one comes from <a href="http://">Algorithms for computer algebra By Keith O. Geddes, Stephen R. Czapor, George Labahn</a> (example 12.8).  I like it because it contains both exponentials and logarithms, in a way that they do not depend on each other, so it can be integrated with either <code>integrate_primitive()</code> or <code>integrate_hyperexponential()</code>.  In either case, the polynomial part is $latex \frac{x}{x + 1}$, so recursively calling the other function is not required.  (for those of you who have been following my <tt>integration3</tt> branch, you may notice that this is blatantly taken from the commit history).</p>
<p><strong>Hover over the code and click on the left-most, "view source" icon (a paper icon with <tt>&lt; &gt;</tt> over it) to view without breaks.  Opens in a new window.</strong></p>
<p>[code language="py"]</p>
<p>In [1]: from sympy.integrals.risch import integrate_primitive,</p>
<p>integrate_hyperexponential</p>
<p>In [2]: f = (x<em>(x + 1)</em>((x<strong>2<em>exp(2</em>x</strong>2) - log(x + 1)<strong>2)</strong>2 +</p>
<p>2<em>x</em>exp(3<em>x<strong>2)<em>(x - (2</em>x</strong>3 + 2</em>x*<em>2 + x + 1)</em>log(x + 1))))/((x +</p>
<p>1)<em>log(x + 1)<strong>2 - (x</strong>3 + x<strong>2)<em>exp(2</em>x</strong>2))</em>*2</p>
<p>In [3]: f</p>
<p>Out[3]:
          ⎛                          2                                                   ⎞
          ⎜⎛                       2⎞                                                   2⎟
          ⎜⎜     2           2  2⋅x ⎟        ⎛    ⎛           2      3⎞           ⎞  3⋅x ⎟
x⋅(1 + x)⋅⎝⎝- log (1 + x) + x ⋅ℯ    ⎠  + 2⋅x⋅⎝x - ⎝1 + x + 2⋅x  + 2⋅x ⎠⋅log(1 + x)⎠⋅ℯ    ⎠</p>
<p>──────────────────────────────────────────────────────────────────────────────────────────
                                                                2
                         ⎛                                    2⎞
                         ⎜   2                  ⎛ 2    3⎞  2⋅x ⎟
                         ⎝log (1 + x)⋅(1 + x) - ⎝x  + x ⎠⋅ℯ    ⎠</p>
<p>In [4]: var('t0, t1')</p>
<p>Out[4]: (t₀, t₁)</p>
<p>In [5]: a, d = map(lambda i: Poly(i, t1), f.subs(exp(x**2),</p>
<p>t0).subs(log(x + 1), t1).as_numer_denom())</p>
<p>In [6]: a</p>
<p>Out[6]:</p>
<p>Poly((x + x<strong>2)*t1</strong>4 + (-2<em>t0<strong>2*x</strong>3 - 2</em>t0<strong>2*x</strong>4)<em>t1</em>*2 +</p>
<p>(-2<em>t0<strong>3*x</strong>2 - 4</em>t0<strong>3*x</strong>3 - 6<em>t0<strong>3*x</strong>4 - 8</em>t0<strong>3*x</strong>5 -</p>
<p>4<em>t0<strong>3*x</strong>6)</em>t1 + 2<em>t0<strong>3*x</strong>3 + 2</em>t0<strong>3*x</strong>4 + t0<em> </em>4<em>x</em>*5 +</p>
<p>t0<strong>4*x</strong>6, t1, domain='ZZ[x,t0]')</p>
<p>In [7]: d</p>
<p>Out[7]: Poly((1 + 2<em>x + x<strong>2)*t1</strong>4 + (-2</em>t0<strong>2*x</strong>2 - 4*t0<strong>2*x</strong>3 -</p>
<p>2<em>t0<strong>2*x</strong>4)</em>t1<strong>2 + t0</strong>4<em>x<strong>4 + 2*t0</strong>4</em>x<strong>5 + t0</strong>4<em>x</em>*6, t1,</p>
<p>domain='ZZ[x,t0]')</p>
<p>In [8]: D = [Poly(1, x), Poly(2<em>x</em>t0, t0), Poly(1/(x + 1), t1)]</p>
<p>In [9]: r = integrate_primitive(a, d, D, [x, t0, t1], [lambda x: log(x +</p>
<p>1), lambda x: exp(x**2)])</p>
<p>In [10]: r</p>
<p>Out[10]:</p>
<p>⎛   ⎛                ⎛ 2⎞⎞      ⎛                ⎛ 2⎞⎞        ⎛ 2⎞                                ⎞</p>
<p>⎜   ⎜                ⎝x ⎠⎟      ⎜                ⎝x ⎠⎟        ⎝x ⎠                ⌠               ⎟</p>
<p>⎜log⎝log(1 + x) + x⋅ℯ    ⎠   log⎝log(1 + x) - x⋅ℯ    ⎠     x⋅ℯ    ⋅log(1 + x)     ⎮   x           ⎟</p>
<p>⎜───────────────────────── - ───────────────────────── - ────────────────────── + ⎮ ───── dx, True⎟</p>
<p>⎜            2                           2                                    2   ⎮ 1 + x         ⎟</p>
<p>⎜                                                           2           2  2⋅x    ⌡               ⎟</p>
<p>⎝                                                        log (1 + x) - x ⋅ℯ                       ⎠</p>
<p>[/code]</p>
<p>An explanation:  <code>f</code> is the function we are integrating.  Preparsing is not implemented yet, so we have to do it manually in <tt>[5]</tt>.  <tt>[8]</tt> is the list of derivations of the monomials we are working with, <code>[x, t0, t1]</code>, which represent $latex x$, $latex e^{x^2}$, and $latex \log{(x + 1)}$, respectively. Because the outermost monomial is a logarithm (primitive), we call <code>integrate_primitive()</code> on it.  The last argument of the function is the back substitution list, in reverse order because that is the order we have to back substitute in.  We can see the result contains an unevaluated Integral.  This is because the recursive calls to integrate over the smaller extensions have not yet been implemented.  In the final version, <code>integrate()</code> will automatically call <code>ratint()</code> in this case on it to give the complete answer.  The second argument of the result, True, indicates that the integral was elementary and that this is the complete integral.</p>
<p>Because the extensions did not depend on each other, we could have also integrated in $latex \mathbb{Q}(x, \log{(x + 1)}, e^{x^2})$ instead of $latex \mathbb{Q}(x, e^{x^2}, \log{(x + 1)})$:</p>
<p>[code language="py"]</p>
<p>In [11]: a1, d1 = map(lambda i: Poly(i, t0), f.subs(exp(x**2), t0).subs(log(x + 1), t1).as_numer_denom())</p>
<p>In [12]: D1 = [Poly(1, x), Poly(1/(x + 1), t1), Poly(2<em>x</em>t0, t0)]</p>
<p>In [13]: r1 = integrate_hyperexponential(a1, d1, D1, [x, t1, t0], [lambda x: exp(x**2), lambda x: log(x + 1)])</p>
<p>In [14]: r1</p>
<p>Out[14]:</p>
<p>⎛   ⎛              ⎛ 2⎞⎞      ⎛                ⎛ 2⎞⎞                                                ⎞</p>
<p>⎜   ⎜log(1 + x)    ⎝x ⎠⎟      ⎜  log(1 + x)    ⎝x ⎠⎟          ⎛ 2⎞                                  ⎟</p>
<p>⎜log⎜────────── + ℯ    ⎟   log⎜- ────────── + ℯ    ⎟       2  ⎝x ⎠                  ⌠               ⎟</p>
<p>⎜   ⎝    x             ⎠      ⎝      x             ⎠      x ⋅ℯ    ⋅log(1 + x)       ⎮   x           ⎟</p>
<p>⎜─────────────────────── - ───────────────────────── + ────────────────────────── + ⎮ ───── dx, True⎟</p>
<p>⎜           2                          2                                        2   ⎮ 1 + x         ⎟</p>
<p>⎜                                                             2           3  2⋅x    ⌡               ⎟</p>
<p>⎝                                                      - x⋅log (1 + x) + x ⋅ℯ                       ⎠</p>
<p>[/code]</p>
<p>We can verify by taking the derivative that the results in each case are antiderivatives of the original function, <code>f</code>, even though they appear different.</p>
<p>[code language="py"]</p>
<p>In [15]: cancel(r[0].diff(x) - f)</p>
<p>Out[15]: 0</p>
<p>In [16]: cancel(r1[0].diff(x) - f)</p>
<p>Out[16]: 0</p>
<p>[/code]</p>
<p>We can see in each case, the remaining unevaluated <code>Integral</code> was in $latex \mathbb{Q}(x)$ only, meaning that the recursive call to <code>integrate_hyperexponential()</code> or <code>integrate_primitive()</code>, respectively, would not have been necessary. Finally, we can see that choosing the correct extension to integrate over can make a difference, time wise:</p>
<p>[code language="py"]</p>
<p>In [17]: %timeit integrate_primitive(a, d, D, [x, t0, t1], [lambda x: log(x + 1), lambda x: exp(x**2)])</p>
<p>1 loops, best of 3: 1.91 s per loop</p>
<p>In [18]: %timeit integrate_hyperexponential(a1, d1, D1, [x, t1, t0], [lambda x: exp(x**2), lambda x: log(x + 1)])</p>
<p>1 loops, best of 3: 2.63 s per loop</p>
<p>[/code]</p>
<p>Just as with the exponential case, the function can prove the integrals are non-elementary. This is the so-called <a href="http://en.wikipedia.org/wiki/Logarithmic_integral">logarithmic integral</a>:</p>
<p>[code language="py"]</p>
<p>In [19]: f1 = 1/log(x)</p>
<p>In [20]: a, d = map(lambda i: Poly(i, t1), f1.subs(log(x), t1).as_numer_denom())</p>
<p>In [21]: a</p>
<p>Out[21]: Poly(1, t1, domain='ZZ')</p>
<p>In [22]: d</p>
<p>Out[22]: Poly(t1, t1, domain='ZZ')</p>
<p>In [23]: integrate_primitive(a, d, [Poly(1, x), Poly(1/x, t1)], [x, t1], [log])</p>
<p>Out[23]: (0, False)</p>
<p>[/code]</p>
<p>The second argument, <code>False</code>, indicates that the integral was non-elementary.  Namely, the function has proven that the function $latex f - D(0) = \frac{1}{\log{(x)}}$ does not have an elementary anti-derivative over $latex \mathbb{Q}(x, \log{(x)})$ (see the <a href="http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/">previous post</a> for more information).</p>
<p>Finally, be aware that, just as with <code>integrate_hyperexponential()</code> many integrals will  raise <code>NotImplementedError</code>, because the subroutines necessary to solve them have not yet been finished.</p>
<p>[code language="py"]</p>
<p>In [25]: f = log(log(x))**2</p>
<p>In [26]: f.diff(x)</p>
<p>Out[26]:</p>
<p>2⋅log(log(x))</p>
<p>─────────────
   x⋅log(x)</p>
<p>In [27]: a, d = map(lambda i: Poly(i, t1),</p>
<p>cancel(f.diff(x)).subs(log(x), t0).subs(log(t0), t1).as_numer_denom())</p>
<p>In [28]: a</p>
<p>Out[28]: Poly(2*t1, t1, domain='ZZ')</p>
<p>In [29]: d</p>
<p>Out[29]: Poly(t0*x, t1, domain='ZZ[x,t0]')</p>
<p>In [30]: D = [Poly(1, x), Poly(1/x, t0), Poly(1/(x*t0), t1)]</p>
<p>In [31]: integrate_primitive(a, d, D, [x, t0, t1], [lambda x: log(log(x)), log])</p>
<hr>
<p>NotImplementedError: Remaining cases for Poly RDE not yet implemented.</p>
<p>[/code]</p>
<p>Now one thing that I want to add from the above examples taken from the commit message is that logarithms are not the only function that are primitive.  The Li function (the logarithmic integral, as above), considered as an elementary extension of $latex \mathbb{Q}(x, \log{(x)})$ is also primitive.  But even among the commonly defined elementary functions, there is one other, acrtangents.  </p>
<p>[code language="py"]</p>
<p>In [32]: diff(atan(x)**2, x)</p>
<p>Out[32]: </p>
<p>2⋅atan(x)</p>
<p>─────────
       2 
  1 + x  </p>
<p>In [33]: integrate_primitive(Poly(2*t, t), Poly(1 + x<strong>2, t), [Poly(1, x), Poly(1/(1 + x</strong>2), t)], [x, t], [atan])</p>
<p>Out[33]: </p>
<p>⎛    2         ⎞</p>
<p>⎝atan (x), True⎠</p>
<p>In [34]: integrate_primitive(Poly(t, t), Poly(x, t), [Poly(1, x), Poly(1/(1 + x**2), t)], [x, t], [atan])</p>
<p>Out[34]: </p>
<p>⎛⌠                  ⎞</p>
<p>⎜⎮ atan(x)          ⎟</p>
<p>⎜⎮ ─────── dx, False⎟</p>
<p>⎜⎮    x             ⎟</p>
<p>⎝⌡                  ⎠</p>
<p>[/code]</p>
<p>Due to a bug in the code right now, the final version returns the non-elementary integral in the final result.  Suffice it to say that it has proven that $latex \int {\frac{\arctan{(x)}}{x} dx}$ is non-elementary. As far as I know, this isn't any special function.  Actually, it's just a random function containing arctan that looked non-elementary to me that I plugged in and found out that I was correct.  It's very similar in form to the <a href="http://en.wikipedia.org/wiki/Exponential_integral">exponential integral</a> (Ei) or the <a href="http://en.wikipedia.org/wiki/Sine_integral#Sine_integral">Sine/Cosine Integral</a> (Si/Ci), which is how I guessed that it would be non-elementary.  Maybe it should be called ATi().</p>
<p><strong>Status Update</strong></p>
<p>So it has come to my attention that the suggested "pencils down" date is one week from Monday, and the hard "pencils down" date is two weeks from Monday (see the <a href="http://socghop.appspot.com/document/show/gsoc_program/google/gsoc2010/timeline">Google Summer of Code Timeline</a>).  Now, no matter how fast I work, my work cannot be pushed in until Mateusz's latest polys branch gets pushed in, because my work is based on top of it.  I plan on continuing work on the integration algorithm beyond the summer until I finish the transcendental part of the algorithm, and even after that, I want to look into implementing other integration related things, like definite integration using <a href="http://en.wikipedia.org/wiki/Meijer-G">Meijer G-functions,</a> and the algebraic part of the algorithm.  But for now, these are the things that I need to do for the transcendental part, which is this summer's work:</p>
<p><em>1. Implement the preparsing algorithms. </em> This part is two-fold.  First, I need to implement algorithms based on the Risch Structure Theorems, which allow me to determine if an extension is algebraic or not (if it is algebraic, we cannot integrate it because only the transcendental part is implemented).  The other part will be the function that actually goes through an expression and tries to build up a differential extension from it so it can be integrated.  This can be a tricky part. For example, if we want to integrate $latex f = e^x + e^{\frac{x}{2}}$, we want to first choose $latex t_1=e^{\frac{x}{2}}$ so that $latex f = t_1^2 + t_1$, because if we choose $latex t_1=e^x$, then $latex t_2=e^{\frac{x}{2}}=\sqrt{t_1}$ will be algebraic over $latex \mathbb{Q}(x, t_1)$.  This is one case where we might try adding an algebraic extensions but where it can be avoided.  The solution will have to be to go through and find the common denominators of the exponentials.  I'm also considering that this might happen in more advanced ways, so it could be necessary for the function to backtrack in the extension tree to see if it can do it in an entirely transcendental way.  Fortunately, the Risch Structure Theorems give us a decision procedure for determining if an extension can be written in terms of the previous extensions (is algebraic over it), but this will still be a very hard function to get right.</p>
<p><em>2. Finish the remaining cases for <code>integrate_hyperexponential()</code> and <code>integrate_primitive()</code>.</em> As you could see in this post, as well as in the <a href="http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/">previous one</a>, there are many integrals that cannot yet be integrated because the special cases for them have not been implemented yet.  Most of these actually rely on implementing the structure theorem algorithms from <strong>1</strong>, and implementing them once that is finished will not take long, because they will just be straight copying of the pseudocode from Bronstein's book.  But some of them, particularly ones from the primitive case, are not spelt out so well in Bronstein's book, and will require more thinking (and thus time) on my part.  I should note that the Structure Theorem algorithms are also this way.</p>
<p><em> 3. Implement the hypertangent case. </em> The ability to integrate in tangent extensions is the other <em>third</em> I mentioned above.  Since tangents require more special casing, I plan on doing this only after I have finished <strong>1</strong> and <strong>2</strong>.  This is actually not much work, because most of the algorithms for solving the particular subproblem for tangents (called the <em>Coupled Risch Differential Equation</em>) are exactly the same as those for solving the subproblem for hyperexponentials (the <em>Risch Differential Equation</em>), which are already (mostly) implemented in the hyperexponential part.  There are only a few extra functions that need to be written for it.  Also, you will still be able to integrate functions that contain tangents, such as $latex e^{\tan{(x)}}$ (recall <a href="http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/">last time</a> that we showed that <code>integrate_hyperexponential()</code> can prove that this does not have an elementary integral).  It just won't be able to integrate when the top-most extension is a tangent.</p>
<p>So here is what I plan on doing.  Right now, I am going to focus my work on <strong>1</strong>, since most of <strong>2</strong> can't be done until it is anyway.  But more importantly, I want to have a prototype user-level function for the Risch Algorithm.  The reason I want this is so that people can try it out, without having to do the preparsing like I did above, but rather they can just call <code>risch_integrate(f, x)</code>, and it will return the integral of <code>f</code>, prove that it is non-elementary and reduce it into the elementary and non-elementary parts, or explain why it cannot do it (either because the function is not transcendental or because something is not implemented yet).  My chief desire for doing this is so that people can try out my code and find the bugs in it for me.  I have already found many critical errors in the code (returns a wrong result), and I want to iron these out before anything goes in.  The best way to do this will be to release a working user-level function and hope that people try it out for me.  </p>
<p>Also, even if <strong>2</strong> and <strong>3</strong> are not finished, if I have <strong>1</strong>, I can integrate it with <code>integrate()</code> (no pun intended) and just have it bail if it raises <code>NotImplementedError</code> I will need to come up with a way to differentiate between this and the case where it returns an unevaluated <code>Integral</code> because it has proven that an elementary antiderivative does not exist.  Any suggestions?</p>
<p>I plan on continuing work after the summer until I finish <strong>1</strong> through <strong>3</strong>, though I won't pretend that my work won't slow down considerably when I start classes in August.  I also promise to finish the <a href="http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/">Risch Algorithm posts</a> that I promised.</p>
<p>And for what it's worth, I plan on working my ass off this next two weeks.</p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/07/24/the-risch-algorithm-part-2-elementary-functions.html" class="u-url">The Risch Algorithm: Part 2, Elementary Functions</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/07/24/the-risch-algorithm-part-2-elementary-functions.html" rel="bookmark"><time class="published dt-published" datetime="2010-07-24T03:32:57+00:00" itemprop="datePublished" title="Publication date">2010-07-24 03:32</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/07/24/the-risch-algorithm-part-2-elementary-functions.html#disqus_thread" data-disqus-identifier="cache/posts/2010/07/24/the-risch-algorithm-part-2-elementary-functions.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>In <a href="http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/">Part 1</a> of this series of blog posts, I gave what I believed to be the prerequisites to understanding the mathematics behind the Risch Algorithm (aside from a basic understanding of derivatives and integrals from calculus).  In this post, I will elaborate on what is meant by "elementary function," a term that is thrown around a lot when talking about Risch integration.</p>
<p>The usual definition of elementary function given in calculus is any function that is a constant, a polynomial, an exponential ($latex e^x$, $latex 2^x$), a logarithm ($latex \ln({x})$, $latex \log_{10}({x})$), one of the standard trig functions or their inverses (sin, cos, tan, arcsin, arccos, arctan, etc.), and any combination of these functions via addition, subtraction, multiplication, division, taking powers, and composition.  Thus, even a function as crazy as <a href="2010/07/crazy-function.png"><img src="2010/07/crazy-function.png" alt="" title="crazy function" width="193" height="41" class="alignnone size-full wp-image-632"></a> is elementary, by this definition.  </p>
<p>But for the rigorous definition of an elementary function, we must take into consideration what field we are working over.  Before I get into that, I need some definitions.  Suppose that $latex k$ is the field we are working over.  You can imagine that $latex k=\mathbb{Q}(x)$, the field of rational functions in x with rational number coefficients.  As with the previous post, imagine $latex t$ as a function, for example, $latex t = f(x)$.  Let $latex K$ be a differential extension of $latex k$.  We have not defined this, but it basically means that our derivation $latex D$ works the same in $latex K$ as it does in $latex k$.  You can imagine here that $latex K=k[t]$.  </p>
<p>We say that $latex t \in K$ is a <strong>primitive</strong> over $latex k$ if $latex Dt \in k$.  In other words, the derivative of $latex t$ is does not contain $latex t$, only elements of $latex k$.  Obviously, by the definition of a derivation (see the <a href="http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/">last post</a> in the series), any element of $latex k$ is a primitive over $latex K$, because the derivative of any element of a field is again an element of that field (you can see this by the definition of a derivation, also given in the last post).  But also if $latex t=log(a)$ for some $latex a \in k$, then $latex t$ is a primitive over $latex k$, because $latex Dt=\frac{Da}{a}\in k$.  </p>
<p>We say that $latex t \in K^*$ is a <strong>hyperexponential</strong> over $latex k$ if $latex \frac{Dt}{t}\in k$.  Written another way, $latex Dt=at$ for some $latex a\in k$.  We know from calculus that the functions that satisfy differential equations of the type $latex \frac{dy}{dx}=ay$ are exactly the exponential functions, i.e., $latex y=e^{\int{a\ dx}}$.  </p>
<p>The last class of functions that needs to be considered is <strong><a href="http://en.wikipedia.org/wiki/Algebraic_function">algebraic functions</a></strong>.  I will not go into depth on algebraic functions, because my work this summer is only on integrating purely transcendental functions.  Therefore, the only concern we shall have with algebraic functions in relation to the integration algorithm is to make sure that whatever function we are integrating is <em>not</em> algebraic, because the transcendental algorithms will not be valid if they are.  Hopefully in a future post I will be able to discuss the Risch Structure Theorems, which give necessary and sufficient conditions for determing if a Liouvillian function (see next paragraph) is algebraic.  </p>
<p>Now, we say that a function $latex t \in K$ is <strong>Liouvillian</strong> over $latex k$ if $latex t$ is algebraic, a primitive, or a hyperexponential over $latex k$.  For $latex t\in K$ to be a <strong>Liouvillian monomial</strong> over $latex k$, we have the additional condition that $latex \mathrm{Const}(k) = \mathrm{Const}(k(t))$. This just means that we cannot consider something like $latex \log({2})$ over $latex \mathbb{Q}$ as a Liouvillian monomial.  Otherwise (I believe) we could run into undecidability problems.  </p>
<p>We call $latex t \in K$ a <strong>logarithm</strong> over $latex k$ if $latex Dt=\frac{Db}{b}$ for some $latex b \in k^<em>$, i.e., $latex t=\log({b})$.  We call $latex t \in K^</em>$ an <strong>exponential</strong> over $latex k$ if $latex \frac{Dt}{t}=Db$ (or $latex Dt=tDb$) for some $latex b \in k$, i.e., $latex t=e^b$.  Note the difference between an <em>exponential</em> monomial and a <em>hyperexponential</em> monomial.  </p>
<p>We can finally give the rigorous definition of an elementary extension.  $latex K$ is an <strong>elementary extension</strong> of $latex k$ if there are $latex t_1, \dots, t_n \in K$ such that $latex K=k(t_1,\dots,t_n)$ and $latex t_i$ is elementary over $latex k(t_1, \dots, t_{i-1})$ for all $latex i \in {1,\dots,n}$.  An <strong>elementary function </strong> is any element of an elementary extension of $latex \mathbb{C}(x)$ with the derivation $latex D=\frac{d}{dx}$.  A function $latex f\in k$ has an <strong>elementary integral</strong> over $latex k$ if there exists an elementary extension $latex K$ of $latex k$ and $latex g\in K$ such that $latex Dg=f$, i.e., $latex f=\int{g}$.  </p>
<p>Usually, we start with $latex \mathbb{Q}(x)$, the field of rational functions in x with rational number coefficients. We then build up an elementary extension one function at a time, with each function either being a logarithm or exponential of what we have already built up, or algebraic over it.  As I noted above, we will ignore algebraic functions here.  We generally start with $latex \mathbb{Q}$ because it is computable (important problems such as the zero equivalence problem or the problem of determining certain field isomorphisms are decidable), but the above definition lets us start with any subfield of $latex \mathbb{C}$.  </p>
<p>Now you may be wondering: we've covered algebraic functions, exponentials and logarithms, and obviously rational functions are elements of $latex \mathbb{Q}(x)$, but what about trigonometric functions?  Well, from a theoretical stand point, we can make our lives easier by noticing that all the common trigonometric functions can be represented as exponentials and logarithms over $latex \mathbb{Q}(i)$.  For example, $latex \cos{x} = \frac{e^{ix} + e^{-ix}}{2}$.  You can see <a href="http://en.wikipedia.org/wiki/Trig_identities#Exponential_definitions">here</a> that all the common trig functions can be represented as complex exponentials or logarithms like this.  However, from an algorithmic standpoint, we don't want do convert all trig expressions into complex exponentials and logarithms in order to integrate them.  For one thing, our final result will be in terms of complex exponentials and logarithms, not the original functions we started with, and converting them back may or may not be an easy thing to do.  Also, aside from the fact that we have different functions than we were expecting, we also will end up with an answer containing $latex \sqrt{-1}$, even if our original integrand did not.  </p>
<p>Fortunately, the integrating tangents directly is a solved problem, just like integrating algebraic, exponential, or logarithmic functions is solved.  We can't integrate functions like $latex \sin{x}$ or $latex \cos{x}$ directly as monomials like we can with $latex \tan{x}$ or $latex e^x$, because the derivatives of sin and cos are not polynomials in their respective selves with coefficients in $latex \mathbb{C}(x)$.  However, we can use a trick or two to integrate them.  One way is to rewrite $latex \cos{x}=\frac{1 - \tan^2{\frac{x}{2}}}{1 + \tan^2{\frac{x}{2}}}$ and proceed to integrate it as a tangent.  Another alternative is to write $latex \cos{x}=\frac{1}{\sec{x}}=\sqrt{\frac{1}{\sec^2{x}}}=\sqrt{\frac{1}{\tan^2{x} + 1}}$.  This function is algebraic over $latex \mathbb{Q}(x, \tan{(x)})$, but if we do not already have $latex \tan{x}$ in our differential extension, it is transcendental, and we can rewrite it as $latex e^{-\frac{\log{(1 + \tan^2{x})}}{2}}$ (this is used in Bronstein's text, so I believe what I just said is correct, though I haven't verified it with the structure theorems just yet).   These both work using the relevant identities for sin too.  Of course, there is still the problem of rewriting the final integrand back in terms of sin or cos.  Otherwise, you will get something like $latex \frac{2e^x\tan({\frac{x}{2}}) - \tan^2({\frac{x}{2}})e^x + e^x}{2 + 2\tan^2({\frac{x}{2}})}$ instead of $latex \frac{e^x(\sin{(x)} + \cos{(x)})}{2}$ for $latex \int{\cos{(x)}e^xdx}$.  Bronstein doesn't elaborate on this too much in his book, so it is something that I will have to figure out on my own.</p>
<p>The second option I gave above leads nicely into the main point I wanted to make here about elementary functions.  Notice that everywhere in the definitions above, things depend on the field we are working in.  Therefore, $latex e^{\tan{x}}$ cannot be an elementary extension over $latex \mathbb{Q}(x)$, but it can be over $latex \mathbb{Q}(x, \tan{x})$.  Also, the <a href="http://en.wikipedia.org/wiki/Error_function">error function</a>, defined as $latex \mathrm{erf}{(x)} = \frac{2}{\sqrt{\pi}}\int{e^{-x^2}dx}$ cannot be an elementary extension over $latex \mathbb{Q}(x)$, but it can over $latex \mathbb{Q}(x, e^{-x^2})$. In fact this is how we can integrate in terms of some special functions, including the error function: by manually adding $latex e^{-x^2}$ (or whatever) to our differential extension.   Therefore, the usual definition of an elementary anti-derivaitve and the above Risch Algorithm definition of an elementary integral coincide only when the extension consists only of elementary functions of the form of the usual definition (note that above, our final fields are $latex \mathbb{Q}(x, \tan{x}, e^{\tan{x}})$ and $latex \mathbb{Q}(x, e^{-x^2}, \mathrm{erf}{(x)})$, respectively).  </p>
<p>Originally, I was also going to talk about Liouville's Theorem in this blog post, but I think it has already gotten long enough (read "I'm getting tired"), so I'll put that off until next time.  </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/07/17/a-hard-week.html" class="u-url">A hard week</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/07/17/a-hard-week.html" rel="bookmark"><time class="published dt-published" datetime="2010-07-17T04:38:22+00:00" itemprop="datePublished" title="Publication date">2010-07-17 04:38</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/07/17/a-hard-week.html#disqus_thread" data-disqus-identifier="cache/posts/2010/07/17/a-hard-week.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>After last week's <a href="http://asmeurersympy.wordpress.com/2010/07/12/integration-of-exponential-functions/">breakthrough</a>, work this week has been very slow.  I started working on the Parametric Risch Differential Equation Problem, which is almost identical to the Risch Differential Equation Problem in how it is solved, except there are a few extra steps.  Unfortunately, because it is so similar, Bronstein breezes through the description.  This is fine for the parts that are the same, but he is a little unclear on how some of the new parts fit in.  Also, his pseudocode has a line more or less saying </p>
<p>[code]</p>
<p>if r1 = … = rn = 0 then
    N = -1
else
    N = max(deg(r1), …, deg(rn))</p>
<p>for i from 0 to N
    for j from 1 to m
        Mij = coefficient(rj, t^i)</p>
<p>[/code]</p>
<p>where M is a matrix.  It is not very clear what this is supposed to mean in the case where N = -1.  Obviously, you can't have a a matrix with negative dimensions.  Clearly, this means that this particular function doesn't apply somehow in this case, but I am not really even sure where it fits in to the whole algorithm at this point in reading.  After reading a few more pages in, it gives a few hints here and there on how it is to be used, but never is it explicitly shown, in pseudocode or otherwise.  So for now, I think my best bet is to read ahead and get a fuller understanding of the complete function before I try implementing anything (this is what I had been doing before, but I caught up to myself).  </p>
<p>Also, on an unrelated note, I just found out today that I passed my <a href="http://socghop.appspot.com/document/show/gsoc_program/google/gsoc2010/faqs#evaluations">Google Summer of Code midterm evaluation</a>.  This means that I will receive half of my stipend for the program (the other half comes after passing the final evaluation at the end of the summer), and that I can continue working on my project in the program.  </p>
<p>EDIT:</p>
<p>Later in the text, it runs through an example and says "… $latex dc = -1$, hence M and A are 0 by 0 matrices."  So obviously, that is what was meant.  </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/07/12/integration-of-exponential-functions.html" class="u-url">Integration of exponential functions</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/07/12/integration-of-exponential-functions.html" rel="bookmark"><time class="published dt-published" datetime="2010-07-12T06:22:06+00:00" itemprop="datePublished" title="Publication date">2010-07-12 06:22</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/07/12/integration-of-exponential-functions.html#disqus_thread" data-disqus-identifier="cache/posts/2010/07/12/integration-of-exponential-functions.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>So for the first time this summer, I missed my blogging deadline.  I have been on vacation for the past few weeks, and have spent a good bit of the last week in the car, driving home. But that's not my excuse.  I was on vacation the week before, when I wrote up my <a href="http://asmeurersympy.wordpress.com/2010/06/30/the-risch-algorithm-part-1/">lengthy blog post on the Risch Algorithm</a>.  My excuse is that I wanted to finish up my <code>integrate_hyperexponential()</code> function before I posted, so I could write about it.  Well, I finished it on Thursday (today is Sunday, the post was due Friday), but I ran into unexpected bugs (imagine that) that has postponed it actually working until now. I also ended up doing API changes 3 different times (they are basically incrementally all one change, from supporting only one extension to properly supporting multiple extensions.  Look for long commits in my recent commit history in my branch if you are interested).  </p>
<p>So here is the function.  It integrates exponential functions.  You still have to manually create the differential extension, as before.  Here are some examples.  You can try them in my <a href="http://github.com/asmeurer/sympy/tree/integration2">integration2</a> branch (I have rebased over Mateusz's latest polys9update.  The latest branch is always integration<code>n</code>, where <code>n</code> is the largest integer available).  </p>
<p><strong>Hover over the code and click on the left-most, "view source" icon (a paper icon with <tt>&lt; &gt;</tt> over it) to view without breaks.  Opens in a new window.</strong></p>
<p>[code language="py"]</p>
<p>In [1]: from sympy.integrals.risch import *</p>
<p>In [2]: var('t1, t')</p>
<p>Out[2]: (t₁, t)</p>
<p>In [3]: r = exp(2<em>tan(x))</em>tan(x) + tan(x) + exp(tan(x))</p>
<p>In [4]: r</p>
<p>Out[4]: 
 2⋅tan(x)                    tan(x)
ℯ        ⋅tan(x) + tan(x) + ℯ      </p>
<p>In [5]: rd = r.diff(x)</p>
<p>In [6]: rd</p>
<p>Out[6]: 
    ⎛         2   ⎞  2⋅tan(x)             2      ⎛       2   ⎞  2⋅tan(x)   ⎛       2   ⎞  tan(x)
1 + ⎝2 + 2⋅tan (x)⎠⋅ℯ        ⋅tan(x) + tan (x) + ⎝1 + tan (x)⎠⋅ℯ         + ⎝1 + tan (x)⎠⋅ℯ      </p>
<p>In [7]: a, d = map(lambda i: Poly(i, t), rd.subs(tan(x), t1).subs(exp(t1), t).as_numer_denom()) # Manually create the extension</p>
<p>In [8]: a</p>
<p>Out[8]: Poly((1 + 2<em>t1 + t1<strong>2 + 2*t1</strong>3)</em>t<strong>2 + (1 + t1</strong>2)<em>t + 1 + t1</em>*2, t, domain='ZZ[t1]')</p>
<p>In [9]: d</p>
<p>Out[9]: Poly(1, t, domain='ZZ')</p>
<p>In [10]: integrate_hyperexponential(a, d, [Poly(1, x), Poly(1 + t1<strong>2, t1), Poly((1 + t1</strong>2)*t, t)], [x, t1, t], [lambda x: exp(tan(x)), tan])</p>
<p>Out[10]: </p>
<p>⎛                   ⌠                                 ⎞</p>
<p>⎜ 2⋅tan(x)          ⎮ ⎛       2   ⎞       tan(x)      ⎟</p>
<p>⎜ℯ        ⋅tan(x) + ⎮ ⎝1 + tan (x)⎠ dx + ℯ      , True⎟</p>
<p>⎝                   ⌡                                 ⎠</p>
<p>[/code]</p>
<p>We have to manually build up the differential extension (<code>[7]</code>).  The first element is $latex x$, which is already there.  Next, we add $latex t_1 = \tan{x}$, and finally $latex t = e^{\tan{x}} = e^{t_1}$.  The third argument of <code>integrate_hyperexponential()</code> is what gives these variables their identities: their derivatives.  The fourth argument is the list of the extension symbols, and the last argument is a list of the functions for which the symbols stand for, in reverse order (because we have to back substitute in the solution in reverse order).  </p>
<p>The unevaluated Integral in the solution is due to the recursive nature of the Risch algorithm.  Eventually, an outer function in the algorithm will recursively integrate until it reaches the ground field, $latex \mathbb{Q}$.  It will also do the proper preparsing automatically as well.  The second element of the solution, <code>True</code>, indicates that the integral is elementary, and thus the given solution is the complete integral of the original integrand, which we can see ($latex \int (1 + \tan^2{x})dx=\tan{x}$).  </p>
<p>Another example:</p>
<p>[code language="py"]</p>
<p>In [1]: from sympy.integrals.risch import *</p>
<p>In [2]: var('t')</p>
<p>Out[2]: (t,)</p>
<p>In [3]: rd = exp(-x**2)</p>
<p>In [4]: rd</p>
<p>Out[4]: 
   2
 -x 
ℯ   </p>
<p>In [5]: a, d = map(lambda i: Poly(i, t), rd.subs(exp(x**2), t).as_numer_denom())</p>
<p>In [6]: a</p>
<p>Out[6]: Poly(1, t, domain='ZZ')</p>
<p>In [7]: d</p>
<p>Out[7]: Poly(t, t, domain='ZZ')</p>
<p>In [8]: integrate_hyperexponential(a, d, [Poly(1, x), Poly(2<em>x</em>t, t)], [x, t], [lambda x: exp(x**2)])</p>
<p>Out[8]: (0, False)</p>
<p>[/code]</p>
<p>Here the second argument of the solution is <code>False</code>, which indicates that the algorithm has proven that the integral of $latex e^{-x^2}$ is not elementary!   The first argument 0 indicates that actually it is the integral of $latex e^{-x^2} - \frac{d}{dx}(0)$ that is not elementary, i.e., the Risch algorithm will reduce an integrand into an integrated function part and non-elementary part.  For example:</p>
<p>[code language="py"]</p>
<p>In [1]: from sympy.integrals.risch import *</p>
<p>In [2]: var('t1, t')</p>
<p>Out[2]: (t₁, t)</p>
<p>In [3]: rd = exp(x)/tan(x) + exp(x)/(1 + exp(x))</p>
<p>In [4]: rd</p>
<p>Out[4]: 
   x        x<br>
  ℯ        ℯ <br>
────── + ──────
     x   tan(x)
1 + ℯ          </p>
<p>In [5]: a, d = map(lambda i: Poly(i, t), rd.subs(exp(x), t).subs(tan(x), t1).as_numer_denom())</p>
<p>In [6]: a</p>
<p>Out[6]: Poly(t*<em>2 + (1 + t1)</em>t, t, domain='ZZ[t1]')</p>
<p>In [7]: d</p>
<p>Out[7]: Poly(t1*t + t1, t, domain='ZZ[t1]')</p>
<p>In [8]: integrate_hyperexponential(a, d, [Poly(1, x), Poly(1 + t1**2, t1), Poly(t, t)], [x, t1, t], [exp, tan])</p>
<p>Out[8]: </p>
<p>⎛   ⎛     x⎞       ⎞</p>
<p>⎝log⎝1 + ℯ ⎠, False⎠</p>
<p>[/code]</p>
<p>This indicates that the integral of $latex (\frac{e^x}{\tan{x}} + \frac{e^x}{1 + e^x}) - \frac{d}{dx}(\log{(1 + e^x)}) = \frac{e^x}{\tan{x}}$ is not elementary.  That is one advantage that the new algorithm will have over the present one.  Currently, the present algorithm just returns an unevaluated Integral for the above <code>rd</code>, but the new one will be able to return $latex \log{(1 + e^x)} + \int{\frac{e^x}{\tan{x}}dx}$.  It will be able to do this even if rd were rewritten as $latex \frac{e^x \tan{x} + e^x + e^{2x}}{e^x \tan{x} + \tan{x}}$ (notice that this is exactly what <code>.as_numer_denom()</code> is doing anyway in <code>[5]</code>, as you can see in <code>[6]</code> and <code>[7]</code>).  Furthermore, it will have actually <em>proven</em> that the remaining $latex \int{\frac{e^x}{\tan{x}}dx}$ is non-elementary.  I plan on having some kind of marker in the pretty printed unevaluated <code>Integral</code> to indicate this.  Suggestions on what this should be are welcome.  </p>
<p>Finally, the full algorithm appears to be faster (probably asymptotically faster) than the current implementation:</p>
<p>[code language="py"]</p>
<p>In [1]: from sympy.integrals.risch import *</p>
<p>In [2]: var('t1, t')</p>
<p>Out[2]: (t₁, t)</p>
<p>In [3]: rd = exp(x)<em>x</em>*4</p>
<p>In [4]: a, d = map(lambda i: Poly(i, t), rd.subs(exp(x), t).as_numer_denom())</p>
<p>In [5]: integrate_hyperexponential(a, d, [Poly(1, x), Poly(t, t)], [x, t], [lambda x: exp(x)])</p>
<p>Out[5]: </p>
<p>⎛    x    4  x         x      3  x       2  x      ⎞</p>
<p>⎝24⋅ℯ  + x ⋅ℯ  - 24⋅x⋅ℯ  - 4⋅x ⋅ℯ  + 12⋅x ⋅ℯ , True⎠</p>
<p>In [6]: %timeit integrate_hyperexponential(a, d, [Poly(1, x), Poly(t, t)], [x, t], [exp])</p>
<p>10 loops, best of 3: 28 ms per loop</p>
<p>In [7]: integrate(rd, x)</p>
<p>Out[7]: 
    x    4  x         x      3  x       2  x
24⋅ℯ  + x ⋅ℯ  - 24⋅x⋅ℯ  - 4⋅x ⋅ℯ  + 12⋅x ⋅ℯ </p>
<p>In [8]: %timeit integrate(rd, x)</p>
<p>1 loops, best of 3: 218 ms per loop</p>
<p>[/code]</p>
<p>Of course, keep in mind that I am timing what will be an internal function against a full function.  But if you increase the exponent on x, you find that there is no way the addition of preparsing time (which shouldn't be affected by such a change) will cause it to become as slow as the current <code>integrate()</code>.  Like I said, I am pretty sure that it is asymptotic.  For example:</p>
<p>[code language="py"]</p>
<p>In [1]: from sympy.integrals.risch import *</p>
<p>In [2]: var('t1, t')</p>
<p>Out[2]: (t₁, t)</p>
<p>In [3]: rd = exp(x)<em>x</em>*10</p>
<p>In [4]: a, d = map(lambda i: Poly(i, t), rd.subs(exp(x), t).as_numer_denom())</p>
<p>In [5]: integrate_hyperexponential(a, d, [Poly(1, x), Poly(t, t)], [x, t], [lambda x: exp(x)])</p>
<p>Out[5]: </p>
<p>⎛         x    10  x              x           3  x          5  x        7  x       9  x       8  x         6  x           4  x            2  x      ⎞</p>
<p>⎝3628800⋅ℯ  + x  ⋅ℯ  - 3628800⋅x⋅ℯ  - 604800⋅x ⋅ℯ  - 30240⋅x ⋅ℯ  - 720⋅x ⋅ℯ  - 10⋅x ⋅ℯ  + 90⋅x ⋅ℯ  + 5040⋅x ⋅ℯ  + 151200⋅x ⋅ℯ  + 1814400⋅x ⋅ℯ , True⎠</p>
<p>In [6]: %timeit integrate_hyperexponential(a, d, [Poly(1, x), Poly(t, t)], [x, t], [exp])</p>
<p>10 loops, best of 3: 42 ms per loop</p>
<p>In [7]: integrate(rd, x)</p>
<p>Out[7]: 
         x    10  x              x           3  x          5  x        7  x       9  x       8  x         6  x           4  x            2  x
3628800⋅ℯ  + x  ⋅ℯ  - 3628800⋅x⋅ℯ  - 604800⋅x ⋅ℯ  - 30240⋅x ⋅ℯ  - 720⋅x ⋅ℯ  - 10⋅x ⋅ℯ  + 90⋅x ⋅ℯ  + 5040⋅x ⋅ℯ  + 151200⋅x ⋅ℯ  + 1814400⋅x ⋅ℯ </p>
<p>In [8]: %timeit integrate(rd, x)</p>
<p>1 loops, best of 3: 2.78 s per loop</p>
<p>[/code]</p>
<p>There is one thing I should mention.  I haven't implemented all the cases in <code>rischDE()</code>, which is the subproblem for exponential functions (more on this in a future "The Risch Algorithm" post).  So some integrals will fail with a <code>NotImplementedError</code>, indicating that there is a function that I still need to implement to solve the integral:</p>
<p>[code language="py"]</p>
<p>In [1]: from sympy.integrals.risch import *</p>
<p>In [2]: var('t1, t')</p>
<p>Out[2]: (t₁, t)</p>
<p>In [3]: rd = (exp(x) - x<em>exp(2</em>x)*tan(x))/tan(x)</p>
<p>In [4]: a, d = map(lambda i: Poly(i, t), rd.subs(exp(x), t).subs(tan(x), t1).as_numer_denom())</p>
<p>In [5]: a</p>
<p>Out[5]: Poly(-t1<em>x</em>t**2 + t, t, domain='ZZ[x,t1]')</p>
<p>In [6]: d</p>
<p>Out[6]: Poly(t1, t, domain='ZZ[t1]')</p>
<p>In [7]: integrate_hyperexponential(a, d, [Poly(1, x), Poly(1 + t1**2, t1), Poly(t, t)], [x, t1, t], [exp, tan])</p>
<hr>
<p>...</p>
<p>NotImplementedError: The ability to solve the parametric logarithmic derivative problem is required to solve this RDE</p>
<p>[/code]</p>
<p>So feel free to give this a try and let me know what you think.  You will have to do the preparsing as I have done above, which means that you also have to be careful that any extension that you make is not the derivative or logarithmic derivative of an element of the field you have already built up.  You also cannot use algebraic functions, as I mentioned before, including things like $latex e^\frac{\log{x}}{2}$ (functions like these are called the logarithmic derivatives of k(t)-radicals, which I will also discuss in a future "The Risch Algorithm" post).  If you just use simple extensions like <code>t1 = tan(x);t=exp(x)</code> like I have above, you won't need to worry about this.  Each derivative Poly should be in the variable that it is the derivative of (e.g., start with <code>Poly(1, x)</code>, then add <code>Poly(1 + t1<strong>2, t1)</strong></code>, <code>Poly(t2*(1 + t12), t2)</code>, etc.).  Everything else should be a Poly in <code>t</code>, the last element of the extension.  And in cause you didn't get it, the last extension must be an exponential function.  </p>
<p>Also, I didn't have to do it in any of the above examples, but the first and second arguments to <code>integrate_hyperexponential()</code> <em>must</em> be canceled (<code>a, d = a.cancel(d, include=True)</code> will do this for you), or you will get a wrong result!  I spent a good day of debugging until I figured this out.  The existence of other bugs didn't help.</p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/06/30/the-risch-algorithm-part-1.html" class="u-url">The Risch Algorithm: Part 1</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/06/30/the-risch-algorithm-part-1.html" rel="bookmark"><time class="published dt-published" datetime="2010-06-30T03:43:00+00:00" itemprop="datePublished" title="Publication date">2010-06-30 03:43</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/06/30/the-risch-algorithm-part-1.html#disqus_thread" data-disqus-identifier="cache/posts/2010/06/30/the-risch-algorithm-part-1.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>My work this week isn't very interesting, even insomuch as my work any week is interesting, so this week I have elected to start a series of blog posts about the Risch Algorithm in general.  I will start out with the basics in this post.</p>
<p>Anyone who has taken Calculus knows a handful of heuristics to calculate integrals.  u-substitution, partial fractions, integration by parts, trigonometric substitution, and table integration are a few of the more popular ones.  These are general enough to work for most integrals that are encountered in problems in Physics, Engineering, and so on, as well as most of those generated by solving differential equations from the same fields.  But these fall short in a couple of ways.  First off, they are just heuristics.  If they fail, it does not mean that no integral exists.  This means that they are useless for proving that certain functions, such as $latex e^{-x^2}$ do not have integrals, no matter how hard you try to find them.  Second, they work for only relatively simple functions.  For example, suppose you have a rational function in $latex \log{x}$ and $latex x$.  An example would be $latex \frac{(\log{x})^2 + 2\log{x} + x^2 + 1}{x\log{x} + 2x^3}$.  We are not interested in integrating this function, but rather in finding it back given its derivative, $latex - \frac{1 + 7 x^{2} \log{x} + \log{x} + (\log{x})^2 + 3 x^{2} + 6 x^{2} (\log{x})^2 + (\log{x})^3 + 2 x^{4}}{4 x^{4} \log{x} + x^{2} (\log{x})^2 + 4 x^{6}}$.  The only method I named above that would come even close to being applicable to this integrand is partial fractions.  This requires multivariate partial fraction decomposition (with respect to $latex x$ and $latex \log{x}$), and gives $latex -{\frac {2\,{x}^{2}+1+\log{x} }{{x}^{2}}}+{\frac {-1+8\,{x}^{4}-16\,{x}^{6}-{x}^{2}}{ \left( \log{x} +2\,{x}^{2} \right) ^{2}{x}^{2}}}+{\frac {-3\,{x}^{2}+12\,{x}^{4}-1}{ \left( \log{x} +2\,{x}^{2} \right) {x}^{2}}}$, which brings us no closer to a solution. </p>
<p>The reason that I started with a function and then computed its derivative was to show how easy it is to come up with a very complicated function that has an elementary anti-derivative.  Therefore, we see that the methods from calculus are not the ones to use if we want an integration algorithm that is complete.  The Risch Integration Algorithm is based on a completely different approach.  At its core lies Liouville's Theorem, which gives us the form of any elementary anti-derivative.   (I wish to point out at this point that heuristics like this are still useful in a computer algebra system such as SymPy as fast preprocessors to the full integration algorithm).</p>
<p>The Risch Algorithm works by doing polynomial manipulations on the integrand, which is entirely deterministic (non-heuristic), and gives us the power of all the theorems of algebra, allowing us to actually prove that anti-derivatives cannot exist when they don't.  To start off, we have to look at derivations.  As I said, everything with the Risch Algorithm is looked at algebraically (as opposed to analytically).  The first thing to look at is the derivative itself.  We define a derivation as any function $latex D$ on a ring $latex R$ that satisfies two properties:</p>
<ol>
<li>
<p>$latex D(a + b) = Da + Db$ (Sum Rule),</p>
</li>
<li>
<p>$latex D(ab) = aDb + bDa$ (Product Rule)</p>
</li>
</ol>
<p>for any $latex a, b \in R$.  Furthermore, define the set of constant elements as $latex Const_D(R) = {a \in R\textrm{ such that }Da = 0}$.  From just these two rules, you can prove all the rules from calculus such as the power rule and the quotient rule.  Defining things algebraically lets us avoid analytic problems, such as discontinuities and the need to prove convergence all the time.  Another problem from analysis is the multivalue nature of certain functions, namely the natural logarithm.  We get around this by defining $latex \log{a}$ as the unique function satisfying $latex D\log{a} = \frac{Da}{a}$, for $latex a \neq 0$.   From this definition we can prove the famous logarithmic identities $latex \log{ab} = \log{a} + \log{b}$ and $latex \log{a^n} = n\log{a}$ for logarithmic derivatives, again using only the two rules for a derivation given above.  For example, $latex D\log{ab}=\frac{Dab}{ab}=\frac{aDb + bDa}{ab} = \frac{bDa}{ab} + \frac{aDb}{ab} = $$latex \frac{Da}{a} + \frac{Db}{b}=D\log{a} + D\log{b}=D(\log{a} + \log{b})$.  </p>
<p>The above definition for the natural logarithm gives the first insight into how the integration algorithm works.  We define transcendental functions in terms of their derivatives.  So if $latex t = e^x$, then $latex Dt/t = 1$.  We can define all of the trigonometric functions in terms of $latex e^x$ and $latex \log{x}$ if we use $latex \sqrt{-1}$, but we can also avoid this.  For example, if $latex t = \tan{x}$, then $latex Dt = 1 + t^2$ because $latex \frac{d}{dx}\tan{x} = \sec^2{x} = 1 + \tan^2{x}$.  </p>
<p>We say that $latex t\in K$ is a <em>monomial</em> over the field $latex k$ with respect to a derivation $latex D$ if it satisfies</p>
<ol>
<li>
<p>$latex t$ is transcendental over $latex k$,</p>
</li>
<li>
<p>$latex D[t]\in k[t]$.</p>
</li>
</ol>
<p>The first condition is necessary because the we are only going to deal with the trancenental version of the Risch Algorithm (the algebraic case is solved too, but the solution method is quite different, and I am not implementing it this summer).  The second condition just says that the derivative of t is a polynomial in t and a rational function in x.  The functions I mentioned above all satisfy these properties for $latex K = \mathbb{Q}$.  Theorems in analysis show that $latex \log{x}$, $latex e^x$, and $latex \tan{x}$ are all transcendental over $latex \mathbb{Q}[x]$.  This is actually the only use of analysis that we make in the integration algorithm.  Also, we see that if $latex t_1=\log{x}$, $latex t_2=e^x$, and $latex t_3=\tan{x}$, then $latex Dt_1=\frac{1}{x}$, $latex Dt_2=t_2$, and $latex Dt_3=1 + t_3^2$, which are all polynomials in their respective $latex t_i$ and rational functions in $latex x$.  In the algorithm, $latex K$ is actually a tower of monomial extensions of $latex \mathbb{Q}$, so $latex t_n$ is a monomial over $latex \mathbb{Q}(x, t_1, \dots, t_{n-1})$.   This allows us to work with functions like $latex e^{\tan{x}}$.  We can't make $latex t=e^{\tan{x}}$ directly because $latex \frac{d}{dx}e^{\tan{x}} = (1 + \tan^2{x})e^{\tan{x}}$ is not a polynomial in $latex t$ (it also contains $latex \tan{x}$) .  But if we let $latex t_1$ be such that $latex Dt_1=1 + t_1^2$, i.e., $latex t_1=\tan{x}$, then we can let $latex t_2$ be such that $latex Dt_2=(1 + t_1^2)t_2$, i.e., $latex t_2=e^{\tan{x}}$.  Remember that the $latex t_i$ are all "functions" of x, but there is no need to write $latex t=t(x)$ as long as we remember that $latex Dt\neq 0$, i.e., $latex t\not \in Const_D(K)$.  This is another advantage of using algebraic over analytic methods; it allows us to reduce an integral down to a rational function in the "symbols" $latex x$ and $latex t_1, t_2, \dots, t_n$.  By convention, we make the first extension $latex t_0$ such that $latex Dt_0=1$, i.e., $latex t_0=x$.  I will just call it $latex x$ here instead of $latex t_0$, to avoid confusion.  </p>
<p>This is the preparsing that I alluded to in an <a href="http://asmeurersympy.wordpress.com/2010/06/26/quick-update/">earlier post</a> that I have not implemented yet.  The reason that I haven't implemented it yet is not just because I haven't gotten around to it.  We have to be careful when we build up the extension that each element is indeed transcendental over the already built-up field $latex k$.  For example, although it appears transcendental, the function $latex e^{\frac{1}{2}\log{(1 + x^2)}}$ is really algebraic because it equals $latex \sqrt{1 + x^2}$.  There are additional requirements, such that each extension is not the derivative of logarithmic derivative of an element of $latex k$ (see also the example I gave in the previous post).  This is the part that I was talking about in my <a href="http://asmeurersympy.wordpress.com/2010/06/26/quick-update/">previous post</a> that is not written out as much as the other algorithms in Bronstein's book.  So this is algorithmically solved, just like the rest of the Algorithm, but it is non-trivial and may end up being the hardest part of the algorithm for me to implement, just because it will probably require the most figuring out on my part.  </p>
<p>So we can see that we can convert a transcendental integral, such as the one above, into a rational function in x and monomial extensions $latex t_1, t_2, \dots, t_n$.  For example, the above integrand would become $latex - \frac{1 + t + t^{2} + 3 x^{2} + 6 t^{2} x^{2} + 7 t x^{2} + t^{3} + 2 x^{4}}{t^{2} x^{2} + 4 t x^{4} + 4 x^{6}}$.  We then perform certain polynomial manipulations on this integrand, using the fact that $latex Dx=1$ and $latex Dt=\frac{1}{x}$.  For the transcendental case of the Risch Algorithm, this is similar to the rational function integration that I outlined in <a href="http://asmeurersympy.wordpress.com/2010/06/11/integration-of-rational-functions/">this post</a>, and has Liouville's Theorem at its core.  This is where I will start off next time.  </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/06/26/quick-update.html" class="u-url">Quick Update</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/06/26/quick-update.html" rel="bookmark"><time class="published dt-published" datetime="2010-06-26T03:16:52+00:00" itemprop="datePublished" title="Publication date">2010-06-26 03:16</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/06/26/quick-update.html#disqus_thread" data-disqus-identifier="cache/posts/2010/06/26/quick-update.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>I've spend most of this week sitting in a car, so while I have been able to do some work, I haven't had much time to write up a blog post.  So, to comply with <a href="http://groups.google.com/group/sympy/browse_thread/thread/7d7dceb34db45302">Ondrej's rule</a>, here is a quick update.</p>
<p>I have been working my way through Bronstein's book.  I finished the outer algorithmic layer of the implantation.  Basically, the algorithm does polynomials manipulation on the integrand.  It first reduces the integrand into smaller integrals, until it gets to an integral where a subproblem must be solved to solve it.  The subproblem that must be solved differs depending on the type of the integral.  The first one that comes up in Bronstein's text is the Risch Differential Equation, which arises from the integration of exponential functions.  (I will explain all of these thing in more detail in a future blog post).  At this point, the algorithms begin to recursively depend on each other, requiring me to implement more and more algorithms at a time in order for each to work.  To make things worse, a very fundamental set of algorithms are only described in the text, not given in pseudo-code, so I have had to figure those things out.   These are algorithms to determine if a differential extension is a derivative or logarithmic derivative of elements that have already been extended.  Again, I will explain better in a future post, but the idea is that you replace elements in an integrand with dummy variables, but each element has to be transcendental over the previous elements.  So if you have $latex \int (e^x + e^{x^2} + e^{x + x*^2})dx$, and you set $latex t_1 = e^x$ and $latex t_2 = e^{x^2}$ ($latex Dt_1 = t_1$ and $latex Dt_2 = 2xt_2$), then you cannot make $latex t_3 = e^{x + x^2}$ because $latex e^{x + x^2} = t_1t_2$.  The ability to determine if an element is a derivative or a logarithmic derivative of an element of the already build differential extension is important not only for building up the extension for the integrand (basically the preparsing), but also for solving some of the cases of the subproblems such as the Risch Differential Equation problem.</p>
<p>So I am still figuring out some of the details on that one.  The description in the book is pretty good (this is probably the best written math textbook I have ever seen), but I still have had to figure out some of the mathematical details on paper (which is something I enjoy anyway, but it can be more stressful).  Hopefully by the next time I can have some code that is working enough to actually demonstrate solving some complex integrals, (with manual preparsing), and even more excitingly, prove that some non-elementary integrals, such as the classic $latex \int e^{-x^2}dx$, are indeed so.   And I also hope to have some more explanations on how the Risch algorithm works in future posts.  </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/06/16/strange-python-behavior-can-someone-please-explain-to-me-what-is-going-on-here.html" class="u-url">Strange Python Behavior (can someone please explain to me what is going on here?)</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/06/16/strange-python-behavior-can-someone-please-explain-to-me-what-is-going-on-here.html" rel="bookmark"><time class="published dt-published" datetime="2010-06-16T04:49:06+00:00" itemprop="datePublished" title="Publication date">2010-06-16 04:49</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/06/16/strange-python-behavior-can-someone-please-explain-to-me-what-is-going-on-here.html#disqus_thread" data-disqus-identifier="cache/posts/2010/06/16/strange-python-behavior-can-someone-please-explain-to-me-what-is-going-on-here.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<a href="http://asmeurersympy.wordpress.com/2009/07/20/modifying-a-list-while-looping-through-it-in-python/">Every once in a while</a>, seemingly really simple Python code does something completely unexpected for me. Look at the following snippet of Python code.  This is run straight from the 2.6.5 interpreter, with no other commands executed.  Do you notice anything strange?
<p>[code language="py"]</p>
<p>$python</p>
<p>Python 2.6.5 (r265:79359, Mar 24 2010, 01:32:55) </p>
<p>[GCC 4.0.1 (Apple Inc. build 5493)] on darwin</p>
<p>Type "help", "copyright", "credits" or "license" for more information.</p>
<p>&gt;&gt;&gt;; l = lambda i: a[i]</p>
<p>&gt;&gt;&gt; l</p>
<p>&lt;function at="" 0x39e7f0=""&gt;</p>
<p>&gt;&gt;&gt; H = [(1, 2), (3, 4)]</p>
<p>&gt;&gt;&gt; [l(0) + l(1) for a in H]</p>
<p>[3, 7]</p>
<p>[/code]</p>
<p>Did you spot it?  Here is a hint. Running a different but similar session:</p>
<p>[code language="py"]</p>
<p>$python</p>
<p>Python 2.6.5 (r265:79359, Mar 24 2010, 01:32:55) </p>
<p>[GCC 4.0.1 (Apple Inc. build 5493)] on darwin</p>
<p>Type "help", "copyright", "credits" or "license" for more information.</p>
<p>&gt;&gt;&gt; l = lambda i: a[i]</p>
<p>&gt;&gt;&gt; l</p>
<p>&lt;function at="" 0x39e7f0=""&gt;</p>
<p>&gt;&gt;&gt; l(0)</p>
<p>Traceback (most recent call last):
  File "", line 1, in 
  File "", line 1, in 
NameError: global name 'a' is not defined</p>
<p>[/code]</p>
<p>Do you see it now?  I defined the lambda function <code>l</code> in terms of <code>a</code> without defining first defining <code>a</code>!  And furthermore, it just works when <code>a</code> is defined.  This is actually independent of the fact that we are working in a list comprehension, as this continuation of the previous session shows:</p>
<p>[code language="py"]</p>
<p>&gt;&gt;&gt; a = [3, 4, 5]</p>
<p>&gt;&gt;&gt; l(0)</p>
<p>3</p>
<p>[/code]</p>
<p>But I want to expand on the list comprehension example, because there even more bizzare things going on here.  Restarting a new session again:</p>
<p>[code language="py"]</p>
<p>$python</p>
<p>Python 2.6.5 (r265:79359, Mar 24 2010, 01:32:55) </p>
<p>[GCC 4.0.1 (Apple Inc. build 5493)] on darwin</p>
<p>Type "help", "copyright", "credits" or "license" for more information.</p>
<p>&gt;&gt;&gt; l = lambda i: a[i]</p>
<p>&gt;&gt;&gt; H = [(1, 2), (3, 4)]</p>
<p>&gt;&gt;&gt; [l(0) + l(1) for a in H]</p>
<p>[3, 7]</p>
<p>&gt;&gt;&gt; (l(0) + l(1) for a in H)</p>
<p>&lt;generator object="" at="" 0x3a4350=""&gt;</p>
<p>&gt;&gt;&gt; list((l(0) + l(1) for a in H))</p>
<p>[7, 7]</p>
<p>[/code]</p>
<p>So, if you are astute and have been using Python for long enough, you should be able to catch what is going on here.  If you don't know, here is a hint (continuation of previous session):</p>
<p>[code language="py"]</p>
<p>&gt;&gt;&gt; a</p>
<p>(3, 4)</p>
<p>[/code]</p>
<p>So, as you may know, in Python 2.6 and earlier, list comprehension index variables "leek" into the local namespace.  The strange thing here is that although the list comprehension would reset it, the generator version does not.  Well, normally, it does do this:</p>
<p>[code language="py"]</p>
<p>&gt;&gt;&gt; x = 1</p>
<p>&gt;&gt;&gt; [x for x in range(10)]</p>
<p>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</p>
<p>&gt;&gt;&gt; x</p>
<p>9</p>
<p>&gt;&gt;&gt; del x</p>
<p>&gt;&gt;&gt; list((x for x in range(10)))</p>
<p>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</p>
<p>&gt;&gt;&gt; x</p>
<p>Traceback (most recent call last):
  File "", line 1, in 
NameError: name 'x' is not defined</p>
<p>&gt;&gt;&gt; x = 1</p>
<p>&gt;&gt;&gt; list((x for x in range(10)))</p>
<p>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</p>
<p>&gt;&gt;&gt; x</p>
<p>1</p>
<p>[/code]</p>
<p>So the above bit has something to do with the way the <code>lambda</code> function was defined with the <code>a</code>.  By the way, here is what happens with the generator comprehension (is that what these are called?) if <code>a</code> is not defined:</p>
<p>[code language="py"]</p>
<p>&gt;&gt;&gt; del a</p>
<p>&gt;&gt;&gt; list((l(0) + l(1) for a in H))</p>
<p>Traceback (most recent call last):
  File "", line 1, in 
  File "", line 1, in 
  File "", line 1, in 
NameError: global name 'a' is not defined</p>
<p>[/code]</p>
<p>This is how I discovered this.  I had defined a lambda function using an variable that was then passed to a list comprehension that used this variable as the index without realizing it. But then I tried converting this into a generator comprehension to see if it would be faster, and got the above error.  </p>
<p>Finally, since the "feature" of leaking list comprehension loop variables into the local namespace is <a href="http://docs.python.org/release/3.0.1/whatsnew/3.0.html#changed-syntax">going away</a> in Python 3, I expected things to behave at least a little differently in Python 3.  I tried the above in a Python 3.1.2 interpreter and got the following:</p>
<p>[code language="py"]</p>
<p>$python3</p>
<p>Python 3.1.2 (r312:79147, Mar 23 2010, 22:02:05) </p>
<p>[GCC 4.2.1 (Apple Inc. build 5646) (dot 1)] on darwin</p>
<p>Type "help", "copyright", "credits" or "license" for more information.</p>
<p>&gt;&gt;&gt; l = lambda i: a[i]</p>
<p>&gt;&gt;&gt; l</p>
<p>&lt;function at="" 0x100585a68=""&gt;</p>
<p>&gt;&gt;&gt; H = [(1, 2), (3, 4)]</p>
<p>&gt;&gt;&gt; [l(0) + l(1) for a in H]</p>
<p>Traceback (most recent call last):
  File "", line 1, in 
  File "", line 1, in 
  File "", line 1, in 
NameError: global name 'a' is not defined</p>
<p>&gt;&gt;&gt; list((l(0) + l(1) for a in H))</p>
<p>Traceback (most recent call last):
  File "", line 1, in 
  File "", line 1, in 
  File "", line 1, in 
NameError: global name 'a' is not defined</p>
<p>[/code]</p>
<p>So in Python 3, both the list comprehension and the generator comprehensions act the same, which is not too surprising.  I guess I should recode that piece of code to make it future proof, although this doesn't seem easy at the moment, and it may require converting a one-liner into a six-liner.  If you are interested, the piece of code is <a href="http://github.com/asmeurer/sympy/blob/15c3675ff67be854c12c349ed9034f12bb2f5247/sympy/integrals/risch.py#L297">here</a>.</p>
<p>So can anyone provide any insight into what is going on with that lambda function?  Running it with the <code>-3</code> switch to <code>python2.6</code> didn't give any warnings related to it.  </p>
<p><strong>Update:</strong> As I noted in a <a href="http://asmeurersympy.wordpress.com/2010/06/16/strange-python-behavior-can-someone-please-explain-to-me-what-is-going-on-here/#comment-121">comment</a>, I figured out how to make this future-proof.  I need to convert it from </p>
<p>[code language="py"]</p>
<p>def residue_reduce_derivation(H, D, x, t, z):
    lambdafunc = lambda i: i*derivation(a[1], D, x, t).as_basic().subs(z, i)/ \
         a[1].as_basic().subs(z, i)
    return S(sum([RootSum(a[0].as_poly(z), lambdafunc) for a in H]))
[/code]</p>
<p>to</p>
<p>[code language="py"]</p>
<p>def residue_reduce_derivation(H, D, x, t, z):
    return S(sum((RootSum(a[0].as_poly(z), lambda i: i*derivation(a[1], D, x, t).as_basic().subs(z, i)/ \
        a[1].as_basic().subs(z, i)) for a in H)))
[/code]</p>
<p>Thanks to all the commenters for the explanations.  </p>
<p>Also, you may have noticed that I discovered that if you use <tt>[code]</tt> instead of <tt>&lt;code&gt;</tt>, you get these nicer code blocks that <em>actually respect indentation!</em>  Now I just need to figure out how to make them syntax highlight Python code.</p>
<p><strong>Update 2:</strong> <tt>[code='py']</tt> colors it!  Sweet!</p>
<p><strong>Update 3:</strong> I just discovered that SymPy has a <code>Lambda()</code> object that handles this better.  In particular, it pretty prints the code, and is what is already being used for <code>RootSum()</code> in the rational function integrator, at least in Mateusz's polys9.  </p>
<p>[code language="py"]</p>
<p>&gt;&gt;&gt; integrate(1/(x**5 + 1), x)</p>
<p>log(1 + x)/5 + RootSum(625<em>_t<strong>4 + 125*_t</strong>3 + 25</em>_t<em><em>2 + 5</em>_t + 1, Lambda(_t, _t</em>log(x + 5*_t)))                                                   </p>
<p>[/code]</p>
<p>Still, this has been a very good learning experience.  </p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/06/15/a-weeklog.html" class="u-url">A Weeklog</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/06/15/a-weeklog.html" rel="bookmark"><time class="published dt-published" datetime="2010-06-15T21:45:22+00:00" itemprop="datePublished" title="Publication date">2010-06-15 21:45</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/06/15/a-weeklog.html#disqus_thread" data-disqus-identifier="cache/posts/2010/06/15/a-weeklog.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<a href="http://ondrejcertik.blogspot.com/2010/06/week-may-30-june-4.html">These</a> <a href="http://ondrejcertik.blogspot.com/2010/06/week-june-5-june-11.html">seem</a> <a href="http://haz-tech.blogspot.com/2010/06/plowing-forward.html">to</a> <a href="http://ojensen.wordpress.com/2010/06/15/array-arguments/">be</a> all the rave these days, so I figured, why not jump on the bandwagon:
<p><code></code></p>
<p>Aaron-Meurer:doc aaronmeurer20100615153531(integration$)$git weekreport </p>
<p>Aaron Meurer (20):
      Fix some bugs in Poly
      Make Poly(sin(x)/x*t, t, domain='EX').clear_denoms() work
      Fix integrate to work correctly with heurisch.py
      Use more efficient gcdexdiophantine() algorithm
      Add support for taking the derivation over the coefficient domain in risch.py
      Add (but do not yet use) splitfactor_sqf() in risch.py
      Add polynomial_reduce() to risch.py
      Add tests for algorithms in risch.py in a new test_risch.py file
      Only allow coercion to larger domains
      Allow coercion from ZZ(a) to ZZ(a, b)
      Fix doctest in new heurisch.py file
      Add residue_reduce()
      Formatting fixes in docstrings in sympy/polys/algebratools.py
      Add includePRS option to resultant functions
      Add permute method to DMP
      Add a test for the includePRS option of resultant()
      Have residue_reduce() make S_i monic
      Rewrite polynomial_reduce() non-recursively
      Add integrate_hypertangent_polynomial()
      Add integrate_nonlinear_no_specials()
</p>
</div>
    </div>
    </article>
    <article class="h-entry post-text">
    <header>
        <h1 class="p-name entry-title"><a href="posts/2010/06/11/integration-of-rational-functions.html" class="u-url">Integration of rational functions</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Aaron Meurer</span></p>
            <p class="dateline"><a href="posts/2010/06/11/integration-of-rational-functions.html" rel="bookmark"><time class="published dt-published" datetime="2010-06-11T19:39:58+00:00" itemprop="datePublished" title="Publication date">2010-06-11 19:39</time></a></p>
                <p class="commentline">
        
    <a href="posts/2010/06/11/integration-of-rational-functions.html#disqus_thread" data-disqus-identifier="cache/posts/2010/06/11/integration-of-rational-functions.html">Comments</a>


        </p>
</div>
    </header>
    <div class="e-content entry-content">
    <div>
<p></p>
<p>So for this week's blog post I will try to explain how the general algorithm for integrating rational functions works.  Recall that a <a href="http://en.wikipedia.org/wiki/Rational_function">rational function</a> is the quotient of two polynomials.  We know that using common denominators, we can convert the sum of any number of rational functions into a single quotient, $latex \frac{a_nx^n + a_{n-1}x^{n-1} + \cdots + a_2x^2 + a_1x + a_0}{b_nx^n + b_{n-1}x^{n-1} + \cdots + b_2x^2 + a_1x + a_0}$.  Also, using <a href="http://en.wikipedia.org/wiki/Polynomial_division">polynomial division</a> we can rewrite any rational function as the sum of a polynomial and the quotient of two polynomials such that the degree of the numerator is less than the degree of the denominator ($latex F(x) = \frac{b(x)}{c(x)} = p(x) + \frac{r(x)}{g(x)}$, with $latex deg(r) &lt; deg(g)$).  Furthermore, we know that the representation of a rational function is not unique.  For example, $latex \frac{(x + 1)(x - 1)}{(x + 2)(x - 1)}$ is the same as $latex \frac{x + 1}{x + 2}$ except at the point $latex x = 1$, and $latex \frac{(x - 1)^2}{x - 1}$ is the same as $latex x - 1$ everywhere.  But by using <a href="http://en.wikipedia.org/wiki/Euclid%27s_algorithm_for_polynomials#Polynomials">Euclid's algorithm</a> for finding the GCD of polynomials on the numerator and the denominator, along with polynomial division on each,  we can cancel all common factors to get a representation that is unique (assuming we expand all factors into one polynomial).  Finally, using polynomial division with remainder, we can rewrite any rational function $latex F(x)$ as $latex \frac{a(x)}{b(x)} = p(x) + \frac{a(x)}{d(x)}$, where $latex a(x)$, $latex b(x)$, $latex c(x)$, $latex d(x)$, and $latex p(x)$ are all polynomials, and the degree of $latex a$ is less than the degree of $latex d$.  </p>
<p>We know from calculus that the integral of any rational function consists of three parts: the polynomial part, the rational part, and the logarithmic part (consider arctangents as complex logarithms).  The polynomial part is just the integral of $latex p(x)$ above.  The rational part is another rational function, and the logarithmic part, which is a sum of logarithms of the form $latex a\log{s(x)}$, where $latex a$ is an algebraic constant and $latex s(x)$ is a polynomial (note that if $latex s(x)$ is a rational function, we can split it into two logarithms of polynomials using the log identities).  </p>
<p>To find the rational part, we first need to know about square-free factorizations.  An important result in algebra is that any polynomial with rational coefficients can be factored uniquely into irreducible polynomials with rational coefficients, up to multiplication of a non-zero constant and reordering of factors, similar to how any integer can be factored uniquely into primes up to multiplication of 1 and -1 and reordering of factors (technically, it is with coefficients from a unique factorization domain, for which the rationals is a special case, and up to multiplication of a unit, which for rationals is every non-zero constant).  A polynomial is square-free if this unique factorization does not have any polynomials with powers greater than 1.  Another theorem from algebra tells us that irreducible polynomials over the rationals do not have any repeated roots, and so given this, it is not hard to see that a polynomial being square-free is equivalent to it not having repeated roots.  </p>
<p>A <a href="http://en.wikipedia.org/wiki/Square-free_factorization">square-free factorization</a> of a polynomial is a list of polynomials, $latex P_1P_2^2 \cdots P_n^n$, where each $latex P_i$ is square-free (in other words, $latex P_1$ is the product of all the factors of degree 1, $latex P_2$ is the product of all the factors of degree 2, and so on).  There is a relatively simple algorithm to compute the square-free factorization of a polynomial, which is based on the fact that $latex gcd(P, \frac{dp}{dx})$ reduces the power of each irreducible factor by 1.  For example:</p>
<p><a href="2010/06/gcd.png"><img src="2010/06/gcd.png" alt="" title="gcd" width="246" height="175" class="alignnone size-full wp-image-420"></a></p>
<p>(Sorry for the picture.   WordPress code blocks do not work)</p>
<p>It is not too hard to prove this using the product rule on the factorization of P.  So you can see that by computing $latex \frac{P}{gcd(P, \frac{dP}{dx})}$, you can obtain $latex P_1P_2\cdots P_n$.  Then, by recursively computing $latex A_0 = P$, $latex A_1 = gcd(A_0, \frac{dA_0}{dx})$, $latex A2 = gcd(A_1, \frac{dA_1}{dx})$, … and taking the quotient each time as above, we can find the square-free factors of P.  </p>
<p>OK, so we know from partial fraction decompositions we learned in calculus that if we have a rational function of the form $latex \frac{Q(x)}{V(x)^n}$ , where $latex V(x)$ is square-free, the integral will be a rational function if $latex n &gt; 1$ and a logarithm if $latex n = 1$.  We can use the partial fraction decomposition that is easy to find once we have the square-free factorization of the denominator to rewrite the remaining rational function as a sum of terms of the form $latex \frac{Q}{V_k^k}$, where $latex V_i$ is square-free.  Because $latex V$ is square-free, $latex gcd(V, V')=1$, so the <a href="http://en.wikipedia.org/wiki/Extended_Euclidean_algorithm">Extended Euclidean Algorithm</a> gives us $latex B_0$ and $latex C_0$ such that $latex B_0V + C_0V'=1$ (recall that $latex g$ is the gcd of $latex p$ and $latex q$ if and only if there exist $latex a$ and $latex b$ relatively prime to $latex g$ such that $latex ap+bq=g$.  This holds true for integers as well as polynomials). Thus we can find $latex B$ and $latex C$ such that $latex BV + CV'= \frac{Q}{1-k}$.  Multiplying through by $latex \frac{1-k}{V^k}$, $latex \frac{Q}{V^k}=-\frac{(k-1)BV'}{V^k} + \frac{(1-k)C}{V^{k-1}}$, which is equal to $latex \frac{Q}{V^k} = (\frac{B'}{V^{k-1}} - \frac{(k-1)BV'}{V^k}) + \frac{(1-k)C-B'}{V^{k-1}}$.  You may notice that the term in the parenthesis is just the derivative of  $latex \frac{B}{V^{k-1}}$, so we get $latex \int\frac{Q}{V^k}=\frac{B}{V^{k-1}} + \int\frac{(1-k)C - B'}{V^{k-1}}$.  This is called Hermite Reduction.  We can recursively reduce the integral on the right hand side until the $latex k=1$. Note that there are more efficient ways of doing this that do not actually require us to compute the partial fraction decomposition, and there is also a linear version due to Mack (this one is quadratic), and an even more efficient algorithm called the Horowitz-Ostrogradsky Algorithm, that doesn't even require a square-free decomposition.  </p>
<p>So when we have finished the Hermite Reduction, we are left with integrating rational functions with purely square-free denominators.  We know from calculus that these will have logarithmic integrals, so this is the logarithmic part.  </p>
<p>First, we need to look at resultants and PRSs. The <a href="http://en.wikipedia.org/wiki/Resultant">resultant</a> of two polynomials is defined as differences of the roots of the two polynomials, i.e., $latex resultant(A, B) = \prod_{i=1}^n\prod_{j=1}^m (\alpha_i - \beta_j)$, where $latex A = (x - \alpha_1)\cdots(x - \alpha_n)$ and $latex B = (x - \beta_1)\cdots(x - \beta_m)$ are monic polynomials split into linear factors.  Clearly, the resultant of two polynomials is 0 if and only if the two polynomials share a root. It is an important result that the resultant of two polynomials can be computed from only their coefficients by taking the determinant of the <a href="http://en.wikipedia.org/wiki/Sylvester_matrix">Sylvester Matrix</a> of the two polynomials.  However, it is more efficiently calculated using a polynomial remainder sequence  (PRS) (sorry, there doesn't seem to be a Wikipedia article), which in addition to giving the resultant of A and B, also gives a sequence of polynomials with some useful properties that I will discuss below.  A polynomial remainder sequence is a generalization of the Euclidian algorithm where in each step, the remainder $latex R_i$ is multiplied by a constant $latex \beta_i$.  The Fundamental PRS Theorem shows how to compute specific $latex \beta_i$ such that the resultant can be calculated from the polynomials in the sequence. </p>
<p>Then, if we have $latex \frac{A}{D}$, left over from the Hermite Reduction (so $latex D$ square-free), let $latex R=resultant_t(A-t\frac{dD}{dx}, D)$, where $latex t$ is a new variable, and $latex \alpha_i$ be the distinct roots of R.  Let $latex p_i=\gcd(A - \alpha_i\frac{dD}{dx}, D)$.  Then it turns out that the logarithmic part of the integral is just $latex \alpha_1\log{p_1} + \alpha_2\log{p_2} + \cdots \alpha_n\log{p_n}$.  This is called the Rothstein-Trager Algorithm.</p>
<p>However, this requires finding the prime factorization of the resultant, which can be avoided if a more efficient algorithm called the Lazard-Rioboo-Trager Algorithm is used. I will talk a little bit about it.  It works by using subresultant polynomial reminder sequences. </p>
<p>It turns out that the above $latex gcd(A-\alpha\frac{dD}{dx}, D)$ will appear in the PRS of $latex D$ and $latex A-t\frac{dD}{dx}$.  Furthermore, we can use the PRS to immediately find the resultant $latex R=resultant_t(A-t\frac{dD}{dx}, D)$, which as we saw, is all we need to compute the logarithmic part.  </p>
<p>So that's rational integration.  I hope I haven't bored you too much, and that this made at least a little sense.  I also hope that it was all correct.  Note that this entire algorithm has already been implemented in SymPy, so if you plug a rational function in to <code>integrate()</code>, you should get back a solution.  However, I describe it here because the transcendental case of the Risch Algorithm is just a generalization of rational function integration.</p>
<p>As for work updates, I found that the Poly version of the heursitic Risch algorithm was considerably slower than the original version, due to inefficiencies in the way the polynomials are currently represented in SymPy.  So I have put that aside, and I have started implementing algorithms from the full algorithm.  There's not much to say on that front.  It's tedious work.  I copy the algorithm from Bronstein's book, then try make sure that it is correct based on the few examples given and from the mathematical background given, and when I'm satisfied, I move on to the next one.  Follow my <a href="http://github.com/asmeurer/sympy/tree/integration">integration</a> branch if you are interested.</p>
<p>In my next post, I'll try to define some terms, like "elementary function," and introduce a little differential algebra, so you can understand a little bit of the nature of the general integration algorithm.</p>
</div>
    </div>
    </article>
</div>

        <nav class="postindexpager">
        <ul class="pager">
            <li class="previous">
                <a href="index-5.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-3.html" rel="next">Older posts</a>
            </li>
        </ul>
        </nav>


        
       <script>var disqus_shortname="nikolademo";(function(){var a=document.createElement("script");a.async=true;a.src="//"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>



        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});</script>
        <script src="assets/js/mathjax.js"></script>


        </div>
        <!--End of body content-->

        <footer>
            Contents © 2014         <a href="mailto:asmeurer@gmail.com">Aaron Meurer</a> - Powered by         <a href="http://getnikola.com" rel="nofollow">Nikola</a>         
        </footer>
    </div>
</div>


            <script src="assets/js/all-nocdn.js"></script>
    
<!-- Social buttons -->
<div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style">
<a class="addthis_button_more">Share</a>
<ul>
<li>
<a class="addthis_button_facebook"></a>
</li>
<li>
<a class="addthis_button_google_plusone_share"></a>
</li>
<li>
<a class="addthis_button_linkedin"></a>
</li>
<li>
<a class="addthis_button_twitter"></a>
</li>
</ul>
</div>
<script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"></script>
<!-- End of social buttons -->


    <script>jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script>
    

</body>
</html>
